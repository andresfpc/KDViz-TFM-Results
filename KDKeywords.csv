"Title","Abstract","Keywords","Authors","Journal","DOI","URL"
"A1","Self-Service Technology Research: A bibliometric co-citation visualization analysis","As a value co-creation tool, there is growing adoption of self-service technology (SST) in hospitality. However, SST has received limited hospitality research attention. As a guide for future research, the purpose of this study was to conduct a bibliometric analysis focusing, first, on the hospitality and tourism SST literature, but then expanding to include the broader business SST literatures. The goals of this research were to examine the evolution and current trends in SST research; to identify the studies which have made key contributions to the intellectual foundation, development, and turning points; and to identify key SST research topics, trends, and questions. The analysis covers 199 journal articles published in HTM (n<U+2009>=<U+2009>23) and the broader business management literature (n<U+2009>=<U+2009>176) between 2000 and 2017. The results identify foundational articles, turning point articles, and article clusters. The study closes with recommendations for future hospitality SST research as well as theoretical implications.","Self-service technology,Value co-creation,Bibliometric co-citation analysis,Intellectual Foundation/Structure,Knowledge evolution","HakseungShin,Richard R.Perdue","International Journal of Hospitality Management","https://doi.org/10.1016/j.ijhm.2019.01.012","https://www.sciencedirect.com/science/article/pii/S0278431918302901"
"A2","A scientometric analysis and critical review of construction related ontology research","There is a wide range of literature on adopting ontology to solve construction problems, but no review of existing studies has systematically analyzed and visualized the trends in ontology research. This study reviews ontology research mainly published in the Scopus database from 2007 to 2017 with the combination of scientometric analysis and critical review. Scientometric analysis (e.g. co-author, co-word, co-citation, and clusters) objectively visualized the research status quo while a critical review was used to identify the research themes and challenges of ontology research in the construction industry. The results identified a large network of co-authors in this field to understand collaboration relationships. Over half the papers (53%) were published by the following three countries: the United States, the United Kingdom, and Canada. The top co-occurring keywords were “project management” at which ontology facilitates knowledge management and information retrieval. When the time factor was taken into consideration, keywords naturally evolved from “project management”, and “knowledge management” to “building information modeling”, and “compliance control” with the successful adoption of information techniques in the construction industry. Four research themes were identified with the combination of cluster analysis and critical review: “Domain ontology”, “Industry foundation classes”, “Automated compliance checking”, and “Building information modeling”. This review provides an in-depth understanding of existing ontology research and indicates the emerging trends in this research domain.","Ontology,Research trends,Scientometrics,CiteSpace,Construction industry","BotaoZhongab,HaitaoWuab,HengLic,SamadSepasgozard,HanbinLuoab,LingHeab","Automation in Construction","https://doi.org/10.1016/j.autcon.2018.12.013","https://www.sciencedirect.com/science/article/pii/S0926580518305648"
"A3","The human factor in supply chain forecasting: A systematic review","Demand forecasts are the lifeblood of supply chains. Academic literature and common industry practices indicate that demand forecasts are often subject to human interventions. Judgmental forecasting or judgmental forecast adjustments can cause both positive and negative repercussions to the rest of the supply chain. This paper provides the first systematic literature review of judgmental forecasting and adjustments focusing on key features that impact various decisions in supply chains. A carefully assembled and shortlisted literature pool is analyzed for systematic mapping of the published works using bibliometric tools. The primary sub streams of research within the broader scope of the field are synthesized from a rigorous keyword cluster analysis and a thorough discussion is presented. Our review concludes by encapsulating the key learnings from four decades of academic research in judgmental forecasting and suggests future research avenues to expand our understanding of the role of humans in demand forecasting and supply chain decision-making.","Supply chain management,Demand forecasting,Judgment,Behavioral operations,Literature review","H. NilesPerera†,JasonHurley†,BehnamFahimnia,MohsenReisi","European Journal of Operational Research","https://doi.org/10.1016/j.ejor.2018.10.028","https://www.sciencedirect.com/science/article/pii/S0377221718308816"
"A4","The worldwide research trends on water ecosystem services","In recent decades, the scarcity of water resources, the deterioration of aquatic ecosystems and associated repercussions for other ecosystems have become major global challenges. In this context, research on water ecosystem services has become increasingly important. The objective of this work is to analyse the evolution of this line of research worldwide for the period 1998–2017. A bibliometric analysis showed that this line of research has been gaining relevance within the ecosystem services field. Exponential growth has been observed in such research, and more than 65% of the studies have been performed in the last five years. Economic analyses have little relevance and gradually have lost relative importance. Results show that the most used keywords during the studied period are Ecosystem, Biodiversity, Water Quality, Ecology and Climate Change. The highest contributing countries on this topic are USA, China, UK, Germany and Australia. The leading institutions in this research field are the Chinese Academy of Sciences, the Research Center for Eco-Environmental Sciences and the Wageningen University and Research Centre. A high level of international collaboration is observed between the different agents involved in ecosystem services research and extensive cooperation networks. Three differentiated clusters have been detected around which this type of work is grouped: aquatic ecosystems, forest ecosystems and agricultural ecosystems. The interactions between different types of ecosystems must be investigated with respect to water, and holistic frameworks should be developed that integrate the different disciplines to achieve a more complete analysis of the set of services that contribute to the sustainable management of the different types of ecosystems.","Scientific research,Ecosystem services,Water,Bibliometric analysis,Scopus","José A.Aznar-Sáncheza,Juan F.Velasco-Muñoza,Luis J.Belmonte-Ureñaa,FranciscoManzano-Agugliarob","Ecological Indicators","https://doi.org/10.1016/j.ecolind.2018.12.045","https://www.sciencedirect.com/science/article/pii/S1470160X18309786"
"A5","Analysis on the theory and practice of industrial symbiosis based on bibliometrics and social network analysis","Industrial symbiosis (IS) can generate economic, social, and environmental benefits, and support sustainable development; thus, many governments and scholars are devoted to exploring it. To analyze and evaluate the current status and development trends of industrial symbiosis, this study selects “industrial symbiosis” as a research title to search the Web of Science (core collection) database, and uses the bibliometrics and social network analysis (SNA) methods. The results turn out that an increasing amount of research has been devoted to industrial symbiosis in recent years. They also show that the study of industrial symbiosis has obvious cross-disciplinary characteristics. Current research on industrial symbiosis mainly focuses on four issues: evolution and development, operation carriers, driving mechanisms, and efficiency evaluation of industrial systems. The research of the industrial symbiosis network will greatly promote the industrial green development for the industrial transformation and upgrading of various countries. Many methods are used to examine these four questions, including case studies, life cycle assessment (LCA), material flow analysis (MFA), data envelopment analysis (DEA), multi-criteria decision making (MCDM), emergy analysis, and SNA. This article provides the trends of industrial symbiosis research for further study. The data mining can be used in the industrial symbiosis network and a dynamic simulation industry symbiotic evolutionary process model can be discussed in the future.","Industrial symbiosis,Co-word analysis,Bibliometrics,Social network analysis (SNA)","MaoxingHuang,ZhenzhenWang,TingChen","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.12.131","https://www.sciencedirect.com/science/article/pii/S0959652618338435"
"A6","Mapping the bike sharing research published from 2010 to 2018: A scientometric review","An increasing number of studies since 2010 have examined bike sharing from diverse perspectives to provide the best travel practices of “the last mile”. However, few studies have attempted to comprehensively review existing literature over the past decade. The present study aims to map bike sharing research published between 2010 and 2018. A total of 208 relevant articles were collected to conduct scientometric analysis. The results revealed that the most significant contributions in bike sharing research primarily originated from the US, China, Canada, England and Australia. Critical institutions, publications and articles were also identified. The knowledge domains of bike sharing research focus mainly on topic categories of factors & barrier, system optimization, behavior & impact, safety & health, and sharing economy. Evolutionary trends in bike sharing research tend to move from the safety and benefits of bike usage to more complex external impacts, system optimization, design and integration with public transit. Furthermore, increasing interests and outputs in the new generation of dockless bike sharing programs were observed from the research community for the past two years. The present study contributes to the existing body of knowledge on bike sharing by presenting a new, integrated and holistic knowledge map. This study offers valuable guidance and in-depth understanding to researchers, operators and policy makers who wish to promote bike sharing sustainability, as well as for follow-up studies, updates and management.","Bike sharing,Review,Scientometric,Knowledge map,Sustainable transportation","HongyunSia,Jian-gangShia,GuangdongWub,JindaoChenac,XianboZhaod","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.12.157","https://www.sciencedirect.com/science/article/pii/S0959652618338678"
"A7","A bibliometric analysis of the essential oil-bearing plants exposed to the water stress: How long way we have come and how much further?","Water stress is of the most influential factors limiting plant growth and impairing plant metabolism and the stress conditions have been considered as an advantageous phenomenon and many studies regarding with water stress-induced essential oil changes have been performed. In most of the studies, essential oil and its compositional changes have been reported. However, quantitative data are lacking on the profile of published researches in water stress x essential oil interactions. The objective of the current study was to examine the profile of original and review articles under the topic of water stress and essential oil using bibliometric analysis. We identified 129 relevant and available peer-reviewed publications from 1992 to 2017 from the Scopus database. The retrieved documents were analyzed using VOSviewer.Based on the number of publications, Iran was the predominant country in publishing those documents, followed by India, Egypt and United States. The distribution of the frequency of authors and the number of their publications were fitted with the Lotka’s Law. Kolmogorov–Smirnov goodness-of-fit test results showed that there was no difference between theoretical (expected) and observed authors numbers. Furthermore, the Lamiaceae and Apiaceae families are the most studied plant groups. Of those plant families, basil (Ocimum spp.) and sage (Salvia spp.) species were more pronounced in the studies. According to the cluster results, three groups including terms associated with “stress conditions”, “studied plant group”, and “secondary metabolites” were determined. For the exogenous chemicals applied to improve stress-induced perturbations, salicylic acid was found to be most preferred and used as a growth regulator. Most articles were concentrated in several journals. In fact, almost a quarter of the document was published in only three journals namely, Industrial Crops and Products, Journal of Essential Oil-Bearing Plants and Scientia Horticulturae. These journals can be considered as the core journals for knowledge dissemination of essential oil content and its compositional alteration induced with water stress applications.","Bibliometric analysis,Essential oil,Drought,Water stress,Water deficiency","MuhittinKulakab,AliOzkanc,RecepBindakd","Scientia Horticulturae","https://doi.org/10.1016/j.scienta.2018.11.031","https://www.sciencedirect.com/science/article/pii/S0304423818308124"
"A8","Internet of Things (IoT), mobile cloud, cloudlet, mobile IoT, IoT cloud, fog, mobile edge, and edge emerging computing paradigms: Disambiguation and research directions","Currently, we are experiencing a technological shift, which is expected to change the way we program and interact with the world. Cloud computing and mobile computing are two prominent research areas that have already had such an impact. The Internet of Things (IoT), which is concerned with building a network of Internet-enabled devices to promote a smart environment, is another promising area of research. Numerous emerging computing paradigms related to those areas of research and/or their intersections have come into play. These include Mobile Cloud Computing (MCC), cloudlet computing, mobile clouds, mobile IoT computing, IoT cloud computing, fog computing, Mobile Edge Computing (MEC), edge computing, the Web of Things (WoT), the Semantic WoT (SWoT), the Wisdom WoT (W2T), opportunistic sensing, participatory sensing, mobile crowdsensing, and mobile crowdsourcing. Unfortunately, those paradigms suffer from the lack of standard definitions, and so we frequently encounter a single term referring to various paradigms or several terms referring to a single paradigm. Accordingly, this paper attempts to disambiguate those paradigms and explain how and where they fit in the above three areas of research and/or their intersections before it becomes a serious problem. They are tracked back to their inception as much as possible. This is in addition to discussing research directions in each area. The paper also introduces technologies related to the IoT such as ubiquitous and pervasive computing, the Internet of Nano Things (IoNT), and the Internet of Underwater Things (IoUT).","Cloudlet computing,Crowdsensing,Crowdsourcing,Edge computing,Fog computing,Internet of things,Mobile cloud,Mobile cloud computing,Mobile edge computing,Opportunistic sensing,Participatory sensing,Semantic web of things,Web of things,Wisdom web of things","HananElazharyab","Journal of Network and Computer Applications","https://doi.org/10.1016/j.jnca.2018.10.021","https://www.sciencedirect.com/science/article/pii/S1084804518303497"
"A9","A scientometric analysis and visualization of global green building research","In this paper, the first inclusive scientometric review of global green building research (GGBR) is presented. The aim of this review study is to systematically analyze and visualize the state-of-the-art of the GGBR. To this end, a quantitative method – science mapping – was employed to analyze 6867 related bibliographic records retrieved from Scopus. The research findings are instructive in identifying and understanding trends and patterns, including core research areas, journals, institutions, and countries, and how these are linked, within the existing body of literature on green building (GB). They also assist in recognizing the gaps and deficiencies in the current GGBR and thus useful and promising directions for future research. This research has implications for journal editors, practitioners, policy makers, researchers, and research institutions, e.g., universities. It can help these stakeholders make vital contributions to developing and accruing intellectual wealth to the GB area, while providing them with a detailed understanding of the trend and status quo of the GGBR.","Green building,Sustainability,Research,Scientometrics,Review","AmosDarkoa,Albert P.C.Chana,XiaosenHuoa,De-GraftOwusu-Manub","Building and Environment","https://doi.org/10.1016/j.buildenv.2018.12.059","https://www.sciencedirect.com/science/article/pii/S0360132318308175"
"A10","A novel big data analytics framework for smart cities","The emergence of smart cities aims at mitigating the challenges raised due to the continuous urbanization development and increasing population density in cities. To face these challenges, governments and decision makers undertake smart city projects targeting sustainable economic growth and better quality of life for both inhabitants and visitors. Information and Communication Technology (ICT) is a key enabling technology for city smartening. However, ICT artifacts and applications yield massive volumes of data known as big data. Extracting insights and hidden correlations from big data is a growing trend in information systems to provide better services to citizens and support the decision making processes. However, to extract valuable insights for developing city level smart information services, the generated datasets from various city domains need to be integrated and analyzed. This process usually referred to as big data analytics or big data value chain. Surveying the literature reveals an increasing interest in harnessing big data analytics applications in general and in the area of smart cities in particular. Yet, comprehensive discussions on the essential characteristics of big data analytics frameworks fitting smart cities requirements are still needed. This paper presents a novel big data analytics framework for smart cities called “Smart City Data Analytics Panel — SCDAP”. The design of SCDAP is based on answering the following research questions: what are the characteristics of big data analytics frameworks applied in smart cities in literature and what are the essential design principles that should guide the design of big data analytics frameworks have to serve smart cities purposes? In answering these questions, we adopted a systematic literature review on big data analytics frameworks in smart cities. The proposed framework introduces new functionalities to big data analytics frameworks represented in data model management and aggregation. The value of the proposed framework is discussed in comparison to traditional knowledge discovery approaches.","Analytics framework,Apache Hadoop,Apache spark,Big data,Smart cities","Ahmed M. ShahatOsman","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.06.046","https://www.sciencedirect.com/science/article/pii/S0167739X17307446"
"A11","Interdisciplinarity as diversity in citation patterns among journals: Rao-Stirling diversity, relative variety, and the Gini coefficient","Questions of definition and measurement continue to constrain a consensus on the measurement of interdisciplinarity. Using Rao-Stirling (RS) Diversity sometimes produces anomalous results. We argue that these unexpected outcomes can be related to the use of “dual-concept diversity” which combines “variety” and “balance” in the definitions (ex ante). We propose to modify RS Diversity into a new indicator (DIV) which operationalizes “variety,” “balance,” and “disparity” independently and then combines them ex post. “Balance” can be measured using the Gini coefficient. We apply DIV to the aggregated citation patterns of 11,487 journals covered by the Journal Citation Reports 2016 of the Science Citation Index and the Social Sciences Citation Index as an empirical domain and, in more detail, to the citation patterns of 85 journals assigned to the Web-of-Science category “information science & library science” in both the cited and citing directions. We compare the results of the indicators and show that DIV provides improved results in terms of distinguishing between interdisciplinary knowledge integration (citing references) versus knowledge diffusion (cited impact). The new diversity indicator and RS diversity measure different features. A routine for the measurement of the various operationalization of diversity (in any data matrix) is made available online.","Interdisciplinary,Diversity,Journal,Gini,Variety,Rao-Stirling","LoetLeydesdorffa,Caroline S.Wagnerb,LutzBornmannc","Journal of Informetrics","https://doi.org/10.1016/j.joi.2018.12.006","https://www.sciencedirect.com/science/article/pii/S1751157718303535"
"A12","A bibliometric analysis of the research dealing with the impact of additive manufacturing on industry, business and society","In this paper, we provide an extensive bibliometric review of the literature dealing with the impact of AM on industry, business and society, by mapping prior research in the field, across a wide spectrum of journals. The analysis illustrates the evolution of AM research over the last few decades, the main outlets for publication, the level of concentration or fragmentation of the scientific community, the geographical density of the research collaborations and the employed methodologies. We also disentangle the main topics that have been addressed by the community of scholars debating the impact of AM and depict the current knowledge base on which AM research is grounded.","","FedericoCaviggiolia,ElisaUghettoab","International Journal of Production Economics","https://doi.org/10.1016/j.ijpe.2018.11.022","https://www.sciencedirect.com/science/article/pii/S0925527318304730"
"A13","International research collaboration: An emerging domain of innovation studies?","International research collaboration (IRC) has been increasingly important as an emerging area of innovation studies. This study reviews the intellectual base, main research trajectories and intellectual communities of the IRC research domain over the period 1957–2015. It integrates qualitative review and three quantitative analyses including co-citation network analysis, main path analysis and bibliographic coupling analysis. The results show that the IRC research has gone through three phases, namely, “emergence” (1957–1991), “fermentation” (1992–2005) and “take-off” (2006–2015) phases. The co-citation network analysis confirms that the IRC research field has been developed under the influence of two pioneering studies related to bibliometrics research. The main research trajectories in IRC studies over the three development phases and over the whole period are identified based on the main path analysis, which shows that co-authorship analysis is the main research method in IRC studies. A bibliographic coupling analysis suggests that the whole IRC research domain can be classified into five distinct intellectual areas: drivers of IRC, IRC patterns, IRC effects, IRC networks and IRC measurement. Seven topics for future research are also identified.","International research collaboration,Evolution and future research agenda,Co-citation network analysis,Main path analysis,Bibliographic coupling analysis","KaihuaChenad1,YiZhangb1,XiaolanFuc1","Research Policy","https://doi.org/10.1016/j.respol.2018.08.005","https://www.sciencedirect.com/science/article/pii/S0048733318301926"
"A14","Healthy aging: A bibliometric analysis of the literature","Due to dramatic growth of the aging population worldwide, there has been an urgent call for a public health strategy to manage healthy aging, with the ultimate goal being advancement of aging research. Considerable progress has been made in uncovering the mystery of aging process using multidisciplinary methods. There is a growing consensus in the field that aging traits which were originally thought to be disparate are likely to be interconnected. Thus, emerging research is needed to incorporate current findings of aging by building multiscale network models. This study reported the network of healthy aging research using bibliometric approaches. Based on the results, aging of the brain and muscle is a primary research focus which is a critical part of the multiscale network regulating the aging process. Among aging-associated diseases, Alzheimer's disease and frailty are among the main research focuses, and emerging work has focused on developing diagnostic tools for these diseases. For research on anti-aging interventions, calorie restriction, physical activity, and anti-aging pharmacology are the main interventions, of which the underlying mechanisms have been comprehensively studied in animal models.","Healthy aging,Neuropsychological assessment,Alzheimer's disease,Calorie restriction,Physical activity,Frailty","Yao-HuaGua,Jin-BingBaib,Xiao-LiChenc,Wen-WenWua,Xiang-XiangLiua,Xiao-DongTana","Experimental Gerontology","https://doi.org/10.1016/j.exger.2018.11.014","https://www.sciencedirect.com/science/article/pii/S0531556518304637"
"A15","Forecasting technology trends using text mining of the gaps between science and technology: The case of perovskite solar cell technology","How to detect and identify the future trends of emerging technologies as early as possible is crucial for government R&D strategic planning and enterprises' practices. To avoid the weakness of using only scientific papers or patents to study the development trends of emerging technologies, this paper proposes a framework that uses scientific papers and patents as data resources and integrates the text mining and expert judgment approaches to identify technology evolution paths and forecast technology development trends within the short term. The perovskite solar cell technology is selected as a case study. In this case, the text mining and expert judgment methods are applied to analyze the technology evolution path, and gaps analysis between science and technology is used to forecast the technology development trend. This paper will contribute to the technology forecasting and foresight methodology, and will be of interest to solar photovoltaic technology R&D experts.","Technology trend,Technology forecasting,Text mining,Perovskite solar cell technology","XinLia,QianqianXiea,TugrulDaimbcd,LuchengHuanga","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2019.01.012","https://www.sciencedirect.com/science/article/pii/S0040162517316347"
"A16","Expert forecast and realized outcomes in technology foresight","Contrary to what happens in forecasting, in which the repetitive nature of events lends itself to the ex post validation of expert judgments, it is usually very difficult to compare directly the forecast of technology foresight studies with realized outcomes. When the comparison is feasible, therefore, there is large opportunity for learning and methodological refinement. The authors of this study had the opportunity to re-examine the findings of a technology foresight exercise on the medical device industry with realized technological performance, five years later. Among the findings of the comparison exercise, intriguing false positive as well as false negative cases have been identified. The paper suggests that these cases are due to specific cognitive and motivational biases of experts and examines the way in which they are at work in the foresight process. It argues that these biases are due to the inability of experts to reason systematically in abstract (or “functional”) terms during the whole foresight process. It also suggests a methodology to mitigate the biases and to manage the emergence of false positives and false negatives.","Expert forecast,Medical device industry,Cognitive biases,Abstract reasoning,Failure mode analysis,Functional analysis","RiccardoApredaa,AndreaBonaccorsibd,Felicedell'Orlettac,GualtieroFantonib","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.12.006","https://www.sciencedirect.com/science/article/pii/S0040162518309776"
"A17","Networks of innovation: the sociotechnical assemblage of tabletop computing","We theorize on the heterogonous network of people, visions, concepts, technological artifacts, and organizations that come together to enable product innovation. Drawing on the conceptual framing and mechanisms of actor-network theory (ANT), we focus on the relationships among human and non-human actors and their roles to enact new products. We do this to contribute both evidence and theory regarding the concept of a sociotechnical assemblage that serves as the innovation network. Advancing a sociotechnical conceptualization of innovation focuses attention on the contributions of, and linkages among, different types of actors; individuals and organizations, visions and concepts, and technological artifacts and prototypes together create a means for innovation to occur. The empirical basis for this theorizing comes from a detailed study of the community of research scientists, faculty, and graduate students; institutions such as research labs, funding sources, and product companies who were (and mostly still are) involved in tabletop computing. Analysis highlights the centrality of visions, concepts and technological artifacts in the innovation network. We also find that formal organizations play important, but often unrealized, roles in supporting innovation.","Innovation network,Actor-network theory,Sociotechnical assemblage,Tabletop computing","Mohammad HosseinJarrahia1,SteveSawyerb1","Research Policy: X","https://doi.org/10.1016/j.repolx.2018.100001","https://www.sciencedirect.com/science/article/pii/S259014511830001X"
"A18","Implementation of lean practices in the construction industry: A systematic review","The implementation of lean principles and approaches is gaining grounds in the construction industry globally. However, there is no clear understanding of the number and categories of lean practices implemented and the benefits associated with it in the planning, design and construction of building and infrastructure projects. This paper relied on a systematic review of published literature in Scopus, Science Direct and Google Scholar to identify and categorize the different lean practices implemented in the construction industry and the benefits derivable from them. Totally, 102 documents published between 1996 and 2018 were reviewed and their contents analyzed using descriptive statistics and content analysis. A total of 32 different lean practices categorised into design and engineering; planning and control; construction and site management; and health and safety management were identified. The review also found that the last planner system and just-in-time were the top two most implemented lean practices and about 20 different economic, social and environmental benefits were linked to the implementation of lean practices in the construction industry. This review is instructive that lean practices have good prospects for enhancing the productivity of the construction industry and achieving sustainable built environment, but a critical mass uptake and sustained implementation are required to attain these goals.","Construction industry,Lean construction practice,Lean principles,Systematic review","OluwatosinBabalola,Eziyi O.Ibem,Isidore C.Ezema","Building and Environment","https://doi.org/10.1016/j.buildenv.2018.10.051","https://www.sciencedirect.com/science/article/pii/S0360132318306760"
"A19","A bibliometric analysis of extended key account management literature","Key account management (KAM) has played an important role in business, and this study reviews key account management research using bibliometric techniques. This review includes 373 KAM relevant articles published in 68 journals between 1979 and 2016. In our analysis, we extend the discussion on KAM literature by highlighting areas such as the roles of technology and conflict as well as relationship planning and implementation. We discuss the value of co-creation, inter-organizational design elements, and dyad-level performance measures. We examine five distinctive time-periods and find that KAM relevant literature has progressed 1) from selling and relationship-building approaches to key network management, 2) from network innovation to governance, 3) from network-level performance to co-creation of business solutions and values, 4) from product and service performance to incorporating sustainability. Finally, we present the fifth transition based on a network-view of KAM and identify future research aimed at integrating areas such as network-based orientation, applications of organizational theories, organizational innovativeness, network competence for optimal structure and processes, network-based KAM teams, value-sharing mechanisms, co-created value measurement, and value sustenance within networks. We identify areas of future research and expect the adoption and application of key account management concepts to grow across multiple disciplinary fields.","Key account management,Bibliometrics,Document co-citation analysis,Network view,Trends and directions for future research","PrashantKumara,ArunSharmab,JariSaloc","Industrial Marketing Management","https://doi.org/10.1016/j.indmarman.2019.01.006","https://www.sciencedirect.com/science/article/pii/S0019850118304954"
"A20","Opinion leader detection: A methodological review","A social network as an essential communication platform facilitates the interactions of online users. Based on the interactions, users can influence or be affected by the opinions of others. The users being able to influence and shape the opinions of others are considered as opinion leaders. The problem of identifying opinion leaders is an important task due to its wide applications in reality, including product adoption for marketing and societal analytics. The problem has been attracting proliferating studies over the recent years. To overview and provide insights of the methodologies and enlighten the future study, we review the well-known techniques for opinion leader detection problems. These techniques are classified into descriptive approaches, statistical and stochastic methods, diffusion process based approaches, topological based methods, data mining and learning methods, and approaches based on hybrid content mining. The advantages and drawbacks of each method are systematically analyzed and compared, to provide deep understanding into the existing research challenges and the direction of future trends. The findings of this review would be useful for those researchers are interested in identifying opinion leaders and influencers in social networks and related fields.","Opinion leader,Social network analysis,Flow of influence,Influential users/nodes,Graph mining","Seyed Mojtaba HosseiniBamakana,IldarNurgalievab,QiangQua","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.07.069","https://www.sciencedirect.com/science/article/pii/S0957417418304950"
"A21","Renewable energy source integration into power networks, research trends and policy implications: A bibliometric and research actors survey analysis","This article studies the integration of variable renewable energy sources (RES) into power networks. The main goal is to confront the contents and trends of scientific literature with the eyes and projects of researchers on future topics and issues to be solved, especially in terms of the modeling of electrical systems. The analysis relies on a bibliometric study of the Scopus database on the topic and on an online survey sent to the corresponding authors of the identified papers. The paper analyzes the dynamics of publication, clusters of collaboration, and main topics studied. It then identifies potential research leads, among which unresolved challenges regarding technical aspects, markets and financing issues, and social aspects. The disparity of models and results is still a necessary evil as research is not mature enough to integrate in one model all the very complex parameters of VRE integration into power systems. There is a lack of recurrence, though, such as the impact of emergent technologies or the development of substitute low carbon-emitting technology (other than solar and wind), need to be addressed. The paper also advocates the need for a systemic vision, for both research and policymakers that goes beyond the sole power system.","Q42,Q48,Q55,Keywords,Variable renewable energy,Bibliometric analysis,Scenario,Survey,Power network,Policy","EmmanuelHacheade,AngéliquePallebc","Energy Policy","https://doi.org/10.1016/j.enpol.2018.09.036","https://www.sciencedirect.com/science/article/pii/S0301421518306499"
"A22","A systematic literature review and classification of knowledge discovery in traditional medicine","Introduction and ObjectiveDespite the importance of machine learning methods application in traditional medicine there is a no systematic literature review and a classification for this field. This is the first comprehensive literature review of the application of data mining methods in traditional medicine.,MethodWe reviewed 5 database between 2000 to 2017 based on the Kitchenham systematic review methodology. 502 articles were identified and reviewed for their relevance to application of machine learning methods in traditional medicine, 42 selected papers were classified and categorized on four dimension; 1) application domain of data mining techniques in traditional medicine; 2) the data mining methods most frequently used in traditional medicine; 3) main strength and limitation of data mining techniques in traditional medicine; 4) the performance evaluation methods in data mining methods in traditional medicine.,ResultThe result obtained showed that main application domain of data mining techniques in traditional medicine was related to syndrome differentiation. Bayesian Networks (BNs), Artificial Neural Networks (ANNs) and Support Vector Machines (SVMs) were recognized as being the methods most frequently applied in traditional medicine. Furthermore, each data mining techniques has its own strength and limitations when applied in traditional medicine. Single scaler methods were frequently used for performance evaluation of data mining methods.,ConclusionMachine learning methods have become an important research field in traditional medicine. Our research provides information about this methods by examining the related articles.","Data mining,Traditional medicine,Knowledge discovery,Machine learning","GoliArjia,RezaSafdaria,HosseinRezaeizadehb,AlirezaAbbassianb,MehrshadMokhtaranc,MohammadHossein Ayatib","Computer Methods and Programs in Biomedicine","https://doi.org/10.1016/j.cmpb.2018.10.017","https://www.sciencedirect.com/science/article/pii/S0169260718312859"
"A23","Trends on enzyme immobilization researches based on bibliometric analysis","In this survey, a bibliometric analysis of the global scientific production on enzyme immobilization researches was developed using Web of Science© database. The time-span comprised the period from 1991 to 2017. A total of 9636 documents related to the subject were retrieved and analyzed according to seven main aspects: publication years, journals, countries, authors, organizations, keywords, and Web of Science categories. The results indicated that the countries with the highest number of publications were China and the United States. The most expressive international collaborative networks were evidenced between Brazil and Spain and between the USA and China. Additionally, the Spanish researchers were the ones that contributed most to this domain, while the Consejo Superior de Investigaciones Científicas and the Chinese Academy of Sciences were the most emblematic organizations. Finally, the analysis of keywords revealed that biosensor, lipase and glucose oxidase were the most cited terms among all publications, and also indicated the existence of a possible knowledge gap involving the terms Escherichia coli, Candida rugosa lipase and cytochrome-c in the context of enzyme immobilization. This study was efficient to evaluate the trends of the body of literature on enzyme immobilization research, subsidizing future decision-making in this field of science.","Bibliometric map,Enzymatic immobilization,VOSviewer","Maria Carolina PereiraGonçalvesa,Theo GuenterKieckbuscha,Rafael FirmaniPernaa,Jaqueline TomiêFujimotob,Sergio Andres VillalbaMoralesa,João PauloRomanellic","Process Biochemistry","https://doi.org/10.1016/j.procbio.2018.09.016","https://www.sciencedirect.com/science/article/pii/S1359511318308511"
"A24","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2018.11.002","https://www.sciencedirect.com/science/article/pii/S0140670118300444"
"A25","Emergence of DSS efforts in genomics: Past contributions and challenges","Large amounts of data in biomedical research (from clinical data to gene expression data) are being generated. Use of these data sets and their associated knowledge are essential to understand the biological mechanisms behind diseases. While patients' clinical data from EHR can help researchers accurately and appropriately trace the performance of various kinds of medicines on the patients, the microarray data for the same pool of patients can contain valuable information for discovery of disease-associated gene expression patterns and can help classify the patients. However, research in the area of integrating genomic data with clinical data is still in its infancy and is riddled with many challenges. Even though data and knowledge sets are easily available from genome sequences and protein structural data of organisms, they usually are of many different varieties. Integrating them for a better understanding of biological functions at all levels is complicated. If we want to obtain the full benefit of functional genomics, we need to find a seamless way to integrate large amounts of patient datasets with genomic datasets in the field of biomedicine. Few papers in the decision support systems (DSS) literature provide an overview of Genomic Clinical Decision Support (GCDS) challenges that span data, knowledge, input/output, and architecture/implementation. This paper presents a unique effort dedicated to providing a comprehensive listing and a concise description of the DSS methodological challenges that arise from integrating complex and massive-scale genomic data with Clinical Decision Support (CDS) systems.","Genomics,Decision support system,Clinical decision support,Data integration,Knowledge base integration,Decision support system architecture","ArunSena,AhmadAl Kawamb,AniruddhaDattab","Decision Support Systems","https://doi.org/10.1016/j.dss.2018.10.011","https://www.sciencedirect.com/science/article/pii/S0167923618301684"
"A26","Mapping futures studies scholarship from 1968 to present: A bibliometric review of thematic clusters, research trends, and research gaps","This article provides a visual, objective and comprehensive review of the academic activity in futures studies from its origin (Futures, Volume 1, 1968) to present. Several bibliometric visualizations of the cumulated 50 years of futures studies scholarship are created to show 1) thematic clusters of research, 2) research intensity, 3) recent research trends, 4) research trajectory by cluster over time, 5) relative clusters’ representation within and across journals and 6) research locations. The 6 research clusters identified by the clustering algorithm are renamed corporate foresight; past & futures; humanity at the limen; environmental futures; post-normality & complexity, and technological trends, according to their underlying themes, and discussed in depth one by one. Several objective observations on the maps’ structure uncover the main research gaps in the literature. Based on these observations, the article provides 6 recommendations on how to fill these research gaps to improve the discipline’s fragmentation. Based on the visualizations, it can also be observed that the majority of futures studies publications belong to two clusters: past & futures and corporate foresight, and that the sudden increase in the total number of futures studies articles citations after 2004 is attributable to the corresponding increase in the relative percentage of research activity in one cluster: corporate foresight.","Futures studies,Review,Bibliometric,Science map,Research gaps,Research trends","AlessandroFergnani","Futures","https://doi.org/10.1016/j.futures.2018.09.007","https://www.sciencedirect.com/science/article/pii/S0016328718303100"
"A27","Extracting commercialization opportunities of the Internet of Things: Measuring text similarity between papers and patents","In the field of technology management, methods have been developed to detect technologies that are important in industry by analyzing massive numbers of documents. Such methods have been applied to the field of the Internet of Things as well to investigate technological trends. The Internet of Things consists of several conventional concepts, such as radio frequency identification, near field communication, and sensor networks. However, no research compares these technologies by analyzing massive quantities of papers and patents. Thus, in this study, we explored the research areas of technologies related to the Internet of Things, for which there are opportunities for commercialization in the near future. We also discuss potential applications of these technologies in diverse systems.","Citation analysis,Text similarity,Internet of Things,Radio frequency identification,Near field communication,Sensor networks","YasutomoTakanoab,YuyaKajikawaa","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.08.008","https://www.sciencedirect.com/science/article/pii/S0040162516304516"
"A28","Disentangling the evolution of MEDLINE bibliographic database: A complex network perspective","Scientific knowledge constitutes a complex system that has recently been the topic of in-depth analysis. Empirical evidence reveals that little is known about the dynamic aspects of human knowledge. Precise dissection of the expansion of scientific knowledge could help us to better understand the evolutionary dynamics of science. In this paper, we analyzed the dynamic properties and growth principles of the MEDLINE bibliographic database using network analysis methodology. The basic assumption of this work is that the scientific evolution of the life sciences can be represented as a list of co-occurrences of MeSH descriptors that are linked to MEDLINE citations. The MEDLINE database was summarized as a complex system, consisting of nodes and edges, where the nodes refer to knowledge concepts and the edges symbolize corresponding relations. We performed an extensive statistical evaluation based on more than 25 million citations in the MEDLINE database, from 1966 until 2014. We based our analysis on node and community level in order to track temporal evolution in the network. The degree distribution of the network follows a stretched exponential distribution which prevents the creation of large hubs. Results showed that the appearance of new MeSH terms does not also imply new connections. The majority of new connections among nodes results from old MeSH descriptors. We suggest a wiring mechanism based on the theory of structural holes, according to which a novel scientific discovery is established when a connection is built among two or more previously disconnected parts of scientific knowledge. Overall, we extracted 142 different evolving communities. It is evident that new communities are constantly born, live for some time, and then die. We also provide a Web-based application that helps characterize and understand the content of extracted communities. This study clearly shows that the evolution of MEDLINE knowledge correlates with the network’s structural and temporal characteristics.","Complex networks,Network evolution,Science of science,Bibliographic databases,MEDLINE","AndrejKastrin,DimitarHristovski","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2018.11.014","https://www.sciencedirect.com/science/article/pii/S1532046418302272"
"A29","Chapter 10: Data-Driven Visualizations in Metabolic Phenotyping","Modern analytical technologies based on nuclear magnetic (NMR) spectroscopy and mass spectrometry (MS) generate vast amounts of raw metabolic data from biological samples. Data visualization techniques play an indispensable role for converting raw data into biological insights. This book chapter demonstrates the utilization of different visualization techniques, including examples for different data types and stages of analysis. These are described in detail under three headings: (i) metabolic phenotyping data and the corresponding data analysis; (ii) knowledge bases; (iii) and literature for enhanced interpretation of data-driven insights from metabolic phenotyping data.","Metabolomics,Data,Visualization,Graphics,Graphs,Plots","DieterGalea,IvanLaponogov,KirillVeselkov","The Handbook of Metabolic Phenotyping,The Handbook of Metabolic Phenotyping","https://doi.org/10.1016/B978-0-12-812293-8.00010-4","https://www.sciencedirect.com/science/article/pii/B9780128122938000104"
"A30","Index","","","","Encyclopedia of Bioinformatics and Computational Biology","https://doi.org/10.1016/B978-0-12-809633-8.09001-4","https://www.sciencedirect.com/science/article/pii/B9780128096338090014"
"A31","Problems and Changes in Digital Libraries in the Age of Big Data From the Perspective of User Services","Based on the investigation of the position of user service for constructing digital libraries in the big data era, this paper points out that not only data resources of modern digital library have the characteristics of big data, but also the existing library services need to use big data methods to achieve reform and innovation, including resource transferring, resource utilization, social identity, thinking innovation. We focus on the importance of user services and types of big data resources that digital libraries can utilize, which include big data within libraries such as user behavior data and digital literature resource, and other big data outside libraries such as scholarly big data. We also examine the problems and potential of digital libraries in the age of big data relative to data, technology, services, and users. Using existing big data resources and considering the characteristics of current users' needs from the perspective of users, more effective ideas and methods to improve existing services in digital library can be put forward. At the same time, it is the personalized need of users in the age of big data that constitute the driving factor for the development of digital library from resource-sharing service to user-oriented service.","Big Data,Digital library,User service,Service innovation","ShuqingLia,FusenJiaoa,YongZhanga,XiaXub","The Journal of Academic Librarianship","https://doi.org/10.1016/j.acalib.2018.11.012","https://www.sciencedirect.com/science/article/pii/S0099133318302532"
"A32","Structural trend and conceptual evolution of research on genetically modified organisms using a science mapping approach","The aim of this study is to analyze the network structure and the conceptual evolution of research on genetically modified organisms (GMOs) through time. A scientific mapping approach was used to this aim and applied to a set of scientific publications about GMOs from 1990 to 2016 retrieved from the Elsevier Scopus database. Throughout the analyzed period, the Scopus search provided 13,851 documents. In the twenty-seven years period considered, USA resulted as the most productive country followed by China and Germany. According to the co-term analysis, nominal phrases were individually assigned into three clusters, which distinguished three separate branches of research: the genomics studies, the genetic transformation, and the agronomic topics. Furthermore, results demonstrated that before 2000 the GMOs research was mainly focused on Agrobacterium tumefaciens. To the contrary, from 2000 onwards, the researchers' attention mainly concentrated on the Arabidopsis thaliana, the most used model organism in laboratory studies. The year 2000 represented also the starting point for the studies of both the negative and positive impacts of GM plants cultivation on the environment as well as on citizen health. This study allowed, on one side, to demonstrate the increasing scientific interest in GMOs research field and, on the other side, to highlight the shifting towards new GM topics like the social acceptability of the genetically modified products and the environmental impacts of biotechnologies. This study may represent a useful tool for researchers and policy makers to identify research gaps and overlaps in the GM scientific field.","Agriculture,Bibliometric mapping,Environment,GMO,Network analysis,Scopus","RaparelliElisabettaa,MacariGabrieleb,ScaglioneMassimoa,BajoccoSofiaa,Scarascia MugnozzaGiuseppec","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.09.118","https://www.sciencedirect.com/science/article/pii/S0959652618328385"
"A33","Primary transcripts: From the discovery of RNA processing to current concepts of gene expression - Review","The main purpose of this review is to recall for investigators - and in particular students -, some of the early data and concepts in molecular genetics and biology that are rarely cited in the current literature and are thus invariably overlooked. There is a growing tendency among editors and reviewers to consider that only data produced in the last 10–20 years or so are pertinent. However this is not the case. In exact science, sound data and lucid interpretation never become obsolete, and even if forgotten, will resurface sooner or later. In the field of gene expression, covered in the present review, recent post-genomic data have indeed confirmed many of the earlier results and concepts developed in the mid-seventies, well before the start of the recombinant DNA revolution.Human brains and even the most powerful computers, have difficulty in handling and making sense of the overwhelming flow of data generated by recent high-throughput technologies. This was easier when low throughput, more integrative methods based on biochemistry and microscopy dominated biological research. Nowadays, the need for organising concepts is ever more important, otherwise the mass of available data can generate only \"building ruins\" - the bricks without an architect.Concepts such as pervasive transcription of genomes, large genomic domains, full domain transcripts (FDTs) up to 100<U+202F>kb long, the prevalence of post-transcriptional events in regulating eukaryotic gene expression, and the 3D-genome architecture, were all developed and discussed before 1990, and are only now coming back into vogue. Thus, to review the impact of earlier concepts on later developments in the field, I will confront former and current data and ideas, including a discussion of old and new methods. Whenever useful, I shall first briefly report post-genomic developments before addressing former results and interpretations. Equally important, some of the terms often used sloppily in scientific discussions will be clearly defined.As a basis for the ensuing discussion, some of the issues and facts related to eukaryotic gene expression will first be introduced. In chapter 2 the evolution in perception of biology over the last 60 years and the impact of the recombinant DNA revolution will be considered. Then, in chapter 3 data and theory concerning the genome, gene expression and genetics will be reviewed. The experimental and theoretical definition of the gene will be discussed before considering the 3 different types of genetic information - the \"Triad\" - and the importance of post-transcriptional regulation of gene expression in the light of the recent finding that 90% of genomic DNA seems to be transcribed. Some previous attempts to provide a conceptual framework for these observations will be recalled, in particular the \"Cascade Regulation Hypothesis\" (CRH) developed in 1967–85, and the \"Gene and Genon\" concept proposed in 2007.A knowledge of the size of primary transcripts is of prime importance, both for experimental and theoretical reasons, since these molecules represent the primary units of the \"RNA genome\" on which most of the post-transcriptional regulation of gene expression occurs. In chapter 4, I will first discuss some current post-genomic topics before summarising the discovery of the high Mr-RNA transcripts, and the investigation of their processing spanning the last 50 years. Since even today, a consensus concerning the real form of primary transcripts in eukaryotic cells has not yet been reached, I will refer to the viral and specialized cellular models which helped early on to understand the mechanisms of RNA processing and differential splicing which operate in cells and tissues. As a well-studied example of expression and regulation of a specific cellular gene in relation to differentiation and pathology, I will discuss the early and recent work on expression of the globin genes in nucleated avian erythroblasts.An important concept is that the primary transcript not only embodies protein-coding information and regulation of its expression, but also the 3D-structure of the genomic DNA from which it was derived. The wealth of recent post-genomic data published in this field emphasises the importance of a fundamental principle of genome organisation and expression that has been overlooked for years even though it was already discussed in the 1970–80ties. These issues are addressed in chapter 5 which focuses on the involvement of the nuclear matrix and nuclear architecture in DNA and RNA biology. This section will make reference to the Unified Matrix Hypothesis (UMH), which was the first molecular model of the 3D organisation of DNA and RNA.The chapter on the \"RNA-genome and peripheral memories\" discusses experimental data on the ribonucleoprotein complexes containing pre-mRNA (pre-mRNPs) and mRNA (mRNPs) which are organised in nuclear and cytoplasmic spaces respectively. Finally, \"Outlook \" will enumerate currently unresolved questions in the field, and will propose some ideas that may encourage further investigation, and comprehension of available experimental data still in need of interpretation. In chapter 8, some propositions and paradigms basic to the authors own analysis are discussed. \"In conclusion\" the raison d'être of this review is recalled and positioned within the overall framework of scientific endeavour.","AEVAvian Erythroblastosis Virus,AEV-cellsleukaemia-cells transformed by a temperature-sensitive AEV,CRMCis-Regulatory Module,FDTFull-Domain Transcript,LCRLocus-Control Region,MREMajor Regulatory Element,PTPrimary Transcript,OPERONregulatory program in bacteria,GENONregulatory program adapted to eukaryotic systems,CRHCascade Regulation Hypothesis,UMHUnified Matrix Hypothesis,Keywords,Primary transcripts,Eukaryotic genomes,3D DNA-RNA structure,Transcription,RNA processing,Regulation of gene expression,Theory of genome organisation and expression","KlausScherrer","Experimental Cell Research","https://doi.org/10.1016/j.yexcr.2018.09.011","https://www.sciencedirect.com/science/article/pii/S0014482718309480"
"A34","Twenty-five years of business systems research and lessons for international business studies","Since 1992, the national business systems (NBS) approach has been increasingly used to analyse not only firm characteristics, structures and strategies within NBS, but also the nature of international business and its interactions with both national and transnational institutions. In reviewing 25 years of NBS literature, we heed calls in IB journals urging researchers to use NBS notions and findings in IB research. Our systematic review of 96 articles analyses the patterns and contributions of NBS literature, revealing four thematic junctures: (1) comparative business systems, (2) firm internationalisation and the management/organisation inside MNCs, (3) the role of internationalisation in the development of organisational capabilities and innovation and (4) the emergence of transnational communities in and across firms and societies. Themes are described in terms of (a) the research questions (RQ) they focus on, (b) how NBS approach investigates the RQ and what are the major findings, (c) how IB frames and approaches the same RQ, (d) how does the NBS approach extend the perspectives of IB and (e) what are the problems faced by NBS in terms of developing further insights into the RQ. Our review contributes to the recent endeavour of IB research to institutionalism, encouraging a productive dialogue between IB and NBS research.","National business systems,International business studies,MNC strategies,Comparative management/organisational studies,Organisational capabilities and innovation,Transnational communities,Institutionalism","Mohammad B.Ranaa,GlennMorganb","International Business Review","https://doi.org/10.1016/j.ibusrev.2018.11.008","https://www.sciencedirect.com/science/article/pii/S0969593117306443"
"A35","Beyond patent analytics: Insights from a scientific and technological data mashup based on a case example","Although access to open and commercial digital sources is easily available thanks to the proliferation of the internet, R&D departments still face the challenge of how to analyze information from several sources. This paper addresses this issue specifically when technological and scientific information needs to be analyzed in an integrated manner. 12,577 families of patents, 2601 scientific papers and 706 news articles are combined, normalized and analyzed using their own metadata and text. A software tool is used to extract insights from semi-structured and unstructured data by means of text mining. Additionally, interactive force-directed graph visualization is employed to show the multiple relations of concepts during different time periods with regard to the entire technology ecosystem. Through a case study of 3D printing technology, this paper shows how to apply mashup and obtain the benefits, and it defines the challenges of using interactive visualization representation.","Data mashup,Network analysis,Visual analytics,Patent analysis,Scientific paper analysis,News article analysis","AlessandroComai","World Patent Information","https://doi.org/10.1016/j.wpi.2018.10.002","https://www.sciencedirect.com/science/article/pii/S0172219018300255"
"A36","Tech mining to validate and refine a technology roadmap","This study uses 'tech mining' (extracting intelligence from R&D data) to validate and refine the content of a particular section of a landmark roadmap of nanotechnology for aeronautics. We utilize topical content from publications and patents to analyze the developmental status of nanocomposite coating technologies. This enables us to validate predictions made by specialists, as presented in the target technology roadmap section. Moreover, we augment that roadmap section by providing additional information on nanocomposite-related emerging technologies. This study supports use of tech mining as a means to inform technology roadmapping, both when creating a new roadmap and to check progress.","Technology roadmap,Tech mining,Scientometrics,Patent analysis,Nanocomposite coatings","GeetLahotiab,Alan L.Portercd,ChuckZhangab,JanYoutiee,BenWangabf","World Patent Information","https://doi.org/10.1016/j.wpi.2018.07.003","https://www.sciencedirect.com/science/article/pii/S0172219018300152"
"A37","A unified knowledge compiler to provide support the scientific community","The scientific community represents an insatiable network with important needs related to the searching of information. The ever-broadening amount of domain-scientific on-line information that can be found requires increasingly sophisticated frameworks to manage it. Nevertheless, these frameworks are usually focused on specific useful functionalities and work more like expert systems than general purpose approaches. In order to ease the research process to the scientific community, the Unified Knowledge Compiler (UNIKO) framework is presented. This framework includes, among other functionalities, the recommendation of articles and authors related to a specific field of application, the evaluation of reputation scores of articles and authors, and the sentiment analysis of the texts of the articles. UNIKO is built as a hybrid framework based on Knowledge-Based Systems and Content-Based Recommendation Systems. In order to evaluate the performance of the system, several experiments have been done. The first experiment is developed to illustrate the reputation scoring task. The second one addresses the sentiment scores calculation based on a lexicon which is supported by a Convolutional Neural Network. The last experiment shows the recommendation tasks based on specific similarity measures and unsupervised learning.","Knowledge management,Information retrieval,Intelligent systems,Information analysis,Sentiment analysis,Machine learning","AlbertoFernández-Isabel1a,Juan CarlosPrieto1a,FelipeOrtega1a,IsaacMartín de Diego1a,JavierM. Moguerza1a,JoséMena1b,SaraGalindo1b,LianaNapalkova1b","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2018.07.044","https://www.sciencedirect.com/science/article/pii/S0950705118303952"
"A38","Construction of visual cognitive computation model for sports psychology based on knowledge atlas","A total of 584 thematic journals were included in the “Chinese Journal of Psychology” from 1996 to 2017 as the basic data set for this study, using bibliometrics, co-occurrence analysis, word frequency analysis, etc., and using CiteSpace III. Software mapping of knowledge. Visual analysis of published papers, research hotspots, research topic time zones, core authors, author co-occurrences, and research institutions of sports psychology research in China. It aims to fully grasp the dynamics of research on the development of sports psychology in China. The process provides a valuable reference for the theoretical research and practice of sports psychology in China. The results show that: Taking time as the axis, the amount of published documents can be divided into three stages: slow growth stage, rapid growth stage, and stable development stage; research topic time zone is also divided into three stages, and the basis for division of each stage is For the introduction of national sports reforms or new policies; 1996–2017, the focus of sports psychology disciplines is the application of sports psychology in physical education and sports training; the core authors in the field are representatives of Yan Jun, Wang Jin, and Yan. Gang Yan, etc.; The core organization of the volume of documents issued is based on professional sports colleges. The representative agency is Beijing Sport University.","Sports psychology,Sports,Knowledge mapping,Visualization,Knowledge atlas","JianqiangGuoa,ShuBinLiub,XianLiua","Cognitive Systems Research","https://doi.org/10.1016/j.cogsys.2018.07.028","https://www.sciencedirect.com/science/article/pii/S1389041718303310"
"A39","The current landscape of learning analytics in higher education","Learning analytics can improve learning practice by transforming the ways we support learning processes. This study is based on the analysis of 252 papers on learning analytics in higher education published between 2012 and 2018. The main research question is: What is the current scientific knowledge about the application of learning analytics in higher education? The focus is on research approaches, methods and the evidence for learning analytics. The evidence was examined in relation to four earlier validated propositions: whether learning analytics i) improve learning outcomes, ii) support learning and teaching, iii) are deployed widely, and iv) are used ethically. The results demonstrate that overall there is little evidence that shows improvements in students' learning outcomes (9%) as well as learning support and teaching (35%). Similarly, little evidence was found for the third (6%) and the forth (18%) proposition. Despite the fact that the identified potential for improving learner practice is high, we cannot currently see much transfer of the suggested potential into higher educational practice over the years. However, the analysis of the existing evidence for learning analytics indicates that there is a shift towards a deeper understanding of students’ learning experiences for the last years.","Learning analytics,Literature review,Higher education,Research methods,Evidence","OlgaViberga,MathiasHatakkab,OlofBältera,AnnaMavroudia","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2018.07.027","https://www.sciencedirect.com/science/article/pii/S0747563218303492"
"A40","Patenting activity in the food safety sector","Research on science and technology policy has heavily relied on patent data. However, relatively few studies of food safety patent activity appear in scholarly literature. This paper provides a discussion on patents as a measure of new knowledge generation in the food safety sector. In so doing, there are inherent challenges to identifying a research taxonomy for this multidisciplinary area. To overcome these challenges, the paper uses a natural language approach that can be applied to other research areas where boundaries of fields are not well defined.","Food safety,Patent,Machine learning,Research taxonomy","Yeong JaeKima,KayeHusbands Fealingb,EvgenyKlochikhinc","World Patent Information","https://doi.org/10.1016/j.wpi.2018.08.005","https://www.sciencedirect.com/science/article/pii/S0172219018300176"
"A41","Systematic method for finding emergence research areas as data quality","The analysis of the transformation and changes in scientific disciplines has always been a critical path for policymakers and researchers. The current study examines the changes in the research areas of data and information quality (DIQ). The aim of this study was to detect different types of changes occurring in the scientific areas including birth, death, growth, decline, merge, and splitting. A model has been developed for this data mining. To test the model, all DIQ articles published in online scientific citation indexing service or Web of Science (WOS) between 1970 and 2016 were extracted and analyzed using the given model. The study is related to the Big Data as well as the integration methods in Big Data which is the most important area in DIQ. It is demonstrated that the first and second emerging research areas are sub-disciplines of entity resolution and record linkage. Accordingly, linkage and privacy are the first emerging research area and the entity resolution using ontology is the second in DIQ. This is followed by the social media issues and genetic related DIQ issues.","Data quality,Text mining,Science mapping,Data mining,Trend analysis","BabakSohrabia,AhmadKhalilijafarabadb","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.08.003","https://www.sciencedirect.com/science/article/pii/S0040162517318140"
"A42","Research Landscape of Business Intelligence and Big Data analytics: A bibliometrics study","Business Intelligence that applies data analytics to generate key information to support business decision making, has been an important area for more than two decades. In the last five years, the trend of “Big Data” has emerged and become a core element of Business Intelligence research. In this article, we review academic literature associated with “Big Data” and “Business Intelligence” to explore the development and research trends. We use bibliometric methods to analyze publications from 1990 to 2017 in journals indexed in Science Citation Index Expanded (SCIE), Social Science Citation Index (SSCI) and Arts & Humanities Citation Index (AHCI). We map the time trend, disciplinary distribution, high-frequency keywords to show emerging topics. The findings indicate that Computer Science and management information systems are two core disciplines that drive research associated with Big Data and Business Intelligence. “Data mining”, “social media” and “information system” are high frequency keywords, but “cloud computing”, “data warehouse” and “knowledge management” are more emphasized after 2016.","Bibliometrics,Big Data analytics,Business Intelligence,Research trend","LiangTing-Penga,LiuYu-Hsib1","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.05.018","https://www.sciencedirect.com/science/article/pii/S0957417418303099"
"A43","An assessment of technology forecasting: Revisiting earlier analyses on dye-sensitized solar cells (DSSCs)","The increasingly uncertain dynamics of technological change pose special challenges to traditional technology forecasting tools, which facilitates future-oriented technology analysis (FTA) tools to support the policy processes in the fields of science, technology & innovation (ST&I) and the management of technology (MOT), rather than merely forecasting incremental advances via analyses of continuous trends. Dye-sensitized solar cells are a promising third-generation photovoltaic technology that can add functionality and lower costs to enhance the value proposition of solar power generation in the early years of the 21st century. Through a series of technological forecasting studies analyzing the R&D patterns and trends in Dye-sensitized solar cells technology over the past several years, we have come to realize that validating previous forecasts is useful for improving ST&I policy processes. Yet, rarely do we revisit forecasts or projections to ascertain how well they fared. Moreover, few studies pay much attention to assessing FTA techniques. In this paper, we compare recent technology activities with previous forecasts to reveal the influencing factors that led to differences between past predictions and actual performance. Beyond our main aim of checking accuracy, in this paper we also wish to gain some sense of how valid those studies were and whether they proved useful to others in some ways.","Technology forecasting,Technology foresight,Technology emergence,Research evaluation,Dye-sensitized solar cells (DSSCs)","YingHuangae,Alan L.Porterbc,YiZhangd,XiangpengLiane,YingGuoe","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.10.031","https://www.sciencedirect.com/science/article/pii/S0040162517318541"
"A44","Validation strategies for the interpretation of microstructure imaging using diffusion MRI","Extracting microanatomical information beyond the image resolution of MRI would provide valuable tools for diagnostics and neuroscientific research. A number of mathematical models already suggest microstructural interpretations of diffusion MRI (dMRI) data. Examples of such microstructural features could be cell bodies and neurites, e.g. the axon's diameter or their orientational distribution for global connectivity analysis using tractography, and have previously only been possible to access through conventional histology of post mortem tissue or invasive biopsies. The prospect of gaining the same knowledge non-invasively from the whole living human brain could push the frontiers for the diagnosis of neurological and psychiatric diseases. It could also provide a general understanding of the development and natural variability in the healthy brain across a population. However, due to a limited image resolution, most of the dMRI measures are indirect estimations and may depend on the whole chain from experimental parameter settings to model assumptions and implementation.Here, we review current literature in this field and highlight the integrative work across anatomical length scales that is needed to validate and trust a new dMRI method. We encourage interdisciplinary collaborations and data sharing in regards to applying and developing new validation techniques to improve the specificity of future dMRI methods.","","Tim B.Dyrbyab,Giorgio M.Innocenticd,MartinBeche,HenrikLundella","NeuroImage","https://doi.org/10.1016/j.neuroimage.2018.06.049","https://www.sciencedirect.com/science/article/pii/S1053811918305561"
"A45","Bibliometric analysis for highly cited papers in operations research and management science from 2008 to 2017 based on Essential Science Indicators","The Essential Science Indicators (ESI) database is widely used to assess scientific outputs. The ESI database contains papers that entered the top 1% of sum citations in one discipline in the past ten years. Therefore, highly cited papers included in ESI database are of high quality in each field. This paper provides a bibliometric overview on the papers included in the ESI database in the field of operations research & management science. During the years of 2008–2017, there are 646 ESI highly cited papers in this area. Based on these 646 papers, we identify the most influential actors including journals, counties/regions, and institutes. The co-authorship relations among countries, institutes and authors characterize the collaboration status in the field of operations research and management science. The most cited papers are then presented. Finally, author keywords, keywords plus and words in title are analyzed, with hot research topics and future directions being provided.","Operations research,Management science,Essential Science Indicators,Bibliometric,Highly cited papers","LiaoHuchangab,TangMinga,LiZongmina,BenjaminLevc","Omega","https://doi.org/10.1016/j.omega.2018.11.005","https://www.sciencedirect.com/science/article/pii/S0305048318308697"
"A46","Understanding the use of Virtual Reality in Marketing: A text mining-based review","The current study intends to highlight the most relevant studies in simulated realities with special attention to VR and marketing, showing how studies have evolved over time and discussing the findings. A text-mining approach using a Bayesian statistical topic model called latent Dirichlet allocation is employed to conduct a comprehensive analysis of 150 articles from 115 journals, all indexed in Web of Science.The findings reveal seven relevant topics, as well as the number of articles published over time, the authors most cited in VR papers and the leading journals in each topic. The article also provides theoretical and practical implications and suggestions for further research.","Virtual Reality,Simulated realities,Marketing,Text mining","Sandra Maria CorreiaLoureiroa,JoãoGuerreiroa,SaraEloyb,DanielaLangaroa,PadmaPanchapakesanc","Journal of Business Research","https://doi.org/10.1016/j.jbusres.2018.10.055","https://www.sciencedirect.com/science/article/pii/S0148296318305368"
"A47","Promoting novelty, rigor, and style in energy social science: Towards codes of practice for appropriate methods and research design","A series of weaknesses in creativity, research design, and quality of writing continue to handicap energy social science. Many studies ask uninteresting research questions, make only marginal contributions, and lack innovative methods or application to theory. Many studies also have no explicit research design, lack rigor, or suffer from mangled structure and poor quality of writing. To help remedy these shortcomings, this Review offers suggestions for how to construct research questions; thoughtfully engage with concepts; state objectives; and appropriately select research methods. Then, the Review offers suggestions for enhancing theoretical, methodological, and empirical novelty. In terms of rigor, codes of practice are presented across seven method categories: experiments, literature reviews, data collection, data analysis, quantitative energy modeling, qualitative analysis, and case studies. We also recommend that researchers beware of hierarchies of evidence utilized in some disciplines, and that researchers place more emphasis on balance and appropriateness in research design. In terms of style, we offer tips regarding macro and microstructure and analysis, as well as coherent writing. Our hope is that this Review will inspire more interesting, robust, multi-method, comparative, interdisciplinary and impactful research that will accelerate the contribution that energy social science can make to both theory and practice.","Validity,Research methods,Research methodology,Interdisciplinary research,Research excellence","Benjamin K.Sovacoolab,JonnAxsenc,SteveSorrella","Energy Research & Social Science","https://doi.org/10.1016/j.erss.2018.07.007","https://www.sciencedirect.com/science/article/pii/S2214629618307230"
"A48","Longitudinal trend of global artemisinin research in chemistry subject areas (1983–2017)","Artemisinin, the initial and main drug for malaria prevention and treatment internationally, was first extracted from the plant Artemisia annua L. by Chinese scientists in 1972. Research on artemisinin in chemistry subject areas shows a rapid growth since the 1980s. To evaluate the evolutionary trends and draw the knowledge map of artemisinin research, 1316 relevant publications are analysed based on bibliometrics. The global research status, emerging trends and future directions are also visualised and discussed. Furthermore, a historical overview of chemical synthesis on artemisinin is illustrated via timeline in terms of industrialisation. Overall, this study provides a novel method to visualise further information about artemisinin research and a comprehensive perspective to understand the longitudinal trend over the last 30<U+202F>years.","Atemisinin,QingHaoSu,Bibliometric analysis,Chemical synthesis,Evolutionary trend,Knowledge map","WanqiXua,ZhongmeiZoua,JinPeib,LinfangHuanga","Bioorganic & Medicinal Chemistry","https://doi.org/10.1016/j.bmc.2018.09.030","https://www.sciencedirect.com/science/article/pii/S0968089618310290"
"A49","A retrospective analysis with bibliometric of energy security in 2000–2017","In recent years, some countries are facing the problem of energy security. Energy security is an important factor affecting the national economy and environment. There are many investigations about energy security, but few of them are bibliometric analysis, including co-citation analysis, hot topics, burst detection, and emerging trends. Therefore, this paper adopts a bibliometric method to address the above issues and provide a general picture of the research field. By downloading 2845 articles from Web of Science and analyzing the results given by CiteSpace, the main conclusions of the most productive countries, institutions, sources, authors, and interesting research directions in the energy security researches are visually demonstrated. For instance, Energy Policy, Renewable Sustainable Energy Reviews, and Applied Energy are the major sources for energy security researches. The emerging trends in energy security researches are energy security, the exploring proposition, the integrated assessment. This paper provides an overall analysis of energy security researches and gives some inspirations for the researchers in this area to do further investigations.","Energy security,CiteSpace,National economy,Diversity,Bibliometric method","WeiZhouab,AiqingKoua,JinChena,BingqingDingc","Energy Reports","https://doi.org/10.1016/j.egyr.2018.10.012","https://www.sciencedirect.com/science/article/pii/S2352484718301720"
"A50","The role of inflammation in core features of depression: Insights from paradigms using exogenously-induced inflammation","A wealth of evidence has implicated inflammation in the development of depression. Yet, the heterogeneous nature of depression has impeded efforts to understand, prevent, and treat the disease. The purpose of this integrative review is to summarize the connections between inflammation and established core features of depression that exhibit more homogeneity than the syndrome itself: exaggerated reactivity to negative information, altered reward processing, decreased cognitive control, and somatic syndrome. For each core feature, we first provide a brief overview of its relevance to depression and neurobiological underpinnings, and then review evidence investigating a potential role of inflammation. We focus primarily on findings from experimental paradigms of exogenously-induced inflammation. We conclude that inflammation likely plays a role in exaggerated reactivity to negative information, altered reward reactivity, and somatic symptoms. There is less evidence supporting an effect of inflammation on cognitive control as assessed by standard neuropsychological measures. Finally, we discuss implications for future research and recommendationsfor how to test the role of inflammation in the pathogenesis of heterogeneous psychiatric disorders.","Inflammation,Depression,Cognitive control,Somatic,Mood,Reward,Endophenotype","Larissa N.Dooleya,Kate R.Kuhlmanbc,Theodore F.Roblescd,Naomi I.Eisenbergercd,Michelle G.Crasked,Julienne E.Bowercd","Neuroscience & Biobehavioral Reviews","https://doi.org/10.1016/j.neubiorev.2018.09.006","https://www.sciencedirect.com/science/article/pii/S0149763418302161"
"A51","Does deep learning help topic extraction? A kernel k-means clustering method with word embedding","Topic extraction presents challenges for the bibliometric community, and its performance still depends on human intervention and its practical areas. This paper proposes a novel kernel k-means clustering method incorporated with a word embedding model to create a solution that effectively extracts topics from bibliometric data. The experimental results of a comparison of this method with four clustering baselines (i.e., k-means, fuzzy c-means, principal component analysis, and topic models) on two bibliometric datasets demonstrate its effectiveness across either a relatively broad range of disciplines or a given domain. An empirical study on bibliometric topic extraction from articles published by three top-tier bibliometric journals between 2000 and 2017, supported by expert knowledge-based evaluations, provides supplemental evidence of the method’s ability on topic extraction. Additionally, this empirical analysis reveals insights into both overlapping and diverse research interests among the three journals that would benefit journal publishers, editorial boards, and research communities.","Bibliometrics,Topic analysis,Cluster analysis,Text mining","YiZhanga,JieLua,FengLiua,QianLiuab,AlanPortercd,HongshuChena,GuangquanZhanga","Journal of Informetrics","https://doi.org/10.1016/j.joi.2018.09.004","https://www.sciencedirect.com/science/article/pii/S1751157718300257"
"A52","SIOG 2018 – Abstract Submission – Poster Presentations","","","","Journal of Geriatric Oncology","https://doi.org/10.1016/S1879-4068(18)30440-5","https://www.sciencedirect.com/science/article/pii/S1879406818304405"
"A53","A comprehensive approach to reviewing latent topics addressed by literature across multiple disciplines","This paper proposes an approach to capturing and reviewing scientific literature addressing latent topics across multiple scientific fields. As latent topics like moral values are affected by word polysemy and synonymy, a traditional keyword-based approach is often ineffective and therefore inappropriate. As a result, scientific literature addressing latent topics tends to be fragmented thereby constraining efforts to address similar and complementary research challenges. A novel approach to reviewing the literature by utilizing both semantic fields and probabilistic topic models has therefore been developed. We illustrate this approach by reviewing the literature addressing the value justice in the energy sector and compare this with a regular keyword-based approach. The new approach results in a more complete overview of the relevance of energy justice as compared to the traditional keyword-based approach. This novel approach can be applied to other latent topics including other values or phenomena such as societal resistance to technologies, thereby leading to an increased understanding of existing relevant literature and the identification of new areas of research.","Latent topics,Probabilistic topic models,Semantic fields,Energy sector,Moral values,Justice","Tristan E.de Wildt,Emile J.L.Chappin,Geertenvan de Kaa,Paulien M.Herder","Applied Energy","https://doi.org/10.1016/j.apenergy.2018.06.082","https://www.sciencedirect.com/science/article/pii/S030626191830953X"
"A54","Visual ranking of academic influence via paper citation","With rapid growth of digital publishing, a great deal of document datum has been published online for a widely spread of knowledge innovations, which is an important resource for human survival and social development. However, it is a time-consuming and difficult task to conduct a high-efficiency access of valuable papers from an extremely large document database. A set of ranking techniques have been proposed to evaluate the influence of articles by counting the number and quality of citations, such as PageRank. In fact, the influence of an article does not merely depend on the account of citations, which is also highly related to the citation network. In this paper, we propose a visual analytics system for visual ranking of academic influence of articles, based on an insightful analysis of citation network. Firstly, a characterization of articles is established through word2vec model, based on an analogy between the articles in citation network and natural language processing (NPL) terms. Then, the difference between articles in the vectorized space is employed to optimize the PageRank model and achieve desired influence ranking results. A set of meaningful visual encodings are also designed to present the relationships among articles, such as the visualization of high-dimensional vectors and time-varying citation networks. At last, a visualization framework is implemented for visual ranking of academic influence of articles, with the ranking models and visual designs integrated. Case studies based on real-world datasets and interviews with domain experts have demonstrated the effectiveness of our system in the evaluation of academic influence of articles.","Visual analysis,Citation network,Word2vec model,PageRank model","ZhiguangZhou,ChenShi,MiaoxinHu,YuhuaLiu","Journal of Visual Languages & Computing","https://doi.org/10.1016/j.jvlc.2018.08.007","https://www.sciencedirect.com/science/article/pii/S1045926X18301265"
"A55","Tracking the neurodynamics of insight: A meta-analysis of neuroimaging studies","The nature of insight has been the interdisciplinary focus of scientific inquiry for over 100 years. Behavioral studies and biographical data suggest that insight, as a form of creative cognition, consists of at least four separate but intercorrelated stages as described by Wallas (1926). Yet no quantitative evidence was available for insight- or insight-stage-specific brain mechanisms that generalize across various insight tasks. The present work attempted, for one, to present an integrated and comprehensive description of the neural networks underlying insight and, for another, to identify dynamic brain mechanisms related to the four hypothetical stages of insight. To this end, we performed two quantitative meta-analyses: one for all available studies that used neuroimaging techniques to investigate insight, and the other for the phasic brain activation of insight drawn from task characteristics, using the activation likelihood estimation (ALE) approach. One key finding was evidence of an integrated network of insight-activated regions, including the right medial frontal gyrus, the left inferior frontal gyrus, the left amygdala and the right hippocampus. Importantly, various brain areas were variably recruited during the four stages. Based on the ALE results, the general and stage-specific neural correlates of insight were determined and potential implications are discussed.","Creative insight,Meta-analysis,Neuroimaging,Incubation,Brain network","WangbingShenab,YuTongc,FengLia,YuanYuand,BernhardHommelb,ChangLiue,JingLuof","Biological Psychology","https://doi.org/10.1016/j.biopsycho.2018.08.018","https://www.sciencedirect.com/science/article/pii/S0301051118300358"
"A56","Construction automation: Research areas, industry concerns and suggestions for advancement","Construction automation has shown the potential to increase construction productivity after years of technical development and experimenting in its field. Exactly how, and the possible benefits and challenges of construction automation, though is unclear and missing from current research efforts. In order to better understand the comprehensive potential of construction automation for increasing construction productivity and the associated possible ramifications, an objective and data-driven review of the use of automation technologies in construction was done. The review was accomplished by using text mining methods on publically available written documents, covering a wide range of relevant data including scientific publications and social media. The text mining software VOS Viewer and RapidMiner Studio were used to determine the most promising areas of research through the analysis of scientific publications, and the main areas of concern of industry through the analysis of text on social media, respectively. These research areas and concerns are summarized in this paper, and based on them suggestions for industry are made to help advance the uptake of automation in construction.","Construction automation technologies,Cluster mapping,Text mining","QianChena,BorjaGarcía de Sotobc,Bryan T.Adeya","Automation in Construction","https://doi.org/10.1016/j.autcon.2018.05.028","https://www.sciencedirect.com/science/article/pii/S0926580517311068"
"A57","Polarization in the social sciences: Assortative mixing in social science collaboration networks is resilient to interventions","Academic collaboration in the social sciences is characterized by a polarization between hermeneutic and nomological researchers. This polarization is expressed in different publication strategies. The present article analyzes the complete co-authorship networks in a social science discipline in two separate countries over five years using an exponential random graph model. It examines whether and how assortative mixing in publication strategies is present and leads to a polarization in scientific collaboration. In the empirical analysis, assortative mixing is found to play a role in shaping the topology of the network and significantly explains collaboration. Co-authorship edges are more prevalent within each of the groups, but this mixing pattern does not fully account for the extent of polarization. Instead, a thought experiment reveals that other components of the complex system dampen or amplify polarization in the data-generating process and that microscopic interventions targeting behavior change with regard to assortativity would be hindered by the resilience of the system. The resilience to interventions is quantified in a series of simulations on the effect of microscopic behavior on macroscopic polarization. The empirical study controls for geographic proximity, supervision, and topical similarity (using a vector space model), and the interplay of these factors is likely responsible for this resilience. The paper also predicts the co-authorship network in one country based on the model of collaborations in the other country.","Scientific collaboration,Co-authorship network,Polarization,Assortative mixing,Exponential random graph model,Network intervention,Social sciences","PhilipLeifeld","Physica A: Statistical Mechanics and its Applications","https://doi.org/10.1016/j.physa.2018.05.109","https://www.sciencedirect.com/science/article/pii/S0378437118306460"
"A58","PDF of the Full Issue","","","","Annals of Emergency Medicine","https://doi.org/10.1016/S0196-0644(18)31270-8","https://www.sciencedirect.com/science/article/pii/S0196064418312708"
"A59","Heavy metal loss from agricultural watershed to aquatic system: A scientometrics review","Heavy metal pollution in soil and aquatic environments has attracted widespread attention due to its persistence, accumulation in the food chain and negative effects on ecological and human health. However, analyses of the watershed-scale migration mechanisms of heavy metal loss from agricultural systems to aquatic systems have seldom been studied systematically. Therefore, this review summarizes the available data in the literature (2003–2017) using CiteSpace software to provide insights into the specific characteristics of heavy metal loss from agricultural watersheds to aquatic systems and consequently shows global development trends that scientists can use for establishing future research directions. As opposed to traditional review articles by experts, this study provides a new method for quantitatively visualizing information about the development of this field over the past decade. The results indicate that among all countries, China was the most active contributor with the most publications and cooperated the most with other countries. In addition, most articles were classified as environmental sciences and ecology, environmental sciences or agricultural studies. Furthermore, based on a keyword co-word analysis by CiteSpace, it was concluded that erosion-linked transport of heavy metals was the most influencing factor of mitigation mechanism. Additionally, the migration characteristics of heavy metals in farmland soils and water under the complex environment impacts of various factors such as climate change and land-use changes were of great significance that future studies should focus on.","Heavy metal,CiteSpace,Agricultural system,Aquatic environment,Diffuse pollution,China","WeiOuyanga,YidiWanga,ChunyeLina,MengchangHea,FanghuaHaob,HongbinLiuc,WeihongZhude","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.04.434","https://www.sciencedirect.com/science/article/pii/S0048969718315833"
"A60","Using discussion logic in analyzing online group discussions: A text mining approach","We propose a Discussion Logic-based Text Analytics (DiLTA) framework, which combines theories developed in social science and text mining fields. The framework extracts features that uncover discussion logic and uses these features in analyzing online discussions. A series of models are proposed including conversation disentanglement, coherence analysis, and visualization. Validation experiments showed that DiLTA achieved significantly superior performance over existing text analytics methods in reconstructing internal structure. A case study using DiLTA-enabled visualization on a healthcare forum illustrates the great potential of DiLTA in assisting comprehension of the internal linkage, structure, and logic of online group discussions.","Online group discussion,Discussion logic, Toulmin’s model of argument,Conversation disentanglement,Coherence analysis,Discussion representation","ShashaDenga,YiluZhoub,PengzhuZhangc,AhmedAbbasid","Information & Management","https://doi.org/10.1016/j.im.2018.09.013","https://www.sciencedirect.com/science/article/pii/S0378720618301393"
"A61","Intellectual structure of strategic management research in the hospitality management field: A co-citation analysis","This study investigates the intellectual structure of strategic management (SM) research in the hospitality industry through co-citation analysis. This study analyzes the evolution of SM research from related SM articles inclusively published in hospitality- and tourism-focused journals as well as business- and management-focused journals from 1971 to 2016. This study is the first to map the intellectual structure of SM research in the hospitality industry to analyze the changes in the influence of the most significant studies, journals, and disciplines/fields as well as the relationships among the subfields on SM research in the hospitality industry. This study suggests that marketing is a dominant subfield in SM research within the hospitality industry. In addition, the resource-based view is a dominant approach in the field, although the positioning school was dominant during the field’s early stages.","Strategic management,Intellectual structure,Co-citation,Network,Hospitality","Mehmet AliKöseoglua,FevziOkumusb,Ismail CagriDogancd,RobLawa","International Journal of Hospitality Management","https://doi.org/10.1016/j.ijhm.2018.09.006","https://www.sciencedirect.com/science/article/pii/S027843191830361X"
"A62","Sustainability in the collaborative economy: A bibliometric analysis reveals emerging interest","The growing field of the collaborative economy is expanding geometrically and little retrospective work on this evolution has been made so far. A number of literature reviews have been focusing on specific business models of the collaborative economy deemed sustainable such as car-sharing, sharing, peer-to-peer business models, crowdsourcing, access-based consumption, community, or specific platforms (e.g. Uber, Airbnb), and some others with broader areas of focus. This paper presents a thorough bibliometric and network analysis combining both Scopus and Web of Science databases that provides fresh new insights into the evolution of the collaborative economy research field and its increasing coverage of sustainability-related topics. A first step identifies 729 published studies and uses bibliometrics to provide a description of the research field. A second stage involves networks analysis to identify influential authors, impactful publications, as well as established and emergent research clusters. A more thorough content analysis identifies key research topics, the attention granted to sustainability, interrelations, and collaboration patterns in the field. Data mapping techniques graphically depict the evolution of publications over time and identify areas of current research interests and potential directions for future research, namely in sustainability.","Collaborative economy,Bibliometrics,Content analysis,Literature review,Network analysis,Sustainability","MyriamErtz,SébastienLeblanc-Proulx","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.06.095","https://www.sciencedirect.com/science/article/pii/S0959652618317451"
"A63","Identifying technology convergence in the field of robotics research","Robots have been developed as a result of the merging of various sophisticated technologies such as mechanical engineering, control systems, electronics, and software and they have played a significant role in automating the manufacturing industry. However, their rate of introduction in service sectors, especially the medical and healthcare sectors, is much slower than expected. Technology convergence may be one of the keys to promote the introduction of robots in new sectors e.g., the medical & healthcare sectors.Technological relatedness including technology convergence has been measured by various methodologies using citation network analysis, clustering, or technology similarity. Although these measurements could identify the overall characteristics of technology convergence, more detailed analyses are required to identify the specific patterns and instances of this convergence. The purpose of this research is first, to identify the technology convergence more precisely than before by using a new methodology named “module-based mining methodology;” second, to extract the patterns of technology convergence; and finally to examine the processes of technology convergence in the field of robotics research. This study would enable researchers and policymakers to achieve accelerated development of new products and services for new sectors including the medical and healthcare market.","Citation network analysis,Robotics,Technology convergence,Tech mining,Technological relatedness","ToshihiroKosea,IchiroSakatab","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.09.005","https://www.sciencedirect.com/science/article/pii/S0040162517318929"
"A64","Transport biofuels technological paradigm based conversion approaches towards a bio-electric energy framework","The continuing dependence on fossil fuels and the rising energy use in the transport sector have resulted in increased research into viable transport biofuels to mitigate climate change and improve energy security. As transport biofuels now only have a small share of the transport sector energy supply and the complexity in providing the fuels because of issues related to available land and food security, this paper develops conversion path solutions for transport biofuel development based on a technological paradigm study. A data-driven approaches system (DAS) that combines visualization analyses with technological paradigm theory is proposed to reveal the key areas and trends in transport biofuels. Timeline, timezones, and cluster visualizations identified the transport biofuel technological paradigm (TBTP) from current transport biofuel developments; a pre-shift phase (including TBTP competition and TBTP diffusion) and a shift phase (TBTP shift), which respectively relate to conventional biofuels, advanced biofuels, and biofuel cells. However, from further DAS trend analyses and the practical findings, electric energy trends were revealed, indicating that there was a paradigm shift from the biofuel paradigm to a bio-electric energy paradigm. From the developed bio-electric energy framework, both indirect and direct methods were found to have led to an this electric energy conversion to an e-bio fuel cell vehicle for fuel cell electric vehicles (FCEV) and bioelectricity for electric vehicles (EV), both of which can contribute to a low-carbon, sustainable transportation future.","Bio-electric energy framework,Conversion approaches,Literature mining,Technological paradigm,Transport biofuels","MeihuiLiac,JiupingXuab,HepingXieb,YinhangWangc","Energy Conversion and Management","https://doi.org/10.1016/j.enconman.2018.07.049","https://www.sciencedirect.com/science/article/pii/S0196890418307842"
"A65","Extracting and mapping industry 4.0 technologies using wikipedia","The explosion of the interest in the industry 4.0 generated a hype on both academia and business: the former is attracted for the opportunities given by the emergence of such a new field, the latter is pulled by incentives and national investment plans. The Industry 4.0 technological field is not new but it is highly heterogeneous (actually it is the aggregation point of more than 30 different fields of the technology). For this reason, many stakeholders feel uncomfortable since they do not master the whole set of technologies, they manifested a lack of knowledge and problems of communication with other domains.Actually such problem is twofold, on one side a common vocabulary that helps domain experts to have a mutual understanding is missing Riel et al. [1], on the other side, an overall standardization effort would be beneficial to integrate existing terminologies in a reference architecture for the Industry 4.0 paradigm Smit et al. [2].One of the basics for solving this issue is the creation of shared semantic for industry 4.0. The paper has an intermediate goal and focuses on the development of an enriched dictionary of Industry 4.0 enabling technologies, with definitions and links between them in order to help the user in actively surfing the new domains by starting from known elements to reach the most far away from his/her background and knowledge.","Industry 4.0,Digital industry,Industrial IoT,Big data,Digital currency,Programming languages,Computing,Embedded systems,IoT,Internet of things","FilippoChiarelloa,LeonelloTrivellib,AndreaBonaccorsia,GualtieroFantonic","Computers in Industry","https://doi.org/10.1016/j.compind.2018.04.006","https://www.sciencedirect.com/science/article/pii/S0166361517306176"
"A66","A bibliometric review of the innovation adoption literature","Innovation adoption is of utmost importance for company survival. That is why it is important to develop a thorough understanding of this research domain and the themes it encapsulates. Since the early work of Everett Rogers, the adoption of innovation literature has attracted considerable attention and has continued to grow rapidly, resulting in a large but fragmented body of literature. The goal of this study is to provide a coherent overview of the theoretical cornerstones as well as recent research trends in the innovation adoption literature. To this end, we conducted a bibliometric review and performed bibliographic coupling and co-citation analysis. First, based on co-citation analysis, we illustrate that innovation adoption research is built on four theoretical cornerstones including: institutional theory; theory of reasoned action; theory concerning the determinants of adoption, and; diffusion theory. Second, bibliographic coupling was used to assess the current research trends. This review is the first to identify thematic areas in an exhaustive manner revealing five clusters of thematic related publications or “research trends”: determinants of IT adoption; adoption of technological standards; organizational rationales associated with adoption; modelling diffusion, and; adoption of agricultural innovations. We conclude this review with the limitations and future research orientations in the field of innovation adoption.","Innovation adoption,Literature review,Bibliographic coupling,Co-citation analysis","Johannes A.W.H.van Oorschota,ErwinHofmanb,Johannes I.M.Halmana","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.04.032","https://www.sciencedirect.com/science/article/pii/S0040162517303943"
"A67","Preservice teacher proficiency with transformations-based congruence proofs after a college proof-based geometry class","This report explores pre-service teachers’ proficiency with concepts of transformational geometry at the end of a semester-long advanced geometry course. In the course, the instructor incorporated transformational geometry content, including congruence proofs, in an attempt to prepare the pre-service teachers to teach high school geometry in alignment with the Common Core State Standards for Mathematics. At the conclusion of the course, students expressed a preference for using traditional triangle congruence criteria (SAS, ASA, SSS, and AAS) over using transformations to complete proofs, but were nevertheless generally successful in completing proofs using transformations. Similarly, while the students often described thinking of transformations in terms of analytic forms, they were successfully able to prove triangle congruences in synthetic contexts. Finally, some evidence indicates that students may have motion or process conceptions of transformations, but not map or object conceptions, but this evidence is not conclusive.","Mathematics teacher education,Transformational geometry,Proof","MeredithHegga,DimitriPapadopoulosb,BrianKatzc,TimothyFukawa-Connellya","The Journal of Mathematical Behavior","https://doi.org/10.1016/j.jmathb.2018.07.002","https://www.sciencedirect.com/science/article/pii/S0732312317301153"
"A68","Visualization and analysis of mapping knowledge domain of road safety studies","Mapping knowledge domain (MKD) is an important application of visualization technology in Bibliometrics, which has been extensively applied in psychology, medicine, and information science. In this paper we conduct a systematic analysis of the development trend on road safety studies based on the Science Citation Index Expanded (SCIE) and Social Sciences Citation Index (SSCI) articles published between 2000 and 2018 using the MKD software tools VOSviewer and Sci2 Tool. Based on our analysis, we first present the annual numbers of articles, origin countries, main research organizations and groups as well as the source journals on road safety studies. We then report the collaborations among the main research organizations and groups using co-authorship analysis. Furthermore, we adopt the document co-citation analysis, keywords co-occurrence analysis, and burst detection analysis to visually explore the knowledge bases, topic distribution, research fronts and research trends on road safety studies. The proposed approach based on the visualized analysis of MKD can be used to establish a reference information and research basis for the application and development of methods in the domain of road safety studies. In particular, our results show that the knowledge bases (classical documents) of road safety studies in the last two decades have focused on five major areas of “Crash Frequency Data Analysis”, “Driver Behavior Questionnaire”, “Safety in Numbers for Walkers and Bicyclists”, “Road Traffic Injury and Prevention”, and “Driving Speed and Road Crashes”. Among the research topics, the five dominant clusters are “Causation and Injury Severity Analysis of Road Accidents”, “Epidemiologic Study and Prevention of Road Traffic Injury”, “Intelligent Transportation System and Active Safety”, “Young drivers’ driving behavior and psychology”, and “Older drivers’ psychological and physiological characteristics”. Finally, the burst keywords in research trends include Cycling, Intelligent Transportation Systems, and Distraction.","Road safety,Bibliometrics,Mapping knowledge domain,Visualization,VOSviewer,Sci2 Tool","XinZoua,Wen LongYueb,Hai LeVuc","Accident Analysis & Prevention","https://doi.org/10.1016/j.aap.2018.06.010","https://www.sciencedirect.com/science/article/pii/S0001457518302744"
"A69","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2018.08.002","https://www.sciencedirect.com/science/article/pii/S0140670118300286"
"A70","Design, the Language of Innovation: A Review of the Design Studies Literature","There is a vast body of research exploring the myriad ways design can contribute to business success. For example, businesses seeing to generate new products, services, processes, models, and strategies as part of their efforts to innovate often turn to design for support and leverage. But how clearly have scholars defined the relationship between design and innovation? Is it even possible to explain the connection between the two? In this article, we investigate whether the design literature published over the past thirty years contains an answer to these questions. We organize our findings into clusters describing the key roles that design activity plays in the innovation process, how designers personally play a part, and the internal and external factors that contribute to design/innovation associations. We also introduce the notion that design language—be it visual, methodological, or procedural—has become not only an organizing principle that supports innovative initiatives, it has become the language of innovation itself.","Design,Innovation,Design studies,Roles of design,Literature review","Ricardo J.Hernándeza,RachelCoopera,BruceTetherb,EmmaMurphyc","She Ji: The Journal of Design, Economics, and Innovation","https://doi.org/10.1016/j.sheji.2018.06.001","https://www.sciencedirect.com/science/article/pii/S2405872618300534"
"A71","Assessing ecological restoration as a research topic using bibliometric indicators","A bibliometric analysis was performed to evaluate the global scientific production on ecological restoration from the period of 1997 to 2017. This analysis was based on online database of Science Citation Index Expanded – Web of Science© and a total of 3297 publications was retrieved. The analysis comprised seven main aspects: (1) publication activity, (2) Web of Science categories, (3) journals, (4) countries, (5) authors, (6) organizations and (7) keywords. The results indicated that the annual publications on ecological restoration study have recently increased. The USA play an important role as they have published highly in this field and have been the most frequent partner in international collaborations. American researchers have accumulated most of the publications. The Chinese Academy of Science is the emblematic organization, with 363 published papers. The Restoration Ecology and Ecological Engineering are the two most used journals to disseminate results. The major related research areas are “Environmental Science Ecology”, “Forestry” and “Biodiversity Conservation”. Studies about “restoration”, “pinus ponderosa”, “climate change”, “biodiversity” and “ecosystem services” have become the main subject of research along the years. Analyses of keywords suggested that there is a relatively lack of information about “soil” and “tropical ecosystems” among the analyzed studies. Overall, this framework proved to be effective to evaluate the recent research trends and to contribute with researchers and governments on management and decision-making on science.","VOSviewer,Bibliometric map,Restoration ecology,Soil,Tropical ecosystems,Systemic approach","João PauloRomanellia,Jaqueline TomiêFujimotob,Marcilene DantasFerreiraa,Douglas HenriqueMilanezc","Ecological Engineering","https://doi.org/10.1016/j.ecoleng.2018.06.015","https://www.sciencedirect.com/science/article/pii/S0925857418302283"
"A72","Teaching English for Research Publication Purposes to science students in China: A case study of an experienced teacher in the classroom","","","YongyanLia,JohnFlowerdewbc,MargaretCargilld","Journal of English for Academic Purposes","https://doi.org/10.1016/j.jeap.2018.07.006","https://www.sciencedirect.com/science/article/pii/S1475158518302273"
"A73","Full Issue PDF","","","","JACC: Cardiovascular Imaging","https://doi.org/10.1016/S1936-878X(18)30691-0","https://www.sciencedirect.com/science/article/pii/S1936878X18306910"
"A74","Social media big data analytics: A survey","Big data analytics has recently emerged as an important research area due to the popularity of the Internet and the advent of the Web 2.0 technologies. Moreover, the proliferation and adoption of social media applications have provided extensive opportunities and challenges for researchers and practitioners. The massive amount of data generated by users using social media platforms is the result of the integration of their background details and daily activities. This enormous volume of generated data known as “big data” has been intensively researched recently. A review of the recent works is presented to obtain a broad perspective of the social media big data analytics research topic. We classify the literature based on important aspects. This study also compares possible big data analytics techniques and their quality attributes. Moreover, we provide a discussion on the applications of social media big data analytics by highlighting the state-of-the-art techniques, methods, and the quality attributes of various studies. Open research challenges in big data analytics are described as well.","Big data,Social media,Machine learning,Analytics","Norjihan AbdulGhania,SurayaHamida,Ibrahim AbakerTargio Hashemb,EjazAhmedc","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2018.08.039","https://www.sciencedirect.com/science/article/pii/S074756321830414X"
"A75","Knowledge management: A global examination based on bibliometric analysis","Knowledge management (KM) is a field of research that has gained wide acceptance in the scientific community and management literature. This article presents a bibliometric overview of the academic research on KM in the business and management areas. Various bibliometric methods are used to perform this overview, including performance analysis and science mapping of the KM field. The performance analysis uses a series of bibliometric indicators, such as the h-index, productivity and citations. In addition, the VOSviewer software is used to map the bibliographic material. Science mapping uses co-citations and the concurrency of keywords. References were obtained from the Web of Science database. We identified and classified the most relevant research in the field according to journals, articles, authors, institutions and countries. The results show that research in this field has increased significantly in the last ten years and that the USA is the most influential country in all aspects in this field. It is important to consider, however, that science continues to advance in this and in all fields and that data rapidly change over time. Therefore, this paper fulfills an informational role that shows that most of the fundamental research of KM is in business and management areas.","Knowledge management,Bibliometrics,Web of Science","MagalyGaviria-Marinac,José M.Merigóbd,HugoBaier-Fuentesc","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.07.006","https://www.sciencedirect.com/science/article/pii/S0040162517304055"
"A76","A comprehensive review of state-of-the-art concentrating solar power (CSP) technologies: Current status and research trends","Concentrating solar power (CSP) has received significant attention among researchers, power-producing companies and state policymakers for its bulk electricity generation capability, overcoming the intermittency of solar resources. The parabolic trough collector (PTC) and solar power tower (SPT) are the two dominant CSP systems that are either operational or in the construction stage. The USA and Spain are global leaders in CSP electricity generation, whereas developing countries such as China and India are emerging by aggressive investment. Each year, hundreds of articles have been published on CSP. However, there is a need to observe the overall research development of this field which is missing in the current body of literature. To bridge this gap, this study 1) provides a most up-to-date overview of the CSP technologies implemented across the globe, 2) reviews previously published review articles on this issue to highlight major findings and 3) analyzes future research trends in the CSP research. Text mining approach is utilized to analyze and visualize the scientific landscape of the research. Thermal energy storage, solar collector and policy-level analysis are found as core topics of discussion in the previous studies. With a holistic analysis, it is found that direct steam generation (DSG) is a promising innovation which is reviewed in this study. This paper provides a comprehensive outlook on the CSP technologies and its research which offers practical help to the future researchers who start to research on this topic.","Concentrating solar power (CSP),Concentrated solar power,Solar thermal power plant,Solar thermal electricity,Renewable energy,Direct steam generation","Md TasbirulIslama,NazmulHudaa,A.B.Abdullahb,R.Saidurcd","Renewable and Sustainable Energy Reviews","https://doi.org/10.1016/j.rser.2018.04.097","https://www.sciencedirect.com/science/article/pii/S1364032118303113"
"A77","The more multidisciplinary the better? – The prevalence and interdisciplinarity of research collaborations in multidisciplinary institutions","Scientific research is increasingly relying on collaborations to address complex real-world problems. Many researchers, policymakers, and administrators consider a multidisciplinary environment an important factor for fostering research collaborations, especially interdisciplinary ones that involve researchers from different disciplines. However, it remains unknown whether a higher level of multidisciplinarity within an academic institution is associated with internal collaborations that are more prevalent and more interdisciplinary. Analyzing 90,000 publications by 2500 faculty members in over 100 academic institutions from three multidisciplinary areas, information, public policy, and neuroscience, we investigated the connection between multidisciplinarity and research collaborations. Based on social network analysis and text mining, our analysis suggests that more multidisciplinary institutions are not necessarily more collaborative, although they do feature collaborations that are more interdisciplinary. Our findings provide implications for academic administrators and policymakers to promote research collaborations and interdisciplinarity in academic institutions.","Multidisciplinarity,Interdisciplinarity,Collaboration,Network analysis,Text mining","ZhiyaZuo,KangZhao","Journal of Informetrics","https://doi.org/10.1016/j.joi.2018.06.006","https://www.sciencedirect.com/science/article/pii/S1751157718300452"
"A78","Reframing socio-hydrological research to include a social science perspective","There is increasing recognition of the need to incorporate the complex and dynamic interactions between society and water in studies of water resource systems. The study of human-water dynamics requires the involvement of researchers from different disciplines, including hydrology and social science. This paper tracks recent trends in socio-hydrological research using quantitative and qualitative methods. Bibliographic metrics and network analysis are used to identify general trends and illustrate the internal connections in this small but growing interdisciplinary field. Results show that hydrologists dominate research in socio-hydrology as presently defined, with far less participation from social scientists. Research questions for socio-hydrology tend to focus on system dynamics and are often not framed in a way that engages the interests and expertise of social scientists. A qualitative analysis addresses key barriers to the interdisciplinary development of socio-hydrology and identifies research needs and directions for better integration of the human dimensions of water science. Attracting social scientists to this field requires a broader conceptualization of socio-hydrology to focus on sustainable development, risk assessment, hazard management, resilience, adaptation, and knowledge mobilization in addition to hydrology’s traditional focus on systems modeling and decision support. We propose three themes for thematic focus: systemic risk and natural hazards; sustainability science; and adaptive governance. This broader framing of socio-hydrology is inherently more interdisciplinary, brings new methods and viewpoints to the field, and ensures that place-based local values are included in studies of water system dynamics.","Human-water interaction,System dynamics,Bibliographic metrics,Network analysis,Interdisciplinary","LiXuab,PatriciaGoberac,Howard S.Wheaterab,YuyaKajikawade","Journal of Hydrology","https://doi.org/10.1016/j.jhydrol.2018.05.061","https://www.sciencedirect.com/science/article/pii/S0022169418303883"
"A79","Industry 4.0 as an enabler of proximity for construction supply chains: A systematic literature review","The fourth industrial revolution (Industry 4.0) is changing not only the manufacturing industry but also the construction industry and its connected supply chains. Construction supply chains (CSCs) have specific characteristics, such as being temporary organizations that require high coordination efforts to align the processes of supply chain actors. The concept of proximity is used to analyze synchronization between suppliers and the construction site. This article presents a framework for explaining Industry 4.0 concepts that increase or reduce proximity. We find that Industry 4.0 technologies mainly influence technological, organizational, geographical and cognitive proximity dimensions. This presents benefits and challenges for CSCs. This framework is based on the results of a systematic literature review of scientific papers and analysis of applicability through practical publications and examples from industrial case studies.","Industry 4.0,Proximity,Construction,Supply chain management,Systematic literature review,Supply chain coordination","PatrickDallasegaa,ErwinRaucha,ChristianLinderb","Computers in Industry","https://doi.org/10.1016/j.compind.2018.03.039","https://www.sciencedirect.com/science/article/pii/S0166361517305043"
"A80","Applying network analysis to assess coastal risk planning","Adequate response to risks affecting coasts requires an integrated and coordinated multi-risk governance system, with ongoing evaluation of statutory planning documents and responsible stakeholders. Traditionally, such analyses have been carried out using mainly qualitative approaches. This paper adopts a more systemic and quantitative perspective on assessing planning systems and stakeholder relationships in connection with coastal risk. We apply network analysis to the Catalan coast (Northwestern Mediterranean Basin), paying special attention to the level of climate change integration in the planning system, as an aggravating factor of current risk dynamics. Our results demonstrate and quantify the complexity of Catalan coastal risk planning, which requires dealings with multi-level legal and administrative frameworks. Also highlighted is dissimilar management traditions according to risk type: the perspective on flooding risk is more unified and multi-risk focused, whereas coastal erosion (a significant issue for the Catalan coast) is managed more sectorially from a centralized administrative level. Climate change, moreover, is weakly accounted for in current statutory planning. We also acknowledge the relevance of using qualitative information as an important complement in interpreting results and making policy recommendations.","Network analysis,Coastal risk,Planning system,Climate change","ElisabetRocaa,AnnaJulià-Verdaguera,MíriamVillaresa,MartíRosas-Casalsb","Ocean & Coastal Management","https://doi.org/10.1016/j.ocecoaman.2018.02.001","https://www.sciencedirect.com/science/article/pii/S0964569116304744"
"A81","Mapping the Journal of Vocational Behavior: A 23-year review","This article uses bibliometric analysis to review the Journal of Vocational Behavior (JVB) over 23<U+202F>years. To conduct this review, we systematically analyzed 1490 JVB articles published from 1994 to 2016. We draw on this analysis to answer the questions: a) What key works did JVB articles build on during this period? and b) What key topics, articles, and trends appeared in the journal? We then provide empirically grounded reviews of major topic areas in JVB, and discuss recommendations for future research. This review is accompanied by two analytic science maps: 1) a co-citation map that reveals 466 key works referenced by JVB articles (http://bit.ly/JVBFoundationsMap), and 2) a topic map that reveals 353 JVB article topics, topic relations, topic trends, and citation rates associated with each topic (http://bit.ly/JVBTopicMap). These maps provide an overview of key vocational behavior topics and scholarship that readers can download and interactively explore to help guide their future research.","Careers,Vocational psychology,Vocational behavior,Science mapping,Bibliometrics","Eliza K.Byingtona1,WillFelpsb1,YehudaBaruchc","Journal of Vocational Behavior","https://doi.org/10.1016/j.jvb.2018.07.007","https://www.sciencedirect.com/science/article/pii/S0001879118300848"
"A82","Innovation pathways in additive manufacturing: Methods for tracing emerging and branching paths from rapid prototyping to alternative applications","In recent years, the Forecasting Innovation Pathway approach (FIP) has shown to be a promising set of tools to capture potential developments in emerging fields through capturing indications of endogenous futures. However, the FIP approach is reliant on a clear demarcated area to study, a challenge for emerging technology fields where uncertainty and rhetoric abound. This paper presents an addition to the FIP toolbox that helps characterise and demarcate boundaries of emerging fields to allow for deeper analysis through other FIP methods. We illustrate this approach through an exercise for 3D printing technology (also known as Additive Manufacturing). We show that 3D printing can be represented by a dominant design: a tri-partite configuration of printer, material and digital design software. In the past decade we have seen significant branching from applications in rapid-prototyping to medical, fashion, aeronautics and supply chain management with a variety of elements coming together in tri-partite configurations. The paper adds to the current FTA literature an approach building on evolutionary theories of technical change to help with such situations – emerging, evolving and branching ‘innovation pathways’. Moreover, we developed a methodology to construct these innovation paths.","Branching path,Trajectory,Innovation pathways,Paradigm,Industry scenario,Meso-level","Douglas K.R.Robinsonab,AxelLagnaua,Wouter P.C.Boonc","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.07.012","https://www.sciencedirect.com/science/article/pii/S0040162518301720"
"A83","Combining co-citation clustering and text-based analysis to reveal the main development paths of smart cities","Bibliometrics is a powerful tool for analyzing knowledge domains and revealing their cognitive-epistemological structure. Different mathematical models and statistical techniques have been proposed and tested to carry out bibliometric analyses and demonstrate their effectiveness in uncovering how fields of research are intellectually structured. These include two hybrid techniques that allow clusters of related documents obtained from a co-citation analysis to be labeled using textual data. This paper reports on the findings of a bibliometric study in which these hybrid techniques are combined to: (1) build and visualize the network of publications shaping the intellectual structure of the smart city research field by considering the first two decades of literature dealing with this subject; (2) map the clusters of thematically-related publications; and (3) reveal the emerging development paths of smart cities that each thematic cluster represents and the strategic principles they embody. The five development paths which the analysis uncovers and the strategic principles each stands on are then compared by reviewing the most recent literature on smart cities. Overall, this bibliometric study offers a systematic review of the research on smart cities produced since 1992 and helps bridge the division affecting this research area, demonstrating that it is caused by the dichotomous nature of the development paths of smart cities that each thematic cluster relates to and the strategic principles they in turn support.","Smart city,Sustainable urban development,Urban innovation,Bibliometrics,Co-citation analysis,Content analysis,Development paths","LucaMoraa,MarkDeakinb,AlasdairReidb","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.07.019","https://www.sciencedirect.com/science/article/pii/S0040162518310333"
"A84","Frontiers of low-carbon technologies: Results from bibliographic coupling with sliding window","It is of great significance to quickly and accurately detect the current and future development trends of low-carbon technologies (LCT). However, there is a lack of detecting research fronts of low-carbon technologies based on the bibliographic data. This paper proposes a research framework integrating LCT domains and the bibliometric coupling with sliding window technique to explore the LCT research fronts in recent decade (from 2007 to 2016). Eleven research fronts matching the foresight given by LCT experts are identified, including carbon capture and storage (CCS) in power generation, technology transfer, technology diffusion, electrocoagulation, magnetic nanoparticles, critical metals application, electrocatalytic water oxidation, ionic liquids, mutually immiscible ionic liquids, electric vehicle (China), electric vehicle (UK and USA). Closer investigation of the evolution shows that CCS application in the power plants and hydrogen production from water electrolysis are two emerging fronts. Besides, bibliometric coupling with sliding window is an effective tool to detect the frontiers of low-carbon technologies. Finally, the implications of the research for LCT monitoring and development are discussed.","Low-carbon technologies,Research fronts,Bibliometric coupling,Sliding window,Data driven","Yi-MingWeiabcd,Jin-WeiWangabcd,TianqiChenab,Bi-YingYuabcd,HuaLiaoabcd","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.04.170","https://www.sciencedirect.com/science/article/pii/S0959652618312034"
"A85","Systematic survey of big data and data mining in internet of things","In recent years, the Internet of Things (IoT) has emerged as a new opportunity. Thus, all devices such as smartphones, transportation facilities, public services, and home appliances are used as data creator devices. All the electronic devices around us help our daily life. Devices such as wrist watches, emergency alarms, and garage doors and home appliances such as refrigerators, microwaves, air conditioning, and water heaters are connected to an IoT network and controlled remotely. Methods such as big data and data mining can be used to improve the efficiency of IoT and storage challenges of a large data volume and the transmission, analysis, and processing of the data volume on the IoT. The aim of this study is to investigate the research done on IoT using big data as well as data mining methods to identify subjects that must be emphasized more in current and future research paths. This article tries to achieve the goal by following the conference and journal articles published on IoT-big data and also IoT-data mining areas between 2010 and August 2017. In order to examine these articles, the combination of Systematic Mapping and literature review was used to create an intended review article. In this research, 44 articles were studied. These articles are divided into three categories: Architecture & Platform, framework, and application. In this research, a summary of the methods used in the area of IoT-big data and IoT-data mining is presented in three categories to provide a starting point for researchers in the future.","Internet of things,Systematic survey,Big data,Data mining","ShabnamShadrooa,Amir MasoudRahmaniab","Computer Networks","https://doi.org/10.1016/j.comnet.2018.04.001","https://www.sciencedirect.com/science/article/pii/S1389128618301579"
"A86","Exploring technology opportunities by visualizing patent information based on generative topographic mapping and link prediction","The shortening lifetime of technology requires companies to make intensive efforts to continuously explore new technology. Although many researchers have proposed visualization methods to find technology opportunities, little attention has been paid to present detailed directions of technology development with specified characteristics of technology. Thus, this research aims to suggest a systematic approach to conducting technology opportunity analysis by visualizing patent information, such as patent documents and citation relationships. First, keywords that explain core concepts, functions, and so on are extracted from collected patent documents by text mining. Second, patents are visualized in a two-dimensional space, and vacant cells are identified with their estimated keyword vectors by generative topographic mapping (GTM). Third, since many vacant cells will be potential candidates for developing new technologies, link prediction tools can choose promising vacant cells to connect existing cells with potential, but not yet existent, cells. Finally, the results of prediction are tested by comparing the predicted cells with the actual developed cells. The research reported in this paper is based in three technologies that have emerging, stable, and declining patterns, in order to illustrate the proposed approach, and investigate in which types it is relevant. It is found that the proposed approach provided a good prediction performance in the case of a technology that has a stable pattern. In addition, among link prediction methods, a semantic similarity-based approach showed better prediction results than a machine learning technique due to modest data availability for training. Thus, the results of this research can help R&D managers plan and evaluate R&D projects for technology development.","Technology opportunity analysis,Visualization,Patent information,GTM,Link prediction","ByungunYoona,Christopher L.Mageeb","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.01.019","https://www.sciencedirect.com/science/article/pii/S0040162517309848"
"A87","History and trends in solar irradiance and PV power forecasting: A preliminary assessment and review using text mining","Text mining is an emerging topic that advances the review of academic literature. This paper presents a preliminary study on how to review solar irradiance and photovoltaic (PV) power forecasting (both topics combined as “solar forecasting” for short) using text mining, which serves as the first part of a forthcoming series of text mining applications in solar forecasting. This study contains three main contributions: (1) establishing the technological infrastructure (authors, journals & conferences, publications, and organizations) of solar forecasting via the top 1000 papers returned by a Google Scholar search; (2) consolidating the frequently-used abbreviations in solar forecasting by mining the full texts of 249 ScienceDirect publications; and (3) identifying key innovations in recent advances in solar forecasting (e.g., shadow camera, forecast reconciliation). As most of the steps involved in the above analysis are automated via an application programming interface, the presented method can be transferred to other solar engineering topics, or any other scientific domain, by means of changing the search word. The authors acknowledge that text mining, at its present stage, serves as a complement to, but not a replacement of, conventional review papers.","Text mining,Solar forecasting,Review,Photovoltaics","DazhiYanga,JanKleisslb,Christian A.Gueymardc,Hugo T.C.Pedrob,Carlos F.M.Coimbrab","Solar Energy","https://doi.org/10.1016/j.solener.2017.11.023","https://www.sciencedirect.com/science/article/pii/S0038092X17310022"
"A88","Multilevel approach for combinatorial optimization in bipartite network","Multilevel approaches aim at reducing the cost of a target algorithm over a given network by applying it to a coarsened (or reduced) version of the original network. They have been successfully employed in a variety of problems, most notably community detection. However, current solutions are not directly applicable to bipartite networks and the literature lacks studies that illustrate their application for solving multilevel optimization problems in such networks. This article addresses this gap and introduces a multilevel optimization approach for bipartite networks and the implementation of a general multilevel framework including novel algorithms for coarsening and uncorsening, applicable to a variety of problems. We analyze how the proposed multilevel strategy affects the topological features of bipartite networks and show that a controlled coarsening strategy can preserve properties such as degree and clustering coefficient centralities. The applicability of the general framework is illustrated in two optimization problems, one for solving the Barber’s modularity for community detection and the second for dimensionality reduction in text classification. We show that the solutions thus obtained are statistically equivalent, regarding accuracy, to those of conventional approaches, whilst requiring considerably lower execution times.","Complex networks,Bipartite networks,Combinatorial optimization,Meta-heuristic,Multilevel optimization,Large-scale networks","AlanValejo,Maria CristinaFerreira de Oliveira,Geraldo P.R.Filho,Alneu de AndradeLopes","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2018.03.021","https://www.sciencedirect.com/science/article/pii/S0950705118301539"
"A89","Intelligent and effective informatic deconvolution of “Big Data” and its future impact on the quantitative nature of neurodegenerative disease therapy","Biomedical data sets are becoming increasingly larger and a plethora of high-dimensionality data sets (“Big Data”) are now freely accessible for neurodegenerative diseases, such as Alzheimer's disease. It is thus important that new informatic analysis platforms are developed that allow the organization and interrogation of Big Data resources into a rational and actionable mechanism for advanced therapeutic development. This will entail the generation of systems and tools that allow the cross-platform correlation between data sets of distinct types, for example, transcriptomic, proteomic, and metabolomic. Here, we provide a comprehensive overview of the latest strategies, including latent semantic analytics, topological data investigation, and deep learning techniques that will drive the future development of diagnostic and therapeutic applications for Alzheimer's disease. We contend that diverse informatic “Big Data” platforms should be synergistically designed with more advanced chemical/drug and cellular/tissue-based phenotypic analytical predictive models to assist in either de novo drug design or effective drug repurposing.","Big data,Informatics,High-dimensionality,Alzheimer's disease,Aging,Molecular signature,Transcriptomics,Metabolomics,Proteomics,Genomics","StuartMaudsleyab1,ViswanathDevanarayanc1,BronwenMartina,HugoGeertsd,Brain Health Modeling Initiative (BHMI)","Alzheimer's & Dementia","https://doi.org/10.1016/j.jalz.2018.01.014","https://www.sciencedirect.com/science/article/pii/S1552526018300402"
"A90","Cross-citation and authorship analysis of hotel performance studies","This study develops a literature review of hotel performance studies, and provides insights by adopting a cross-citation network approach. Two research questions are defined. First question focuses on the most cross-cited papers and journals, and identifies salient trends. Second question considers who are the most popular cross-cited and citing authors. This work is rooted in bibliometric studies, and adopts a relational approach. Based on cross-citations, a network is built by using 734 papers published during the period 1996–2015, as nodes and the cross-citations between them as links. Exploratory analysis reveals spectacular growth of outputs, with the last time period (2011–2015) including 56% of outputs. The most cross-cited papers possess the characteristics of: being older; representing 1% of sample but accounting for 14% of cross-citations. The 734 papers are published in 164 journals, but they show a clear core-periphery structure with International Journal of Hospitality Management ranked first.","Hotel performance,Bibliometric analysis,Citation,Cross-citation,Network analysis","RuggeroSainaghia,PaulPhillipsb,RodolfoBaggiocd,AurelioMauria","International Journal of Hospitality Management","https://doi.org/10.1016/j.ijhm.2018.02.004","https://www.sciencedirect.com/science/article/pii/S0278431917307454"
"A91","Lung cancer and particulate pollution: A critical review of spatial and temporal analysis evidence","BackgroundParticulate matter (PM) has been recognized as one of the key risk factors of lung cancer. However, spatial and temporal patterns of this association remain unclear. Spatiotemporal analyses incorporate the spatial and temporal structure of the data within random effects models, generating more accurate evaluations of PM-lung cancer associations at a scale that can better inform lung cancer prevention programs.,MethodsWe conducted a critical review of spatial and temporal analyses of PM and lung cancer. The databases of PubMed, Web of Science and Scopus were searched for potential articles published until September 30, 2017. We included studies that applied spatial and temporal analyses to evaluate the associations of PM2.5 (inhalable particles with diameters that are 2.5<U+202F>µm and smaller) and PM10 (inhalable particles with diameters that are 10<U+202F>µm and smaller) with lung cancer.,ResultsWe identified 17 articles eligible for the review. Of these, 11 focused on PM2.5, five on PM10, and one on both. These studies suggested a significant positive association between PM2.5 exposure and the risk of lung cancer. Relative risks of lung cancer mortality ranged from 1.08 (95% confidence interval (CI): 1.07–1.09) to 1.60 (95%CI: 1.09–2.33) for 10<U+202F>µg/m3 increase in PM2.5 exposure. The association between PM10 and lung cancer had been less well researched and the results were not consistent. In terms of the analysis methods, 16 papers undertook spatial analysis and one paper employed temporal analysis. No paper included spatial and temporal analyses simultaneously and considered spatiotemporal uncertainty into model predictions. Among the 16 papers with spatial analyses, thirteen studies presented maps, while only five and 11 studies utilized spatial exploration and modeling methods, respectively.,ConclusionsAdvanced spatial and temporal epidemiological methods were seldom applied to PM-lung cancer associations. Further research is urgently needed to develop and employ robust and comprehensive spatiotemporal analysis methods for the evaluation of PM-lung cancer associations and the support of lung cancer prevention strategies.","Spatiotemporal epidemiology,Lung cancer,Particulate pollution,PM2.5,PM10","NingWanga,KerrieMengersenb,MichaelKimlincd,MaigengZhoue,ShiluTongafg,LiwenFange,BaohuaWange,WenbiaoHua","Environmental Research","https://doi.org/10.1016/j.envres.2018.03.034","https://www.sciencedirect.com/science/article/pii/S0013935118301634"
"A92","Publication trends and knowledge mapping in 3D printing in orthopaedics","PurposeThree dimensional (3D) printing, also called ‘rapid prototyping’ and ‘additive manufacturing’ is considered as a “second industrial revolution.” With this rapidly emerging technology, CT or MR images are used for the creation of graspable objects from 3D reconstituted images. Patient-specific anatomical models can be, therefore, manufactured efficiently. These can enhance surgeon's understanding of their patients' patho-anatomy and also help in precise preoperative planning. The 3D printed patient-specific guides can also help in achieving accurate bony cuts, precise implant placement, and nice surgical results. Customized implants, casts, orthoses and prosthetics can be created to match an individual patient's anatomy. The 3D printing of individualized artificial cartilage scaffolds and 3D bioprinting are some other areas of growing interest. We aim to study the publication trends in 3D printing as applied to the field of orthopaedics.,Materials and methodsA literature search was performed to extract all papers related to 3D printing applications in orthopaedics and allied sciences on the Pubmed, Web of Science and SCOPUS databases. Suitable keywords and boolean operators (“3D Printing” OR “3-dimensional printing” OR “3D printed” OR “additive manufacturing” OR “rapid prototyping”) AND (‘‘Orthopaedics” OR “Orthopaedics’’) were used, in May 2018. Search was attempted in Cochrane Database of Systematic Reviews, Cochrane Central Register of Controlled Trials, and Database of Abstracts of Review of Effectiveness (DARE) databases, using keywords 3d printing orthopaedics. A similar search was repeated in pubmed and SCOPUS to get more specific papers.No limits were set on the period or evidence level, as 3D printing in orthopaedics is relatively new and evidence available is usually limited to low-level studies. Trends in a publication on these topics were analyzed, focussing on publications, type of research (basic science or clinical), type of publication, authors, institution, and country. Some citations received by these papers were also analyzed in SCOPUS and Web of Science. MS Excel (2008 - Mac version) and VOS Viewer1.6.8 (2018- Mac version) software were used to analyze the search results and for citation mapping respectively. We also identified top 10 most cited articles in the field.,ResultsAn increasing trend in publications in 3D printing-related work in orthopedic surgery and related fields was observed in the recent past. A search on Pubmed using the above strategy revealed 389 documents. A similar search revealed 653 documents on SCOPUS, many (314) of which were from an engineering background and only 271 were related to medicine. No papers were found in the Cochrane database. Search on TRIP database revealed 195 papers. A similar search revealed 237 papers on orthopedic applications on Pubmed and 269 documents on SCOPUS, whereas a search on Web of Science revealed only 23 papers. Publication trends were then analyzed on data derived from SCOPUS database. Overall, most papers were published from China, followed by United States, United Kingdom, and India.,ConclusionThere has been an upsurge of interest in 3D printing in orthopedic surgery, as is evident by an increasing trend in research and publications in this area in the recent years. Presently, 3D printing is in a primitive stage in the field of orthopedic surgery as our knowledge is still insufficient, and costs and learning curve are somewhat high. However, looking at latest publication trends, we are enthusiastic that it holds the key to future in orthopaedics and trauma cases.","3D printing,Rapid prototyping,Additive manufacturing,Orthopaedics,Spine,Arthroplasty","RajuVaishyaa,Mohit KumarPatralekhb,AbhishekVaisha,Amit KumarAgarwala,VipulVijaya","Journal of Clinical Orthopaedics and Trauma","https://doi.org/10.1016/j.jcot.2018.07.006","https://www.sciencedirect.com/science/article/pii/S0976566218302790"
"A93","Hierarchical partitioning of the output space in multi-label data","Hierarchy Of Multi-label classifiERs (HOMER) is a multi-label learning algorithm that breaks the initial learning task to several, easier sub-tasks by first constructing a hierarchy of labels from a given label set and secondly employing a given base multi-label classifier (MLC) to the resulting sub-problems. The primary goal is to effectively address class imbalance and scalability issues that often arise in real-world multi-label classification problems. In this work, we present the general setup for a HOMER model and a simple extension of the algorithm that is suited for MLCs that output rankings. Furthermore, we provide a detailed analysis of the properties of the algorithm, both from an aspect of effectiveness and computational complexity. A secondary contribution involves the presentation of a balanced variant of the k means algorithm, which serves in the first step of the label hierarchy construction. We conduct extensive experiments on six real-world data sets, studying empirically HOMER's parameters and providing examples of instantiations of the algorithm with different clustering approaches and MLCs, The empirical results demonstrate a significant improvement over the given base MLC.","Knowledge discovery,Machine learning,Supervised learning,Text mining","YannisPapanikolaoua,GrigoriosTsoumakasa,IoannisKatakisb","Data & Knowledge Engineering","https://doi.org/10.1016/j.datak.2018.05.003","https://www.sciencedirect.com/science/article/pii/S0169023X17304512"
"A94","A systematic literature review on green supply chain management: Research implications and future perspectives","This article aims to present the Green Supply Chain Management (GSCM) practices from a comprehensive point of view and to analyze the subject's behaviour in the last ten years, through a systematic literature review/bibliometric analysis in articles published from 2006 to 2016. Through the research profiling method, we identified that (i) the most frequent research contexts were “GSCM financial impact” and “motivations to GSCM implementation”, (ii) the automotive, textile/manufacturing and electronic sectors were the most discussed, (iii) the most used research methods were those involving empirical procedures, iv) Web of Science and Scopus databases gathered 96.7% of the articles used in this analysis, (v) there is a high concentration of researches from countries academically established and recognized, while developing countries are also present, (vi) Journal of Cleaner Production was the most cited journal and with more publications about GSCM, (vii) Samir Srivastava's article had the highest Citation Score, and (viii) there are 11 GSCM research clusters. In addition, we discuss the content covered in the literature review, seeking to extend the understanding of the scenario where the GSCM is inserted nowadays and helping to identify research opportunities for researchers interested in such subject.","Green supply chain management,Literature review,Research profiling,Research area clusters","Ualison Rébulade Oliveiraa,Luciano SouzaEspindolaa,Isabele Rochada Silvaa,Iaslin Nostórioda Silvaa,Henrique MartinsRochab","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.03.083","https://www.sciencedirect.com/science/article/pii/S0959652618307406"
"A95","Discovering and forecasting interactions in big data research: A learning-enhanced bibliometric study","As one of the most impactful emerging technologies, big data analytics and its related applications are powering the development of information technologies and are significantly shaping thinking and behavior in today's interconnected world. Exploring the technological evolution of big data research is an effective way to enhance technology management and create value for research and development strategies for both government and industry. This paper uses a learning-enhanced bibliometric study to discover interactions in big data research by detecting and visualizing its evolutionary pathways. Concentrating on a set of 5840 articles derived from Web of Science covering the period between 2000 and 2015, text mining and bibliometric techniques are combined to profile the hotspots in big data research and its core constituents. A learning process is used to enhance the ability to identify the interactive relationships between topics in sequential time slices, revealing technological evolution and death. The outputs include a landscape of interactions within big data research from 2000 to 2015 with a detailed map of the evolutionary pathways of specific technologies. Empirical insights for related studies in science policy, innovation management, and entrepreneurship are also provided.","Technological evolution,Text mining,Bibliometrics,Big data","YiZhanga,YingHuangb,Alan L.Portercd,GuangquanZhanga,JieLua","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.06.007","https://www.sciencedirect.com/science/article/pii/S0040162517315081"
"A96","Flourishing Sustainably in the Anthropocene? Known Possibilities and Unknown Probabilities","Sustainability expresses culturally evolving sets of values, norms, morals, civic engagements, governance, markets, and corporate ethics. Sustainable initiatives emerge as necessary adaptations to ceaseless human activities transforming Earth's energy, matter and information into entropy, externalities, and inequalities. The uncertainty and unknown unknowns intrinsic to life's nonlinear dynamic complexities make sustainability forever provisional, and given planetary scale disruptions humans are triggering, sustainability in the Anthropocene should seek the greatest resilience at city scale. Disruptions impact localities more frequently than nations and it is largely up to local citizens to implement antifragile sustainable practices minimizing such occurrences and enabling robust recoveries.","Agroecology,Biosphere,Cities,Deep learning–play–work,Exergetic efficiency,Externalities,Governance,Inequality,Intergenerational,Internet platforms,Justice,Lifelong learning,Mobility-as-a-Service (MaaS),planetary boundaries,Solar Power Internet,Technosphere","Michael P.Totten","Reference Module in Earth Systems and Environmental Sciences,Reference Module in Earth Systems and Environmental Sciences","https://doi.org/10.1016/B978-0-12-409548-9.10910-8","https://www.sciencedirect.com/science/article/pii/B9780124095489109108"
"A97","A text mining based overview of inventory research in the ISIR special issues 1994–2016","When a research field achieves a certain maturity, it becomes useful for future research to obtain a structured overview of the field: how did it evolve in the past? Where does it currently stand? In what direction does it (possibly) evolve? The purpose of our paper is to offer an overview of inventory research published in the special issues of ISIR (International Society for Inventory Research) Symposia, one of the most important forums of leading inventory research. This paper focuses on the following two research questions: (1) what are the major topics of inventory research in ISIR special issues? and (2) how do important research topics within ISIR special issues evolve over time?We apply text mining as a novel method of content analysis, relying on the 12 special issues of ISIR published in the International Journal of Production Economics between 1994 and 2016, covering 566 papers. The relevance of text mining is based on a structured analysis of literature review type papers in the field of inventory research; this offers a basis for identifying the main topics and terms in the field. Text mining results are further investigated by statistical methods to identify key research areas and their evolution over time.","Literature review,Inventory research,Text mining,ISIR","KrisztinaDemetera,LeventeSzászb,AndreaKoc","International Journal of Production Economics","https://doi.org/10.1016/j.ijpe.2018.06.006","https://www.sciencedirect.com/science/article/pii/S0925527318302500"
"A98","Literature Listing","The quarterly Literature Listing is intended as a current awareness service for readers indicating newly published books, journal and conference articles on: patent search techniques, databases, analysis and classifications; patent searcher certification; patents relating to a) life sciences and pharmaceuticals and b) software; patent policy and strategic issues; trade marks; designs; domain names; and articles reviewing historical aspects of intellectual property or reviewing specific topics/persons. The current Literature Listing was compiled end February 2018. Key resources used are Scopus, Digital Commons, publishers' RSS feeds, and serendipity! Please feel free to send the author details of newly published reports/monographs/books for potential inclusion.","Patents,Designs,Trade marks,Literature listing,Patent analysis,Current awareness","SusanBates1","World Patent Information","https://doi.org/10.1016/j.wpi.2018.04.002","https://www.sciencedirect.com/science/article/pii/S0172219018300346"
"A99","Big data techniques in auditing research and practice: Current trends and future opportunities","This paper analyses the use of big data techniques in auditing, and finds that the practice is not as widespread as it is in other related fields. We first introduce contemporary big data techniques to promote understanding of their potential application. Next, we review existing research on big data in accounting and finance. In addition to auditing, our analysis shows that existing research extends across three other genealogies: financial distress modelling, financial fraud modelling, and stock market prediction and quantitative modelling. Auditing is lagging behind the other research streams in the use of valuable big data techniques. A possible explanation is that auditors are reluctant to use techniques that are far ahead of those adopted by their clients, but we refute this argument. We call for more research and a greater alignment to practice. We also outline future opportunities for auditing in the context of real-time information and in collaborative platforms and peer-to-peer marketplaces.","Auditing,Big data,Data analytics,Statistical techniques","AdrianGeppa,Martina K.Linnenlueckeb,Terrence J.O’Neilla,TomSmithb","Journal of Accounting Literature","https://doi.org/10.1016/j.acclit.2017.05.003","https://www.sciencedirect.com/science/article/pii/S0737460718300090"
"A100","A comparison of automated training-by-example selection algorithms for Evidence Based Software Engineering","ContextStudy search and selection is central to conducting Evidence Based Software Engineering (EBSE) research, including Systematic Literature Reviews and Systematic Mapping Studies. Thus, selecting relevant studies and excluding irrelevant studies, is critical. Prior research argues that study selection is subject to researcher bias, and the time required to review and select relevant articles is a target for optimization.,ObjectiveThis research proposes two training-by-example classifiers that are computationally simple, do not require extensive training or tuning, ensure inclusion/exclusion consistency, and reduce researcher study selection time: one based on Vector Space Models (VSM), and a second based on Latent Semantic Analysis (LSA).,MethodAlgorithm evaluation is accomplished through Monte-Carlo Cross-Validation simulations, in which study subsets are randomly chosen from the corpus for training, with the remainder classified by the algorithm. The classification results are then assessed for recall (a measure of completeness), precision (a measure of exactness) and researcher efficiency savings (reduced proportion of corpus studies requiring manual review as a result of algorithm use). A second smaller simulation is conducted for external validation.,Results and conclusionsVSM algorithms perform better in recall; LSA algorithms perform better in precision. Recall improves with larger training sets with a higher proportion of truly relevant studies. Precision improves with training sets with a higher portion of irrelevant studies, without a significant impact from the training set size. The algorithms reduce the influence of researcher bias and are found to significantly improve researcher efficiency.To improve recall, the findings recommend VSM and a large training set including as many truly relevant studies as possible. If precision and efficiency are most critical, the findings suggest LSA and a training set including a large proportion of truly irrelevant studies.","Research infrastructure,Evidence Based Software Engineering,Systematic Literature Review,Systematic Mapping Studies,Culling,VSM,LSA,Recall,Precision,Document selection","Edgar E.Hasslera,David P.Haleb,Joanne E.Haleb","Information and Software Technology","https://doi.org/10.1016/j.infsof.2018.02.001","https://www.sciencedirect.com/science/article/pii/S0950584917302896"
"A101","Local ensemble learning from imbalanced and noisy data for word sense disambiguation","Natural Language Processing plays a key role in man-machine interactions, allowing computers to understand and analyze human language. One of its more challenging sub-domains is word sense disambiguation, the task of automatically identifying the intended sense (or concept) of an ambiguous word based on the context in which the word is used. This requires proper feature extraction to capture specific data properties and a dedicated machine learning solution to allow for the accurate labeling of the appropriate sense. However, the pattern classification problem posed here is highly challenging, as we must deal with high-dimensional and multi-class imbalanced data that additionally may be corrupted with class label noise. To address these issues, we propose a local ensemble learning solution. It uses a one-class decomposition of the multi-class problem, assigning an ensemble of one-class classifiers to each of the distributions. The classifiers are trained on the basis of low-dimensional subsets of features and a kernel feature space transformation to obtain a more compact representation. Instance weighting is used to filter out potentially noisy instances and reduce overlapping among classes. Finally, a two-level classifier fusion technique is used to reconstruct the original multi-class problem. Our results show that the proposed learning approach displays robustness to both multi-class skewed distributions and class label noise, making it a useful tool for the considered task.","Machine learning,Natural language processing,Imbalanced classification,Multi-class imbalance,Ensemble learning,One-class classification,Class label noise,Word sense disambiguation","BartoszKrawczyk,Bridget T.McInnes","Pattern Recognition","https://doi.org/10.1016/j.patcog.2017.10.028","https://www.sciencedirect.com/science/article/pii/S0031320317304351"
"A102","A survey on data compression techniques: From the perspective of data quality, coding schemes, data type and applications","Explosive growth of data in digital world leads to the requirement of efficient technique to store and transmit data. Due to limited resources, data compression (DC) techniques are proposed to minimize the size of data being stored or communicated. As DC concepts results to effective utilization of available storage area and communication bandwidth, numerous approaches were developed in several aspects. In order to analyze how DC techniques and its applications have evolved, a detailed survey on many existing DC techniques is carried out to address the current requirements in terms of data quality, coding schemes, type of data and applications. A comparative analysis is also performed to identify the contribution of reviewed techniques in terms of their characteristics, underlying concepts, experimental factors and limitations. Finally, this paper insight to various open issues and research directions to explore the promising areas for future developments.","Data compression,Data redundancy,Text compression,Image compression,Information theory,Entropy encoding,Transform coding","J.Uthayakumar,T.Vengattaraman,P.Dhavachelvan","Journal of King Saud University - Computer and Information Sciences","https://doi.org/10.1016/j.jksuci.2018.05.006","https://www.sciencedirect.com/science/article/pii/S1319157818301101"
"A103","Identifying emerging Research and Business Development (R&BD) areas based on topic modeling and visualization with intellectual property right data","Although investments of R&D by government and firms have enlarged and the amount of patents has increased rapidly, R&D almost fails to commercialize for various reasons. For the purpose of decreasing failure rate of technology commercialization, it is important to identify emerging business based on technology in advance and establish appropriate strategy, leading to surviving at the market. Therefore, this paper aims to explore emerging Research and Business Development (R&BD) areas, and establish a business strategy based on valuable patents by comprehensively analyzing IPRs - patent as well as design and trademark. First, unrevealed but potential R&BD areas are explored by analyzing the relation between patent and trademark through topic modeling and network analysis, which aims to preferentially find potential business opportunities that can be implemented by new technology. Potential R&BD areas are recognized as the hidden link in the network of patents and trademarks. Second, emerging R&BD areas are selected by considering the status of the competition and markets through trademark analysis based on generative topographic mapping (GTM) after finding potential R&BD areas with network analysis from the viewpoint of the applicant for a trademark. Finally, new opportunities and strategies for successful R&BD are suggested by analyzing design patents that are representative of the appearance of a product in detail. The result of this study provides more concrete R&BD strategies within the framework of product and business development, based on relations between IPRs, which can be regarded as an initial study that comprehensively utilizes diverse kinds of IPRs.","Intellectual property management,Research and Business Development (R&BD),Network analysis,GTM,Topic modeling","YujinJeong,InchaePark,ByungunYoon","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.05.010","https://www.sciencedirect.com/science/article/pii/S0040162518300039"
"A104","A scientometric review of global research on sustainability and sustainable development","The concept of sustainable development has gained worldwide attention in recent years which had enhanced its implementation. However, few studies have attempted to map the global research of sustainability. This study utilizes scientometric review of global trend and structure of sustainability research in 1991–2016 using techniques such as co-author, co-word, co-citation, clusters, and geospatial analyses. A total of 2094 bibliographic records from the Web of Science database were analyzed to generate the study's research power networks and geospatial map. The findings reveal an evolution of the research field from the definition of its concepts in the Brundtland Commission report to the recent development of models and sustainability indicators. The most significant contributions in sustainability research have originated primarily from the United States, China, United Kingdom and Canada. Also, existing studies in sustainability research focus mainly on subject categories of environmental sciences, green & sustainable science technology, civil engineering, and construction & building technology. Emerging trends in sustainability research were sustainable urban development, sustainability indicators, water management, environmental assessment, public policy, etc.; while the study generated 21 co-citation clusters. This study provides its readers with an extensive understanding of the salient research themes, trends and pattern of sustainability research worldwide.","Sustainable development,Sustainability,Research trends,Scientometric,Built environment","Timothy O.Olawumi,Daniel W.M.Chan","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.02.162","https://www.sciencedirect.com/science/article/pii/S095965261830475X"
"A105","A review of statistically-based landslide susceptibility models","In this paper, we do a critical review of statistical methods for landslide susceptibility modelling and associated terrain zonations. Landslide susceptibility is the likelihood of a landslide occurring in an area depending on local terrain conditions, estimating “where” landslides are likely to occur. Since the first attempts to assess landslide susceptibility in the mid-1970s, hundreds of papers have been published using a variety of approaches and methods in different geological and climatic settings. Here, we critically review the statistically-based landslide susceptibility assessment literature by systematically searching for and then compiling an extensive database of 565 peer-review articles from 1983 to 2016. For each article in the literature database, we noted 31 categories/sub-categories of information including study region/extent, landslide type/number, inventory type and period covered, statistical model used, including variable types, model fit/prediction performance evaluation method, and strategy used to assess the model uncertainty. We present graphical visualisations and discussions of commonalities and differences found as a function of region and time, revealing a significant heterogeneity of thematic data types and scales, modelling approaches, and model evaluation criteria. We found that the range of thematic data types used for susceptibility assessment has not changed significantly with time, and that for a number of studies the geomorphological significance of the thematic data used is poorly justified. We also found that the most common statistical methods for landslide susceptibility modelling include logistic regression, neural network analysis, data-overlay, index-based and weight of evidence analyses, with an increasing preference towards machine learning methods in the recent years. Although an increasing number of studies in recent years have assessed the model performance, in terms of model fit and prediction performance, only a handful of studies have evaluated the model uncertainty. Adopting a Susceptibility Quality Level index, we found that the quality of published models has improved over the years, but top-quality assessments remain rare. We identified a clear geographical bias in susceptibility study locations, with many studies in China, India, Italy and Turkey, and only a few in Africa, South America and Oceania. Based on previous literature reviews, the analysis of the information collected in the literature database, and our own experience on the subject, we provide recommendations for the preparation, evaluation, and use of landslide susceptibility models and associated terrain zonations.","Literature review,Landslide,Susceptibility zonation,Statistical model","PaolaReichenbacha,MauroRossia,Bruce D.Malamudb,MonikaMihirbc,FaustoGuzzettia","Earth-Science Reviews","https://doi.org/10.1016/j.earscirev.2018.03.001","https://www.sciencedirect.com/science/article/pii/S0012825217305652"
"A106","Analysis of publication activity of computational science society in 2001–2017 using topic modelling and graph theory","This paper presents the results of topic modelling and analysis of topic networks using the corpus of the International Conference on Computational Science (ICCS), which contains 5982 domain-specific papers over seventeen years 2001–2017. We discuss the topical structures of ICCS, and show how these topics have evolved over time in response to the topicality of various domains, technologies and methods, and how all these topics relate to one another. This analysis illustrates the multidisciplinary research and collaborations among scientific communities, by constructing static and dynamic networks from the topic modelling results and from the authors’ keywords. The results of this study provide insights regarding the past and future trends of core discussion topics in computational science and show how “computational thinking” has propagated across different fields of study. We used the Non-negative Matrix Factorization (NMF) topic modelling algorithm to discover topics. The resulting topics were then manually labelled and grouped hierarchically on three levels. Next, we applied trend analysis and Change Point Analysis (CPA) to study the evolution of topics over seventeen years and to identify the growing and disappearing topics. We used Gephi to examine the static networks of topics, and an R library called DyA to analyse the dynamic networks of topics. We also analysed the conference as a platform for potential collaboration development through the perspective of collaboration networks. The results show that authors of ICCS papers continue to actively collaborate after the conference - on average authors collaborate with three other ICCS authors, - which suggests that ICCS is a valuable platform for collaboration development.","Topic modelling,Natural language processing,ICCS,Computational science,Graph theory,Collaboration networks","Tesfamariam M.Abuhaya,Sergey V.Kovalchuka,KlavdiyaBocheninaa,Gali-KetemaMbogoa,Alexander A.Visheratina,GeorgeKampisac,Valeria V.Krzhizhanovskayaab,Michael H.Leesab","Journal of Computational Science","https://doi.org/10.1016/j.jocs.2018.04.004","https://www.sciencedirect.com/science/article/pii/S1877750318302461"
"A107","Examining the usage, citation, and diffusion patterns of bibliometric mapping software: A comparative study of three tools","This study investigates the use, citation and diffusion of three bibliometric mapping software tools (CiteSpace, HistCite and VOSviewer) in scientific papers. We first conduct a content analysis of a sample of 481 English core journal papers—i.e., papers from journals deemed central to their respective disciplines—in which at least one of these tools is mentioned. This allows us to understand the predominant mention and citation practices surrounding these tools. We then employ several diffusion indicators to gain insight into the diffusion patterns of the three software tools. Overall, we find that researchers mention and cite the tools in diverse ways, many of which fall short of a traditional formal citation. Our results further indicate a clear upward trend in the use of all three tools, though VOSviewer is more frequently used than CiteSpace or HistCite. We also find that these three software tools have seen the fastest and most widespread adoption in library and information science research, where the tools originated. They have since been gradually adopted in other areas of study, initially at a lower diffusion speed but afterward at a rapidly growing rate.","Software citation,Bibliometric mapping software,Knowledge diffusion,Bibliometrics,Scholarly communication","XuelianPana,ErjiaYanb,MingCuia,WeinaHuaa","Journal of Informetrics","https://doi.org/10.1016/j.joi.2018.03.005","https://www.sciencedirect.com/science/article/pii/S1751157717303292"
"A108","Seagull: A bird’s-eye view of the evolution of technical games research","Within Entertainment Computing, games research has grown to be its own area, with numerous publication venues dedicated to it. As this area evolves, it is fruitful to examine its overall development—which subcommunities and research interests were present from the start, which have come and gone, and which are currently active—to better understand the research community as a whole and where it may proceed. In this paper, we present a data-driven analysis and interactive visualization tool to shed light on how technical domains within the games research field have evolved from 2000 to 2013, based on publication data from over 8000 articles collected from 48 games research venues, including Entertainment Computing, FDG, AIIDE, and DiGRA. The approach we present is descriptive. We first used data mining algorithms to group related papers into clusters of similar research topics and evolve these clusters over time. We then designed an interactive visualization system, named Seagull, comprised of Sankey diagrams that allow us to interactively visualize and examine the transition and coalescing of different clusters across time. We present our descriptive analysis in this paper and also contribute the visualization interface to allow other researchers to examine the data and develop their own analysis.","Games research,Games field mapping,Data-driven meta-analysis,Research community co-evolution,Game field visualization","Truong-Huy D.Nguyena,EdwardMelcerb,AlessandroCanossac,KatherineIsbisterd,MagySeif El-Nasre","Entertainment Computing","https://doi.org/10.1016/j.entcom.2018.02.002","https://www.sciencedirect.com/science/article/pii/S1875952117300289"
"A109","B-PO05-001 to B-PO05-240","","","","Heart Rhythm","https://doi.org/10.1016/j.hrthm.2018.03.028","https://www.sciencedirect.com/science/article/pii/S1547527118302492"
"A110","Emergence scoring to identify frontier R&D topics and key players","Indicators of technological emergence promise valuable intelligence to those determining R&D priorities. We present an implemented algorithm to calculate emergence scores for topical terms from abstract record sets. We offer a family of emergence indicators deriving from those scores. Primary emergence indicators identify “hot topic” terms. We then use those to generate secondary indicators that reflect organizations, countries, or authors especially active at frontiers in a target R&D domain. We also flag abstract records (papers or patents) rich in emergent technology content, and we score research fields on relative degree of emergence. This paper presents illustrative results for example topics – Nano-Enabled Drug Delivery, Non-Linear Programming, Dye Sensitized Solar Cells, and Big Data.","R&D assessment,R&D Indicators,Technology Emergence Indicators,Tech mining,Emerging technology","Alan L.Porterab,JonGarnerb,Stephen F.Carleyb,Nils C.Newmanb","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2018.04.016","https://www.sciencedirect.com/science/article/pii/S0040162517314804"
"A111","Learning the evolution of disciplines from scientific literature: A functional clustering approach to normalized keyword count trajectories","The growing availability of large diachronic corpora of scientific literature offers the opportunity of reading the temporal evolution of concepts, methods and applications, i.e., the history of disciplines involved in the strand under investigation. After a retrieval process of the most relevant keywords, bag-of-words approaches produce words<U+2009><U+202F>×<U+202F><U+2009>time-points contingency tables, i.e. the frequencies of each word in the set of texts grouped by time-points. Through the analysis of word counts over the observed period of time, main purpose of the study is, after reconstructing the “life-cycle” of words, clustering words that have similar life-cycles and, thus, detecting prototypical or exemplary temporal patterns. Unveiling such relevant and (through expert opinion) meaningful inner dynamics enables us to trace a historical narrative of the discipline of interest. However, different history readings are possible depending on the type of data normalization, which is needed to account for the fluctuating size of texts across time and the general problems of data sparsity and strong asymmetry. This study proposes a methodology consisting of (1) a stepwise information retrieval procedure for keywords’ selection and (2) a functional clustering two-stage approach for statistical learning. Moreover, a sample of possible normalizations of word frequencies is considered, showing that the different concept of curve similarity induced in clustering by the type of transformation heavily affects groups’ composition and size. The corpus of titles of scientific papers published by the American Statistical Association journals in the time span 1888–2012 is examined for illustration.","Diachronic corpora,Chronological textual data,Keyword retrieval,Curve clustering,Functional data analysis,Normalization","MatildeTrevisania,ArjunaTuzzib","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2018.01.035","https://www.sciencedirect.com/science/article/pii/S0950705118300510"
"A112","Community detection in networks: A multidisciplinary review","The modern science of networks has made significant advancement in the modeling of complex real-world systems. One of the most important features in these networks is the existence of community structure. In recent years, many community detection algorithms have been proposed to unveil the structural properties and dynamic behaviors of networks. In this study, we attempt a contemporary survey on the methods of community detection and its applications in the various domains of real life. Besides highlighting the strengths and weaknesses of each community detection approach, different aspects of algorithmic performance comparison and their testing on standard benchmarks are discussed. The challenges faced by community detection algorithms, open issues and future trends related to community detection are also postulated. The main goal of this paper is to put forth a review of prevailing community detection algorithms that range from traditional algorithms to state of the art algorithms for overlapping community detection. Algorithms based on dimensionality reduction techniques such as non-negative matrix factorization (NMF) and principal component analysis (PCA) are also focused. This study will serve as an up-to-date report on the evolution of community detection and its potential applications in various domains from real world networks.","Community detection,Clustering algorithms,Modularity,Anomaly detection,Online social networks","Muhammad AqibJaveda,Muhammad ShahzadYounisa,SiddiqueLatifab,JunaidQadirb,AdeelBaigac","Journal of Network and Computer Applications","https://doi.org/10.1016/j.jnca.2018.02.011","https://www.sciencedirect.com/science/article/pii/S1084804518300560"
"A113","Insights into relationships between disruptive technology/innovation and emerging technology: A bibliometric perspective","“Disruptive technology & disruptive innovation” have been of scholarly interest for years, but there is still a need to better understand the nature of disruptions and their relationship to emerging technology processes. This paper pursues these issues by analyzing the interplay of technological emergence, disruption, and innovation. Applying bibliometric methods, the paper explores the conceptual foundations, themes, and research communities within these research domains. The results highlight the multiple theoretical foundations of research around technological change processes, disruption, and emergence. These differences among the domains invite conceptual cross-fertilization and consideration of interdisciplinary approaches to technological (and commercial) emergence.","Disruptive technology,Disruptive innovation,Emerging technology,Bibliometric analysis,Co-citation,Bibliographic coupling","MunanLia,Alan L.Porterbc,ArhoSuominend","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2017.09.032","https://www.sciencedirect.com/science/article/pii/S0040162517314609"
"A114","A bibliometric analysis of creativity in the field of business economics","Creativity and its study in not a new topic. However, this concept has recently begun to be incorporated in business economic studies. The objective of the current study is to establish the results of creativity research in the scope of business economics. Using VOSviewer (Centre for Science and Technology Studies, Leiden University, Leiden, The Netherlands) and SciMAT (University of Granada, Spain) for the construction of scientific maps, the analysis of the most relevant studies in this field was conducted to establish how research has evolved in this area. The results show that initially, creativity was seen as an important skill of an individual and has gradually come to be recognized as a performance drive within organizations to serve as a basis for the development of various study models. The results presented in this study will enable future authors studying creativity to focus their studies more effectively.","Creativity,Business,Economic,Innovation,Bibliometric","MauricioCastillo-Vergara,AlejandroAlvarez-Marin,DarioPlacencio-Hidalgo","Journal of Business Research","https://doi.org/10.1016/j.jbusres.2017.12.011","https://www.sciencedirect.com/science/article/pii/S0148296317305052"
"A115","Bibliometrics: A Means of Visualizing Occupational Licensure Scholarship","ObjectiveThe aim of this study is to systematically identify, analyze, visualize, and interpret scholarship in this important domain.,MethodsThis study uses a bibliometric analysis of the articles published on occupational licensure in the peer-reviewed literature as indexed in bibliographic databases.,ResultsThe occupational licensure research is focused around the emergence of a number of areas of inquiry: educational preparation, economic impact, labor market entry, benefits of occupational licensure, adverse impacts on minority groups, and scope of practice. A single researcher is central to the literature and views the topic through an economic and labor-market participation lens.,ConclusionsThe absence of scholarship relating to public protection must be urgently addressed if occupational licensure models that are proportionate to the level of risk posed by the practitioner are to be developed and enforced.","Legislation,occupational licensure,professional regulation","David C.BentonPhD, RGN, FRCN, FAAN,Carmen A.CatizoneMS, RPh, DPh,Humayun J.ChaudhryDO, MS, MACP, MACOI,Stephen T.DeMersEdD,PaulGraceMS, CAE,William A.HatherillMHA,Mary JoMonahanMSW, LCSW","Journal of Nursing Regulation","https://doi.org/10.1016/S2155-8256(18)30052-8","https://www.sciencedirect.com/science/article/pii/S2155825618300528"
"A116","Past themes and future trends in medical tourism research: A co-word analysis","The purpose of this paper is to analyze the evolution of medical tourism (MT) research from a longitudinal perspective (period 1931–2016). A co-word analysis was applied to themes found in published research listed in the Web of Science (WoS) and Scopus database services.The results reveal six clusters of themes: a) issues regarding ethical implications, trust and accreditation; b) health, wellness, spa tourism and service quality; c) health-related issues, medical treatments and tourism; d) “sensitive” practices in MT; e) medical tourism destinations and marketing; and f) globalization, policies and the effect on international patients. This study is one of the first attempts to use a bibliometric approach and co-word analysis so as to offer powerful insight into the conceptual structure of MT research from academic literature and to visualize all the underlying and interconnected subfields. It also provides a guide to researchers by improving the understanding of the current state of the art and predicting the direction of future research.","Bibliometric analysis,Co-word analysis,Thematic evolution,Medical tourism,Health tourism","Andreade la Hoz-Correaa,FranciscoMuñoz-Leivaa,MártaBakuczb","Tourism Management","https://doi.org/10.1016/j.tourman.2017.10.001","https://www.sciencedirect.com/science/article/pii/S0261517717302200"
"A117","“A tie is a tie? Gender and network positioning in life science inventor collaboration”","Collaborative relationships are an important anchor of innovative activity, and rates of collaboration in science are on the rise. This research addresses differences in men’s and women’s collaborative positioning and collaborator characteristics in science, and whether network influences on scientists’ future productivity may be contingent on gender. Utilizing co-inventor network relations that span thirty years of global life science patenting across sectors, geographic locations, and technological background, I present trends of men’s and women’s involvement in patenting and their collaborative characteristics across time. Amidst some network similarities, women are less likely to connect otherwise unconnected inventors (brokerage) and have greater status-asymmetries between themselves and their co-inventors. In multivariate models that include past and future activity, I find that some network benefits are contingent on gender. Men receive greater returns from network positioning for brokerage ties, and when collaborating with men. Women benefit from collaborating with women, and are more likely to collaborate with women, but both men and women collaborate with mostly men. I discuss the implications of these results for innovative growth, as well as for policies that support men’s and women’s career development.","031,L26,D85,J16,Keywords,Commercial science,Collaboration,Women,Science workforce,Networks","Kjersten BunkerWhittington","Research Policy","https://doi.org/10.1016/j.respol.2017.12.006","https://www.sciencedirect.com/science/article/pii/S0048733317302123"
"A118","Critical evaluation of off-site construction research: A Scientometric analysis","Practical interest in ‘off-site construction’ has risen remarkably over the last decade, and with it there has been a burgeoning of academic research in the field. Complementing this research, a number of literature reviews have been conducted. None, however, are systematic. This study addresses this lack, offering the first bibliometric study to explore the state of off-site construction research (OCR). A quantitative approach using ‘science mapping’ techniques is employed to examine 501 top-ranked construction journal articles. Longitudinal trends in publishing are identified, as are dominant research sub-fields, their connectedness with other areas of study, as well as citation patterns, publication journal areas of focus, key research institutions, key research persons, along with the extent to which these interact with each other in research networks. The findings are instructive in identifying the deficiencies in current research. Among these is a bias towards product research over operations and management, and a sharp compartmentalization of sub-fields, with little or no cross-fertilization between researcher areas, the researchers themselves, nor the research institutions. Clearly, this awareness will inform industry, journal editors and researchers of the need for a deeper exchange of ideas in any future research efforts.","Off-site construction,Research,Critical review,Scientometric analysis,Bibliometric","M. RezaHosseinia,IgorMarteka,Edmundas KazimierasZavadskasb,Ajibade A.Aibinuc,MehrdadArashpourd,NicholasChileshee","Automation in Construction","https://doi.org/10.1016/j.autcon.2017.12.002","https://www.sciencedirect.com/science/article/pii/S092658051730609X"
"A119","Concept coupling learning for improving concept lattice-based document retrieval","The semantic information in any document collection is critical for query understanding in information retrieval. Existing concept lattice-based retrieval systems mainly rely on the partial order relation of formal concepts to index documents. However, the methods used by these systems often ignore the explicit semantic information between the formal concepts extracted from the collection. In this paper, a concept coupling relationship analysis model is proposed to learn and aggregate the intra- and inter-concept coupling relationships. The intra-concept coupling relationship employs the common terms of formal concepts to describe the explicit semantics of formal concepts. The inter-concept coupling relationship adopts the partial order relation of formal concepts to capture the implicit dependency of formal concepts. Based on the concept coupling relationship analysis model, we propose a concept lattice-based retrieval framework. This framework represents user queries and documents in a concept space based on fuzzy formal concept analysis, utilizes a concept lattice as a semantic index to organize documents, and ranks documents with respect to the learned concept coupling relationships. Experiments are performed on the text collections acquired from the SMART information retrieval system. Compared with classic concept lattice-based retrieval methods, our proposed method achieves at least 9%, 8% and 15% improvement in terms of average MAP, IAP@11 and P@10 respectively on all the collections.","Fuzzy formal concept analysis,Lattice-based document retrieval,Coupling relationship","ShufengHaoa,ChongyangShia,ZhendongNiua,LongbingCaob","Engineering Applications of Artificial Intelligence","https://doi.org/10.1016/j.engappai.2017.12.007","https://www.sciencedirect.com/science/article/pii/S0952197617303020"
"A120","Identifying promising technologies using patents: A retrospective feature analysis and a prospective needs analysis on outlier patents","This study suggests a patent-based methodology for identifying emerging technologies by combining a retrospective technological feature analysis and a prospective market-needs analysis. To do this, first, the candidate promising technologies were identified by applying bibliographic coupling to patents, thus producing a list of outlier patents. Then, the measures to evaluate both technological and market characteristics of the candidate technologies were developed, where retrospective patent analysis and sentiment analysis on customer opinions are required. Finally, the candidate technologies are mapped onto two-dimensional space according to the values of the two measures; the final promising technologies are determined to be those that have high values for either technological characteristics or market characteristics. The suggested methodology was applied to an automobile industry, through which its feasibility and usability were verified. This study is one of the few studies to develop technology-evaluation measures based on an ad-hoc analysis of technological characteristics. In addition, it attempts to link patent databases to market databases, aiming to directly reflect customer needs to evaluate the potential of a technology in a market. The approach suggested in this study can be applied to recent patents with little citation information for assessing their value to be deemed as promising technologies; this is expected to contribute both academically and practically to the existing literature on patent analysis.","Promising technology,Retrospective,Prospective,Outlier patent,Needs,Feature","KisikSonga,KyuwoongKimb,SungjooLeec","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2017.11.008","https://www.sciencedirect.com/science/article/pii/S0040162517303542"
"A121","Full Issue PDF","","","","JACC: Cardiovascular Imaging","https://doi.org/10.1016/S1936-878X(18)30154-2","https://www.sciencedirect.com/science/article/pii/S1936878X18301542"
"A122","The relationship between urban forests and race: A meta-analysis","There is ample evidence that urban trees benefit the physical, mental, and social health of urban residents. The environmental justice hypothesis posits that environmental amenities are inequitably low in poor and minority communities, and predicts these communities experience fewer urban environmental benefits. Some previous research has found that urban forest cover is inequitably distributed by race, though other studies have found no relationship or negative inequity. These conflicting results and the single-city nature of the current literature suggest a need for a research synthesis. Using a systematic literature search and meta-analytic techniques, we examined the relationship between urban forest cover and race. First, we estimated the average (unconditional) relationship between urban forest cover and race across studies (studies = 40; effect sizes = 388). We find evidence of significant race-based inequity in urban forest cover. Second, we included characteristics of the original studies and study sites in meta-regressions to illuminate drivers of variation of urban forest cover between studies. Our meta-regressions reveal that the relationship varies across racial groups and by study methodology. Models reveal significant inequity on public land and that environmental and social characteristics of cities help explain variation across studies. As tree planting and other urban forestry programs proliferate, urban forestry professionals are encouraged to consider the equity consequences of urban forestry activities, particularly on public land.","Meta-analysis,Environmental equity,Environmental racism,Urban vegetation,Street trees","Shannon LeaWatkinsa,EdGerrishb","Journal of Environmental Management","https://doi.org/10.1016/j.jenvman.2017.12.021","https://www.sciencedirect.com/science/article/pii/S0301479717311830"
"A123","Forty years of coastal zone management (1975–2014): Evolving theory, policy and practice as reflected in scientific research publications","Since its implementation as public law in the United States in 1972, the theoretical foundation of coastal management has moved forward in diverse directions. Given the time elapsed since the passage of this influential legislation and the growing number of disciplines and scientific papers published on the topic, this work employed bibliometric and social network analysis methods to quantitatively and qualitatively assess coastal management literature published during the period from 1975-2014. The results indicate that coastal management research has increased significantly over time. The emergence of the topic in scholarly work coincides with passage of the Coastal Zone Management Act of 1972 (US Public Law 92–583), and increases in productivity can often be tied to the passage of important legislation or the publication of major policy documents for action on coastal issues. Social network analyses (SNA) indicate loosely connected networks of researchers and institutions, with highly collaborative subgroups that have a significant impact on the field. SNA results also highlight the importance of federal governments and international organizations in driving research and encouraging integrated management. The results indicate that the discipline is evolving to focus more on cross-boundary management strategies, systems perspectives, and consideration of both marine and terrestrial environments.","Coastal zone management,Bibliometrics,Social network analysis,Research trends","TraciBircha,EnriqueReyesb","Ocean & Coastal Management","https://doi.org/10.1016/j.ocecoaman.2017.12.003","https://www.sciencedirect.com/science/article/pii/S0964569117307160"
"A124","Contemporary corporate eco-innovation research: A systematic review","Interest in eco-innovation in the corporate environment has grown considerably in recent years. Given the profound role of eco-innovation, it is therefore important to obtain a better understanding on the latest research progress in the academia and the recent organizational efforts in practice. This review paper addresses this need and contributes to the current literature in three ways. First, this paper presents a descriptive overview on eco-innovation in the corporate environment by examining 395 representative articles published from 2006 to 2015, collected from the Social Citation Index Expanded and Social Sciences Citation Index databases. The characteristics of the terminologies and journals, prevailing themes and changes, the geographical location of prolific authors and main geographical context of research studies in eco-innovation are identified to unravel the evolution of the concerned research studies and institutional contexts. Second, by using co-word and social network analyses, this study finds that the current literature on eco-innovation in the corporate environment is mainly focused on nine areas, including the influence of stakeholders, drivers of eco-innovation, eco-innovation systems, eco-design, new product developments, product service systems, environmental management systems, green supply chain management, and performance & small medium enterprises (SMEs). Third, this study provides an extended conceptual framework that incorporates the notion of ‘driver<U+2192>source<U+2192>position<U+2192>performance’ (D<U+2192>S<U+2192>P<U+2192>P) to find the relationships among the research topics in the eco-innovation field. This framework allows examination of the overall strategies for eco-innovation in the corporate environment so that a firm can gain a competitive edge through their adoption, implementation, assessment, and investment. This systematic review will benefit practitioners and academics by providing the major strands of research in the current studies on eco-innovation. This study also provides insights into four distinctive features of eco-innovation in the corporate environment as well as research gaps of recent eco-innovation studies. This study thus provides future research directions for subsequent eco-innovation research, as well as insights for managers and policy makers on how to enhance and strategize strategies for eco-innovation in the corporate environment.","Eco-innovation in corporate environment,Co-word analysis,Social network analysis,Cluster analysis,Driver-source-position-performance framework","FangHea,XinMiaoa,Christina W.Y.Wongb,StacyLeeb","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2017.10.314","https://www.sciencedirect.com/science/article/pii/S0959652617326215"
"A125","Deriving technology intelligence from patents: Preposition-based semantic analysis","Patents are one of the most reliable sources of technology intelligence, and the true value of patent analysis stems from its capability of describing the content of technology based on the relationships between keywords. To date a number of techniques for analyzing the information contained in patent documents that focus on the relationships between keywords have been suggested. However, a drawback of the existing keyword approaches is that they cannot yet determine the types of relationships between the keywords. This study proposes a novel approach based on preposition semantic analysis network which overcomes the limitations of the existing keywords-based network analysis and demonstrates its potential through an application. A preposition is a word that defines the relationship between two neighboring words, and, in the case of patents, prepositions aid in revealing the relationships between keywords related to technologies. To demonstrate the approach, patents regarding an electric vehicle were employed. 13 prepositions were identified which could be used to define 5 relationships between neighboring technological terms: “inclusion (utilization),” “objective (purpose),” “effect,” “process,” and “likeness.” The proposed approach is expected to improve the usability of keyword-based patent analyses and support more elaborate studies on patent documents.","Technology intelligence,Technology search,Technology trends,Patent analysis,Semantic,Preposition,Text mining,Key-words,Text mining","JaehyeongAna,KyuwoongKimb,LetiziaMortarac,SungjooLeeb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2018.01.001","https://www.sciencedirect.com/science/article/pii/S1751157716303777"
"A126","Bibliometric approximation of a scientific specialty by combining key sources, title words, authors and references","Bibliometric methods for the analysis of highly specialized subjects are increasingly investigated and debated. Information and assessments well-focused at the specialty level can help make important decisions in research and innovation policy. This paper presents a novel method to approximate the specialty to which a given publication record belongs. The method partially combines sets of key values for four publication data fields: source, title, authors and references. The approach is founded in concepts defining research disciplines and scholarly communication, and in empirically observed regularities in publication data. The resulting specialty approximation consists of publications associated to the investigated publication record via key values for at least three of the four data fields. This paper describes the method and illustrates it with an application to publication records of individual scientists. The illustration also successfully tests the focus of the specialty approximation in terms of its ability to connect and help identify peers. Potential tracks for further investigation include analyses involving other kinds of specialized publication records, studies for a broader range of specialties, and exploration of the potential for diverse applications in research and research policy context.","Scientific specialty,Scholarly communication,Bibliometrics,Scientific peers","NadineRons","Journal of Informetrics","https://doi.org/10.1016/j.joi.2017.12.003","https://www.sciencedirect.com/science/article/pii/S1751157716303571"
"A127","Analysis of the intellectual structure of human space exploration research using a bibliometric approach: Focus on human related factors","Human space exploration (HSE) is an interdisciplinary field composed of a range of subjects that have developed dramatically over the last few decades. This paper investigates the intellectual structure of HSE research with a focus on human related factors. A bibliometric approach with quantitative analytical techniques is applied to study the development and growth of the research. This study retrieves 1921 papers on HSE related to human factors from the year 1990 to the year 2016 from Web of Science and constructs a critical citation network composed of 336 papers. Edge-betweenness-based clustering is used to classify the citation network into twelve distinct research clusters based on four research themes: “biological risks from space radiation,” “health and performance during long-duration spaceflight,” “program and in-situ resources for HSE missions,” and “habitat and life support systems in the space environment.” These research themes are also similar to the classification results of a co-occurrence analysis on keywords for a total of 1921 papers. Papers with high centrality scores are identified as important papers in terms of knowledge flow. Moreover, the intermediary role of papers in exchanging knowledge between HSE sub-areas is identified using brokerage analysis. The key-route main path highlights the theoretical development trajectories. Due to the recent dramatic increase in investment by international governments and the private sector, the theoretical development trajectories of key research themes have been expanding from furthering scientific and technical knowledge to include various social and economic issues, thus encouraging massive public participation. This study contributes to an understanding of research trends and popular issues in the field of HSE by introducing a powerful way of determining major research themes and development trajectories. This study will help researchers seek the underlying knowledge diffusion flow from multifaceted aspects to establish future research directions.","Human space exploration,Bibliometrics,Citation analysis,Social network analysis,Co-word analysis,Abbreviations,BCbetween centrality,BCMbiological countermeasures,BPBonacich power centrality,CCcloseness centrality,CPMcritical path method,Ddegree,DCdegree centrality,EDLentry, descent, and landing,GCRgalactic cosmic rays,HSEhuman space exploration,ISRUin-situ resource utilization,ISSinternational space station,LEOlow earth orbit,LSSlife support system,PRpagerank,SNAsocial network analysis,SPCsearch path count,SPEsolar particle event,SPLCsearch path link count,WOSweb of science","Tai SikLeea,Yoon-SunLeeb,JaehoLeeb,Byung ChulChangb","Acta Astronautica","https://doi.org/10.1016/j.actaastro.2017.11.032","https://www.sciencedirect.com/science/article/pii/S0094576517313498"
"A128","Bibliometric analysis of fuzzy theory research in China: A 30-year perspective","The past half-century has witnessed fast development in the field of fuzzy theory (FT), however, few researches have focused on mapping the development of this area in China. Based on the samples of 12,936 publications authored by Chinese scholars on FT researches during the past 30 years, this paper intends to explore the patterns and dynamics by analyzing the geographic distribution of publications, international collaboration, research hot spot, subject categories and journals, and publication contributors. The results indicate that the scientific publications are highly unbalanced at regional levels in China, and the USA is China's most important partner in FT cooperative researches. Collaborations are not indispensable for high-quality research outputs in FT area. The existing researches in the field of FT from Chinese scholars focus primarily on Computer Science and Engineering. The emerging trends of FT researches from Chinese scholars have shifted away from basic FT researches to the applications, such as the areas of decision making, optimization, modeling and design.","Fuzzy theory (FT),China,Bibliometric analysis,Co-citation analysis,Research trends","YuDejianab,XuZeshuibc,WangWanrud","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2017.11.018","https://www.sciencedirect.com/science/article/pii/S0950705117305403"
"A129","Bibliographic and comparative analyses to explore emerging classic texts in megaproject management","Megaproject management (MPM) is a highly complex emerging research field with fragmental and diversified traits. Understanding the work on MPM and its classic texts can help advance the current body of knowledge significantly. However, to date, few quantitative methods exist that can determine the classic texts in MPM. This study aims to investigate the potential emergence of studies on MPM on the basis of bibliometric techniques. We conducted a bibliographic meta-network analysis for the most cited classic texts in five selected management theories as a reference group. By comparing the results from the reference group and from MPM, we identified and discussed several key features in the current MPM studies. This study bridges the gap in the quantitative identification and evaluation of classic texts in MPM theory, and lays out a road map for the future development of MPM theory.","Bibliometric analysis,Classic texts,Megaproject management,Meta-network analysis,Project management theory,Theory development","YongkuiLia,YujieLub,John E.Taylorc,YilongHanb","International Journal of Project Management","https://doi.org/10.1016/j.ijproman.2017.05.008","https://www.sciencedirect.com/science/article/pii/S0263786317306397"
"A130","The evolution of sentiment analysis—A review of research topics, venues, and top cited papers","Sentiment analysis is one of the fastest growing research areas in computer science, making it challenging to keep track of all the activities in the area. We present a computer-assisted literature review, where we utilize both text mining and qualitative coding, and analyze 6996 papers from Scopus. We find that the roots of sentiment analysis are in the studies on public opinion analysis at the beginning of 20th century and in the text subjectivity analysis performed by the computational linguistics community in 1990’s. However, the outbreak of computer-based sentiment analysis only occurred with the availability of subjective texts on the Web. Consequently, 99% of the papers have been published after 2004. Sentiment analysis papers are scattered to multiple publication venues, and the combined number of papers in the top-15 venues only represent ca. 30% of the papers in total. We present the top-20 cited papers from Google Scholar and Scopus and a taxonomy of research topics. In recent years, sentiment analysis has shifted from analyzing online product reviews to social media texts from Twitter and Facebook. Many topics beyond product reviews like stock markets, elections, disasters, medicine, software engineering and cyberbullying extend the utilization of sentiment analysis.","Sentiment analysis,Opinion mining,Bibliometric study,Text mining,Literature review,Topic modeling,Latent Dirichlet Allocation,Qualitative analysis","Mika V.Mäntyläa,DanielGraziotinb,MiikkaKuutilaa","Computer Science Review","https://doi.org/10.1016/j.cosrev.2017.10.002","https://www.sciencedirect.com/science/article/pii/S1574013717300606"
"A131","New firm formation and regional knowledge production modes: Italian evidence","According to the knowledge-spillovers theory of entrepreneurship (KSTE), local knowledge spillovers affect entrepreneurial dynamics, because of knowledge asymmetries and uncertainty. Most of the empirical literature has tested this hypothesis using a measure of local knowledge stock. This paper is aimed at extending the framework by showing that the domains over which local knowledge spans are also important. The paper investigates the impact of the configuration of local knowledge bases on new firm formation dynamics by combining the KSTE framework with the recombinant knowledge approach. Local knowledge bases emerge from the combination of different knowledge inputs. These inputs may be closely or loosely related to one another. Technological differentiation and the relatedness degree of local competences can be interpreted as characteristics of the local knowledge base interacting with the knowledge filter and the entrepreneurial absorptive capacity. The paper proposes a taxonomy of regional modes of knowledge production and investigates new firm formation in 92 Italian NUTS 3 regions observed over the 1995–2009 time span. The results confirm that the availability of local knowledge pools is important, and show that the ‘rich integration’ mode is the configuration that favours the entrepreneurial process. Finally, the policy implications and avenues for further research are presented and discussed.","L26,M13,R11,O33,Keywords,New firm formation,Knowledge-spillovers theory of entrepreneurship,Recombinant knowledge,Absorptive capacity,Knowledge filter,Technological relatedness,Variety","AlessandraColombelliabc,FrancescoQuatraroac","Research Policy","https://doi.org/10.1016/j.respol.2017.10.006","https://www.sciencedirect.com/science/article/pii/S0048733317301762"
"A132","The literature landscape on 1.5°C climate change and cities","","","William FLamb1,Max WCallaghan12,FelixCreutzig13,RadhikaKhosla4,Jan CMinx1","Current Opinion in Environmental Sustainability","https://doi.org/10.1016/j.cosust.2018.02.008","https://www.sciencedirect.com/science/article/pii/S1877343517301434"
"A133","Co-mention network of R packages: Scientific impact and clustering structure","Despite its rising position as a first-class research object, scientific software remains a marginal object in studies of scholarly communication. This study aims to fill the gap by examining the co-mention network of R packages across all Public Library of Science (PLoS) journals. To that end, we developed a software entity extraction method and identified 14,310 instances of R packages across the 13,684 PLoS journal papers mentioning or citing R. A paper-level co-mention network of these packages was visualized and analyzed using three major centrality measures: degree centrality, betweenness centrality, and PageRank. We analyzed the distributive patterns of R packages in all PLoS papers, identified the top packages mentioned in these papers, and examined the clustering structure of the network. Specifically, we found that the discipline and function of the packages can partly explain the largest clusters. The present study offers the first large-scale analysis of R packages’ extensive use in scientific research. As such, it lays the foundation for future explorations of various roles played by software packages in the scientific enterprise.","R,Open software,Scientometrics,Network analysis,Co-mention analysis","KaiLi,ErjiaYan","Journal of Informetrics","https://doi.org/10.1016/j.joi.2017.12.001","https://www.sciencedirect.com/science/article/pii/S1751157717304108"
"A134","Profiling research of the engineering academics who successfully promote education in Sustainable Human Development","Over the last decades, engineering faculties and universities have become increasingly engaged in integrating sustainable development into their different functions. Notwithstanding, more effort is required to effectively integrate sustainability principles as a whole-university approach, and specifically, in technical universities. Scientific literature highlights the main barriers to the success of initiatives that address this shortcoming. A better understanding of the scientific profile of the academics who engage in sustainable development activities can help to develop and promote initiatives for increasing faculty engagement in all academic functions. For this purpose, this study presents a bibliometric analysis of the scientific production of an academic community involved in a European initiative aimed at capacitating engineering academics for sustainable development. Specifically, two groups of academics with different degrees of expertise and involvement in sustainable development were characterized and compared, revealing common trends and similarities of their research production. The results have different implications for future strategies aimed at engaging specific academic profiles in the field of engineering, highlighting especially health science–related fields linked with engineering as a potential opportunity of promoting the integration of sustainable development in engineering education. Further analysis is required to determine the university rankings and their potential implications for the integration of sustainable development, as well as appropriate policies and mechanisms of faculty rewarding and promotion.","Sustainable development,Bibliometrics,Global dimension,Engineering,Interdisciplinary research","BorisLazzarinia,AgustíPérez-Foguetb","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2017.08.234","https://www.sciencedirect.com/science/article/pii/S0959652617319789"
"A135","Chapter 14: Evolution Map of Wearable Technology Patents for Healthcare Field","Wearable technology comprises all products that can be worn on a user’s body to integrate computing with their daily tasks and activities. The technology includes a wide range of devices and applications that help in collecting and displaying real-time health, motion, and other sensory data. From the business side it can be said that, wearable technology has emerged as one of the fastest growing segments in the high-tech market. Increasing with a compound annual growth rate (CAGR) of 42.6%, the sales of wearable devices are expected to reach around 155.7 million units in 2019. Wearable technology patents for application in the fields of healthcare and medical devices have the highest number of patent filings, followed garments/body wear. For consumers the interest in quantifying, monitoring, and improving health metrics has translated into a huge demand for fitness trackers and smart watches. Hence the aim of the study is to understand the evolution and dispersion of wearable technology patents in medical field and identify the future trend. Patent analysis will be used as methodology and scenario development is utilized for future projection. Finally, it can be asserted that ideas registered in the field of wearable health technologies are concentrated in the framework of methods and techniques (A61B) and methods of diagnosis. This can be interpreted as an increase in the need to diagnose human health with real-time healthcare follow-up. Depending on the Internet of Things it is obvious that the system architecture and the information architecture that are needed for the wearable health technologies to work harmoniously. The integration is the key issue to work wearable health technologies in an interoperable way.","Wearable technologies,wearables,healthcare,health,medical devices,patent analysis","SerhatBurmaoglu1,VladimirTrajkovik2,Tatjana LoncarTutukalo3,HaydarYalcin4,BrianCaulfield5","Wearable Technology in Medicine and Health Care,Wearable Technology in Medicine and Health Care","https://doi.org/10.1016/B978-0-12-811810-8.00014-2","https://www.sciencedirect.com/science/article/pii/B9780128118108000142"
"A136","Chapter 7: The Intellectual Structure and Outlooks for Individual Creativity Research: A Bibliometric Analysis for the Period 1950–2016","The aim of this chapter is to present a dynamic perspective of formal scholarly communication through publications by conducting a bibliometric analysis based on cocitation and bibliographic coupling techniques. As such, this study examines how scholarly research in the creativity field has evolved from 1950 to 2016. The cocitation analysis is combined with network visualization by using the most cited articles in different periods portraying the patterns of development of the creativity field based on the ISI Web of Science database. We therefore outline the key articles, authors, and theoretical influxes into the creativity field, and further interpret them using the framework of “invisible colleges.” We complement this analysis of the historical development of the creativity research with the portrayal of the current state of the art of the creativity field based on bibliographic coupling, additionally comparing it to the current developments in its subfield of individual creativity. Based on this analysis, the chapter ends with specific suggestions for further research that could drive this field further.","Creativity,Bibliometric analysis,Cocitation analysis,Bibliographic coupling,“Invisible colleges” framework","SabinaBogilovic*,MatejCerne†","Individual Creativity in the Workplace,Individual Creativity in the Workplace","https://doi.org/10.1016/B978-0-12-813238-8.00007-3","https://www.sciencedirect.com/science/article/pii/B9780128132388000073"
"A137","Chapter 4: Behavioral Corporate Finance","Behavioral Corporate Finance provides new and testable explanations for long-standing corporate-finance puzzles in mergers, investment-cash flow sensitivity, and fads in equity financing or dividend payments. The research applies by applying insights from psychology to the behavior of investors, managers, and third parties (e.g., analysts or bankers). corporate finance decisions. capital-structure decisions. This chapter gives an overview of the three leading streams of research and quantifies publication output and trends in the field. It emphasizes how Behavioral Corporate Finance has contributed to the broader field of Behavioral Economics. One contribution arises from the identification of biased behavior (also) in successful professionals, such as CEOs, entrepreneurs, or analysts. This evidence constitutes a significant departure from the prior focus on individual investors and consumers, where biases could be interpreted as ‘low ability,’ and it implies development of much broader applicability and implications of behavioral biases. A related contribution is the emphasis on individual heterogeneity, i.e., the careful consideration of the type of biases that are plausible for which type of individual and situation.","Behavioral corporate,Managerial biases,Investor biases,Behavioral CEOs,Corporate response","UlrikeMalmendier<U+204E>†","Handbook of Behavioral Economics: Applications and Foundations 1","https://doi.org/10.1016/bs.hesbe.2018.08.001","https://www.sciencedirect.com/science/article/pii/S2352239918300083"
"A138","Data exfiltration: A review of external attack vectors and countermeasures","ContextOne of the main targets of cyber-attacks is data exfiltration, which is the leakage of sensitive or private data to an unauthorized entity. Data exfiltration can be perpetrated by an outsider or an insider of an organization. Given the increasing number of data exfiltration incidents, a large number of data exfiltration countermeasures have been developed. These countermeasures aim to detect, prevent, or investigate exfiltration of sensitive or private data. With the growing interest in data exfiltration, it is important to review data exfiltration attack vectors and countermeasures to support future research in this field.,ObjectiveThis paper is aimed at identifying and critically analysing data exfiltration attack vectors and countermeasures for reporting the status of the art and determining gaps for future research.,MethodWe have followed a structured process for selecting 108 papers from seven publication databases. Thematic analysis method has been applied to analyse the extracted data from the reviewed papers.,ResultsWe have developed a classification of (1) data exfiltration attack vectors used by external attackers and (2) the countermeasures in the face of external attacks. We have mapped the countermeasures to attack vectors. Furthermore, we have explored the applicability of various countermeasures for different states of data (i.e., in use, in transit, or at rest).,ConclusionThis review has revealed that (a) most of the state of the art is focussed on preventive and detective countermeasures and significant research is required on developing investigative countermeasures that are equally important; (b) Several data exfiltration countermeasures are not able to respond in real-time, which specifies that research efforts need to be invested to enable them to respond in real-time (c) A number of data exfiltration countermeasures do not take privacy and ethical concerns into consideration, which may become an obstacle in their full adoption (d) Existing research is primarily focussed on protecting data in ‘in use’ state, therefore, future research needs to be directed towards securing data in ‘in rest’ and ‘in transit’ states (e) There is no standard or framework for evaluation of data exfiltration countermeasures. We assert the need for developing such an evaluation framework.","Data exfiltration,Data leakage,Data theft,Data breach,External attack vector,Countermeasure","FaheemUllahab,MatthewEdwardsc,RajivRamdhanyd,RuzannaChitchyanc,M. AliBabarab,AwaisRashidc","Journal of Network and Computer Applications","https://doi.org/10.1016/j.jnca.2017.10.016","https://www.sciencedirect.com/science/article/pii/S1084804517303569"
"A139","Chapter Two: Linking DNA Metabarcoding and Text Mining to Create Network-Based Biomonitoring Tools: A Case Study on Boreal Wetland Macroinvertebrate Communities","Ecological networks are powerful tools for visualizing biodiversity data and assessing ecosystem health and function. Constructing these networks requires considerable empirical efforts, and this remains highly challenging due to sampling limitations and the laborious and notoriously limited, error-prone process of traditional taxonomic identification. Recent advancements in high-throughput gene sequencing and high-performance computing provide new ways to address these challenges. DNA metabarcoding, a method of bulk taxonomic identification from DNA extracted from environmental samples, can generate detailed biodiversity information through a standardizable analytical pipeline for species detection. When this biodiversity information is annotated with prior knowledge on taxon interactions, body size, and trophic position, it is possible to generate trait-based networks, which we call “heuristic food webs”. Although curating trait matrices for constructing heuristic food webs is a laborious, often intractable process using manual literature surveys, it can be greatly accelerated via text mining, allowing knowledge of relevant traits to be gathered across large databases. To explore this possibility, we employed a General Architecture for Text Engineering (GATE) system to create a hybrid text-mining pipeline combining rule-based and machine-learning modules. This pipeline was then used to query online repositories of published papers for missing data on a key trait, body size, that could not be gathered from existing trophic link libraries of freshwater benthic macroinvertebrates. Combining text-mined body size information with feeding information from existing sources allowed us to generate a database of over 20,000 pairwise trophic interactions. Next, we developed a pipeline that uses taxa lists generated from DNA metabarcoding and annotates this matrix with trophic information from existing databases and text-mined body size data. In this way, we generated heuristic food webs for wetland sites within a large delta complex formed by the confluence of the Peace and Athabasca rivers in northern Alberta: the Peace–Athabasca delta. Finally, we used these putative food webs and their network properties to resolve spatial and temporal differences between the benthic subwebs of wetlands in the Peace and Athabasca sectors of the delta complex. Specifically, we asked two questions. (1) How do food web properties (e.g. number of links, linkage density, trophic height) differ between the wetlands of the Peace and Athabasca deltas? (2) How do food web properties change temporally in wetlands of the two deltas? We discuss using DNA-generated, trait-based food webs as a powerful tool for rapid bioassessment, assess the limitations of our current approach, and outline a path forward to make this powerful tool more widely available for land managers and conservation biologists.","Benthic macroinvertebrates,Bioassessment,Body size,DNA metabarcoding,Ecological network,Traits,Food web,Freshwater,Text mining,Traits,Trophic links","Zacchaeus G.Compson*†,Wendy A.Monk†‡,Colin J.Curry§,DominiqueGravel¶,AlexBush*†,Christopher J.O.Baker<U+2016>#,Mohammad SadnanAl Manir<U+2016>,AlexandreRiazanov<U+2016>,MehrdadHajibabaei**,ShadiShokralla**,Joel F.Gibson††,SonjaStefani‡‡,Michael T.G.Wright**,Donald J.Baird*†","Advances in Ecological Research","https://doi.org/10.1016/bs.aecr.2018.09.001","https://www.sciencedirect.com/science/article/pii/S0065250418300254"
"A140","1: Measuring (private company activity) on the web","This chapter introduces and describes the concept of measuring, with particular emphasis on the need that humans have had, since the dawn of time, to measure the world around them in order to understand, to gather information, and to then make decisions. After describing the types of measurement and clarifying terminological differences (variables, measures, indicators, and metrics), the chapter will explore the challenge of measuring the Internet from its constituent elements. At this point we will introduce the main research disciplines that address this issue from their different goals and methodologies; in particular, cybermetrics and web analytics, which focus on off-page and on-page phenomena, respectively. This will be followed by an introduction to companies as measurable objects. The chapter ends with a comprehensive overview of the main areas of applied research that quantify the presence and web impact of companies through cybermetric techniques, including the main authors, sectors that are analyzed, and the web indicators and sources most widely used by the scientific community to date.","Cybermetrics,link analysis,companies,measurement,indicators,metrics,Internet,web","EnriqueOrduna-Malea,AdolfoAlonso-Arroyo","Cybermetric Techniques to Evaluate Organizations Using Web-Based Data,Cybermetric Techniques to Evaluate Organizations Using Web-Based Data","https://doi.org/10.1016/B978-0-08-101877-4.00001-6","https://www.sciencedirect.com/science/article/pii/B9780081018774000016"
"A141","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2017.12.002","https://www.sciencedirect.com/science/article/pii/S0140670117300449"
"A142","Integration among databases and data sets to support productive nanotechnology: Challenges and recommendations","Many groups within the broad field of nanoinformatics are already developing data repositories and analytical tools driven by their individual organizational goals. Integrating these data resources across disciplines and with non-nanotechnology resources can support multiple objectives by enabling the reuse of the same information. Integration can also serve as the impetus for novel scientific discoveries by providing the framework to support deeper data analyses. This article discusses current data integration practices in nanoinformatics and in comparable mature fields, and nanotechnology-specific challenges impacting data integration. Based on results from a nanoinformatics-community-wide survey, recommendations for achieving integration of existing operational nanotechnology resources are presented. Nanotechnology-specific data integration challenges, if effectively resolved, can foster the application and validation of nanotechnology within and across disciplines. This paper is one of a series of articles by the Nanomaterial Data Curation Initiative that address data issues such as data curation workflows, data completeness and quality, curator responsibilities, and metadata.","Nanomaterials,Nanotechnology,Nanoinformatics,Data integration,Databases,Web services","SandraKarcheraq,Egon L.Willighagenb,JohnRumblecd,FriederikeEhrhartb,Chris T.Evelob,MartinFrittse,SharonGaheene,Stacey L.Harperf,Mark D.Hooverg,NinaJeliazkovah,NastassjaLewinskii,Richard L.Marchese Robinsonjk12,Karmann C.Millsl,Axel P.Mustadm,Dennis G.Thomasn,GeorgiaTsilikiop,Christine OgilvieHendrenq","NanoImpact","https://doi.org/10.1016/j.impact.2017.11.002","https://www.sciencedirect.com/science/article/pii/S2452074817301398"
"A143","Chapter 10: Human Genomic Databases in Translational Medicine","Genomic databases are integral parts of human genome informatics, which enjoyed an exponential growth in the postgenomic era, as a result of the understanding of the genetic etiology of human disorders and the identification of numerous genomic variants. These resources organize this knowledge and variants such that it could be eventually useful not only for molecular diagnosis, but also for clinicians and researchers. Human genomic databases are referred to as online repositories of genomic variants, mainly described for a single or more genes or specifically for a population or ethnic group, aiming to facilitate diagnosis at the DNA level and to correlate genomic variants with specific phenotypic patterns and clinical features. Here, the key features of the main types of human genomic databases that are frequently used in genomic and translational medicine will be summarized, namely locus-specific and national/ethnic genetic databases. In particular, the main activities relating to these genetic database types will be highlighted to describe the existing and emerging database types in this domain and emphasize their potential applications in modern medical genetics, while the key elements that are still missing and holding back the field will be critically discussed.","Database management systems,Genomic databases,Genomic variants,Locus-specific databases,Microattribution,National/ethnic mutation databases","TheodoraKatsila<U+204E>,EmmanouilViennas†,MarinaBartsakoulia<U+204E>,AggelikiKomianou<U+204E>,KonstantinosSarris<U+204E>,GiannisTzimas‡,George P.Patrinos<U+204E>§¶","Human Genome Informatics,Human Genome Informatics","https://doi.org/10.1016/B978-0-12-809414-3.00010-3","https://www.sciencedirect.com/science/article/pii/B9780128094143000103"
"A144","Industry 4.0: a perspective based on bibliometric analysis","The main aim of this contribution is to develop a co-words analysis of the Industry 4.0 research field in order to highlight the themes covered in the last five years (2013–2017). The software tool SciMAT is employed using an approach that allows us to uncover the main research themes and analyze them according to their performance and impact measures. An amount of 333 documents were retrieved from the Web of Science. Our key findings are that the most important research themes were Cyber-Physical-Systems and Cloud-Computing.","Bibliometric Analysis,Science Mapping Analysis,Co-words analysis,Industry 4.0","M.J.Coboa,B.Jürgensb,V.Herrero-Solanac,M.A.Martínezd,E.Herrera-Viedmae","Procedia Computer Science","https://doi.org/10.1016/j.procs.2018.10.278","https://www.sciencedirect.com/science/article/pii/S1877050918319483"
"A145","Profiling heterogeneity of Alzheimer's disease using white-matter impairment factors","The clinical presentation of Alzheimer's disease (AD) is not unitary as heterogeneity exists in the disease's clinical and anatomical characteristics. MRI studies have revealed that heterogeneous gray matter atrophy patterns are associated with specific traits of cognitive decline. Although white matter (WM) impairment also contributes to AD pathology, its heterogeneity remains unclear. The Latent Dirichlet Allocation (LDA) method is a suitable framework to study heterogeneity and allows to identify latent impairment factors of AD instead of simply mapping an overall disease effect. By exploring whole brain WM skeleton images by using LDA, three latent factors were revealed in AD: a temporal-frontal impairment factor (temporal and frontal lobes, especially hippocampus and para-hippocampus), a parietal factor (parietal lobe, especially precuneus), and a long fibre bundle factor (corpus callosum and superior longitudinal fasciculus). As revealed by longitudinal analysis, the latent factors have distinct impact on cognitive decline: for executive function (EF), the temporal-frontal factor was more strongly associated with baseline EF compared with the parietal factor, while the long-fibre bundle factor was most associated with decline rate of EF; for memory, the three factors showed almost equal effect on the baseline memory and decline rate. For each participant, LDA estimates his/her composition profile of latent impairment factors, which indicates disease subtype. We also found that the APOE genotype affects the AD subtype. Specifically, APOE e4 was more associated with the long fibre bundle factor and APOE e2 was more associated with temporal-frontal factor. By investigating heterogeneity and subtypes of AD through white matter impairment factors, our study could facilitate precision medicine.","Heterogeneity,Alzheimer's disease,Mental disorder subtypes,White matter impairment,Latent dirichlet allocation","XiuchaoSui,Jagath C.Rajapakse,The Alzheimer's Disease Neuroimaging Initiative1","NeuroImage: Clinical","https://doi.org/10.1016/j.nicl.2018.10.026","https://www.sciencedirect.com/science/article/pii/S2213158218303358"
"A146","Chapter 5: Data, Results, and Discussion","This chapter presents the data, including the four patterns of organization seen in the population, their frequency, the characteristics of those four types, the discourse presented in organizational charts and library home page of libraries in the population, and the mechanisms of institutional isomorphism demonstrated by the organizational types and the genres of organizational communication. Charts and tables show the distribution of the types and the Field, Tenor, Mode, Genre, and Register (“FTM/GR”) instrument is used to analyze the field, tenor, mode, genre, and register of the documents.","Academic libraries,organization,institutionalism,isomorphism,genre,register,organizational chart,website,qualitative methods,quantitative methods","Mary K.Bolin","The 21st Century Academic Library,The 21st Century Academic Library","https://doi.org/10.1016/B978-0-08-101866-8.00005-7","https://www.sciencedirect.com/science/article/pii/B9780081018668000057"
"A147","Chapter 2: Nanotechnologies for tissue engineering and regeneration","Stem cells (SCs) can self-renew or differentiate into different cell types, which makes them an ideal cell source for therapies based on tissue engineering. Despite these characteristics, the employment of SCs in clinics has seen alternating fortunes because of our limited understanding of the signals governing SC functions and fate, which impairs our ability to engineer systems to deliver SCs in vivo and to guide their correct biological processes. However, experimental evidence demonstrated that SCs are able to recognize biochemical and biophysical signals displayed by material surfaces; most importantly, cells integrate these signals to elaborate fate decisions. Although the mechanisms underlying signal recognition and response have not been thoroughly characterized, there is a general consensus that the cell adhesion process plays a central role. Adhesion represents a communication gate between exogenous signals and intracellular signaling cascades involving the cytoskeleton and the nucleus. In this work we present recent findings on materials engineered to control cell functions through adhesion processes. In particular, we emphasize the role of material signals on SC behavior. Finally, we discuss a few sensing and transductive molecular mechanisms in an effort to draw out unifying elements concerning cell recognition of and reaction to biophysical/biochemical material signals aimed at controlling cell fate through cell adhesion.Microneedles and nanomedicine are two out of several active innovative approaches used to enhance the transdermal drug and vaccine delivery. Their application individually or in combination have shown to be very promising and attracted considerable interest by researchers from both industry and academia over the last 2 decades.Combining the two technologies has growing interest and has shown to be promising approach not only in enhancing the transdermal drug and vaccine permeation for even difficult drug molecules, such as hydrophilic and macromolecules, but also impart protection and controlling the drug release rates. In Subchapter 2.2, we aim to highlight the advances, which has been made in using these two technologies as an individual or in combination with drug and vaccine delivery.Metal implants, in the form of screws, plates, or pins, are extensively used in the treatment of fractures and nonunions or as replacements for malfunctioned joints. These bones implants face many challenges for acceptance and survival upon insertion in the human body. These challenges include severe inflammation, bacterial invasion, and poor biointegration with the traumatized tissue. Titania (TiO2) nanotubes (TNTs) arrays engineered on the surface of Ti implants by simple and scalable electrochemical anodization process, which have been widely explored as a new nanoengineering approach to improve the process of osseointegration and at the same time to be used as depots for loading drugs and their controllable release for localized delivery, and therapeutic purpose. Several advanced functions can be introduced into these multifunctional implants, including biopolymers, nanoparticles or external stimulation (e.g., electrical, electromagnetic and ultrasound) to release the loaded therapeutic agents in a desired manner when required. Subchapter 2.3 highlights the developed concepts of drug releasing implants based on TNTs for enhancing osteogenesis at the bone-implant interface, as an alternative approach to systemic delivery of therapeutic agents.The reconstruction of skeletal defects is a continuing challenge. Bone and dentin are mineralized hard tissues. The primary inorganic component of these two tissues is crystalline hydroxyapatite and the primary organic component is type I collagen, and these two components are cell-manufactured materials. Tissue-engineering strategies using novel biomaterials have emerged as a promising potential for the treatment of mineralization defects. Some of the recent bioinspired biomaterials utilize proteins and peptides as nanoscale building blocks. A key functional property is that biomaterials need to be cell-compatible and mimic the dynamic nature of the extracellular matrix. ECM is a complex environment comprising a plethora of macromolecules. Another class of novel biomaterials that are currently being developed are peptide-based hydrogels. Peptide-based engineered scaffolds present several advantages over traditional protein scaffolds as the control over hydrogel properties and can be easily tailored to the requirement of the tissue. Biomaterials generated by the self-assembly process have varied applications as it mimics nature’s method of material synthesis. Therefore, concepts of protein-based self-assembly can be utilized for constructing useful biomaterials.","stem cells,cell adhesion,cell shape,cytoskeleton,differentiation,mechanotransduction,nanofabrication,soft-lithography,topographic patterns,adhesive islands,microneedles,nanoparticles,microparticles,vaccines,drug delivery,nanomedicine,bone implants,localized drug delivery,titania nanotubes,bone therapy,osseointegration","MaurizioVentre***,ValerioCoppola***,MariaIannone*,Paolo A.Netti***,IsmaielTekko*†,EnekoLarrañeta*,Aoife M.Rodgers**,Christopher J.Scott*,AdrienKissenpfennig**,Ryan F.Donnelly*,ShaheerMaher***,DusanLosic*,AnneGeorge,AmsaveniRamachandran","Nanotechnologies in Preventive and Regenerative Medicine,Nanotechnologies in Preventive and Regenerative Medicine","https://doi.org/10.1016/B978-0-323-48063-5.00002-2","https://www.sciencedirect.com/science/article/pii/B9780323480635000022"
"A148","Lagrangian ocean analysis: Fundamentals and practices","Lagrangian analysis is a powerful way to analyse the output of ocean circulation models and other ocean velocity data such as from altimetry. In the Lagrangian approach, large sets of virtual particles are integrated within the three-dimensional, time-evolving velocity fields. Over several decades, a variety of tools and methods for this purpose have emerged. Here, we review the state of the art in the field of Lagrangian analysis of ocean velocity data, starting from a fundamental kinematic framework and with a focus on large-scale open ocean applications. Beyond the use of explicit velocity fields, we consider the influence of unresolved physics and dynamics on particle trajectories. We comprehensively list and discuss the tools currently available for tracking virtual particles. We then showcase some of the innovative applications of trajectory data, and conclude with some open questions and an outlook. The overall goal of this review paper is to reconcile some of the different techniques and methods in Lagrangian ocean analysis, while recognising the rich diversity of codes that have and continue to emerge, and the challenges of the coming age of petascale computing.","Ocean circulation,Lagrangian analysis,Connectivity,Particle tracking,Future modelling","Erikvan Sebilleab,Stephen M.Griffiesc,RyanAbernatheyd,Thomas P.Adamse,PavelBerlofff,ArneBiastochg,BrunoBlankeh,Eric P.Chassigneti,YuChengj,Colin J.Cotterf,EricDeleersnijderkl,KristoferDöösn,Henri F.Drakeop,SybrenDrijfhoutq,Stefan F.Garye,Arnold W.Heeminkl,JoakimKjellssonrt,Inga MonikaKoszalkagaa,…,Jan D.Zikaabb","Ocean Modelling","https://doi.org/10.1016/j.ocemod.2017.11.008","https://www.sciencedirect.com/science/article/pii/S1463500317301853"
"A149","Mapping the knowledge domains of Building Information Modeling (BIM): A bibliometric approach","Building Information Modeling (BIM) has been recognized as an emerging technological innovation which can help transform the construction industry and it has been adopted broadly in the field of built environment. Due to the rapid development of BIM research, various stakeholders require a state-of-the-art review of the BIM research and implementation. The purpose of this paper is to provide an objective and accurate summary of BIM knowledge using 1874 published BIM-related papers. The results show that 60 key research areas, such as information systems, 3D modeling, design and sustainability and 10 key research clusters, such as architecture design studio, building information and lean construction, are extremely important for the development of BIM knowledge. The results are useful for the identification of research clusters and topics in the BIM community. More importantly, these results can help highlight how BIM-related research evolves over time, thus greatly contributing to understanding the underlying structure of BIM. This study offers useful and new insights to summarize the status quo of BIM knowledge and can be used as a dynamic platform to integrate future BIM developments.","Building Information Modeling (BIM),Bibliometrics,Literature review,Knowledge map","XiaoLia,PengWub,Geoffrey QipingShena,XiangyuWangc,YueTengd","Automation in Construction","https://doi.org/10.1016/j.autcon.2017.09.011","https://www.sciencedirect.com/science/article/pii/S0926580516302783"
"A150","Textual analysis and visualization of research trends in data mining for electronic health records","ObjectivesMedical data mining is one of the most widely used techniques for discovering latent knowledge from databases, which in turn contributes to clinical decisions. In the past decade, medical data mining has advanced rapidly. The objective of this study is to analyse research trends and explore the general research framework in data mining for electronic health records (EHRs).,MethodsWe first conducted a literature retrieval in PubMed, the Web of Science (WOS) core collection, and the Association for Computing Machinery (ACM) digital library for peer-reviewed records (n = 2516) related to data mining for EHRs from 2000 to 2016. Then, we adopted the Latent Dirichlet Allocation (LDA) and Topics over Time (TOT) models to extract topics and analyse topic evolution trends in the retrieved records. The former mainly analysed topic generation, division, mergers and extinction, while the latter analysed the evolution of topic intensity over time.,ResultsWe extracted the important topics and analysed topic evolution. We present the general research framework of data mining for EHRs by combining the topic co-occurrence relations and domain knowledge, including the data, methods, knowledge, and decision levels.,ConclusionsOur work can provide high-level insight for scholars in this emerging field and guide their choices of medical data mining techniques in healthcare knowledge discovery, medical decision support, and public health management.","Medical data mining,Topic discovery,Topic evolution,Visualization,Research framework","JingfengChena,WeiWeiab,ChonghuiGuoab,LinTangabc,LeileiSuna","Health Policy and Technology","https://doi.org/10.1016/j.hlpt.2017.10.003","https://www.sciencedirect.com/science/article/pii/S2211883717300692"
"A151","Information sciences 1968–2016: A retrospective analysis with text mining and bibliometric","This study provides a comprehensive overview of the publications in Information Sciences (INS) from 1968 to 2016 inclusive, which encompasses the history of this journal from its inception. 7721 articles containing 153,606 references, which are the primary data source were downloaded from the Web of Science. It studies the most prolific authors, most cited authors, most representative articles, top influential institutions and the nationalities of the authors whose papers were published in the journal. The key contributors and INS articles that have made profound impact are highlighted on a basis of bibliometric and customized text mining techniques. CiteSpace, a data visualization software, was used to make the comprehensive analysis of the 153,606 citations and construct the co-citation network maps, which can illustrate salient patterns and emerging trends. This paper not only provides the important reference to future studies by exploring the structures and trends of INS publications, which have evolved over time, but also offers a demonstration of an effective analytical method for evaluating journal citation and co-citation data in the future.","Bibliometric,Text mining,Citation and co-citation,Information sciences,CiteSpace","DejianYuab,ZeshuiXubc,WitoldPedryczd,WanruWanga","Information Sciences","https://doi.org/10.1016/j.ins.2017.08.031","https://www.sciencedirect.com/science/article/pii/S0020025516312257"
"A152","Spatially enabling the Global Framework for Climate Services: Reviewing geospatial solutions to efficiently share and integrate climate data & information","In November 2016, the Paris Agreement entered into force calling Parties to strengthen their cooperation for enhancing adaptation and narrowing the gap between climate science and policy. Moreover, climate change has been identified as a central challenge for sustainable development by the United Nations 2030 Agenda for Sustainable Development.Data provide the basis for a reliable scientific understanding and knowledge as well as the foundation for services that are required to take informed decisions. In consequence, there is an increasing need for translating the massive amount of climate data and information that already exists into customized tools, products and services to monitor the range of climate change impacts and their evolution. It is crucial that these data and information should be made available not in the way that they are collected, but in the way that they are being used by the largest audience possible.Considering that climate data is part of the broader Earth observation and geospatial data domain, the aim of this paper is to review the state-of-the-art geospatial technologies that can support the delivery of efficient and effective climate services, and enhancing the value chain of climate data in support of the objectives of the Global Framework for Climate Services. The major benefit of spatially-enabling climate services is that it brings interoperability along the entire climate data value chain. It facilitates storing, visualizing, accessing, processing/analyzing, and integrating climate data and information and enables users to create value-added products and services.","Climate services,Essential Climate Variables,Interoperability,OGC standards,GFCS, GEO/GEOSS","GregoryGiulianiab,StefanoNativid,AndreObregone,MartinBenistona,AnthonyLehmannac","Climate Services","https://doi.org/10.1016/j.cliser.2017.08.003","https://www.sciencedirect.com/science/article/pii/S2405880716300772"
"A153","Some resonances between Eastern thought and Integral Biomathics in the framework of the WLIMES formalism for modeling living systems","Forty-two years ago, Capra published “The Tao of Physics” (Capra, 1975). In this book (page 17) he writes: “The exploration of the atomic and subatomic world in the twentieth century has …. necessitated a radical revision of many of our basic concepts” and that, unlike ‘classical’ physics, the sub-atomic and quantum “modern physics” shows resonances with Eastern thoughts and “leads us to a view of the world which is very similar to the views held by mystics of all ages and traditions.“ This article stresses an analogous situation in biology with respect to a new theoretical approach for studying living systems, Integral Biomathics (IB), which also exhibits some resonances with Eastern thought. Stepping on earlier research in cybernetics1 and theoretical biology,2 IB has been developed since 2011 by over 100 scientists from a number of disciplines who have been exploring a substantial set of theoretical frameworks. From that effort, the need for a robust core model utilizing advanced mathematics and computation adequate for understanding the behavior of organisms as dynamic wholes was identified. At this end, the authors of this article have proposed WLIMES (Ehresmann and Simeonov, 2012), a formal theory for modeling living systems integrating both the Memory Evolutive Systems (Ehresmann and Vanbremeersch, 2007) and the Wandering Logic Intelligence (Simeonov, 2002b). Its principles will be recalled here with respect to their resonances to Eastern thought.","Integral Biomathics,Artificial/synthetic and natural life,Phenomenology,Eastern philosophy,Higher-order logic,Wandering Logic Intelligence,Memory Evolutive Systems","Plamen L.Simeonovabc,Andrée C.Ehresmannd","Progress in Biophysics and Molecular Biology","https://doi.org/10.1016/j.pbiomolbio.2017.05.014","https://www.sciencedirect.com/science/article/pii/S0079610717301141"
"A154","Too hot to reject: The effect of weather variations on the patent examination process at the United States Patent and Trademark Office","This paper documents a small but systematic bias in the patent evaluation system at the United States Patent and Trademark Office (USPTO): external weather variations affect the allowance or rejection of patent applications. I examine 8.8 million reject/allow decisions from 3.5 million patent applications to the USPTO between 2001 and 2014, and find that on unusually warm days patent allowance rates are higher and final rejection rates are lower than on cold days. I also find that on cloudy days, final rejection rates are lower than on clear days. I show that these effects constitute a decision-making bias which exists even after controlling for sorting effects, controlling for applicant-level, application-level, primary class-level, art unit-level, and examiner- level characteristics. The bias even exists after controlling for the quality of the patent applications. While theoretically interesting, I also note that the effect sizes are relatively modest and may not require policy changes from the USPTO. Yet, the results are strong enough to provide a potentially useful instrumental variable for future innovation research.","Patent allowance,USPTO,Weather variations","BalázsKovács","Research Policy","https://doi.org/10.1016/j.respol.2017.08.010","https://www.sciencedirect.com/science/article/pii/S0048733317301440"
"A155","Patent citation: A technique for measuring the knowledge flow of information and innovation","Knowledge cannot be bound, restricted or categorized. Knowledge is precisely an intangible strength that has a definite economic importance if well utilized and commercialized. Knowledge spillover is an occurrence, which is imaginable but difficult to have an effective measurement of it. Patents citation is a developing concept and has gained momentum in recent past. Patents citation contains valuable data and if analyzed well, may sometimes reveal concealed mysteries of the information flow between countries, laboratories, companies, and universities. Profuse technical research has been conducted on this topic by many scientists. Through these experiments, scientists have tried to show that the innovative information hidden in patents crosses every barrier and is taken by the research labs for its further expansion. Patents citation reveals the diffusion of information and its applicability into many other technical fields which give birth to a new technology. This paper presents a comprehensive survey of patents citation analysis covering and promoting the landmark research done in the field of patents citation, informing readers to consider this important segment of patent document as a field for analysis. Also, this paper presents an innovative methodology for generating patent citation network with the help of techniques of Information Retrievals.","Patents,Citation,Diffusion,Information,Innovation,Analysis","P.Sharmaa,R.C.Tripathib","World Patent Information","https://doi.org/10.1016/j.wpi.2017.11.002","https://www.sciencedirect.com/science/article/pii/S0172219017300170"
"A156","Exploring the role of lean thinking in sustainable business practice: A systematic literature review","The shift towards sustainable manufacturing processes and products has influenced business organizations to improve their environmental performance and efficiency. ‘Lean thinking’ has evolved to ‘lean and green thinking’ as a targeted intervention for organizations to implement sustainable business models that reduce waste and improve material efficiency, and subsequently minimise costs. The lean and green concept however is still relatively new and it remains unclear for many as to how exactly lean thinking can contribute to the sustainability transformation of organizations. The objective of this research was to undertake a systematic literature review of how the implementation of lean and green initiatives could lead to sustainable business practice. This article includes an analysis of both conceptual and empirical research papers discussing various industrial contexts, and evaluation of: a) the impact of lean methods on environmental performance; and b) the variety of integrated lean and green models. The review highlights the ad hoc and limited use of lean thinking within corporate sustainability initiatives and the authors establish a ‘lean and green matrix’ that identifies opportunities to embed lean and green practices in five common work streams including waste, energy, emissions, water and chemical management. In addition to comparing different industries and their systems, this review provides a reference point for further investigation into lean and green practices. The findings contribute to the authors’ research agenda that aims to develop a replicable system for holistically exploring strategies in corporate environmental management and prioritising the most appropriate lean methods. It is proposed that industrial practitioners could benefit from such a system, which could transform their organization’s performance through well-integrated and aligned sustainable business practices.","Lean thinking,Sustainable business practice,Lean and green,Systematic literature review,Sustainable business model,Efficiency","H.T.S.Caldera,C.Desha,L.Dawes","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2017.05.126","https://www.sciencedirect.com/science/article/pii/S0959652617310661"
"A157","The science of science: From the perspective of complex systems","The science of science (SOS) is a rapidly developing field which aims to understand, quantify and predict scientific research and the resulting outcomes. The problem is essentially related to almost all scientific disciplines and thus has attracted attention of scholars from different backgrounds. Progress on SOS will lead to better solutions for many challenging issues, ranging from the selection of candidate faculty members by a university to the development of research fields to which a country should give priority. While different measurements have been designed to evaluate the scientific impact of scholars, journals and academic institutions, the multiplex structure, dynamics and evolution mechanisms of the whole system have been much less studied until recently. In this article, we review the recent advances in SOS, aiming to cover the topics from empirical study, network analysis, mechanistic models, ranking, prediction, and many important related issues. The results summarized in this review significantly deepen our understanding of the underlying mechanisms and statistical rules governing the science system. Finally, we review the forefront of SOS research and point out the specific difficulties as they arise from different contexts, so as to stimulate further efforts in this emerging interdisciplinary field.","Science of science,Scholarly data,Complex networks","AnZenga,ZhesiShenac,JianlinZhoua,JinshanWua,YingFana,YouguiWangab,H. EugeneStanleyb","Physics Reports","https://doi.org/10.1016/j.physrep.2017.10.001","https://www.sciencedirect.com/science/article/pii/S0370157317303289"
"A158","A review of research on embodied energy of buildings using bibliometric analysis","The share of embodied energy within the total life cycle of a building is expected to increase and become more significant as low energy and net-zero energy buildings become the norm. In the last two decades, many researchers have studied the embodied energy of buildings and published their findings. However, a comprehensive, quantitative analysis of the literature on the embodied energy of buildings is missing. In this study, in order to provide a better understanding of the field as a whole, a bibliometric approach is applied to create a knowledge map and discover more information about the topic. The primary knowledge structure and the topics for study were discovered by analyzing the keywords and abstract terms of 398 papers published from 1996 to 2015. The results show that life cycle assessment is the keyword with the greatest frequency of occurrence and design is the keyword that has the highest number of co-occurrence relationships with other keywords in the 398 papers. The major three research areas for the embodied energy of buildings are life cycle assessment (LCA), building design, and greenhouse gas emissions. By using the bibliometric method, this study analyzes previous studies to provide new insights into the embodied energy of buildings.","Embodied energy,Building,Bibliometric analysis,Life cycle assessment,Design","RuochenZeng,AbdolChini","Energy and Buildings","https://doi.org/10.1016/j.enbuild.2017.09.025","https://www.sciencedirect.com/science/article/pii/S0378778817305273"
"A159","Global transition to low-carbon electricity: A bibliometric analysis","Decarbonizing the global electricity system is expected to contribute significantly to mitigating climate change. A significant body of research has focused on the development of low-carbon power systems; hence, this bibliometric review is timely. We assess the global scientific research on low-carbon electricity both quantitatively and qualitatively, based on the Science Citation Index Expanded (SCI-Expanded) and Social Sciences Citation Index (SSCI) spanning a quarter century and 13,767 publications. Our analysis illustrates the role of inter-institutional collaboration in successful scientific research on low-carbon power systems. The United States has contributed most to the low-carbon electricity literature with 3074 publications, the highest h-index (58), 8 of the 10 most cited articles, and 4 of the 10 most productive institutions. The Chinese Academy of Science is the most productive institution with 270 publications and notably high levels of international collaboration. Based on an analysis and visualization of author keywords and content analysis, we also characterize three phases of the global transition to low-carbon electricity. The 1990s involved reliance on traditional base-load fuels (coal and nuclear), which spurred the search for cleaner alternatives. These alternatives materialized as the rise of clean coal and wind in the first decade of the 21st century, followed by the growth of solar and natural gas beginning in 2010. Besides this evolution of technologies, we document the transition to more nuanced forms of economic and policy analysis in recent years.","Electricity system,Climate change,Low-carbon,Renewable energy,Bibliometric analysis,Research trends","LuWangab,Yi-MingWeia,Marilyn A.Brownb","Applied Energy","https://doi.org/10.1016/j.apenergy.2017.07.107","https://www.sciencedirect.com/science/article/pii/S0306261917309790"
"A160","bibliometrix: An R-tool for comprehensive science mapping analysis","The use of bibliometrics is gradually extending to all disciplines. It is particularly suitable for science mapping at a time when the emphasis on empirical contributions is producing voluminous, fragmented, and controversial research streams. Science mapping is complex and unwieldly because it is multi-step and frequently requires numerous and diverse software tools, which are not all necessarily freeware. Although automated workflows that integrate these software tools into an organized data flow are emerging, in this paper we propose a unique open-source tool, designed by the authors, called bibliometrix, for performing comprehensive science mapping analysis. bibliometrix supports a recommended workflow to perform bibliometric analyses. As it is programmed in R, the proposed tool is flexible and can be rapidly upgraded and integrated with other statistical R-packages. It is therefore useful in a constantly changing science such as bibliometrics.","Bibliometrics,Science mapping,Workflow,Co-citation,Bibliographic coupling,R package","MassimoAriaa,CorradoCuccurullob","Journal of Informetrics","https://doi.org/10.1016/j.joi.2017.08.007","https://www.sciencedirect.com/science/article/pii/S1751157717300500"
"A161","Understanding the topic evolution in a scientific domain: An exploratory study for the field of information retrieval","Understanding topic evolution in a scientific domain is essential for capturing key domain developments and facilitating knowledge transfer within and across domains. Using a data set on information retrieval (IR) publications, this paper examines how research topics evolve by analyzing the topic trends, evolving dynamics, and semantic word shifts in the IR domain. Knowledge transfer between topics and the developing status of the major topics have been recognized, which are represented by the merging and splitting of local topics in different time periods. Results show that the evolution of a major topic usually follows a pattern from adjusting status to mature status, and sometimes with re-adjusting status in between the evolving process. Knowledge transfer happens both within a topic and among topics. Word migration via topic channels has been defined, and three migration types (non-migration, dual-migration, and multi-migration) are distinguished to facilitate better understanding of the topic evolution.","Topic evolution,Semantic word shifts,Content analysis","BaitongChenab,SatoshiTsutsuic,YingDingbcd,FeichengMab","Journal of Informetrics","https://doi.org/10.1016/j.joi.2017.10.003","https://www.sciencedirect.com/science/article/pii/S1751157717300536"
"A162","Mapping science using Library of Congress Subject Headings","Maps of scientific knowledge are generally created by analyzing scientific literature including journal articles, conference proceedings, books, and monographs. Although citation analysis is the most popular method for generating maps of science from scientific journal articles and their citations, other relationships between scientific topics can be used to map science. This study offers a map of science generated from examining non-fiction book topics and their relationships as defined by Library of Congress Subject Heading (LCSH) co-assignments. The resulting map reveals which sub-disciplines of science must be learned together, showing that Physics and Mathematics are the central topics required to practice science, which is not revealed by previous studies. This novel LCSH-based science map reveals new relations between the major sub-disciplines of science to produce a more complete representation of scientific domains and how they interact.","Map of science,LCSH,Gephi,Assignment,Citation","FeiShua,Jesse DavidDinneenb,BanafshehAsadia,Charles-AntoineJuliena","Journal of Informetrics","https://doi.org/10.1016/j.joi.2017.08.008","https://www.sciencedirect.com/science/article/pii/S1751157717300950"
"A163","A dynamic forward-citation full path model for technology monitoring: An empirical study from shale gas industry","The utilization of shale gas has become one of the important options to transit into low-carbon economy in the world and its vigorous development relies on successful technology revolution to a great extent. Based on patent data, this paper analyzes the development trends and the status quo of technical innovation of shale gas quantitatively by means of patent maps. A new dynamic model named Forward-Citation Full Path (FCFP) is investigated to identify the key development paths in technology clusters and monitor potential breakthrough technologies on those key paths. Then we employ topic modeling and text mining for patent abstracts to explore the potential promising topics with high innovation activeness in aid of providing specific references for development and foresight of the shale gas technology. The results show that: (1) The patent center of shale gas has been transferring from North American to the Asia-Pacific region and the technological innovation is mainly driven by preferential tax policy and loose environmental regimes. (2) Current hotspots of shale gas technology are production technique including stimulation treatments, environmental protection technology of fracturing fluid and geological prospecting technology. (3) There are five potential topics with high innovation activeness identified by topic modeling and text mining which are synthetic carbon oxide, hydraulic fracturing, fracturing propping agents, horizontal well, and technologies of reservoir exploration and modeling. (4) By means of visualization of technology clusters, it is found that promising technologies are refined simulation technology for shale gas exploration, multi-interval fracturing techniques in horizontal wells with deep pay zones, water treatment and environmental protection technology in shale gas production. (5) The suggested dynamic FCFP model can effectively identify the key development paths and monitor potential breakthrough technology of shale gas.","Technology foresight,Patent map,Technology monitoring,Path identification,Shale gas,JEL classification,L71,O31,O32,O33,O34,Q55","Yi-MingWei,Jia-NingKang,Bi-YingYu,HuaLiao,Yun-FeiDu","Applied Energy","https://doi.org/10.1016/j.apenergy.2017.08.121","https://www.sciencedirect.com/science/article/pii/S0306261917311443"
"A164","Open source software ecosystems: A Systematic mapping","Context: Open source software (OSS) and software ecosystems (SECOs) are two consolidated research areas in software engineering. OSS influences the way organizations develop, acquire, use and commercialize software. SECOs have emerged as a paradigm to understand dynamics and heterogeneity in collaborative software development. For this reason, SECOs appear as a valid instrument to analyze OSS systems. However, there are few studies that blend both topics together.Objective: The purpose of this study is to evaluate the current state of the art in OSS ecosystems (OSSECOs) research, specifically: (a) what the most relevant definitions related to OSSECOs are; (b) what the particularities of this type of SECO are; and (c) how the knowledge about OSSECO is represented.Method: We conducted a systematic mapping following recommended practices. We applied automatic and manual searches on different sources and used a rigorous method to elicit the keywords from the research questions and selection criteria to retrieve the final papers. As a result, 82 papers were selected and evaluated. Threats to validity were identified and mitigated whenever possible.Results: The analysis allowed us to answer the research questions. Most notably, we did the following: (a) identified 64 terms related to the OSSECO and arranged them into a taxonomy; (b) built a genealogical tree to understand the genesis of the OSSECO term from related definitions; (c) analyzed the available definitions of SECO in the context of OSS; and (d) classified the existing modelling and analysis techniques of OSSECOs.Conclusion: As a summary of the systematic mapping, we conclude that existing research on several topics related to OSSECOs is still scarce (e.g., modelling and analysis techniques, quality models, standard definitions, etc.). This situation calls for further investigation efforts on how organizations and OSS communities actually understand OSSECOs.","Software ecosystem,Open source software,Systematic mapping,Literature review,OSS,SECO,OSSECO","OscarFranco-Bedoyaab,DavidAmellera,DolorsCostala,XavierFrancha","Information and Software Technology","https://doi.org/10.1016/j.infsof.2017.07.007","https://www.sciencedirect.com/science/article/pii/S0950584917304512"
"A165","Fuzzy formal concept analysis based opinion mining for CRM in financial services","Owing to the easy access to social media, consumers or customers are increasingly turning to social media to express their grievances and feedback on various products and services offered by the Banking, Financial, Services and Insurance industry. Because non-redressal of complaints eventually leads to customer churn, there is an urgent need to analyze the complaints. In this regard, we propose a novel descriptive analytics model that performs complaints/grievances analytics and summarizes the lengthy and verbose complaints concisely in a form that resembles association rules. The proposed hybrid model comprises fuzzy formal concept analysis and concept-level sentiment analysis (FFCA + SA) in tandem, which in turn is compared against formal concept analysis and concept-level sentiment analysis (FCA + SA). Because of the immediate fallout of the negative sentiments, a financial company is interested in studying them in more detail than the positive ones. Therefore, the model generates a list of ‘association rules’, the corresponding negative sentiment score along with the list of associated documents. Association rules are rank ordered according to the negative sentiment score, which in turn reflects severity affected services/products. The proposed model also provides interactive visualization that enables business analysts and managers to access a specific set of complaints without having to go through the entire set thoroughly. This saves a lot of time that would have otherwise been spent on cumbersome manual operations. Moreover, partial evaluation of the proposed methodology by human annotators yielded 64.06% matching score in terms of the opinions determination of aspects.","Sentiment analysis,Fuzzy formal concept analysis,Customer complaints,Text mining,Association rules,Descriptive analytics","KumarRaviab,VadlamaniRavia,P. Sree Rama KrishnaPrasadc","Applied Soft Computing","https://doi.org/10.1016/j.asoc.2017.05.028","https://www.sciencedirect.com/science/article/pii/S1568494617302910"
"A166","Abstracts","","","","The Journal of Molecular Diagnostics","https://doi.org/10.1016/S1525-1578(17)30482-8","https://www.sciencedirect.com/science/article/pii/S1525157817304828"
"A167","Improving fitness: Mapping research priorities against societal needs on obesity","Science policy is increasingly shifting towards an emphasis in societal problems or grand challenges. As a result, new evaluative tools are needed to help assess not only the knowledge production side of research programmes or organisations, but also the articulation of research agendas with societal needs. In this paper, we present an exploratory investigation of science supply and societal needs on the grand challenge of obesity – an emerging health problem with enormous social costs. We illustrate a potential approach that uses topic modelling to explore: (a) how scientific publications can be used to describe existing priorities in science production; (b) how policy records (in this case here questions posed in the European parliament) can be used as an instance of mapping discourse of social needs; (c) how the comparison between the two may show (mis)alignments between societal concerns and scientific outputs. While this is a technical exercise, we propose that this type of mapping methods can be useful to domain experts for informing strategic planning and evaluation in funding agencies.","Research agenda,Science mapping,Societal needs,Obesity,Topic modeling","LorenzoCassiab,AgénorLahatteb,IsmaelRafolscde,PierreSautierbc,Élisabethde Turckheimbf","Journal of Informetrics","https://doi.org/10.1016/j.joi.2017.09.010","https://www.sciencedirect.com/science/article/pii/S1751157717301542"
"A168","Popular Research Topics in Marketing Journals, 1995–2014","During the past two decades, the focus of marketing has moved from the tactics of persuasion to the strategies of value cocreation. After moving toward cognitive science and corporate strategies in the early 2000s, marketing research returned to its traditional domains of consumer psychologies and customer management. While conscientious consumers are gradually restraining themselves from selfish indulgence, marketers have refocused on a new set of values that encompass mental, experiential, and societal well-being. In this regard, we adopt an unprecedented approach by incorporating topic modeling with social network analysis. The results show that, in terms of topic heterogeneity, the most impactful journals are the most diverse, whereas each runner-up has a unique focus. Among the journals, we detect two major co-authorship communities, and among the topics, we detect three. Further, we find that the communities of the most cited papers are composed of heterogeneous clusters of similar topics. The pivots within, and the bridges between, these communities are also reported. In the spirit of collaborative research, our topic model and network analysis are shared via online collaboration and visualization platforms that readers can use to explore our models interactively and to download the dataset for further studies.","Topic model,Text mining,Data visualization,Reproducible and collaborative research","Yung-JanChoa,Pei-WenFub,Chi-ChengWub","Journal of Interactive Marketing","https://doi.org/10.1016/j.intmar.2017.06.003","https://www.sciencedirect.com/science/article/pii/S1094996817300373"
"A169","Freehand 3-D Ultrasound Imaging: A Systematic Review","Two-dimensional ultrasound (US) imaging has been successfully used in clinical applications as a low-cost, portable and non-invasive image modality for more than three decades. Recent advances in computer science and technology illustrate the promise of the 3-D US modality as a medical imaging technique that is comparable to other prevalent modalities and that overcomes certain drawbacks of 2-D US. This systematic review covers freehand 3-D US imaging between 1970 and 2017, highlighting the current trends in research fields, the research methods, the main limitations, the leading researchers, standard assessment criteria and clinical applications. Freehand 3-D US systems are more prevalent in the academic environment, whereas in clinical applications and industrial research, most studies have focused on 3-D US transducers and improvement of hardware performance. This topic is still an interesting active area for researchers, and there remain many unsolved problems to be addressed.","Three-dimensional ultrasound imaging,Three-dimensional ultrasound freehand systems,Three-dimensional ultrasound calibration,Three-dimensional ultrasound reconstruction,Three-dimensional ultrasound sensorless methods,Systematic review","Mohammad HamedMozaffari,Won-SookLee","Ultrasound in Medicine & Biology","https://doi.org/10.1016/j.ultrasmedbio.2017.06.009","https://www.sciencedirect.com/science/article/pii/S0301562917302776"
"A170","Co-citation and cluster analyses of extant literature on social networks","Over one billion people are currently using social media such as social websites (Facebook Newsroom, 2015); consequently, numerous academic scholars have developed interest in studying the use of social media and social networks. However, few studies have focused on examining the core factors of social networks. In this study, we collected studies on social-network-related topics that were published between January 1996 and December 2014, assembling a total of 2565 articles and 81,316 citations. Co-citation analysis and cluster analysis were applied to verify seven main factors regarding social networks: (a) the measure of complex social networks; (b) community structure; (c) strong and weak ties; (d) the evolution of social networks; (e) network structure and relationship; (f) value concept and measurement strategies; and (g) social capital. Finally, the results of this study were further discussed to elucidate the core topics relevant to social networks.","Social network,Document co-citation,Multidimensional scaling analysis,Cluster analysis","Wen-LungShiauac,Yogesh K.Dwivedib,Han SuanYangc","International Journal of Information Management","https://doi.org/10.1016/j.ijinfomgt.2017.04.007","https://www.sciencedirect.com/science/article/pii/S0268401216300962"
"A171","Detecting and predicting the topic change of Knowledge-based Systems: A topic-based bibliometric analysis from 1991 to 2016","The journal Knowledge-based Systems (KnoSys) has been published for over 25 years, during which time its main foci have been extended to a broad range of studies in computer science and artificial intelligence. Answering the questions: “What is the KnoSys community interested in?” and “How does such interest change over time?” are important to both the editorial board and audience of KnoSys. This paper conducts a topic-based bibliometric study to detect and predict the topic changes of KnoSys from 1991 to 2016. A Latent Dirichlet Allocation model is used to profile the hotspots of KnoSys and predict possible future trends from a probabilistic perspective. A model of scientific evolutionary pathways applies a learning-based process to detect the topic changes of KnoSys in sequential time slices. Six main research areas of KnoSys are identified, i.e., expert systems, machine learning, data mining, decision making, optimization, and fuzzy, and the results also indicate that the interest of KnoSys communities in the area of computational intelligence is raised, and the ability to construct practical systems through knowledge use and accurate prediction models is highly emphasized. Such empirical insights can be used as a guide for KnoSys submissions.","Topic analysis,Topic detection and tracking,Bibliometrics,Text mining,Knowledge-based Systems","ZhangYi,ChenHongshu,LuJie,ZhangGuangquan","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2017.07.011","https://www.sciencedirect.com/science/article/pii/S0950705117303271"
"A172","A systematic literature review on methods that handle multiple quality attributes in architecture-based self-adaptive systems","ContextHandling multiple quality attributes (QAs) in the domain of self-adaptive systems is an understudied research area. One well-known approach to engineer adaptive software systems and fulfill QAs of the system is architecture-based self-adaptation. In order to develop models that capture the required knowledge of the QAs of interest, and to investigate how these models can be employed at runtime to handle multiple quality attributes, we need to first examine current architecture-based self-adaptive methods.,ObjectiveIn this paper we review the state-of-the-art of architecture-based methods for handling multiple QAs in self-adaptive systems. We also provide a descriptive analysis of the collected data from the literature.,MethodWe conducted a systematic literature review by performing an automatic search on 28 selected venues and books in the domain of self-adaptive systems. As a result, we selected 54 primary studies which we used for data extraction and analysis.,ResultsPerformance and cost are the most frequently addressed set of QAs. Current self-adaptive systems dealing with multiple QAs mostly belong to the domain of robotics and web-based systems paradigm. The most widely used mechanisms/models to measure and quantify QAs sets are QA data variables. After QA data variables, utility functions and Markov chain models are the most common models which are also used for decision making process and selection of the best solution in presence of many alternatives. The most widely used tools to deal with multiple QAs are PRISM and IBM's autonomic computing toolkit. KLAPER is the only language that has been specifically developed to deal with quality properties analysis.,ConclusionsOur results help researchers to understand the current state of research regarding architecture-based methods for handling multiple QAs in self-adaptive systems, and to identity areas for improvement in the future. To summarize, further research is required to improve existing methods performing tradeoff analysis and preemption, and in particular, new methods may be proposed to make use of models to handle multiple QAs and to enhance and facilitate the tradeoffs analysis and decision making mechanism at runtime.","","SaraMahdavi-Hezavehiad,Vinicius H.S.Durelliab,DannyWeynscd,ParisAvgerioue","Information and Software Technology","https://doi.org/10.1016/j.infsof.2017.03.013","https://www.sciencedirect.com/science/article/pii/S0950584917302860"
"A173","Gamified crowdsourcing: Conceptualization, literature review, and future agenda ","Two parallel phenomena are gaining attention in human–computer interaction research: gamification and crowdsourcing. Because crowdsourcing's success depends on a mass of motivated crowdsourcees, crowdsourcing platforms have increasingly been imbued with motivational design features borrowed from games; a practice often called gamification. While the body of literature and knowledge of the phenomenon have begun to accumulate, we still lack a comprehensive and systematic understanding of conceptual foundations, knowledge of how gamification is used in crowdsourcing, and whether it is effective. We first provide a conceptual framework for gamified crowdsourcing systems in order to understand and conceptualize the key aspects of the phenomenon. The paper's main contributions are derived through a systematic literature review that investigates how gamification has been examined in different types of crowdsourcing in a variety of domains. This meticulous mapping, which focuses on all aspects in our framework, enables us to infer what kinds of gamification efforts are effective in different crowdsourcing approaches as well as to point to a number of research gaps and lay out future research directions for gamified crowdsourcing systems. Overall, the results indicate that gamification has been an effective approach for increasing crowdsourcing participation and the quality of the crowdsourced work; however, differences exist between different types of crowdsourcing: the research conducted in the context of crowdsourcing of homogenous tasks has most commonly used simple gamification implementations, such as points and leaderboards, whereas crowdsourcing implementations that seek diverse and creative contributions employ gamification with a richer set of mechanics.","Gamification,Crowdsourcing,Literature review,Research agenda,Human computation,Persuasive technology","BenediktMorschheuserab,JuhoHamaricd,JonnaKoivistoc,AlexanderMaedchea","International Journal of Human-Computer Studies","https://doi.org/10.1016/j.ijhcs.2017.04.005","https://www.sciencedirect.com/science/article/pii/S1071581917300642"
"A174","Long-term knowledge evolution modeling for empirical engineering knowledge","In this era of knowledge economy, appropriate management of the rapidly evolving knowledge is a real and urgent issue for factories and enterprises, in order to maintain the competitive edges. However, facing the onerous analysis required for understanding the long-term knowledge evolution, especially the evolving of empirical knowledge in the engineering field, effective and comprehensive modeling methods for knowledge evolution are absent. In this paper, a novel knowledge evolution modeling method is proposed for portraying the long-term evolution of empirical engineering knowledge (EEK) and assisting engineers in comprehending the evolving history. Three phases, EEK elicitation and formalization, EEK networks foundation, and family-tree evolution model construction, are included in the modeling method. This method is developed using natural language processing, semantic similarity calculation, fuzzy neural network prediction, clustering algorithm, and latent topic extraction techniques. To evaluate the performance of the proposed modeling method, an evolution model of empirical knowledge in computer-aided design (CAD) is constructed and then verified. Experimental results show that the proposed method outperforms the former approaches in feasibility and effectiveness, and hence opens up a better way of further understanding the long-term evolution course of EEK.","Knowledge evolution,Empirical engineering knowledge (EEK),Evolution model,Knowledge representation,Data visualization","XinyuLia,ZuhuaJianga,BoSongab,LijunLiua","Advanced Engineering Informatics","https://doi.org/10.1016/j.aei.2017.08.001","https://www.sciencedirect.com/science/article/pii/S1474034616300349"
"A175","Using bipartite heterogeneous networks to speed up inductive semi-supervised learning and improve automatic text categorization","Due to the volume of texts available in digital form, the organization, management and knowledge extraction are laborious and frequently impossible to be handled. To automatically cope with these tasks, usually classification models are generated through supervised learning techniques. Unfortunately, this type of learning usually demands a huge human effort to label large volume of texts to build accurate classification models. Since collecting unlabeled texts is easy and inexpensive in several domains, the generation of classification models through inductive semi-supervised learning has been highlighted in recent years. Inductive semi-supervised learning allows to build a classification model using labeled and unlabeled texts. In this scenario, the goal is to augment the set of labeled documents with unlabeled documents to better discriminate class patterns. Hence, fewer texts must be previously labeled. However, semi-supervised learning algorithms that consider texts represented in a vector space model usually obtain unsatisfactory classification performances and are surpassed by semi-supervised learning algorithms that consider texts represented in a network. Nevertheless, despite the classification performances, effective approaches based on networks are generated through the similarities among documents and the classification of a new document are also based on the computation of similarities. This implies to set parameters and compute similarities to both generation the networks and classification of new documents. This approach is not feasible to generate fast responses and consequently to classify a huge volume of texts. In this article, we propose an approach to induce a classification model through semi-supervised learning considering text collections represented by bipartite heterogeneous networks. Bipartite networks are easily and quickly generated, leading to classification performance equivalent or better than other approaches based on network or vector space model and allows a fast classification of new documents. The results presented in this article demonstrate that the proposed approach is able to (i) speed up semi-supervised learning, (ii) speed up the classification of new documents and (iii) surpass classification performance of other existing inductive semi-supervised learning techniques.","Text classification,Transductive learning,Graph-based learning,Label propagation,Bipartite heterogeneous network","RafaelGeraldeli Rossia,Alneu deAndrade Lopesb,SolangeOliveira Rezendeb","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2017.06.016","https://www.sciencedirect.com/science/article/pii/S0950705117302903"
"A176","Bibliometrics study on the Journal of American College Health: 1994–2014","ObjectiveTo help readers around the world comprehensively understand the development of the journal and evolution of cooperation study, we employed a bibliometrics analysis for the Journal of American College Health.,MethodsOne-thousand-one-hundred-forty-three articles published in this journal from 1994 were analyzed using the bibliometrics and visualization software CiteSpace.,ResultsThe annual number of published articles and cited studies increased. The published studies by RP Keeling and H Wechsler were at the forefront. “College student” and “alcohol” were prevalent keywords. University of Wisconsin and Harvard University were the institutional leaders of contributions.,ConclusionsThis journal provides an important platform for sharing research achievements and promoting cooperation in this field. The level of articles published is continually improving. A research cooperative network promoted by famous scholars and institutions is developing. However, cross-regional and international cooperation is relatively limited.","Journal of American College Health,CiteSpace,Bibliometrics,Knowledge mapping,Visualization analysis","XiaoZhenga,Yong-JuLiua,Wei-HongHub,HuangHuangc,Yan-PeiNid,Hui-NingZhaoa,Zhen-ZhenJina,Chi-ChenZhanga","Chinese Nursing Research","https://doi.org/10.1016/j.cnre.2017.07.004","https://www.sciencedirect.com/science/article/pii/S2095771817300646"
"A177","Solar energy technologies and open innovation: A study based on bibliometric and social network analysis","This paper aims to identify the development of solar energy technologies through open innovation. Manuscripts about solar energy and open innovation published between the years 2000 and 2014 in journals indexed by Web of Science Core Collection were used to create a database and terms related to solar energy and open innovation were sought in papers title, summary and keywords. By using words “cooperation” and “collaboration” as a proxy to map open innovation, it was found that this approach exist widely for solar energy researches and most important publications was developed collaboratively. Social network analysis methodology was used to identified clusters of local, national and international partnerships, which prove that researches cooperation to solar energy technological development is true. International cooperation is prevalent in countries like the Netherlands, United Kingdom, Spain and Germany. National partnership occurs in Japan, United States, France, Italy and South Korea. China has predominant local cooperation profile, but it will be major international collaborative actor in solar energy researches next years. Also, a set of recommendations based on findings was provided to construct a better environment for cooperation and to improve solar energy researches.","Solar energy,Open innovation,Cooperation,Bibliometrics,Social network analysis","Alex Fabiannede Paulo,Geciane SilveiraPorto","Energy Policy","https://doi.org/10.1016/j.enpol.2017.06.007","https://www.sciencedirect.com/science/article/pii/S0301421517303610"
"A178","Exploring 4G patent and litigation informatics in the mobile telecommunications industry","Patent informatics are often analysed for IP protections, particularly in high-tech industries. This research develops a computer-supported generic methodology for discovering evolutions and linkages between litigations and disputed patents. The IP litigations in mobile telecommunications are used as the case study. An ontology framework representing the 4G domain knowledge is defined first. Then, a modified formal concept analysis (MFCA) approach is developed to discover the evolutionary linkages of legal cases and their disputed patents. In addition to citation-based patent analysis, this research provides a new approach in identifying legal and technical evolutions for future R&D planning and IP strategies.","Mobile telecommunications,Patents,Knowledge e-discovery,Formal concept analysis,Ontology","Charles V.Trappeya,Amy J.C.Trappeyb","World Patent Information","https://doi.org/10.1016/j.wpi.2017.08.007","https://www.sciencedirect.com/science/article/pii/S0172219016300692"
"A179","Embedding unstructured side information in product recommendation","Various researchers have already engaged in using auxiliary side information within recommender applications to improve the quality and accuracy of recommendations. This side information has either been in the form of structured information such as product specifications and user demographic information or unstructured information such as product reviews. The abundance of unstructured information compared to structured information entices the use of such unstructured information in the recommendation process. Existing works that employ unstructured content have been confined to standard text modeling technique such as the use of frequency measures or topic modeling techniques. In this paper, we propose to model unstructured content about both products and users through the exploitation of word embedding techniques. More specifically, we propose to learn both user and product representations from any type of unstructured textual contents available in different external information sources using recurrent neural networks. We then apply our learnt product and user representations on two recommendation frameworks based on matrix factorization and link prediction to enhance the recommendation task. Experimental results on four datasets constructed from the Rotten Tomatoes website (movie review aggregator database) have shown the effectiveness of our proposed approach in different real-world situations compared to the state of the art.","Matrix factorization,User and product embeddings,Recurrent neural networks,Recommender systems","FatemehPourgholamalia,MohsenKahania,EbrahimBagherib,ZeinabNoorianb","Electronic Commerce Research and Applications","https://doi.org/10.1016/j.elerap.2017.08.001","https://www.sciencedirect.com/science/article/pii/S1567422317300571"
"A180","Literature listing","The quarterly Literature Listing is intended as a current awareness service for readers indicating newly published books, journal and conference articles on: patent search techniques, databases, analysis and classifications; patent searcher certification; patents relating to a) life sciences and pharmaceuticals and b) software; patent policy and strategic issues; trade marks; designs; domain names; and articles reviewing historical aspects of intellectual property or reviewing specific topics/persons. The current Literature Listing was compiled early June 2017. Key resources used are Scopus, Digital Commons, publishers' RSS feeds, and serendipity! Please feel free to send the author details of newly published reports/monographs/books for potential inclusion.","Patents,Designs,Trade marks,Literature listing,Patent analysis,Current awareness","SusanBates","World Patent Information","https://doi.org/10.1016/j.wpi.2017.06.003","https://www.sciencedirect.com/science/article/pii/S0172219017300583"
"A181","Mapping Human Resource Management: Reviewing the field and charting future directions","Using recent advances in science mapping, this article systematically reviews the Human Resource Management (HRM) field. We analyze 12,157 HRM research articles published over 23 years to reveal the topic content and intellectual structure of HRM scholarship. A downloadable, searchable HRM topic map is provided (http://bit.ly/HR-Map) that reveals: a) 1702 HRM article topics, b) the number of articles on each topic, c) topic relations, trends, and impact, and d) five major HRM topic clusters. We discuss the overall intellectual structure of HRM scholarship and review the five topic clusters. Next, the topic content of HRM scholarship is compared to that of 6114 articles from the practitioner-oriented outlet HR Magazine. We identify 100 topics emphasized to a much greater degree in the practitioner-oriented literature. Seven key themes for future research that could help align HRM scholarship with the interests of HR practitioners are identified and discussed.","Human Resource Management,Science mapping,Bibliometric,Research-practice gap","Maria PanayiotaMarkoullia,Colin I.S.G.Leeb,ElizaByingtona,Will A.Felpsa","Human Resource Management Review","https://doi.org/10.1016/j.hrmr.2016.10.001","https://www.sciencedirect.com/science/article/pii/S1053482216300699"
"A182","A literature review on individual creativity support systems","Individual creativity support systems have been developed to facilitate creative work. This article reviews the various design requirements and approaches proposed for supporting individual creative work, as well as relevant creativity theories. Current creativity support systems use many approaches in supporting the collection of relevant information and the creation of ideas or artifacts. However, the designs are typically based on just a few creativity theories. Based on various creativity theories, we propose a new integrated framework for individual creativity support systems. This framework enumerates aspects, components, and features of creativity support systems.","Creativity support systems,Innovation,Design,Creativity theory","KaiWanga,Jeffrey V.Nickersonb","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2017.04.035","https://www.sciencedirect.com/science/article/pii/S0747563217302777"
"A183","A Science Cloud for Smart Cities Research","Cities are densely populated and heavily equipped areas with a high level of service provision. Smart cities can use these conditions to achieve the goals of a smart society for their citizens. To facilitate such developments, the necessary IT-infrastructure has to be in place for supporting, amongst many other things, the whole lifecycle of big data management and analytics for research activities. At the Centre for IT-Intelligent Smart Energy for Cities, we have therefore been developing a flexible infrastructure, based on open sourcetechnologies. This paper presents this solution and its application in a city and building research.","Infrastructure for smart cities,cloud computing,big data research,case examples,building application","A.Hellera,X.Liub,P.Giannioua","Energy Procedia","https://doi.org/10.1016/j.egypro.2017.07.369","https://www.sciencedirect.com/science/article/pii/S1876610217329739"
"A184","Standards as a driving force that influences emerging technological trajectories in the converging world of the Internet and things: An investigation of the M2M/IoT patent network","While standards are said to create windows of opportunity in facilitation of technological convergence, it is not clear how they affect technological trajectories and strategic choices of firms in the face of convergence and in the process of catch-up. There is little research on the relationship between standards and technological trajectories, particularly in the age of convergence. This paper investigates how standards shape the emerging M2M/IoT technological trajectory and influence convergence in terms of technological importance and diversity. We, firstly, found that standards are a driving force of technological convergence. The second finding is that 3GPP standards assume a crucial role in setting the boundary conditions of the M2M/IoT technological systems. Third, we identified strategic groups and strategic patents that centered around the M2M/IoT trajectory. Forth, standards serve as an important factor in the process of creating a new path for catch-up firms (e.g. Huawei). These findings make contributions to innovation and standards studies by empirically examining the relationship between technological trajectories and standards. Furthermore, they clearly cast light on ongoing cooperation and competition along the M2M/IoT trajectory, and offer practical implications for catch-up strategies.","M2M/IoT,Standards,Technological trajectory,Catch-up","Dong-hyuKima,HeejinLeeb,JooyoungKwakc","Research Policy","https://doi.org/10.1016/j.respol.2017.05.008","https://www.sciencedirect.com/science/article/pii/S0048733317300835"
"A185","Biomedical Text Mining","Much information in the biomedical domain is documented and shared in the form of text. From scientific abstracts and publications to patient records and annotations in database entries, words in natural language form the main currency in which we represent, communicate, and store our knowledge. When we seek information within the vast knowledge repositories, we are faced with the need to sift through the text in order to retrieve and extract the information we need. Text mining is the high-level term denoting all activity pertaining to obtaining information from text – be it published documents, electronic health records, or drug labels. It encompasses a wide range of methods involving natural language processing, information extraction, information retrieval, and machine learning. Here, we aim to introduce the reader to the challenges of text mining and to the methods used for addressing them.","Articles,Database curation.,Documents,Electronic health records,Information extraction,Information retrieval,Machine learning,Natural language processing,Publications,PubMed,Text categorization,Text classification,Text mining","HagitShatkay","Encyclopedia of Bioinformatics and Computational Biology","https://doi.org/10.1016/B978-0-12-809633-8.12370-2","https://www.sciencedirect.com/science/article/pii/B9780128096338123702"
"A186","Corporate social responsibility for supply chain management: A literature review and bibliometric analysis","Corporate social responsibility (CSR) in supply chain management (SCM) has gained an increasing research attention in recent years. Extant studies have discussed stakeholder interests, performance evaluation, ethical sourcing, and sustainable production. The purpose of this paper is to develop a systematic study quantitatively depicting the knowledge structure and the intellectual progress of CSR for SCM. This research adopts bibliometric analysis in conjunction with network analysis to systematically evaluate the CSR-related publications for SCM. The analysis involves 628 peer-reviewed articles identified with careful selection of influential work. Data analytic techniques including citation analysis, co-citation analysis and co-word analysis are used. Key findings for researchers include (1) an analytical discussion of the five sub-fields that constitute the intellectual structure of CSR for SCM; (2) Theoretical and conceptual research significantly dominate in this field; (3) The topics of sustainable development and economic and social effects are more frequently discussed among scholars; (4) Key research gaps include lacking of practical and normative modeling research, and considering from the supplier perspectives in emerging economies. The findings suggest that future research would emerge a greater depth of practical and modeling analysis to enrich the theories.","Bibliometric analysis,Co-citation analysis,Co-word analysis,Corporate social responsibility,Supply chain management","YuntingFenga,QinghuaZhua,Kee-HungLaib","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2017.05.018","https://www.sciencedirect.com/science/article/pii/S0959652617309435"
"A187","Combining multiple scholarly relationships with author cocitation analysis: A preliminary exploration on improving knowledge domain mappings","Author cocitation analysis (ACA) is a branch of bibliometrics and knowledge representation that aims to map knowledge domains. However, ACA has been criticized because count-based measurement is too simple, and resulting maps are insufficiently informative. Since different scholarly relationships, e.g., coauthorship and author bibliographic coupling relationships, can extract out different relationships among authors in various perspectives, combining them with ACA for constructing knowledge domain mappings is our major purpose. The proposed method constructs the hybrid matrix from all relationships in four steps: relationship normalization, calculating the similarity between scholarly relationships, calculating adjustment parameters, and constructing hybrid relationships. The important parameters for integrating these matrices are calculated according to the distance in the hyperspace transformed from the similarity among the scholarly relationships by exploratory factor analysis. Compared with ACA, the results of the proposed method show: (1) More sub-fields in the given discipline can be identified when combining other scholarly relationships; (2) The more scholarly relationships added into ACA, the more details in terms of research area the method will find; (3) Good visualization in clustering is depicted when we combine other scholarly relationships. As a result, the proposed method offers a good choice to understand researchers and to map knowledge domains in a study field for integrating more scholarly relationships at the same time.","Author cocitation analysis,Coauthorship analysis,Author bibliographic coupling analysis,Scholarly network,Scientific intellectual structure,Knowledge domain mapping,Exploratory factor analysis (EFA),Bibliometrics","YiBua,ShaokangNib,Win-binHuangb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2017.06.004","https://www.sciencedirect.com/science/article/pii/S1751157716303674"
"A188","Semantic homophily in online communication: Evidence from Twitter","People are observed to assortatively connect on a set of traits. This phenomenon, termed assortative mixing or sometimes homophily, can be quantified through assortativity coefficient in social networks. Uncovering the exact causes of strong assortative mixing found in social networks has been a research challenge. Among the main suggested causes from sociology are the tendency of similar individuals to connect (often itself referred as homophily) and the social influence among already connected individuals. Distinguishing between these tendencies and other plausible causes and quantifying their contribution to the amount of assortative mixing has been a difficult task, and proven not even possible from observational data. However, another task of similar importance to researchers and in practice can be tackled, as we present here: understanding the exact mechanisms of interplay between these tendencies and the underlying social network structure. Namely, in addition to the mentioned assortativity coefficient, there are several other static and temporal network properties and substructures that can be linked to the tendencies of homophily and social influence in the social network and we herein investigate those.Concretely, we tackle a computer-mediated communication network (based on Twitter mentions) and a particular type of assortative mixing that can be inferred from the semantic features of communication content that we term semantic homophily. Our work, to the best of our knowledge, is the first to offer an in-depth analysis on semantic homophily in a communication network and the interplay between them. We quantify diverse levels of semantic homophily, identify the semantic aspects that are the drivers of observed homophily and show insights in its temporal evolution. By analyzing these mechanisms we increase understanding on what are the semantic aspects that shape and how they shape the human computer-mediated communication. In addition, our analysis framework presented on this concrete case can be easily adapted, extended and applied on other type of social networks and for different types of homophily.","Homophily,Semantics,Influence,Semantic relatedness,Twitter,Wikipedia,Social network analysis,Computational social science","SanjaŠcepanovica,IgorMishkovskib,BrunoGonçalvesc,Trung HieuNguyend,PanHuief","Online Social Networks and Media","https://doi.org/10.1016/j.osnem.2017.06.001","https://www.sciencedirect.com/science/article/pii/S2468696417300204"
"A189","Application of Database Approaches to the Study of Earth’s Aeolian Environments: Community Needs and Goals","Aeolian science is faced with significant challenges that impact its ability to benefit from recent advances in information technology. The discipline deals with high-end systems in the form of ground and satellite based sensors, computer modeling and simulation, and wind tunnel experiments. Aeolian scientists also collect field data manually with observational methods that may differ significantly between studies with little agreement on even basic morphometric parameters and terminology. Data produced from these studies, while forming the core of research papers and reports, is rarely available to the community at large. Recent advances are also superimposed on an underlying semantic structure that dates to the 1800’s or earlier that is confusing, with ambiguously defined, and at times even contradictory, meanings.The aeolian “world-view” does not always fit within neat increments nor is defined by crisp objects. Instead change is continuous and features are fuzzy. Development of an ontological framework to guide spatiotemporal research is the fundamental starting point for organizing data in aeolian science. This requires a “rethinking” of how we define, collect, process, store and share data along with the development of a community-wide collaborative approach designed to bring the discipline into a data rich future. There is also a pressing need to develop efficient methods to integrate, analyze and manage spatial and temporal data and to promote data produced by aeolian scientists so it is available for preparing diagnostic studies, as input into a range of environmental models, and for advising national and international bodies that drive research agendas. This requires the establishment of working groups within the discipline to deal with content, format, processing pipelines, knowledge discovery tools and database access issues unique to aeolian science.Achieving this goal requires the development of comprehensive and highly-organized databases, tools that allow aeolian scientists as well as those in related disciplines to access and analyze the wealth of data available, and a supporting infrastructure and community-wide effort that allows aeolian scientists to communicate their results in replicable ways to scientists and decision and policy makers. Fortunately, much of the groundwork required to move aeolian science into a data rich future has been developed in other data rich physical science fields, and within the computer science and information technology disciplines.","","Louis A.Scuderia,Gary S.Weissmanna,Adrian J.Hartleyb,XiaopingYangc,NicholasLancasterd","Aeolian Research","https://doi.org/10.1016/j.aeolia.2017.05.004","https://www.sciencedirect.com/science/article/pii/S1875963716301732"
"A190","A bibliometric-based survey on AHP and TOPSIS techniques","In recent years, the employment of multiple criteria decision analysis (MCDA) techniques in solving complex real-world problems has increased exponentially. The willingness to build advanced decision models, with higher capabilities to support decision making in a wide range of applications, promotes the integration of MCDA techniques with efficient systems such as intelligence and expert systems, geographic information systems, etc. Amongst the most applied MCDA techniques are Analytic Hierarchy Process (AHP) and Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS). The development of a comprehensive perspective on research activities associated with the applications of these methods provides insights into the contributions of countries, institutes, authors and journals towards the advancements of these methods. Furthermore, it helps in identifying the status and trends of research. This in turn will help researchers in shaping up and improving future research activities and investments. To meet these aims, a bibliometric analysis based on data harvested from Scopus database was carried out to identify a set of bibliometric performance indicators (i.e. quantitative indicators such as productivity, and qualitative indicators such as citations and Hirsch index (h-index)). Additionally, bibliometric visualization maps were employed to identify the hot spots of research. The total research output was 10,188 documents for AHP and 2412 documents for TOPSIS. China took a leading position in AHP research (3513 documents; 34.5%). It was also the leading country in TOPSIS research (846 documents; 35.1%). The most collaborated country in AHP research was the United States, while in case of TOPSIS it was China. The United States had gained the highest h-index (78) in AHP research, while in TOPSIS it was Taiwan with h-index of 46. Expert Systems with Applications journal was the most productive journal in AHP (204; 2.0%) and TOPSIS research (125; 5.2%), simultaneously. University of Tehran, Iran and Islamic Azad University, Iran were the most productive institutions in AHP (173; 1.7%) and TOPSIS (115; 4.8%) research, simultaneously. The major hot topics that utilized AHP and will continue to be active include different applications of geographic information systems, risk modeling and supply chain management. While for TOPSIS, they are supply chain management and sustainability research. Overall, this analysis has shown increasing recognition of powerful of MCDA techniques to support strategic decisions. The efficacy of these methods in the previous context promotes their progress and advancements.","Multiple criteria decision analysis,Scopus,Impact factor,Operation research,Citation,Bibliometric maps","Shaher H.Zyoud,DanielaFuchs-Hanusch","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2017.02.016","https://www.sciencedirect.com/science/article/pii/S0957417417300982"
"A191","ivga: A fast force-directed method for interactive visualization of complex networks","Complex networks play a very important role in various fields of science as data structures, which aggregate information about mutual relationships between numerous objects. The structural properties of these large graphs can be scrutinized throughout their interactive visualization. However, visual analysis of complex networks consisting of |V| ~ 106+ vertices represents a great challenge for nowadays computer systems both from computational and storage perspective. Therefore, the existing graph drawing methods involving greater than O(|V|) time and space complexity cannot be regarded as promising tools in the advent of the Big Data era. We present here a new and very fast graph drawing method with O(|V|) time and space complexity – ivga (interactive visualization of graphs). We evaluate its usefulness and performance by testing ivga on the large complex networks from the Stanford Large Network Dataset Collection. We demonstrate that ivga allows for very fast interactive visualization of large graphs consisting of up to a few million vertices on a regular laptop what makes it very competitive to other state-of-art graph drawing methods. Particularly, we recommend ivga method for interactive visualization of large non-planar complex networks such as small-world and scale-free social networks. The main concept of ivga can be seriously considered in developing tools for visualization and analysis of really huge networks, with billions of vertices and edges, on Big Data systems.","Graph visualization,Complex networks,Force-directed method,Big Data","WitoldDzwinel,RafalWcislo,WojciechCzech","Journal of Computational Science","https://doi.org/10.1016/j.jocs.2016.09.001","https://www.sciencedirect.com/science/article/pii/S1877750316301430"
"A192","Fuzzy rule based profiling approach for enterprise information seeking and retrieval","With the exponential growth of information available on the Internet and various organisational intranets there is a need for profile based information seeking and retrieval (IS&R) systems. These systems should be able to support users with their context-aware information needs. This paper presents a new approach for enterprise IS&R systems using fuzzy logic to develop task, user and document profiles to model user information seeking behaviour. Relevance feedback was captured from real users engaged in IS&R tasks. The feedback was used to develop a linear regression model for predicting document relevancy based on implicit relevance indicators. Fuzzy relevance profiles were created using Term Frequency and Inverse Document Frequency (TF-IDF) analysis for the successful user queries. Fuzzy rule based summarisation was used to integrate the three profiles into a unified index reflecting the semantic weight of the query terms related to the task, user and document. The unified index was used to select the most relevant documents and experts related to the query topic. The overall performance of the system was evaluated based on standard precision and recall metrics which show significant improvements in retrieving relevant documents in response to user queries.","Enterprise search,Enterprise information seeking & retrieval,Personalised information retrieval,Fuzzy logic, Expert search,Rulebased summarisation,Fuzzy profiling","ObadaAlhabashneha,RahatIqbalb,FaiyazDoctorb,AnneJamesc","Information Sciences","https://doi.org/10.1016/j.ins.2016.12.040","https://www.sciencedirect.com/science/article/pii/S0020025516322605"
"A193","Mapping research on carbon emissions trading: a co-citation analysis","Carbon emissions trading (CET) is a market mechanism, aims to promote the control of globe greenhouse-gas emissions. It is an important part of international environmental cooperation and it is also the important application research filed of environmental economics and institutional economics. There is a very obvious phenomenon that the publications about CET increasing year by year. This paper adopts the scientometric analysis method to assess the current state and explore the development trends of carbon emission trading domain based on the literature data retrieved from Web of Science. The research results of this paper could answer the following questions clearly. 1) Which subject category is the most popular in CET research area? Which journal published the most number of articles in this area? Which institution and country is the most productive in CET domain? 2) What are the major research areas and what documents are the most cited? Which journal are the most representative in CET research domain? 3) What are the new emerging trends and development in CET research area? On the whole, the research method in this paper provided a fresh research approach to assess the performance of CET research. The findings may help for the new researchers to pick out the most relevant articles, journals, institutions and seize the research frontier in CET field.","CET,Review,CiteSpace,Visualization analysis,Quantitative","DejianYuac,ChaoXub","Renewable and Sustainable Energy Reviews","https://doi.org/10.1016/j.rser.2016.11.144","https://www.sciencedirect.com/science/article/pii/S1364032116309005"
"A194","A visual UML-based conceptual model of information-seeking by computer science researchers","The information-seeking process carried out by researchers is complex and full of different variables. We have represented this complexity for computer science researchers in the form of a conceptual model. The model is presented in a visual form using the UML modeling language, since it allows conveying all the complexity present in such a process with greater clarity. It has been obtained after carrying out two qualitative studies —a focus group and semi-structured interviews— with computer science researchers. The proposed overall model is composed of 4 sub-models: of the documents used in the process, of the tasks undertaken, of the user, and of the information-seeking process context. The conceptual model proposed can serve for the purpose of better understanding the information-seeking process, for example for librarians or for software designers wanting to provide a support to such task. It can also be useful as a framework to characterize different software solutions aimed to information-seeking in research activities, and to compare them.","Information-seeking process,Visual conceptual model,Information retrieval,Human-computer interaction,Qualitative study analysis,UML","CristianMoral,AngelicaDe Antonio,XavierFerre","Information Processing & Management","https://doi.org/10.1016/j.ipm.2016.10.005","https://www.sciencedirect.com/science/article/pii/S030645731630560X"
"A195","Patterns for emerging application integration scenarios: A survey","The discipline of enterprise application integration (EAI) enables the decoupled communication between (business) applications, and thus became a cornerstone of today’s IT architectures. In 2004, the book by Hohpe and Woolf on Enterprise Integration Patterns (EIP) provided a fundamental collection of messaging patterns, denoting the building blocks of many EAI system implementations. Since then, multiple new trends and a broad range of new application scenarios have emerged, e. g., cloud and mobile computing, multimedia streams. These developments ultimately lead to conceptual changes and challenges such as larger data volumes (i. e., message sizes), a growing number of messages (i. e., velocity) and communication partners, and even more diverse message formats (i. e., variety). However, the research since 2004 focused on isolated EAI solutions, and thus a broader and integrated analysis of solutions and new patterns is missing. In this survey, we summarize new trends and application scenarios which serve as a frame to structure our survey of academic research on EIP, existing systems for EAI and also to classify integration patterns from these sources. We evaluate recently developed integration solutions and patterns in the context of real-world integration scenarios. Finally, we derive and summarize remaining challenges and open research questions.","Cloud integration,Device integration,Enterprise application integration,Enterprise integration patterns,Hybrid integration","DanielRitterab,NormanMaya,StefanieRinderle-Mab","Information Systems","https://doi.org/10.1016/j.is.2017.03.003","https://www.sciencedirect.com/science/article/pii/S0306437917301084"
"A196","5.21: Computational Toxicology","Computational toxicology played an important role in the ongoing paradigm shift in the field of toxicology. Computation toxicology is inherently a multidisciplinary field, and it comprises the building of models of many different types with different techniques. This article explains a variety of model building techniques and various supporting resources needed to build high-quality predictive models. The article is divided into four broad areas: (1) computational toxicology resources, (2) computational toxicology projects, (3) computational toxicology modeling, and (4) future directions and perspectives. All areas are composed around common themes of developmental toxicology and direct and indirect input from various computational toxicological analysis and integrative modeling. Predictive models also benefit from multiple data types and various available knowledge bases that play an important role from comprehensive understanding of toxicity. An integrative approach using, for example, biological pathways to inform feature selection for models has capability to balance statistical performance and a better understanding of modes of action. Due to these advantages, computational toxicology will be an indispensable cornerstone in future advances in toxicological sciences.","Bioinformatics,Computational toxicity,Drug-induced liver injury,Endocrine disruptor knowledge base,Endocrine disruptors,High-throughput screening,Liver toxicity knowledge base,Ontology,Quantitative structure–activity relationships (QSARs),Text mining,Toxicogenomics","S.Thakkar,R.Perkins,H.Hong,W.Tong","Comprehensive Toxicology (Third Edition)","https://doi.org/10.1016/B978-0-12-801238-3.64317-9","https://www.sciencedirect.com/science/article/pii/B9780128012383643179"
"A197","Visual patent trend analysis for informed decision making in technology management","Patent information is increasingly important for decision makers. Their demand for exploratory trend and competitor analysis poses new challenges with respect to the processing and visualization of patent data. We present PatStream: a highly interactive approach for decision support through patent exploration, which offers a streamgraph-based visualization for trends at different levels of abstraction and facilitates the combined analysis of their various aspects, including patent applicants, IPC distributions and innovativeness. PatStream integrates powerful natural language processing techniques for concept extraction and patent similarity assessment to allow for content-oriented visualization and analysis.","Patent analysis,Trend analysis,Visualization,Visual analysis,Patent information,Natural language processing","QiHana,FlorianHeimerlb,JoanCodina-Filbac,SteffenLohmanne,LeoWannercd,ThomasErtla","World Patent Information","https://doi.org/10.1016/j.wpi.2017.04.003","https://www.sciencedirect.com/science/article/pii/S0172219017300455"
"A198","Ranking in evolving complex networks","Complex networks have emerged as a simple yet powerful framework to represent and analyze a wide range of complex systems. The problem of ranking the nodes and the edges in complex networks is critical for a broad range of real-world problems because it affects how we access online information and products, how success and talent are evaluated in human activities, and how scarce resources are allocated by companies and policymakers, among others. This calls for a deep understanding of how existing ranking algorithms perform, and which are their possible biases that may impair their effectiveness. Many popular ranking algorithms (such as Google’s PageRank) are static in nature and, as a consequence, they exhibit important shortcomings when applied to real networks that rapidly evolve in time. At the same time, recent advances in the understanding and modeling of evolving networks have enabled the development of a wide and diverse range of ranking algorithms that take the temporal dimension into account. The aim of this review is to survey the existing ranking algorithms, both static and time-aware, and their applications to evolving networks. We emphasize both the impact of network evolution on well-established static algorithms and the benefits from including the temporal dimension for tasks such as prediction of network traffic, prediction of future links, and identification of significant nodes.","Complex networks,Ranking,Centrality metrics,Temporal networks,Recommendation,Network science","HaoLiaoa,Manuel SebastianMarianiba,MatúšMedocdb,Yi-ChengZhangb,Ming-YangZhoua","Physics Reports","https://doi.org/10.1016/j.physrep.2017.05.001","https://www.sciencedirect.com/science/article/pii/S0370157317300935"
"A199","A survey on trends of cross-media topic evolution map","Rapid advancements in internet and social media technologies have made “information overload” a rampant and widespread problem. Complex subjects, histories, or issues break down into branches, side stories, and intertwining narratives; a “topic evolution map” can assist in joining together and clarifying these disparate parts of an unfamiliar territory. This paper reviews the extant research on topic evolution map based on text and cross-media corpora over the past decade. We first define a series of necessary terms, then go on to describe the traditional topic evolution map per 1) topic evolution over time, based on the probabilistic generative model, and 2) topic evolution from a non-probabilistic perspective. Next, we discuss the current state of research on topic evolution map based on the cross-media corpus, including some open questions and possible future research directions. The main contribution of this review is in its construction of an evolution map that can be used to visualize and integrate the extant studies on topic modeling – specifically in regards to cross-media research.","Cross-media,Topic evolution,Topic map,Probabilistic generative model","HoukuiZhouacd,HuiminYuab,RolandHua,JunguoHucd","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2017.03.009","https://www.sciencedirect.com/science/article/pii/S0950705117301272"
"A200","Using ontology-based semantic similarity to facilitate the article screening process for systematic reviews","ObjectiveSystematic Reviews (SRs) are utilized to summarize evidence from high quality studies and are considered the preferred source of evidence-based practice (EBP). However, conducting SRs can be time and labor intensive due to the high cost of article screening. In previous studies, we demonstrated utilizing established (lexical) article relationships to facilitate the identification of relevant articles in an efficient and effective manner. Here we propose to enhance article relationships with background semantic knowledge derived from Unified Medical Language System (UMLS) concepts and ontologies.,MethodsWe developed a pipelined semantic concepts representation process to represent articles from an SR into an optimized and enriched semantic space of UMLS concepts. Throughout the process, we leveraged concepts and concept relations encoded in biomedical ontologies (SNOMED-CT and MeSH) within the UMLS framework to prompt concept features of each article. Article relationships (similarities) were established and represented as a semantic article network, which was readily applied to assist with the article screening process. We incorporated the concept of active learning to simulate an interactive article recommendation process, and evaluated the performance on 15 completed SRs. We used work saved over sampling at 95% recall (WSS95) as the performance measure.,ResultsWe compared the WSS95 performance of our ontology-based semantic approach to existing lexical feature approaches and corpus-based semantic approaches, and found that we had better WSS95 in most SRs. We also had the highest average WSS95 of 43.81% and the highest total WSS95 of 657.18%.,ConclusionWe demonstrated using ontology-based semantics to facilitate the identification of relevant articles for SRs. Effective concepts and concept relations derived from UMLS ontologies can be utilized to establish article semantic relationships. Our approach provided a promising performance and can easily apply to any SR topics in the biomedical domain with generalizability.","Evidence-based practice,Systematic review,Text mining,Automatic article classification,Semantic similarity,Biomedical ontologies","XiaonanJiab,AlanRitterb,Po-YinYena","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2017.03.007","https://www.sciencedirect.com/science/article/pii/S1532046417300576"
"A201","APhA2017 abstracts of contributed papers","","","","Journal of the American Pharmacists Association","https://doi.org/10.1016/j.japh.2017.04.011","https://www.sciencedirect.com/science/article/pii/S1544319117302145"
"A202","Research trajectories of Service-Dominant Logic: Emergent themes of a unifying paradigm in business and management","We describe the research trajectories associated with S-D Logic and the scholarly activity it encompasses across a breadth of disciplines by conducting a bibliometric analysis of a body of literature citing two fundamental S-D Logic publications between 2004–2014. The bibliometric analysis reveals four pertinent research trajectories: Value co-creation, Resources (incl. integration), Brands, and Innovation. These empirical findings are supported by qualitative insights and projections obtained from structured interviews with S-D Logic scholars using the Delphi method, which identifies ten research trajectories: Actors, Context, Innovation, Institutions, Markets, Resources, Service, Systems, Value co-creation, and Value propositions. The main tenets, relevant literature, and syntheses of research questions for the aforementioned research trajectories are provided. Results indicate that the scientific community is evaluating fundamental ontological and epistemological questions of S-D Logic. Emergent themes (complex and fractal phenomena, generic conceptualizations, technological innovation and democratization processes, and institutionalization practices) are discussed. The results provide insight into the development of paradigms in the managerial sciences. The delineation of the paradigm's thematic boundaries, its emergent themes, and identification of central research trajectories informs an advanced understanding of the nature of economic exchange and value creation for both practitioners and the managerial sciences, thus aiding the transdisciplinary production of knowledge.","S-D logic,Delphi,Value co-creation,Resources,Innovation,Systems,Institutions,Symbols,Practices,Processes","AttilaPohlmannab,ValtteriKaartemoc","Industrial Marketing Management","https://doi.org/10.1016/j.indmarman.2017.01.001","https://www.sciencedirect.com/science/article/pii/S0019850117300056"
"A203","Intellectual structure of knowledge in iMetrics: A co-word analysis","As an iMetrics technique, co-word analysis is used to describe the status of various subject areas, however, iMetrics itself is not examined by a co-word analysis. For the purpose of using co-word analysis, this study tries to investigate the intellectual structure of iMetrics during the period of 1978 to 2014. The research data are retrieved from two core journals on iMetrics research (Scientometrics, and Journal of Informetrics) and relevant articles in six journals publishing iMetrics studies. Application of hierarchical clustering led to the formation of 11 clusters representing the intellectual structure of iMetrics, including “Scientometric Databases and Indicators,” “Citation Analysis,” “Sociology of Science,” “Issues Related to Rankings of Universities, Journals, etc.,” “Information Visualization and Retrieval,” “Mapping Intellectual Structure of Science,” “Webometrics,” “Industry–University–Government Relations,” “Technometrics (Innovation and Patents), “Scientific Collaboration in Universities”, and “Basics of Network Analysis.” Furthermore, a two-dimensional map and a strategic diagram are drawn to clarify the structure, maturity, and cohesion of clusters.","iMetrics,Information metrics,Co-word analysis,Strategic diagram,Knowledge structure","Ali AkbarKhasseh,FaramarzSoheili,Hadi SharifMoghaddam,Afshin MousaviChelak","Information Processing & Management","https://doi.org/10.1016/j.ipm.2017.02.001","https://www.sciencedirect.com/science/article/pii/S0306457316303338"
"A204","Computer-aided diagnosis: A survey with bibliometric analysis","Computer-aided diagnosis (CAD) has been a promising area of research over the last two decades. However, CAD is a very complicated subject because it involves a number of medicine and engineering-related fields. To develop a research overview of CAD, we conducted a literature survey with bibliometric analysis, which we report here. Our study determined that CAD research has been classified and categorized according to disease type and imaging modality. This classification began with the CAD of mammograms and eventually progressed to that of brain disease. Furthermore, based on our results, we discuss future directions and opportunities for CAD research. First, in contrast to the typical hypothetical approach, the data-driven approach has shown promise. Second, the normalization of the test datasets and an evaluation method is necessary when adopting an algorithm and a system. Third, we discuss opportunities for the co-evolution of CAD research and imaging instruments—for example, the CAD of bones and pancreatic cancer. Fourth, the potential of synergy with CAD and clinical decision support systems is also discussed.","Computer-aided diagnosis,CAD,Citation network analysis,Bibliometric analysis","RyoheiTakahashi,YuyaKajikawa","International Journal of Medical Informatics","https://doi.org/10.1016/j.ijmedinf.2017.02.004","https://www.sciencedirect.com/science/article/pii/S1386505617300357"
"A205","Forecasting potential sensor applications of triboelectric nanogenerators through tech mining","The Triboelectric Nanogenerator (TENG), invented in 2012, is an emerging energy harvesting technology that efficiently converts ambient mechanical energy into electricity. Much work has been done to develop this device and improve its performance. However, no systematic report about its applications through large-scale publication and patent data analysis is available. In this study, we use “Tech Mining,” a systematic analytical method based on structured texts applied to publication and patent abstract data, to analyze potential applications of TENGs. A series of applications from product scale to industry scale are identified. The findings show that when used as sensors, TENGs are mostly applicable in automation and energy-intensive industries such as automotive, medical or surgical devices, consumer electronics and household appliances. TENGs in the form of sensors can also be integrated with future-oriented and exponentially growing technologies such as robotics, drones, nanotechnology, and bioinformatics that will create enormous value for future economies. Moreover, applications of TENGs as sensors are also in line with current global trends of science and technology development, including the “Internet of Things,” big data, clean energy, and smart cities. Combined with those technologies and industries, TENGs can help in tackling challenges of global warming, environmental pollution and security systems. We suggest the TENG research community to widen interdisciplinary collaboration, pursue connections with industry, and file more patents as R&D progresses. In addition, research limitations and future development directions of TENG are pointed out.","Triboelectric nanogenerator,Tech mining,Sensors,Application","HaoshuPenga1,XudongFangb1,SamiraRanaeic,ZhenWend,Alan L.Portere","Nano Energy","https://doi.org/10.1016/j.nanoen.2017.04.006","https://www.sciencedirect.com/science/article/pii/S2211285517302069"
"A206","Computation of heterogeneous object co-embeddings from relational measurements","Dimensionality reduction and data embedding methods generate low dimensional representations of a single type of homogeneous data objects. In this work, we examine the problem of generating co-embeddings or pattern representations from two different types of objects within a joint common space of controlled dimensionality, where the only available information is assumed to be a set of pairwise relations or similarities between instances of the two groups. We propose a new method that models the embedding of each object type symmetrically to the other type, subject to flexible scale constraints and weighting parameters. The embedding generation relies on an efficient optimization dispatched using matrix decomposition, that is also extended to support multidimensional co-embeddings. We also propose a scheme of heuristically reducing the parameters of the model, and a simple way of measuring the conformity between the original object relations and the ones re-estimated from the co-embeddings, in order to achieve model selection by identifying the optimal model parameters with a simple search procedure. The capabilities of the proposed method are demonstrated with multiple synthetic and real-world datasets from the text mining domain. The experimental results and comparative analyses indicate that the proposed algorithm outperforms existing methods for co-embedding generation.","Co-embedding generation,Relational information,Heterogeneous object analysis,Joint space projection.","YuWua,TingtingMub,PanosLiatsisc,John Y.Goulermasa","Pattern Recognition","https://doi.org/10.1016/j.patcog.2016.12.004","https://www.sciencedirect.com/science/article/pii/S0031320316303909"
"A207","Smart sustainable cities of the future: An extensive interdisciplinary literature review","In recent years, the concept of smart sustainable cities has come to the fore. And it is rapidly gaining momentum and worldwide attention as a promising response to the challenge of urban sustainability. This pertains particularly to ecologically and technologically advanced nations. This paper provides a comprehensive overview of the field of smart (and) sustainable cities in terms of its underlying foundations and assumptions, state–of–the art research and development, research opportunities and horizons, emerging scientific and technological trends, and future planning practices. As to the design strategy, the paper reviews existing sustainable city models and smart city approaches. Their strengths and weaknesses are discussed with particular emphasis being placed on the extent to which the former contributes to the goals of sustainable development and whether the latter incorporates these goals. To identify the related challenges, those models and approaches are evaluated and compared against each other in line with the notion of sustainability. The gaps in the research within the field of smart sustainable cities are identified in accordance with and beyond the research being proposed. As a result, an integrated approach is proposed based on an applied theoretical perspective to align the existing problems and solutions identification for future practices in the area of smart sustainable urban planning and development. As to the findings, the paper shows that critical issues remain unsettled, less explored, largely ignored, and theoretically underdeveloped for applied purposes concerning existing models of sustainable urban form as to their contribution to sustainability, among other things. It also reveals that numerous research opportunities are available and can be realized in the realm of smart sustainable cities. Our perspective on the topic in this regard is to develop a theoretically and practically convincing model of smart sustainable city or a framework for strategic smart sustainable urban development. This model or framework aims to address the key limitations, uncertainties, paradoxes, and fallacies pertaining to existing models of sustainable urban form—with support of ICT of the new wave of computing and the underlying big data and context–aware computing technologies and their advanced applications. We conclude that the applied theoretical inquiry into smart sustainable cities of the future is deemed of high pertinence and importance—given that the research in the field is still in its early stages, and that the subject matter draws upon contemporary and influential theories with practical applications. The comprehensive overview of and critique on existing work on smart (and) sustainable cities provide a valuable and seminal reference for researchers and practitioners in related research communities and the necessary material to inform these communities of the latest developments in the area of smart sustainable urban planning and development. In addition, the proposed holistic approach is believed to be the first of its kind. That is, it has not been, to the best of one’s knowledge, investigated or produced elsewhere.","Smart cities,Sustainable cities,Smart sustainable cities,Sustainable urban forms,Urban sustainability,Sustainable development goals,ICT,Computing,Planning,Big data analytics","Simon EliasBibria,JohnKrogstieb","Sustainable Cities and Society","https://doi.org/10.1016/j.scs.2017.02.016","https://www.sciencedirect.com/science/article/pii/S2210670716304073"
"A208","1.20: Space-Time GIS and Its Evolution","Human activities and surrounding environments dynamically change over space and time. Geographers have long studied this change by describing patterns and processes across spatial and temporal scales in domains such as human migration, transportation, environmental change, and socio-economic dynamics. In the last two decades, the geographic information system (GIS) and geographic information science (GISci) research communities have witnessed a growing interest in studying spatiotemporal data. These data are available largely due to advancements in remote sensing and location-aware technologies and can be used to advance geographic knowledge over time. By incorporating the temporal dimension into the conventional GIS framework, researchers in many fields have contributed toward the development of space-time GIS (ST-GIS). This chapter provides a review of research trends in ST-GIS using dynamic topic modeling, a text mining method to analyze the evolution of topics in the ST-GIS literature.","Dynamic topic modeling,Review,Space-time GIS,Text mining,Trend analysis","AtsushiNara","Comprehensive Geographic Information Systems","https://doi.org/10.1016/B978-0-12-409548-9.09626-3","https://www.sciencedirect.com/science/article/pii/B9780124095489096263"
"A209","Multilevel exploration of the realities of interdisciplinary research centers for the management of knowledge integration","The fostering of interdisciplinarity is increasingly requested of research organizations. However, conventional approaches to academic research management limit our understanding of the way interdisciplinary research (IDR) centers integrate multiple disciplines. This paper proposes a multilevel approach to explore the patterns of knowledge integration and the forms of research organization emerging from the practices and activities of IDR centers. Several bibliometric-based, network-oriented and visualization-rich approaches are used. The cases of two prominent IDR centers are considered: Harvard University's Wyss Institute and Kyoto University's WPI-iCeMS. At the macro level, our results show similarities in the scientific positioning of both IDR centers, which translate into differences in the nature, intensity and drivers of their knowledge interconnections at the meso-level. At the micro-level, we demonstrate that far from idealizations of full convergence, the realities of IDR centers are characterized by heterogeneous patchworks of multi-trajectory research domains—some of these enabling, others generating interdisciplinary knowledge. Differences in knowledge integration occur between but also, and more importantly, within IDR centers. Thus, tailored strategies tuned to the particularities of organizations and topic-based forms of research organization appear to cope better with interdisciplinary knowledge. The understanding of these inter- and intra-organizational differences proves crucial for effectively fostering knowledge integration. An integrated model relating levels of research management and visualization approaches is proposed for the management and assessment of knowledge integration in IDR centers.","Interdisciplinarity,Knowledge integration,Knowledge structures,Bibliometric mapping,University research centers,R&D management/assessment,Multilevel approach,Convergence","AlfonsoÁvila-Robinsona,ShintaroSengokub","Technovation","https://doi.org/10.1016/j.technovation.2017.01.003","https://www.sciencedirect.com/science/article/pii/S0166497217300093"
"A210","Green supply chain performance measures: A review and bibliometric analysis","The concept of green supply chain management is evolving rapidly and gaining popularity in the research community. This research reviews the literature on green supply chain performance measures for the purpose of providing thorough insight into the field. Using bibliometric and network analysis, the research critically evaluates 653 articles published over the past 22 years and identifies some of the top contributing authors, organizations and key research topics related to the field. In addition, the most influential works based on citations and PageRank are also obtained and compared. At last, major research areas and potential future directions are identified by conducting network analysis.","Green supply chain management,Performance measures,Bibliometric analysis,Network analysis","DeepaMishraa,AngappaGunasekaranb,ThanosPapadopoulosc,BenjaminHazend","Sustainable Production and Consumption","https://doi.org/10.1016/j.spc.2017.01.003","https://www.sciencedirect.com/science/article/pii/S2352550917300076"
"A211","Discovering themes and trends in transportation research using topic modeling","Transportation research is a key area in both science and engineering. In this paper, we present an empirical analysis of 17,163 articles published in 22 leading transportation journals from 1990 to 2015. We apply a latent Dirichlet allocation (LDA) model on article abstracts to infer 50 key topics. We show that those characterized topics are both representative and meaningful, mostly corresponding to established sub-fields in transportation research. These identified fields reveal a research landscape for transportation. Based on the results of LDA, we quantify the similarity of journals and countries/regions in terms of their aggregated topic distributions. By measuring the variation of topic distributions over time, we find some general research trends, such as topics on sustainability, travel behavior and non-motorized mobility are becoming increasingly popular over time. We also carry out this temporal analysis for each journal, observing a high degree of consistency for most journals. However, some interesting anomaly, such as special issues on particular topics, are detected from temporal variation as well. By quantifying the temporal trends at the country/region level, we find that countries/regions display clearly distinguishable patterns, suggesting that research communities in different regions tend to focus on different sub-fields. Our results could benefit different parties in the academic community—including researchers, journal editors and funding agencies—in terms of identifying promising research topics/projects, seeking for candidate journals for a submission, and realigning focus for journal development.","Transportation research,Topic modeling,Publication data,Research policy","LijunSuna,YafengYinb","Transportation Research Part C: Emerging Technologies","https://doi.org/10.1016/j.trc.2017.01.013","https://www.sciencedirect.com/science/article/pii/S0968090X17300207"
"A212","3.14: Chemical Data Formats, Fingerprints, and Other Molecular Descriptions for Database Analysis and Searching","In this chapter we strive to provide a comprehensive but reasonably compact overview of the various possibilities for the computational representation of molecules. This includes a detailed introduction to the most commonly used chemical file formats (complemented with a few novel or more specific representations), a thorough overview of the theoretical backgrounds of various molecular fingerprints and descriptors, and a complete section devoted to similarity measures and data fusion approaches. Finally, we provide a list of the most important online chemical databases and conclude the chapter with a short outlook on present trends and future expectations.","Chemical file format,Cheminformatics,Data fusion,Database analysis,Distance metric,Drug design,Molecular descriptor,Molecular fingerprint,Similarity,Virtual screening","D.Bajusz,A.Rácz,K.Héberger","Comprehensive Medicinal Chemistry III","https://doi.org/10.1016/B978-0-12-409547-2.12345-5","https://www.sciencedirect.com/science/article/pii/B9780124095472123455"
"A213","Excavating the mother lode of human-generated text: A systematic review of research that uses the wikipedia corpus","Although primarily an encyclopedia, Wikipedia’s expansive content provides a knowledge base that has been continuously exploited by researchers in a wide variety of domains. This article systematically reviews the scholarly studies that have used Wikipedia as a data source, and investigates the means by which Wikipedia has been employed in three main computer science research areas: information retrieval, natural language processing, and ontology building. We report and discuss the research trends of the identified and examined studies. We further identify and classify a list of tools that can be used to extract data from Wikipedia, and compile a list of currently available data sets extracted from Wikipedia.","Information retrieval,Information extraction,Natural language processing,Ontologies,Wikipedia,Literature review","MohamadMehdia,ChituOkolib,MostafaMesgaric,Finn ÅrupNielsend,ArtoLanamäkie","Information Processing & Management","https://doi.org/10.1016/j.ipm.2016.07.003","https://www.sciencedirect.com/science/article/pii/S0306457316303004"
"A214","Anticipation of converging technology areas — A refined approach for the identification of attractive fields of innovation","A series of product innovations owe their economic success and origin to the impetus and know-how from disciplines and industries that were hitherto unfamiliar to the actors in the industries concerned. This phenomenon, known as “convergence”, leads to emerging industry segments and offers a wide array of opportunities for synergies. Against this background, a significant emphasis has been put on anticipating technology convergence as well as identifying and understanding the changing innovation patterns and industry structure associated with convergence. The timely recognition of converging technological fields enables the innovating enterprises to exert a positive influence on the changing value-chain.This paper introduces a refined methodological approach for the anticipation of converging technology areas based on the concept of knowledge flow. The proposed method is illustrated using patents related to the areas of Nutraceuticals and Functional Food (NFF), Nanotechnology and Wearables.Our results indicate that the emerging technology convergence can be expressed by the concept of “weak signals”. The indices derived from the proposed approach are capable of uncovering the relationships between the individual technological sectors and provide numerical metrics to measure the presence of converging technologies.","Technological convergence,IPC co-classification,Knowledge flow,Functional food,Patent analysis,Wearables","Chie HoonSong,DavidElvers,JensLeker","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2016.11.001","https://www.sciencedirect.com/science/article/pii/S0040162516305959"
"A215","Text mining to gain technical intelligence for acquired target selection: A case study for China's computer numerical control machine tools industry","Technology strategy plays an increasingly important role in today's Mergers and Acquisitions (M&A) activities. Informing that strategy with empirical intelligence offers great potential value to R&D managers and technology policy makers. This paper proposes a methodology, based on patent analysis, to extract technical intelligence to identify M&A target technologies and evaluate relevant target companies to facilitate M&A target selection. We apply the term clumping process and a trend analysis together with policy and market information to profile present R&D status and capture future development signals and trends in order to grasp a range of significant domain-based technologies. Furthermore, a comparison between a selected acquirer and leading players is used to identify significant technologies and sub-technologies for specific strategy-oriented technology M&A activities. Finally, aiming to recommend appropriate M&A target companies, we set up an index-based system to evaluate the acquired target candidates from both firms-side perspective and target firm-side perspective and differentially weigh for specific M&A situations. We provide an empirical study in the field of computer numerical control machine tools (CNCMT) in China to identify technology M&A targets for an emerging Chinese CNCMT company — Estun Automation under different M&A strategies.","Technical intelligence,Mergers and acquisitions,Patent analysis,Text mining","TingtingMaa,YiZhangb,LuHuangc,LiningShangc,KangruiWangc,HuizhuYuc,DonghuaZhuc","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2016.10.061","https://www.sciencedirect.com/science/article/pii/S0040162516305364"
"A216","Modelling to identify influential bloggers in the blogosphere: A survey","The user participatory nature of the social web has revolutionized the use of the conventional web. The social web is an integral part of our daily life. Due to the resulting exponential growth of the social web, a number of research domains have emerged, involving research activities that aim to study human nature, to analyse human sentiments and emotions, and to find the impact of various users in the social networks. Recently, the research focus has shifted to identifying a user's influence on other users in a social network. In the recent literature, we find a number of models proposed to find the most influential users in the blogging community. In this paper, we review the models to find these influential bloggers. The existing models are classified into feature-based and network-based categories. The feature-based models consider the salient factors to measure bloggers' influence. The network models, on the other hand, consider the graph-based social network structure of the bloggers to identify those who have the most impact on fellow members. This survey introduces each model with its features, novel aspects, and the datasets used. In addition to the discussion about the model, a comparative analysis of the datasets is presented. We conclude by discussing applications of the relevant literature, exploring open research issues and challenges, and sharing possible future directions in this active area of research.","Social web,Blog,Model,Influential bloggers,Blogosphere","Hikmat UllahKhanab,AliDaudcb,UmerIshfaqd,TehminaAmjadb,NaifAljohanic,Rabeeh AyyazAbbasice,Jalal S.Alowibdif","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2016.11.012","https://www.sciencedirect.com/science/article/pii/S0747563216307531"
"A217","VISTopic: A visual analytics system for making sense of large document collections using hierarchical topic modeling","Effective analysis of large text collections remains a challenging problem given the growing volume of available text data. Recently, text mining techniques have been rapidly developed for automatically extracting key information from massive text data. Topic modeling, as one of the novel techniques that extracts a thematic structure from documents, is widely used to generate text summarization and foster an overall understanding of the corpus content. Although powerful, this technique may not be directly applicable for general analytics scenarios since the topics and topic–document relationship are often presented probabilistically in models. Moreover, information that plays an important role in knowledge discovery, for example, times and authors, is hardly reflected in topic modeling for comprehensive analysis. In this paper, we address this issue by presenting a visual analytics system, VISTopic, to help users make sense of large document collections based on topic modeling. VISTopic first extracts a set of hierarchical topics using a novel hierarchical latent tree model (HLTM) (Liu et al., 2014). In specific, a topic view accounting for the model features is designed for overall understanding and interactive exploration of the topic organization. To leverage multi-perspective information for visual analytics, VISTopic further provides an evolution view to reveal the trend of topics and a document view to show details of topical documents. Three case studies based on the dataset of IEEE VIS conference demonstrate the effectiveness of our system in gaining insights from large document collections.","Topic-modeling,Text visualization,Visual analytics","YiYangab,QuanmingYaoa,HuaminQua","Visual Informatics","https://doi.org/10.1016/j.visinf.2017.01.005","https://www.sciencedirect.com/science/article/pii/S2468502X17300074"
"A218","1.24: Behavioral Analysis of Learning and Memory in Cephalopods","Many aspects of cephalopods' learning and memory capabilities are still puzzling, despite the large number of studies carried out on the subject over the past century. For example, what do cephalopods need to learn about in the wild? Does context influence the degree of learning in captivity? Do personality traits affect performance? Which are the memory dynamics and the biological machinery involved in memory consolidation and retention?Here we review the wealth of knowledge on learning and memory in cephalopods, from the classical studies to the most recent advancements. Cephalopods' special properties (complex behavior, relatively large brain, simple neural organization) give us the unique opportunity to study the molecular, cellular, and behavioral basis of learning, gaining insights on the evolution of complex nervous systems.","Behavioral flexibility,Cephalopoda,Curiosity,Intelligence,Invertebrates,Learning,Memory,Mollusca","GaiaMarini*,FabioDe Sio*,GiovannaPonte*,GrazianoFiorito","Learning and Memory: A Comprehensive Reference (Second Edition)","https://doi.org/10.1016/B978-0-12-809324-5.21024-9","https://www.sciencedirect.com/science/article/pii/B9780128093245210249"
"A219","Comparing public and scientific discourse in the context of innovation systems","Innovation as a systemic process is not only driven by science and technology but has diverse sources. While there are (numeric) indicators to map S&T developments such as patents, publications or standards, new indicators are required to map other areas of the innovation system. In this regard, one option is the examination of news reporting. News is a recognized channel for innovation diffusion and plays an important role in informing society. To contrast changes and developments in science and society, specifically the link between both is addressed in this article by comparing the content of news articles and scientific publications. Thus, the aim of this article is to first argue the benefit of integrating the media in the innovation system debate because of its recognized role in innovation diffusion and to develop a methodology to automatically compare scientific and media discourses. To process the volume of textual data according to a common analytical scheme, a text mining framework has been developed. The results offer valuable input for examining the present state of themes and technologies and, thereby, support future planning activities.","Innovation system,Text mining,Foresight,Media analysis,Publications analysis,Future technology analysis","VictoriaKayser","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2016.08.005","https://www.sciencedirect.com/science/article/pii/S0040162516302074"
"A220","Firms' knowledge profiles: Mapping patent data with unsupervised learning","Patent data has been an obvious choice for analysis leading to strategic technology intelligence, yet, the recent proliferation of machine learning text analysis methods is changing the status of traditional patent data analysis methods and approaches. This article discusses the benefits and constraints of machine learning approaches in industry level patent analysis, and to this end offers a demonstration of unsupervised learning based analysis of the leading telecommunication firms between 2001 and 2014 based on about 160,000 USPTO full-text patents. Data were classified using full-text descriptions with Latent Dirichlet Allocation, and latent patterns emerging through the unsupervised learning process were modelled by company and year to create an overall view of patenting within the industry, and to forecast future trends. Our results demonstrate company-specific differences in their knowledge profiles, as well as show the evolution of the knowledge profiles of industry leaders from hardware to software focussed technology strategies. The results cast also light on the dynamics of emerging and declining knowledge areas in the telecommunication industry. Our results prompt a consideration of the current status of established approaches to patent landscaping, such as key-word or technology classifications and other approaches relying on semantic labelling, in the context of novel machine learning approaches. Finally, we discuss implications for policy makers, and, in particular, for strategic management in firms.","Technology management,Patent analysis,Unsupervised learning,Topic modelling,Telecommunication industry","ArhoSuominenab,HannesToivanenabc,MarkoSeppänend","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2016.09.028","https://www.sciencedirect.com/science/article/pii/S0040162516303651"
"A221","Detecting rising stars in dynamic collaborative networks","In today's complex academic environment the process of performance evaluation of scholars is becoming increasingly difficult. Evaluation committees often need to search in several repositories in order to deliver their evaluation summary report for an individual. However, it is extremely difficult to infer performance indicators that pertain to the evolution and the dynamics of a scholar. In this paper we propose a novel computational methodology based on unsupervised machine learning that can act as an important tool at the hands of evaluation committees of individual scholars. The suggested methodology compiles a list of several key performance indicators (features) for each scholar and monitors them over time. All these indicators are used in a clustering framework which groups the scholars into categories by automatically discovering the optimal number of clusters using clustering validity metrics. A profile of each scholar can then be inferred through the labeling of the clusters with the used performance indicators. These labels can ultimately act as the main profile characteristics of the individuals that belong to that cluster. Our empirical analysis gives emphasis on the “rising stars” who demonstrate the biggest improvement over time across all of the key performance indicators (KPIs), and can also be employed for the profiling of scholar groups.","Data mining,Time-evolving graphs,Rising stars,Co-authorship graphs,Power graphs,Key performance indicators,Evaluation of scholars","GeorgePanagopoulosa,GeorgeTsatsaronisb,IraklisVarlamisc","Journal of Informetrics","https://doi.org/10.1016/j.joi.2016.11.003","https://www.sciencedirect.com/science/article/pii/S1751157716300645"
"A222","A bibliometric and visual analysis of global geo-ontology research","In this paper, the results of a bibliometric and visual analysis of geo-ontology research articles collected from the Web of Science (WOS) database between 1999 and 2014 are presented. The numbers of national institutions and published papers are visualized and a global research heat map is drawn, illustrating an overview of global geo-ontology research. In addition, we present a chord diagram of countries and perform a visual cluster analysis of a knowledge co-citation network of references, disclosing potential academic communities and identifying key points, main research areas, and future research trends. The International Journal of Geographical Information Science, Progress in Human Geography, and Computers & Geosciences are the most active journals. The USA makes the largest contributions to geo-ontology research by virtue of its highest numbers of independent and collaborative papers, and its dominance was also confirmed in the country chord diagram. The majority of institutions are in the USA, Western Europe, and Eastern Asia. Wuhan University, University of Munster, and the Chinese Academy of Sciences are notable geo-ontology institutions. Keywords such as “Semantic Web,” “GIS,” and “space” have attracted a great deal of attention. “Semantic granularity in ontology-driven geographic information systems, “Ontologies in support of activities in geographical space” and “A translation approach to portable ontology specifications” have the highest cited centrality. Geographical space, computer-human interaction, and ontology cognition are the three main research areas of geo-ontology. The semantic mismatch between the producers and users of ontology data as well as error propagation in interdisciplinary and cross-linguistic data reuse needs to be solved. In addition, the development of geo-ontology modeling primitives based on OWL (Web Ontology Language)and finding methods to automatically rework data in Semantic Web are needed. Furthermore, the topological relations between geographical entities still require further study.","Geo-ontology,Bibliometrics,Visualization,Cluster analysis,Semantic Web,GIS","LinLiabc,YuLiua,HaihongZhuab,ShenYinga,QinyaoLuoa,HengLuoa,XiKuaia,HuiXiaa,HangShena","Computers & Geosciences","https://doi.org/10.1016/j.cageo.2016.10.006","https://www.sciencedirect.com/science/article/pii/S0098300416305659"
"A223","Introduction to a special issue on concept mapping","Concept mapping was developed in the 1980s as a unique integration of qualitative (group process, brainstorming, unstructured sorting, interpretation) and quantitative (multidimensional scaling, hierarchical cluster analysis) methods designed to enable a group of people to articulate and depict graphically a coherent conceptual framework or model of any topic or issue of interest. This introduction provides the basic definition and description of the methodology for the newcomer and describes the steps typically followed in its most standard canonical form (preparation, generation, structuring, representation, interpretation and utilization). It also introduces this special issue which reviews the history of the methodology, describes its use in a variety of contexts, shows the latest ways it can be integrated with other methodologies, considers methodological advances and developments, and sketches a vision of the future of the method’s evolution.","Concept mapping,Structured conceptualization,Brainstorming,Sorting,Multidimensional scaling,Cluster analysis,Pattern matching","William M.Trochim(Professor Policy Analysis & Management)a,DanielMcLindenb","Evaluation and Program Planning","https://doi.org/10.1016/j.evalprogplan.2016.10.006","https://www.sciencedirect.com/science/article/pii/S0149718916301471"
"A224","Malicious accounts: Dark of the social networks","Over the last few years, online social networks (OSNs), such as Facebook, Twitter and Tuenti, have experienced exponential growth in both profile registrations and social interactions. These networks allow people to share different information ranging from news, photos, videos, feelings, personal information or research activities. The rapid growth of OSNs has triggered a dramatic rise in malicious activities including spamming, fake accounts creation, phishing, and malware distribution. However, developing an efficient detection system that can identify malicious accounts, as well as their suspicious behaviors on the social networks, has been quite challenging. Researchers have proposed a number of features and methods to detect malicious accounts. This paper presents a comprehensive review of related studies that deal with detection of malicious accounts on social networking sites. The review focuses on four main categories, which include detection of spam accounts, fake accounts, compromised accounts, and phishing. To group the studies, the taxonomy of the different features and methods used in the literature to identify malicious accounts and their behaviors are proposed. The review considered only social networking sites and excluded studies such as email spam detection. The significance of proposed features and methods, as well as their limitations, are analyzed. Key issues and challenges that require substantial research efforts are discussed. In conclusion, the paper identifies the important future research areas with the aim of advancing the development of scalable malicious accounts detection system in OSNs.","Online social network,Social spam,Malicious behavior,Fake account,Phishing detection,Sybil","Kayode SakariyahAdewolea,Nor BadrulAnuara,AmirrudinKamsina,Kasturi DewiVarathana,Syed AbdulRazakb","Journal of Network and Computer Applications","https://doi.org/10.1016/j.jnca.2016.11.030","https://www.sciencedirect.com/science/article/pii/S1084804516303009"
"A225","A scientometrics review on nonpoint source pollution research","The purpose of this paper is to make insights into certain characteristics of nonpoint source pollution research, and consequently to show the global trends as well as assist researchers to establish future research directions. Based on the SCI-E and SSCI databases, 3246 journal articles on nonpoint source pollution were retrieved from 2001 to 2015. Nonpoint source pollution research maintained steady growth in the past 15 years. Among all countries, USA was the most active contributor with the most publications and cooperation. As for institutions, Chinese Academy of Sciences ranked first with 143 articles, and USDA-ARS in USA played a key role for intimate collaboration with other institutions. And most articles were recorded by Environmental Sciences & Ecology, Environmental Sciences and Water Resources. Further, Journal of Environmental Quality and Water Research were the most productive and influential journals, respectively. Based on keyword co-word and reference co-citation analysis by Citespace, nonpoint source pollution research includes multiple areas (control measures, modeling, pollutants, research regions and technologies). And future researches on nonpoint source pollution will likely focus on SWAT application, GIS and ecological measures.","Nonpoint source,Citespace,Review","CuiyunXiang,YuanWang,HuiwenLiu","Ecological Engineering","https://doi.org/10.1016/j.ecoleng.2016.11.028","https://www.sciencedirect.com/science/article/pii/S0925857416306504"
"A226","1.23: Cyberinfrastructure and High-Performance Computing","With the rapid advance in science, technology, and engineering development, high-resolution geospatial data have become increasingly available. One direct result is the increasing volume of the data. Processing big spatial data is both data- and computing-intensive. When the scale of geospatial data and computation is beyond the capacity of PC-based software and tools due to the limited storage, memory, and computing power, concurrency and parallelism over modern cyberinfrastructure are the future directions and challenges in geocomputation in response to the data-driven geography and geographic information science. This article will review the evolving cyberinfrastructure and summarize the major approaches to implementing high-performance geocomputation on the heterogeneous computer architecture and system.","Big data,Cyberinfrastructure,Geocomputation,Geographic information system and science,Graphics processing unit,High-performance computing,Many integrated core","XuanShi,MiaoqingHuang","Comprehensive Geographic Information Systems","https://doi.org/10.1016/B978-0-12-409548-9.09617-2","https://www.sciencedirect.com/science/article/pii/B9780124095489096172"
"A227","3: LIQUIDS","","","Prof. Dr.Alexander Ya.Malkin,Prof. Dr.AvraamIsayev","Rheology,Rheology (Third Edition)","https://doi.org/10.1016/B978-1-927885-21-5.50009-6","https://www.sciencedirect.com/science/article/pii/B9781927885215500096"
"A228","Virus Databases","Databases are critical to all scientific endeavours. They manage our email, funding, and scientific literature, and provide access to the ever-growing mountains of scientific data. In molecular virology, all researchers are familiar with performing BLAST searches of the DNA and protein sequence databases; however, in some respects these are simple databases tailored to this specific task. This collection of virus databases illustrates a greater diversity of purpose, but reveals they often function to support only one or a few virus families grouped by a common theme. The common characteristic is usually genome size as small RNA viruses are typically sequenced in vastly greater numbers and are much less complex than the large DNA viruses; they have variability at the level of SNPs rather than gene presence/absence. Here, we present the basics of database organization and aim to compare and contrast these features and the manner by which the databases are used by the scientific community.","Bioinformatics,Computational biology,Database,DBMS,Genome,MySQL,Sequence,Virology,Virus","KathleenMcLeod,ChrisUpton","Reference Module in Biomedical Sciences,Reference Module in Biomedical Sciences","https://doi.org/10.1016/B978-0-12-801238-3.95728-3","https://www.sciencedirect.com/science/article/pii/B9780128012383957283"
"A229","Topical cohesion of communities on Twitter","Nowadays, Online Social Networks (OSN) are commonly used by groups of users to communicate. Members of a family, colleagues, fans of a brand, political groups... There is an increasing demand for a precise identification of these groups, coming from brand monitoring, business intelligence and e-reputation management.However, a gap can be observed between the communities detected by many data analytics algorithms on OSN, and effective groups existing in real life: the detected communities often lack of meaning and internal semantic cohesion. Most of existing literature on OSN either focuses on the community detection problem in graphs without considering the topic of the messages exchanged, or concentrates exclusively on the messages without taking into account the social links.In this article, we support the hypothesis that communities extracted on OSN should be topically coherent. We therefore propose a model to represent the groups of interaction on Twitter, the reference on micro-blogging OSN, and two metrics to evaluate the topical cohesion of the detected communities. As an evaluation, we measure the topical cohesion of the groups of users detected by a baseline community detection algorithm.","Online social network,community detection,measure of community topical cohesion","GuillaumeGadekab,AlexandrePaucheta,NicolasMalandaina,KhaledKhelifb,LaurentVercoutera,StéphanBrunessauxb","Procedia Computer Science","https://doi.org/10.1016/j.procs.2017.08.171","https://www.sciencedirect.com/science/article/pii/S1877050917315284"
"A230","An Empirical Study of Nanowire Technological Trends","This paper follows a bibliometric method for nanowire case to make evident the technological trends; to present the relationship between patents; to help the researchers to discover relatively significant patents and to analyse important relationships between patents to identify those with most commercial potential and those which are critical technologies. This research focuses on the nanowire case study due to fact that this field is one of the most mature nanostructures and is one of the highly invested fields in nanotechnology. In terms of methodological approach, this study uses a different patent collection method than previous studies. This new method offers a new taxonomy that could make a significant impact on accurate patent data quests and increase the reliability of the patent analyses. As patent data are valuable sources of technology innovation and for forecasting technical change, this study utilises nanowire patent documents to pick out the technological trends, to identify nanowire technologies which both have the most commercial potential and which are critical at the organisational, national and international levels.","nanotechnology,patent analysis,bibliometrics,visualisation mapping,nanowire","SercanOzcana,NazrulIslamb","The Journal of High Technology Management Research","https://doi.org/10.1016/j.hitech.2017.10.001","https://www.sciencedirect.com/science/article/pii/S1047831017300251"
"A231","Chapter Three: Describing Genomic and Epigenomic Traits Underpinning Emerging Fungal Pathogens","An unprecedented number of pathogenic fungi are emerging and causing disease in animals and plants, putting the resilience of wild and managed ecosystems in jeopardy. While the past decades have seen an increase in the number of pathogenic fungi, they have also seen the birth of new big data technologies and analytical approaches to tackle these emerging pathogens. We review how the linked fields of genomics and epigenomics are transforming our ability to address the challenge of emerging fungal pathogens. We explore the methodologies and bioinformatic toolkits that currently exist to rapidly analyze the genomes of unknown fungi, then discuss how these data can be used to address key questions that shed light on their epidemiology. We show how genomic approaches are leading a revolution into our understanding of emerging fungal diseases and speculate on future approaches that will transform our ability to tackle this increasingly important class of emerging pathogens.","Emerging fungal pathogen,Genome,Epigenome,Epidemiology","Rhys A.Farrer,Matthew C.Fisher","Advances in Genetics","https://doi.org/10.1016/bs.adgen.2017.09.009","https://www.sciencedirect.com/science/article/pii/S0065266017300378"
"A232","1: Basic Concepts and Principles","Many scientific and technological advances can be credited to nanoscience and nanotechnology. Indeed, the scientific technological breakthroughs in these fields have not only affected specific sectors, such as equipment for research or manufacturing certain products, but also many products that are relevant to society as a whole. This chapter presents important descriptions of the key concepts and basic principles necessary for understanding nanoscience and nanotechnology, including the notion of scale; the history of nanoscience and nanotechnology development; the advent of techniques facilitating the fabrication of nanotechnology products; the relationships among politics, economics and research; and some commercial applications.","nanoscience,nanotechnology,nanoscale,nanomaterials,science,economics,policy,nanotechnology products,technology,innovation","F.R.Simões*,H.H.Takeda**","Nanostructures,Nanostructures","https://doi.org/10.1016/B978-0-323-49782-4.00001-2","https://www.sciencedirect.com/science/article/pii/B9780323497824000012"
"A233","Resource management in big data initiatives: Processes and dynamic capabilities","Effective management of organizational resources in big data initiatives is of growing importance. Although academic and popular literatures contain many examples of big data initiatives, very few are repeated in the same organization. This suggests either big data delivers benefits once only per organization or senior managers are reluctant to commit resources to big data on a sustained basis. This paper makes three contributions to the Special Issue's theme of enhancing organizational resource management. One is to establish an archetype business process for big data initiatives. The second contribution directs attention to creating a dynamic capability with big data initiatives. The third identifies drawbacks of resource based theory (RBT) and it's underpinning assumptions in the context of big data. The paper discusses lessons learnt and draws out implications for practice and business research. The paper's intellectual and practical contributions are based on an in-depth case study of the European ICT Poles of Excellence (EIPE) big data initiative and evidence from the extant literature.","Big data,Resource based theory,Dynamic capabilities,Business processes,European Poles Of Excellence","AshleyBraganzaa,LaurenceBrooksb,DanielNepelskic,MagedAlid,RussMoroa","Journal of Business Research","https://doi.org/10.1016/j.jbusres.2016.08.006","https://www.sciencedirect.com/science/article/pii/S0148296316304933"
"A234","1: Category Definitions","","","Dean F.SittigPhD","Clinical Informatics Literacy,Clinical Informatics Literacy","https://doi.org/10.1016/B978-0-12-803206-0.00001-8","https://www.sciencedirect.com/science/article/pii/B9780128032060000018"
"A235","Chapter Y: Automated Information Organization","Information and communication technology is now being increasingly employed in libraries and information centers for improving organization and dissemination of information. Many of the activities, which were earlier being done manually, have now been automated. Besides, a sizeable amount of information sources are now available in electronic or digital format, and Internet has become an important source of information. Not only the existing libraries and their services are now being automated, libraries of new varieties, such as digital libraries and virtual libraries are also coming up. The main areas where efforts are being made to apply computers for increasing the efficiency and speed in the field of information organization are indexing; abstracting; information retrieval tools like thesaurus, ontology, folksonomy, and folksontology; translation; and language processing. These efforts have been briefly discussed in this chapter.","Auto-indexing,auto-abstracting,ontology,folksonomy,folksontology,machine translation,natural language processing","AmitabhaChatterjee","Elements of Information Organization and Dissemination,Elements of Information Organization and Dissemination","https://doi.org/10.1016/B978-0-08-102025-8.00025-9","https://www.sciencedirect.com/science/article/pii/B9780081020258000259"
"A236","Index","","","","Clinical Informatics Literacy,Clinical Informatics Literacy","https://doi.org/10.1016/B978-0-12-803206-0.18001-0","https://www.sciencedirect.com/science/article/pii/B9780128032060180010"
"A237","Nanotechnology, Society, and Environment","Nanotechnology talk is moving out of its comfort zone of scientific discourse. As new products go to market and national and international organizations roll out public engagement programs on nanotechnology to discuss environmental and health issues, various sectors of the public are beginning to discuss what all the fuss is about. Nongovernmental organizations have long since reacted; however, now the social sciences have begun to study the cultural phenomenon of nanotechnology, thus extending discourses and opening out nanotechnology to whole new social dimensions. We report here on these social dimensions and their new constructed imaginings, each of which is evident in the ways in which discourses around nanotechnology intersects with the economy, ecology, health, governance, and imagined futures. We conclude that there needs to be more than just an “environmental, legal, and social implications,” or “ELSI,” sideshow within nanotechnology. The collective public imaginings of nanotechnology include tangles of science and science fiction, local enterprise, and global transformation, all looking forward toward a sustainable future, while looking back on past debates about science and nature. Nanotechnology is already very much embedded in the social fabric of our life and times.","Environment,Equity,Governance,Health,Imaginaries,Nanotechnology and society,Nanotechnology discourse,Nanotechnology ethics,Risk,Science and naturescience communication science","P.Murphy,D.Munshi,P.A.Kurian,A.Lakhtakia,R.V.Bartlett,MonishaChakraborty","Reference Module in Materials Science and Materials Engineering,Reference Module in Materials Science and Materials Engineering","https://doi.org/10.1016/B978-0-12-803581-8.10311-X","https://www.sciencedirect.com/science/article/pii/B978012803581810311X"
"A238","1: The Psychology of Deception","The basis of deception is misdirection—shaping the perceptions and beliefs of the target audience. This chapter begins by exploring some of the traditional deception methods used by magicians and how these techniques can be similarly leveraged by cyber threat actors to circumvent human defenses. In particular, the first section of the chapter provides a rich discussion about passive and active misdirection principles used in conjuring to effectively disguise, distract, and control attention. The chapter then transitions toward other weapons of deception used by magicians to deceive spectators, such as forcing (choice manipulation); suggestion and implication; false objectives; disarming presentation; and Gestalt principles, among others. The final section in the chapter turns to other cognitive and neuropsychological principles and strategies that are used to deceive and exploit psychological vulnerabilities.","Cognitive illusions,Conjuring,Inattentional blindness,Interpersonal deception theory,Magic,Misdirection,Neuropsychology,Nonverbal cues,Psychology","Cameron H.Malin,TerryGudaitis,Thomas J.Holt,MaxKilger","Deception in the Digital Age,Deception in the Digital Age","https://doi.org/10.1016/B978-0-12-411630-6.00001-3","https://www.sciencedirect.com/science/article/pii/B9780124116306000013"
"A239","Analytical mapping of opinion mining and sentiment analysis research during 2000–2015","The new transformed read-write Web has resulted in a rapid growth of user generated content on the Web resulting into a huge volume of unstructured data. A substantial part of this data is unstructured text such as reviews and blogs. Opinion mining and sentiment analysis (OMSA) as a research discipline has emerged during last 15 years and provides a methodology to computationally process the unstructured data mainly to extract opinions and identify their sentiments. The relatively new but fast growing research discipline has changed a lot during these years. This paper presents a scientometric analysis of research work done on OMSA during 2000–2016. For the scientometric mapping, research publications indexed in Web of Science (WoS) database are used as input data. The publication data is analyzed computationally to identify year-wise publication pattern, rate of growth of publications, types of authorship of papers on OMSA, collaboration patterns in publications on OMSA, most productive countries, institutions, journals and authors, citation patterns and an year-wise citation reference network, and theme density plots and keyword bursts in OMSA publications during the period. A somewhat detailed manual analysis of the data is also performed to identify popular approaches (machine learning and lexicon-based) used in these publications, levels (document, sentence or aspect-level) of sentiment analysis work done and major application areas of OMSA. The paper presents a detailed analytical mapping of OMSA research work and charts the progress of discipline on various useful parameters.","Affective computing,Opinion mining,Scientometrics,Sentiment analysis","R.Piryania,D.Madhavib,V.K.Singhc","Information Processing & Management","https://doi.org/10.1016/j.ipm.2016.07.001","https://www.sciencedirect.com/science/article/pii/S030645731630245X"
"A240","Chapter 20: Genomic Databases: Emerging Tools for Molecular Diagnostics","Genome informatics deals with informatics tools used in molecular biology, and it is an important scientific discipline that emerged in the postgenomic era from developments in the field of human genomics. Advances in the understanding of the genetic etiology of human disorders, coupled with advances in technology, have led to the identification of numerous genomic variants. These dictate the organization of this knowledge and these alterations in structured repositories that could eventually be useful not only for molecular diagnosis but also for clinicians and researchers. Genetic or mutation databases are referred to as online repositories of genomic variants, mainly described for one or more genes or specifically for a population or ethnic group, aiming to facilitate diagnosis at the DNA level and to correlate genomic variants with specific phenotypic patterns and clinical features. In this chapter we will summarize the key features of the main types of genetic databases that are frequently used in molecular diagnostics, namely locus-specific and national/ethnic genetic databases. In particular, the main activities relating to these genetic database types will be highlighted to describe the existing and emerging database types in this domain and emphasize their potential applications in modern medical genetics. We will also critically discuss and touch upon the key elements that are still missing and holding back the field.","Database management systems,Genomic databases,Genomic variants,Locus-specific databases,Microattribution,National/ethnic mutation databases","G.P.Patrinos12,T.Katsila1,E.Viennas1,G.Tzimas3","Molecular Diagnostics,Molecular Diagnostics (Third Edition)","https://doi.org/10.1016/B978-0-12-802971-8.00020-1","https://www.sciencedirect.com/science/article/pii/B9780128029718000201"
"A241","Statistical physics of vaccination","Historically, infectious diseases caused considerable damage to human societies, and they continue to do so today. To help reduce their impact, mathematical models of disease transmission have been studied to help understand disease dynamics and inform prevention strategies. Vaccination–one of the most important preventive measures of modern times–is of great interest both theoretically and empirically. And in contrast to traditional approaches, recent research increasingly explores the pivotal implications of individual behavior and heterogeneous contact patterns in populations. Our report reviews the developmental arc of theoretical epidemiology with emphasis on vaccination, as it led from classical models assuming homogeneously mixing (mean-field) populations and ignoring human behavior, to recent models that account for behavioral feedback and/or population spatial/social structure. Many of the methods used originated in statistical physics, such as lattice and network models, and their associated analytical frameworks. Similarly, the feedback loop between vaccinating behavior and disease propagation forms a coupled nonlinear system with analogs in physics. We also review the new paradigm of digital epidemiology, wherein sources of digital data such as online social media are mined for high-resolution information on epidemiologically relevant individual behavior. Armed with the tools and concepts of statistical physics, and further assisted by new sources of digital data, models that capture nonlinear interactions between behavior and disease dynamics offer a novel way of modeling real-world phenomena, and can help improve health outcomes. We conclude the review by discussing open problems in the field and promising directions for future research.","Epidemiology,Vaccination,Human behavior,Complex networks,Data","ZhenWangab,Chris T.Bauchc,SamitBhattacharyyad,Albertod'Onofrioe,PieroManfredif,MatjažPercgh,NicolaPerrai,MarcelSalathéjk,DaweiZhaol","Physics Reports","https://doi.org/10.1016/j.physrep.2016.10.006","https://www.sciencedirect.com/science/article/pii/S0370157316303349"
"A242","Detecting Similar Areas of Knowledge Using Semantic and Data Mining Technologies","Searching for scientific publications online is an essential task for researchers working on a certain topic. However, the extremely large amount of scientific publications found in the web turns the process of finding a publication into a very difficult task whereas, locating peers interested in collaborating on a specific topic or reviewing literature is even more challenging. In this paper, we propose a novel architecture to join multiple bibliographic sources, with the aim of identifying common research areas and potential collaboration networks, through a combination of ontologies, vocabularies, and Linked Data technologies for enriching a base data model. Furthermore, we implement a prototype to provide a centralized repository with bibliographic sources and to find similar knowledge areas using data mining techniques in the domain of Ecuadorian researchers community.","Data Mining,Semantic Web,Linked Data,Data Integration,Query Languages","XavierSumba,FreddySumba,AndresTello,FernandoBaculima,MauricioEspinoza,VíctorSaquicela","Electronic Notes in Theoretical Computer Science","https://doi.org/10.1016/j.entcs.2016.12.009","https://www.sciencedirect.com/science/article/pii/S1571066116301165"
"A243","A new patent processing suite for academic and research purposes","Patent databases are a counterpart of a technical encyclopedia providing a valuable informational source from patent documents. Patents apply to a wide variety of uses, and this is expanding. The increasing kinds of users of patent documents result in a lack of educational programs regarding this matter. This paper describes Patent2Net (P2N) a patentinformatic suite whose purpose is to fill the lack in the academic world (education and research) of a tool to use with students (STEM, Masters, PhD), by valuation services and for defining corpuses for research in general patent analysis, specifically on textual content. P2N is a free open-source modular, scalable, customizable and derivable tool, written in the python language. We present here the main functions of the tool and the technical aspects after discussing the skills to be reached by students for state of the art patent analysis.","Patent retreival,Patent mining,Visualization,Education,Corpus creation,EspaceNet","DavidReymonda,LucQuoniamb","World Patent Information","https://doi.org/10.1016/j.wpi.2016.10.001","https://www.sciencedirect.com/science/article/pii/S0172219016301132"
"A244","Use of a lipid rich strain reveals mechanisms of nitrogen limitation and carbon partitioning in the haptophyte Tisochrysis lutea","Haptophytes are a diverse monophyletic group with a worldwide distribution, known to be significantly involved in global climate regulation in their role as a carbon sink. Because nitrogen is a major limiting macronutrient for phytoplankton in oceans and for cultures of microalgae, understanding the involvement of nitrogen availability in haptophyte carbon partitioning is of global and biotechnological importance. Here, we made an ecophysiological study coupled with comprehensive large scale proteomic analysis to examine differences of behavior in reaction to nitrogen availability changes between a wild type strain of Tisochrysis lutea (WTc1) and a mutant strain (2Xc1) known to accumulate more storage lipids. Strains were grown in chemostats and studied under different ecophysiological conditions including N limitation, N repletion and N depletion. Whereas short time N repletion triggered consumption of carbohydrates in both strains, storage lipid degradation and accumulation during changes of ecophysiological status were recorded in 2Xc1 but not in WTc1. After 3 months of continuous culture, 2Xc1 exhibited an unexpected increase of carbon sequestration ability (+ 50%) by producing twofold more carbohydrates for the same nitrogen availability. Deep proteomic analysis by LC-MS/MS identified and compared the abundance of 4332 proteins, i.e. the deepest coverage of a microalgal proteome obtained to date. Results revealed that storage lipid accumulation is favored by an overall reorganization of carbon partitioning in 2Xc1 cells that increases the metabolism of carbon and energy acquisition, and decreases mitochondrial activity and metabolic conversion of storage lipids to phosphoenolpyruvate before gluconeogenesis.","Algae,Isochrysis,Lipids,Nitrogen,Reverse genomic: proteomic","MatthieuGarniera,GaelBougarana,MarijaPavlovicb,Jean-BaptisteBerarda,GregoryCarriera,AurélieCharriera,FabienneLe Grandc,EwaLukomskaa,CatherineRouxela,NathalieSchreibera,Jean-PaulCadoreta,HélèneRogniauxb,BrunoSaint-Jeana","Algal Research","https://doi.org/10.1016/j.algal.2016.10.017","https://www.sciencedirect.com/science/article/pii/S2211926416305653"
"A245","A systematic literature review of literature reviews in software testing","ContextAny newcomer or industrial practitioner is likely to experience difficulties in digesting large volumes of knowledge in software testing. In an ideal world, all knowledge used in industry, education and research should be based on high-quality evidence. Since no decision should be made based on a single study, secondary studies become essential in presenting the evidence. According to our search, over 101 secondary studies have been published in the area of software testing since 1994. With this high number of secondary studies, it is important to conduct a review in this area to provide an overview of the research landscape in this area.,ObjectiveThe goal of this study is to systematically map (classify) the secondary studies in software testing. We propose that tertiary studies can serve as summarizing indexes which facilitate finding the most relevant information from secondary studies and thus supporting evidence-based decision making in any given area of software engineering. Our research questions (RQs) investigate: (1) Software-testing-specific areas, (2) Types of RQs investigated, (3) Numbers and Trends, and (4) Citations of the secondary studies.,MethodTo conduct the tertiary study, we use the systematic-mapping approach. Additionally, we contrast the testing topics to the number of Google hits to address a general popularity of a testing topic and study the most popular papers in terms of citations. We furthermore demonstrate the practicality and usefulness of our results by mapping them to ISTQB foundation syllabus and to SWEBOK to provide implications for practitioners, testing educators, and researchers.,ResultsAfter a systematic search and voting process, our study pool included 101 secondary studies in the area of software testing between 1994 and 2015. Among our results are the following: (1) In terms of number of secondary studies, model-based approach is the most popular testing method, web services are the most popular system under test (SUT), while regression testing is the most popular testing phase; (2) The quality of secondary studies, as measured by a criteria set established in the community, is slowly increasing as the years go by; and (3) Analysis of research questions, raised and studied in the pool of secondary studies, showed that there is a lack of ‘causality’ and ‘relationship’ type of research questions, a situation which needs to be improved if we, as a community, want to advance as a scientific field. (4) Among secondary studies, we found that regular surveys receive significantly more citations than SMs (p = 0.009) and SLRs (p = 0.014).,ConclusionDespite the large number of secondary studies, we found that many important areas of software testing currently lack secondary studies, e.g., test management, role of product risk in testing, human factors in software testing, beta-testing (A/B-testing), exploratory testing, testability, test stopping criteria, and test-environment development. Having secondary studies in those areas is important for satisfying industrial and educational needs in software testing. On the other hand, education material of ISTQB foundation syllabus and SWEBOK could benefit from the inclusion of the latest research topics, namely search-based testing, use of cloud-computing for testing and symbolic execution.","Secondary studies,Tertiary study,Software testing,Systematic mapping,Systematic literature reviews,Surveys","VahidGarousiab,Mika V.Mäntyläc","Information and Software Technology","https://doi.org/10.1016/j.infsof.2016.09.002","https://www.sciencedirect.com/science/article/pii/S0950584916301446"
"A246","A computational literature review of the technology acceptance model","A literature review is a central part of any research project, allowing the existing research to be mapped and new research questions to be posited. However, due to the limitations of human data processing, the literature review can suffer from an inability to handle large volumes of research articles. The computational literature review (CLR) is proposed here as a complementary part of a wider literature review process. The CLR automates some of the analysis of research articles with analyses of impact (citations), structure (co-authorship networks) and content (topic modeling of abstracts). A contribution of the paper is to demonstrate how the content of abstracts can be analyzed automatically to provide a set of research topics within a literature corpus. The CLR software can be used to support three use cases: (1) analysis of the literature for a research area, (2) analysis and ranking of journals, and (3) analysis and ranking of individual scholars and research teams. The working of the CLR software is illustrated through application to the technology acceptance model (TAM) using a set of 3,386 articles. The CLR is an open source offering, developed in the statistical programming language R, and made freely available to researchers to use and develop further.","Literature review,Computational literature review,Topic models,Lda,Social network analysis,Co-authorship analysis,Citation analysis,Technology acceptance model,Journal ranking","Michael J.Mortensona,RichardVidgenb","International Journal of Information Management","https://doi.org/10.1016/j.ijinfomgt.2016.07.007","https://www.sciencedirect.com/science/article/pii/S0268401216300329"
"A247","Literature listing","The quarterly Literature Listing is intended as a current awareness service for readers indicating newly published books, journal and conference articles on: patent search techniques, databases, analysis and classifications; patent searcher certification; patents relating to a) life sciences and pharmaceuticals and b) software; patent policy and strategic issues; trade marks; designs; domain names; and articles reviewing historical aspects of intellectual property or reviewing specific topics/persons. The current Literature Listing was compiled mid-August 2016. Key resources used are Scopus, Digital Commons, publishers’ RSS feeds, and serendipity!","Patents,Designs,Trade marks,Literature listing,Patent analysis,Current awareness","SusanBates","World Patent Information","https://doi.org/10.1016/j.wpi.2016.09.004","https://www.sciencedirect.com/science/article/pii/S0172219016300990"
"A248","Requirement-driven evolution in software product lines: A systematic mapping study","CONTEXT. Software Product Lines (SPLs) aim to support the development of a whole family of software products through systematic reuse of shared assets. As SPLs exhibit a long life-span, evolution is an even greater concern than for single-systems. For the purpose of this work, evolution refers to the adaptation of the SPL as a result of changing requirements. Hence, evolution is triggered by requirement changes, and not by bug fixing or refactoring.OBJECTIVE. Research on SPL evolution has not been previously mapped. This work provides a mapping study along Petersen’s and Kichenham’s guidelines, to identify strong areas of knowledge, trends and gaps.RESULTS. We identified 107 relevant contributions. They were classified according to four facets: evolution activity (e.g., identify, analyze and plan, implement), product-derivation approach (e.g., annotation-based, composition-based), research type (e.g., solution, experience, evaluation), and asset type (i.e., variability model, SPL architecture, code assets and products).CONCLUSION. Analyses of the results indicate that “Solution proposals” are the most common type of contribution (31%). Regarding the evolution activity, “Implement change” (43%) and “Analyze and plan change” (37%) are the most covered ones. A finer-grained analysis uncovered some tasks as being underexposed. A detailed description of the 107 papers is also included.","Systematic mapping study,Software product lines,Evolution","LeticiaMontalvillo,OscarDíaz","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2016.08.053","https://www.sciencedirect.com/science/article/pii/S0164121216301510"
"A249","Requirements monitoring frameworks: A systematic review","ContextSoftware systems today often interoperate with each other, thus forming a system of systems (SoS). Due to the scale, complexity, and heterogeneity of SoS, determining compliance with their requirements is challenging, despite the range of existing monitoring approaches. The fragmented research landscape and the diversity of existing approaches, however, make it hard to understand and analyze existing research regarding its suitability for SoS.,ObjectiveThe aims of this paper are thus to systematically identify, describe, and classify existing approaches for requirements-based monitoring of software systems at runtime. Specifically, we (i) analyze the characteristics and application areas of monitoring approaches proposed in different domains, we (ii) systematically identify frameworks supporting requirements monitoring, and finally (iii) analyze their support for requirements monitoring in SoS.,MethodWe performed a systematic literature review (SLR) to identify existing monitoring approaches and to classify their key characteristics and application areas. Based on this analysis we selected requirements monitoring frameworks, following a definition by Robinson, and analyzed them regarding their support for requirements monitoring in SoS.,ResultsWe identified 330 publications, which we used to produce a comprehensive overview of the landscape of requirements monitoring approaches. We analyzed these publications regarding their support for Robinson’s requirements monitoring layers, resulting in 37 identified frameworks. We investigated how well these frameworks support requirements monitoring in SoS.,ConclusionsWe conclude that most existing approaches are restricted to certain kinds of checks, particular types of events and data, and mostly also limited to one particular architectural style and technology. This lack of flexibility makes their application in an SoS context difficult. Also, systematic and automated variability management is still missing. Regarding their evaluation, many existing frameworks focus on measuring the performance overhead, while only few frameworks have been assessed in cases studies with real-world systems.","Requirements monitoring,Systems of systems,Systematic literature review","MichaelVierhauser,RickRabiser,PaulGrünbacher","Information and Software Technology","https://doi.org/10.1016/j.infsof.2016.08.005","https://www.sciencedirect.com/science/article/pii/S0950584916301288"
"A250","Patent Information Professional: Swiss army knife chameleon?","","","FredericBaudoura,PhilippeBodartb,EmmanuelleBourbonc,MurielBourgeois-Tassanaryd,CecileBoyer-Jouberte,GrégoireDelannoyf,SamuelHutsebautg,FabienneWindelsh","World Patent Information","https://doi.org/10.1016/j.wpi.2016.09.005","https://www.sciencedirect.com/science/article/pii/S0172219016300357"
"A251","Bibliometric studies in tourism","This study evaluates bibliometric studies in tourism, depicts emerging themes, and offers critical discussions for theory development and future research. To achieve this aim, 190 papers with bibliometric analyses from leading hospitality and tourism journals were selected and critically analyzed. The research findings reveal that bibliometric articles published in these journals significantly increased after 2008. However, systematic review studies emerged as the major group, and relatively few studies utilized evaluative bibliometric and relational bibliometric studies. Study results suggest that paucity still exists, particularly in relational bibliometric studies in tourism. This is one of the first studies in this area that offers critical discussions and suggestions related to theory development and future research in this research vein.","Tourism,Bibliometric studies,Review,Co-citation,Co-authorship","Mehmet AliKoseoglua,RoyaRahimib,FevziOkumusc,JingyanLiud","Annals of Tourism Research","https://doi.org/10.1016/j.annals.2016.10.006","https://www.sciencedirect.com/science/article/pii/S016073831630144X"
"A252","Social innovation research: An emerging area of innovation studies?","While the adoption of Social Innovation (SI) in the governance and policy domain has fueled a rapidly expanding scholarly literature, this field has become characterized by conceptual ambiguity and a diversity of definitions and research settings. This present situation inhibits the integration of findings. This paper traces the content, scope and relatively short history of modern social innovation research across disciplines by applying network and bibliometric analyses, and explores their relevance to innovation studies. Based on data from 172 publications, we analyze scholarly works that directly address the social innovation topic, allowing us to identify the precedence, dynamics and the current map of social innovation research as an emerging field of study. Our analysis suggests that the SI field is grounded in four distinct intellectual communities arising through a somewhat organized diffusion process: 1) Community Psychology; 2) Creativity research; 3) Social and societal challenges; 4) Local development. The interest of SI in the areas of management and entrepreneurship is only very recent and is currently reflected within existing communities. We forge conceptual bridges between the two (currently very separate) domains of social innovation and innovation studies, and the implications of our finding for further research and policy are also discussed.","Social innovation,Social entrepreneurship,Social value,Social technology,Bibliometrics,Integrative literature review","Robert P.van der Haveab,LuisRubalcabacd","Research Policy","https://doi.org/10.1016/j.respol.2016.06.010","https://www.sciencedirect.com/science/article/pii/S004873331630107X"
"A253","A hybrid similarity measure method for patent portfolio analysis","Similarity measures are fundamental tools for identifying relationships within or across patent portfolios. Many bibliometric indicators are used to determine similarity measures; for example, bibliographic coupling, citation and co-citation, and co-word distribution. This paper aims to construct a hybrid similarity measure method based on multiple indicators to analyze patent portfolios. Two models are proposed: categorical similarity and semantic similarity. The categorical similarity model emphasizes international patent classifications (IPCs), while the semantic similarity model emphasizes textual elements. We introduce fuzzy set routines to translate the rough technical (sub-) categories of IPCs into defined numeric values, and we calculate the categorical similarities between patent portfolios using membership grade vectors. In parallel, we identify and highlight core terms in a 3-level tree structure and compute the semantic similarities by comparing the tree-based structures. A weighting model is designed to consider: 1) the bias that exists between the categorical and semantic similarities, and 2) the weighting or integrating strategy for a hybrid method. A case study to measure the technological similarities between selected firms in China’s medical device industry is used to demonstrate the reliability our method, and the results indicate the practical meaning of our method in a broad range of informetric applications.","Patent analysis,Similarity measure,Text mining,Bibliometrics","YiZhanga,LiningShangb,LuHuangb,Alan L.Porterc,GuangquanZhanga,JieLua,DonghuaZhub","Journal of Informetrics","https://doi.org/10.1016/j.joi.2016.09.006","https://www.sciencedirect.com/science/article/pii/S1751157715302169"
"A254","The rise of “malware”: Bibliometric analysis of malware study","Malicious software (malware) is a computer program designed to create harmful and undesirable effects. It considered as one of the many dangerous threats for Internet users. Rootkit, botnet, worm, spyware and Trojan horse are the most common types of malware. Most malware studies aim to investigate novel approaches of preventing, detecting and responding to malware threats. However, despite the many articles published to support the research activities, there is still no trace of any bibliometric report that demonstrates the research trends. This paper aims to fill in that gap by presenting a comprehensive evaluation of malware research practices. It begins by looking at a pool of over 4000 articles that are published between 2005 and 2015 in the ISI Web of Science database. Using bibliometric analysis, this paper discusses the research activities done in both North America, Asia and other continents. This paper performed a detailed analysis by looking at the number of articles published, citations, research area, keywords, institutions, terms, and authors. A summary of the research activities continues by listing the terms into a classification of malware detection system which underlines the important area of malware research. From the analysis, it was concluded that there are several significant impacts of research activities in Asia, in comparison to other continents. In particular, this paper discusses the number of papers published by Asian countries such as China, Korea, India, Singapore and Malaysia in relation to the Middle East and North America.","Malware,Bibliometric analysis,Malware analysis,Intrusion detection system,Mobile malware","Mohd Faizal AbRazakab,Nor BadrulAnuara,<U+204E>,RosliSalleha,AhmadFirdausab","Journal of Network and Computer Applications","https://doi.org/10.1016/j.jnca.2016.08.022","https://www.sciencedirect.com/science/article/pii/S1084804516301904"
"A255","Towards felicitous decision making: An overview on challenges and trends of Big Data","The era of Big Data has arrived along with large volume, complex and growing data generated by many distinct sources. Nowadays, nearly every aspect of the modern society is impacted by Big Data, involving medical, health care, business, management and government. It has been receiving growing attention of researches from many disciplines including natural sciences, life sciences, engineering and even art & humanities. It also leads to new research paradigms and ways of thinking on the path of development. Lots of developed and under-developing tools improve our ability to make more felicitous decisions than what we have made ever before. This paper presents an overview on Big Data including four issues, namely: (i) concepts, characteristics and processing paradigms of Big Data; (ii) the state-of-the-art techniques for decision making in Big Data; (iii) felicitous decision making applications of Big Data in social science; and (iv) the current challenges of Big Data as well as possible future directions.","Big Data,Data deluge,Decision making,Data analysis,Data-intensive applications,Computational social science","WangHaia,XuZeshuiab,HamidoFujitac,LiuShoushengd","Information Sciences","https://doi.org/10.1016/j.ins.2016.07.007","https://www.sciencedirect.com/science/article/pii/S0020025516304868"
"A256","Construction of a pragmatic base line for journal classifications and maps based on aggregated journal-journal citation relations","A number of journal classification systems have been developed in bibliometrics since the launch of the Citation Indices by the Institute of Scientific Information (ISI) in the 1960s. These systems are used to normalize citation counts with respect to field-specific citation patterns. The best known system is the so-called “Web-of-Science Subject Categories” (WCs). In other systems papers are classified by algorithmic solutions. Using the Journal Citation Reports 2014 of the Science Citation Index and the Social Science Citation Index (n of journals = 11,149), we examine options for developing a new system based on journal classifications into subject categories using aggregated journal–journal citation data. Combining routines in VOSviewer and Pajek, a tree-like classification is developed. At each level one can generate a map of science for all the journals subsumed under a category. Nine major fields are distinguished at the top level. Further decomposition of the social sciences is pursued for the sake of example with a focus on journals in information science (LIS) and science studies (STS). The new classification system improves on alternative options by avoiding the problem of randomness in each run that has made algorithmic solutions hitherto irreproducible. Limitations of the new system are discussed (e.g. the classification of multi-disciplinary journals). The system’s usefulness for field-normalization in bibliometrics should be explored in future studies.","Classification,Subject categories,Disciplines,Citation,Journal","LoetLeydesdorffa,LutzBornmannb,PingZhouc","Journal of Informetrics","https://doi.org/10.1016/j.joi.2016.07.008","https://www.sciencedirect.com/science/article/pii/S175115771630102X"
"A257","“Triple negative breast cancer”: Translational research and the (re)assembling of diseases in post-genomic medicine","The paper examines the debate about the nature and status of “Triple-negative breast cancer”, a controversial biomedical entity whose existence illustrates a number of features of post-genomic translational research. The emergence of TNBC is intimately linked to the rise of molecular oncology, and, more generally, to the changing configuration of the life sciences at the turn of the new century. An unprecedented degree of integration of biological and clinical practices has led to the proliferation of bio-clinical entities emerging from translational research. These translations take place between platforms rather than between clinical and laboratory settings. The complexity and heterogeneity of TNBC, its epistemic and technical, biological and clinical dualities, result from its multiple instantiations via different platforms, and from the uneven distribution of biological materials, techniques, and objects across clinical research settings. The fact that TNBC comes in multiple forms, some of which seem to be incompatible or, at least, only partially overlapping, appears to be less a threat to the whole endeavor, than an aspect of an ongoing translational research project. Discussions of translational research that rest on a distinction between basic research and its applications fail to capture the dynamics of this new domain of activity, insofar as application is built-in from the very beginning in the bio-clinical entities that emerge from the translational research domain.","Translational research,Oncology,Breast cancer,Molecular diagnosis,Targeted therapies,Genomics","PeterKeatinga,AlbertoCambrosiob,Nicole C.Nelsonc","Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences","https://doi.org/10.1016/j.shpsc.2016.05.003","https://www.sciencedirect.com/science/article/pii/S1369848616300401"
"A258","Investigating biofuels through network analysis","Biofuel policies are motivated by a plethora of political concerns related to energy security, environmental damages, and support of the agricultural sector. In response to this, much scientific work has chiefly focussed on analysing the biofuel domain and on giving policy advice and recommendations. Although innovation has been acknowledged as one of the key factors in sustainable and cost-effective biofuel development, there is an urgent need to investigate technological trajectories in the biofuel sector by starting from consistent data and appropriate methodological tools. To do so, this work proposes a procedure to select patent data unequivocally related to the investigated sector, it uses co-occurrence of technological terms to compute patent similarity and highlights content and interdependencies of biofuels technological trajectories by revealing hidden topics from unstructured patent text fields. The analysis suggests that there is a breaking trend towards modern generation biofuels and that innovators seem to focus increasingly on the ability of alternative energy sources to adapt to the transport/industrial sector.","C38,O31,Q16,Q42,Keywords,Biofuel,Innovation,Patent data,Topic model,Text mining,Network analysis","YleniaCurcia,Christian A.Mongeau Ospinabc","Energy Policy","https://doi.org/10.1016/j.enpol.2016.07.001","https://www.sciencedirect.com/science/article/pii/S0301421516303536"
"A259","A semantic similarity measure for linked data: An information content-based approach","Linked Data allows structured data to be published in a standard manner so that datasets from diverse domains can be interlinked. By leveraging Semantic Web standards and technologies, a growing amount of semantic content has been published on the Web as Linked Open Data (LOD). The LOD cloud has made available a large volume of structured data in a range of domains via liberal licenses. The semantic content of LOD in conjunction with the advanced searching and querying mechanisms provided by SPARQL has opened up unprecedented opportunities not only for enhancing existing applications, but also for developing new and innovative semantic applications. However, SPARQL is inadequate to deal with functionalities such as comparing, prioritizing, and ranking search results which are fundamental to applications such as recommendation provision, matchmaking, social network analysis, visualization, and data clustering. This paper addresses this problem by developing a systematic measurement model of semantic similarity between resources in Linked Data. By drawing extensively on a feature-based definition of Linked Data, it proposes a generalized information content-based approach that improves on previous methods which are typically restricted to specific knowledge representation models and less relevant in the context of Linked Data. It is validated and evaluated for measuring item similarity in recommender systems. The experimental evaluation of the proposed measure shows that our approach can outperform comparable recommender systems that use conventional similarity measures.","Semantic Web,Linked Data,Linked Open Data,Similarity measures,Semantic similarity,Information content,Ranking,Recommender systems,Collaborative filtering,Content-based filtering","RouzbehMeymandpour,Joseph G.Davis","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2016.07.012","https://www.sciencedirect.com/science/article/pii/S095070511630226X"
"A260","Understanding TRIZ through the review of top cited publications","The development of the Theory of Inventive Problem Solving (TRIZ) has not followed the usual patterns of scientific validation required by engineering methods. Consequently, its outreach within engineering design is interpreted differently in the scholarly community. At the same time, the claimed powerful support in tackling technical problems of any degree of difficulty conflicts with TRIZ diffusion in industrial settings, which is relatively low according to insights into product development practices. The mismatch between ambitious goals and moderate spill-over benefits in the industry ranges among the various open issues concerning TRIZ, its way of thinking, its effectiveness, the usability of its tools. In order to provide a general overview of TRIZ in science, the authors have attempted to analyse reliable and influential sources from the literature. The performed survey includes the top 100 indexed publications concerning TRIZ, according to the number of received citations. Variegated and poorly interconnected research directions emerge in the abundant literature that tackles TRIZ-related topics. The outcomes of the investigation highlight the successful implementation of TRIZ within, among the others, biomimetics and information processing. The traditional borders of mechanical and industrial engineering have been frequently crossed, as the use of TRIZ is also witnessed in the domain of business and services. At the same time, computer-aided platforms represent diffused attempts to boost TRIZ diffusion and applicability.","TRIZ,Conceptual design,Industrial practice,Information processing,Computer-Aided Innovation","LeonidChechurina,YuriBorgiannib","Computers in Industry","https://doi.org/10.1016/j.compind.2016.06.002","https://www.sciencedirect.com/science/article/pii/S0166361516301129"
"A261","Mapping the knowledge of international Chinese medicines treatment on type 2 diabetes: A biblimetrical study","ObjectiveTo uncover and identify the hot topic and frontier of Chinese medicines treatment of type 2 diabetes mellitus (T2DM).,MethodsWeb of Science TM was searched for published articles for Chinese medicines treatment of T2DM ranging from January 1st, 2002 to July 6th, 2016. Knowledge maps of the international Chinese medicines treatment of T2DM are visualized by using document co-occurrence analysis and word frequency analysis (Institution and Journal), co-citation clustering analysis (Co-reference), keyword co-occurrence clustering analysis with CiteSpac III, a tool of scientometrics.,ResultsUniversidad Nacional Autonoma de Mexico is the institution with the highest number of published papers that had been cited in this field, while China has four institutions among the top 10. The journal of the highest frequency of co-cited journal was Diabetes Care, a core one in the field. Keywords co-occurrence network was composed of 185 nodes, 541 lines, and divided into 10 clusters. Co-citation network of co-reference was composed of 407 nodes, 1199 lines, and divided into 20 clusters. Using Chinese medicine to improve insulin resistance and Chinese medicine research on blood glucose control are the hot topics. The frontier contains two aspects: new drugs development and application of intestinal insulin treatment and development and use of traditional Chinese medicine antidiabetic plants.,ConclusionInstitutions from China still plays a major role in TCM-focused T2DM studies. The effect of TCM herbs on insulin resistance is the hot topic of the domain. Developing new TCM herbal medicine that regulates incretin effect is the domain frontier. Research on the Chinese medicines treatment of T2DM needs more high-quality evidence to support, and its mechanism requires further exploration.","Chinese medicine,CiteSpace,Knowledge map,Type 2 diabetes mellitus","JiahuiHu,KangleShi,QinggangMeng","Journal of Traditional Chinese Medical Sciences","https://doi.org/10.1016/j.jtcms.2016.12.002","https://www.sciencedirect.com/science/article/pii/S2095754816302083"
"A262","Digital government and wicked problems","This editorial introduces three examples of innovative research from the 16th International Digital Government Research Conference (dg.o 2015). To position the contributions of these examples meaningfully, we first performed a brief bibliographic analysis of research articles in the knowledge domain of digital government. This analysis provided a detailed examination of the evolution of digital government research themes and helped us introduce the examples in this special issue to the research field. Specifically, the research selected contributes to the theme of “digital government and wicked problems” by examining people's online political behavior, extracting citizens' needs from massive quantities of text data, or engaging constituents across geographical boundaries. At the same time, the bibliographic analysis and research examples together led us to ask whether the research field is ready to adopt wicked problems as a central focus, as it appears that the field is only in the very early stages of understanding the importance of the theme. To facilitate the transition from the current research orientation of the field to the next stage, we provide several suggestions for directions in future research.","","YushimKima,JingZhangb","Government Information Quarterly","https://doi.org/10.1016/j.giq.2016.10.004","https://www.sciencedirect.com/science/article/pii/S0740624X16302295"
"A263","Poster presentations","","","","European Geriatric Medicine","https://doi.org/10.1016/S1878-7649(16)30149-8","https://www.sciencedirect.com/science/article/pii/S1878764916301498"
"A264","Similarities and contrasts of complexity, uncertainty, risks, and resilience in supply chains and temporary multi-organization projects","Although complexity, uncertainty, risk, and resilience are concepts of growing interest, there is a lack of structured synthesis of these concepts and their relationships in supply chain management (SCM) and project management (PM) literatures. This paper addresses this gap through novel tertiary and bibliometric analyses. The tertiary research embraces 22 literature reviews and guides the development of the synthesis framework. The bibliometric analysis includes 1,275 papers and complements the tertiary research with study descriptors, a co-citation, and a static and dynamic/longitudinal co-word network analysis. Authors cite each other within the confines of their research area with no cross-fertilization of studies in PM and SCM, despite several commonalities among the areas. Both areas use similar conceptual definitions and there are close resemblances in risk management in SCM and temporary multi-organization (TMOs) projects. Resilience appears as a new topic in SCM but is absent in TMO. A research agenda closes the paper.","Research synthesis,Project management,Operations management,Supply chain collaboration,Literature review","Antônio Márcio TavaresThoméa1,Luiz FelipeScavardaa,AnnibalScavardab2,Felipe Eduardo Sydio de SouzaThoméc3","International Journal of Project Management","https://doi.org/10.1016/j.ijproman.2015.10.012","https://www.sciencedirect.com/science/article/pii/S0263786315001763"
"A265","Cannibalism in medical topic networks","Analyzing research activities over time can give insight into the research trend and knowledge structure of a domain. Research publication activity of a topic can be measured by a network of keyword terms and their relations in the specific area. The paper analyzes medical topic networks to interpret how clusters and keyword terms change over time. Keywords are extracted from 9730,671 research publications of twenty medical topics over 40 years. Experiments show there is cannibalism which occurs when one cluster is consumed into other clusters of medical topic networks in 50% of the medical topics analyzed. The decrease of modularity values of cannibalism topics shows that research topics collaborate actively and that multidisciplinary fields have emerged over time.","Research publication activity,Network evolution,Keyword extraction,Knowledge structure,Medical domain","SuhyunChae,AvivSegev,UichinLee","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2016.05.017","https://www.sciencedirect.com/science/article/pii/S0950705116301071"
"A266","Literature listing","The quarterly Literature Listing is intended as a current awareness service for readers indicating newly published books, journal and conference articles on: patent search techniques, databases, analysis and classifications; patent searcher certification; patents relating to a) life sciences and pharmaceuticals and b) software; patent policy and strategic issues; trade marks; designs; domain names; and articles reviewing historical aspects of intellectual property or reviewing specific topics/persons. The current Literature Listing was compiled mid-May 2016. Key resources used are Scopus, Digital Commons, publishers' RSS feeds, and serendipity! Please feel free to send the author details of newly published reports/monographs/books for potential inclusion.","Patents,Designs,Trade marks,Literature listing,Patent analysis,Current awareness","SusanBates","World Patent Information","https://doi.org/10.1016/j.wpi.2016.07.001","https://www.sciencedirect.com/science/article/pii/S0172219016300424"
"A267","The evolution of patent mining: Applying bibliometrics analysis and keyword network analysis","Text mining methods allow researchers to investigate technical documents (tech mining) and specifically explore patents for valuable information (patent mining. To the review literature and analyze the evolution of patent analysis and patent mining methods, bibliometrics analysis and keyword-based network analysis is applied on 143 papers extracted from the 'Web of science' database. Bibliometrics analysis was applied to determine top players researching in patent mining. Applying cluster analysis on the keyword network shows three main stages of patent analysis evolution. Also, it is discussed how patent mining is evolutionized in terms of information retrieval, pattern recognition and pattern analysis.","Technology mining,Patent mining,Bibliometrics analysis,Keyword network analysis,Cluster analysis,CiteSpace","FarshadMadani,CharlesWeber","World Patent Information","https://doi.org/10.1016/j.wpi.2016.05.008","https://www.sciencedirect.com/science/article/pii/S0172219016300412"
"A268","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2016.08.002","https://www.sciencedirect.com/science/article/pii/S0140670116300200"
"A269","A recommender system of reviewers and experts in reviewing problems","In this study, we propose the architecture of a content-based recommender system aimed at the selection of reviewers (experts) to evaluate research proposals or articles. We introduce a comprehensive algorithmic framework supported by various techniques of information retrieval. We propose a well-rounded methodology that explores concepts of data, information, knowledge, and relations between them to support a formation of a suitable recommendation. In particular, the developed system helps collecting data characterizing potential reviewers, retrieving information from relational and unstructured data, and formulating a set of recommendations. The designed system architecture is modular from the functional perspective and hierarchical from the technical point of view. Each essential part of the system is treated as a separate module, whereas each layer supports a certain functionality of the system. The modularity of the architecture facilitates its maintainability. The process of information retrieval includes classification of publications, author disambiguation, keywords extraction, and full-text indexing, whereas recommendations are based on the combination of a cosine similarity between keywords and a full-text index. The proposed system has been verified through a case study run at the National Center for Research and Development, Warsaw, Poland.","Reviewer assignment problem,Recommender system,Data acquisition,Information retrieval,Content-based filtering","JaroslawProtasiewicza,WitoldPedryczb,MarekKozlowskia,SlawomirDadasa,TomaszStanislaweka,AgataKopacza,MalgorzataGalezewskaa","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2016.05.041","https://www.sciencedirect.com/science/article/pii/S0950705116301381"
"A270","Automating bibliometric analyses using Taverna scientific workflows: A tutorial on integrating Web Services","Quantitative analysis of the scientific literature is a frequent task in bibliometrics. Several large online resources collect and disseminate bibliographic information, paving the way for broad analyses and statistics. The Europe PubMed Central (PMC) and its Web Services is one of these resources, providing a rich platform to retrieve information and metadata on scientific publications. However, a complete bibliometric analysis that involves gathering information and deriving statistics on an author, topic, or country is laborious when consuming Web Services on the command-line or using low level automation. In contrast, scientific workflow managers can integrate different types of software tools to automate multi-step processes. The Taverna workflow engine is a popular open-source scientific workflow manager, giving easy access to available Web Services. In this tutorial, we demonstrate how to design scientific workflows for bibliometric analyses in Taverna by integrating Europe PubMed Central Web Services and statistical analysis tools. To our knowledge, this is also the first time scientific workflow managers have been used to perform bibliometric analyses using these Web Services.","Bibliometrics,Europe PMC,PubMed,Taverna,Scientific workflows,R,Biomolecular interactions","Arzu TugceGulera,Cathelijn J.F.Waaijerb,YasseneMohammeda,MagnusPalmblada","Journal of Informetrics","https://doi.org/10.1016/j.joi.2016.05.002","https://www.sciencedirect.com/science/article/pii/S1751157716300141"
"A271","Sharing economy: A review and agenda for future research","This paper provides an objective, systematic and holistic review of the sharing economy (SE) academic literature to uncover the theoretical foundations and key themes underlying the field by using co-citation analysis and content analysis. Sixty-six publications on sharing economy with ten papers related to tourism and hospitality from 2010 to 2015 (inclusive) have been identified. This paper revealed three broad areas of foci with sharing economy research in general: (1) SE’s business models and its impacts, (2) nature of SE, and (3) SE’s sustainability development as well as two areas of foci in tourism and hospitality specifically: (1) SE’s impacts on destinations and tourism services (2) SE’s impacts on tourists. The sharing economy has a strong intellectual tradition from lifestyle and social movement field, consumption practice and sharing paradigm. This paper presents a more robust framework and holistic understanding of the sharing economy field and calls for a new theory-informed research agenda on sharing economy to coalesce multi-level perspectives.","Sharing economy,Collaborative consumption,Co-citation analysis,Content analysis,Tourism and hospitality","MingmingCheng","International Journal of Hospitality Management","https://doi.org/10.1016/j.ijhm.2016.06.003","https://www.sciencedirect.com/science/article/pii/S0278431916300743"
"A272","Mapping the evolution of scientific fields based on cross-field authors","Mapping the evolution of scientific fields has drawn much attention in recent years. Researchers have proposed various methods to describe, explain and predict different aspects of science. Network-based analysis has been widely used for knowledge networks, in order to track the changes of research topics and the spread of scientific ideas. Here we propose a novel approach for mapping the science from the perspective of cross-field authors. Computer science is selected based on its interdisciplinary applications. We build a scientific network consisting of computer science conferences as nodes, and two conferences are linked if there exist authors that published papers on both conferences. The scientific fields are identified by community detection algorithm. The results suggest the proposed method based on author overlaps across fields are effective in mapping the science.","Scientific evolution,Network analysis,Interdisciplinary research","XiaolingSun,KunDing,YuanLin","Journal of Informetrics","https://doi.org/10.1016/j.joi.2016.04.016","https://www.sciencedirect.com/science/article/pii/S1751157715302352"
"A273","Analysis of the Intellectual Structure of Scientific Papers about Professional Competences Related to Organizational Psychology","The aim of the scientific paper is to deepen into the domain analysis and network analysis of the bibliography about professional competences from the perspective of organizational psychology, looking for the existing relations between authors and trends, significant because of their direct influence on the members of an organization.The techniques used, network analysis and domain analysis, allow getting clusters that group data with similar features considering units of measure such as co-citation and co-occurrence.As a result, the characteristics of the competence models related to organizational psychology, their limitations, initial development, evolution and trends are presented.","domain analysis,network analysis,professional competencies,organizational psychology,competencies models","Dante A. GuerreroChanduví,Catherin GirónEscobar,Daniel JaraGallo,Valeria CruzAlayza","Procedia - Social and Behavioral Sciences","https://doi.org/10.1016/j.sbspro.2016.06.190","https://www.sciencedirect.com/science/article/pii/S187704281630876X"
"A274","Virtual and remote labs in education: A bibliometric analysis","Laboratory experimentation plays an essential role in engineering and scientific education. Virtual and remote labs reduce the costs associated with conventional hands-on labs due to their required equipment, space, and maintenance staff. Furthermore, they provide additional benefits such as supporting distance learning, improving lab accessibility to handicapped people, and increasing safety for dangerous experimentation. This paper analyzes the literature on virtual and remote labs from its beginnings to 2015, identifying the most influential publications, the most researched topics, and how the interest in those topics has evolved along the way. To do so, bibliographical data gathered from ISI Web of Science, Scopus and GRC2014 have been examined using two prominent bibliometric approaches: science mapping and performance analysis.","Virtual laboratory,Remote laboratory,Web-based experimentation,Bibliometrics,Science mapping","RubenHeradioa,Luisde la Torreb,DanielGalanb,Francisco JavierCabrerizoa,EnriqueHerrera-Viedmac,SebastianDormidob","Computers & Education","https://doi.org/10.1016/j.compedu.2016.03.010","https://www.sciencedirect.com/science/article/pii/S0360131516300677"
"A275","Growth and structure of authorship and co-authorship network in the strategic management realm: Evidence from the Strategic Management Journal","The main objective of this study is to investigate the intellectual structure and evolution of author collaborations from articles published in the Strategic Management Journal between 1980 and 2014. This assessment includes the general view of authorship, authorship patterns, author productivity, ranking of authors, visualization of the co-authorship network, comparison of strategic management co-authorship network attributes with those of other disciplines, the evolution of main components and core authors in the networks by period, discussions on whether the strategic management network fits with the small world network theory, individual network attributes such as degree centrality, Bonacich's power index, closeness centrality, and betweenness centrality. Finally, the authors provide an inclusive evaluation of the results, limitations, and suggestions for future research.","M10,M19,D85,Keywords,Co-authorship,Strategic Management Journal,Social network analysis,Small world,Bibliometrics","Mehmet AliKoseogluab","BRQ Business Research Quarterly","https://doi.org/10.1016/j.brq.2016.02.001","https://www.sciencedirect.com/science/article/pii/S2340943616300019"
"A276","Digital literacy and knowledge societies: A grounded theory investigation of sustainable development","With a structurally entrenched digital divide on the one hand, and increasing ubiquity of the Internet in a techno-centric world on the other, the imperative to exploit information and knowledge for development remains a significant driver for equitable growth. It is posited that the silver-bullet for reducing this gap lies in increasing digital literacies within a society in order integrate segments who may be marginalized into the inclusive mainstream. In enabling greater and wider participation of digital citizens in their countries' socio-economic activities, the opportunities of a sustainable economy arise. This article is a study of ICT policies, applications and the resulting transformations in five mature economies committed to the vision of knowledge-based development with high levels of digital participation among their citizens. Specifically, using a multi-dimensional scorecard derived from prior work, we conduct a grounded theory investigation of how the five societies have applied digital literacies in knowledge-intensive public services such as education, healthcare and e-government, to derive best practices as well as lessons learned.","Digital inclusion and participation,Information entitlement,ICT infrastructure,Smart cities","RaviSharma,Arul-RajFantin,NavinPrabhu,ChongGuan,AmbicaDattakumar","Telecommunications Policy","https://doi.org/10.1016/j.telpol.2016.05.003","https://www.sciencedirect.com/science/article/pii/S0308596116300428"
"A277","Text mining patents for biomedical knowledge","","","RaulRodriguez-Esteban1,MarkusBundschus2","Drug Discovery Today","https://doi.org/10.1016/j.drudis.2016.05.002","https://www.sciencedirect.com/science/article/pii/S1359644616301520"
"A278","Improving the utility of MeSH® terms using the TopicalMeSH representation","ObjectiveTo evaluate whether vector representations encoding latent topic proportions that capture similarities to MeSH terms can improve performance on biomedical document retrieval and classification tasks, compared to using MeSH terms.,Materials and methodsWe developed the TopicalMeSH representation, which exploits the ‘correspondence’ between topics generated using latent Dirichlet allocation (LDA) and MeSH terms to create new document representations that combine MeSH terms and latent topic vectors. We used 15 systematic drug review corpora to evaluate performance on information retrieval and classification tasks using this TopicalMeSH representation, compared to using standard encodings that rely on either (1) the original MeSH terms, (2) the text, or (3) their combination. For the document retrieval task, we compared the precision and recall achieved by ranking citations using MeSH and TopicalMeSH representations, respectively. For the classification task, we considered three supervised machine learning approaches, Support Vector Machines (SVMs), logistic regression, and decision trees. We used these to classify documents as relevant or irrelevant using (independently) MeSH, TopicalMeSH, Words (i.e., n-grams extracted from citation titles and abstracts, encoded via bag-of-words representation), a combination of MeSH and Words, and a combination of TopicalMeSH and Words. We also used SVM to compare the classification performance of tf-idf weighted MeSH terms, LDA Topics, a combination of Topics and MeSH, and TopicalMeSH to supervised LDA’s classification performance.,ResultsFor the document retrieval task, using the TopicalMeSH representation resulted in higher precision than MeSH in 11 of 15 corpora while achieving the same recall. For the classification task, use of TopicalMeSH features realized a higher F1 score in 14 of 15 corpora when used by SVMs, 12 of 15 corpora using logistic regression, and 12 of 15 corpora using decision trees. TopicalMeSH also had better document classification performance on 12 of 15 corpora when compared to Topics, tf-idf weighted MeSH terms, and a combination of Topics and MeSH using SVMs. Supervised LDA achieved the worst performance in most of the corpora.,ConclusionThe proposed TopicalMeSH representation (which combines MeSH terms with latent topics) consistently improved performance on document retrieval and classification tasks, compared to using alternative standard representations using MeSH terms alone, as well as, several standard alternative approaches.","Topic models,MeSH,PubMed,Document retrieval,Document classification","ZhiguoYua,ElmerBernstamb,TrevorCohena,Byron C.Wallacec,Todd R.Johnsona","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2016.03.013","https://www.sciencedirect.com/science/article/pii/S1532046416300041"
"A279","Trackable life: Data, sequence, and organism in movement ecology","Over the past decade an increasing number of ecologists have begun to frame their work as a contribution to the emerging research field of movement ecology. This field's primary object of research is the movement track, which is usually operationalized as a series of discrete “steps and stops” that represent a portion of an animal's “lifetime track.” Its practitioners understand their field as dependent on recent technical advances in tracking organisms and analyzing their movements. By making movement their primary object of research, rather than simply an expression of deeper biological phenomena, movement ecologists are able to generalize across the movement patterns of a wide variety of species and to draw on statistical techniques developed to model the movements of non-living things. Although it can trace its roots back to a long tradition of statistical models of movement, the field relies heavily on metaphors from genomics; in particular, movement tracks have been seen as similar to DNA sequences. Though this has helped movement ecology consolidate around a shared understanding of movement, the field may need to broaden its understanding of movement beyond the sequence if it is to realize its potential to address urgent concerns such as biodiversity loss.","History of ecology,Movement ecology,Big data,Data-centric science,Bioinformatics,Animal tracking","Etienne S.Benson","Studies in History and Philosophy of Science Part C: Studies in History and Philosophy of Biological and Biomedical Sciences","https://doi.org/10.1016/j.shpsc.2016.02.005","https://www.sciencedirect.com/science/article/pii/S1369848616000236"
"A280","Knowledge maps: A systematic literature review and directions for future research","ContextNowadays the concept of knowledge mapping has attracted increased attention from scientists in a variety of academic disciplines and professional practice areas. Among the most important attributes of a knowledge map is its ability to increase communication and share common practices across an entire organisation. However, despite being a promising area for research, the knowledge maps community lacks a widespread understanding of the current state of the art.,ObjectiveThe objective of this article is to explore the world of knowledge mapping by reviewing and analysing the current state of research and providing an overview of knowledge mapping’s concepts, benefits, techniques, classifications and methodologies, which are precisely reviewed, and their features are highlighted. In addition, we offer directions for future research.,MethodBased on the systematic literature review method this study collects, synthesises, and analyses numerous articles on a variety of topics closely related to a knowledge map published from January 2000 to December 2013 on six electronic databases by following a pre-defined review protocol. The articles have been retrieved through a combination of automatic and manual search, hence extensive quantitative and qualitative results of the research are provided.,ResultsFrom the review study, we identified 132 articles addressing knowledge maps that have been reviewed in order to extract relevant information on a set of research questions. We found a generally increasing level of activity during this 5-year period. We noted that while existing research covers a large number of studies on some disciplines, such as systems and tools development, it contains very few studies on other disciplines, such as knowledge maps adoption. To aid this situation, we offer directions for future research.,ConclusionsThe results demonstrated that a knowledge map is an imperative strategy for increasing organisations’ effectiveness. In addition, there is a need for more knowledge maps research.","Knowledge maps,Knowledge management,Systematic literature review","AliBalaida,Mohd ZaidiAbd Rozana,Syed NorrisHikmia,JamshedMemonb","International Journal of Information Management","https://doi.org/10.1016/j.ijinfomgt.2016.02.005","https://www.sciencedirect.com/science/article/pii/S0268401216000098"
"A281","The two faces of inventions: The relationship between recombination and impact in pharmaceutical biotechnology","‘Recombination’ and ‘impact’ have become well established constructs to understand the origins of inventions and their importance for the development of future inventions. Despite forming these two familiar ‘faces of inventions’, their specific relationship has only marginally been subject to inquiry. To address this, this paper studies the relationship between the level of recombination of inventions and their technological impact, along two steps. First, in contrast to the common idea of a linear relationship between recombination and impact we argue that the relationship is in fact a non-linear one. Second, we distinguish between different levels of recombination (low, intermediate, high) and determine their differential impact, thereby establishing which type of recombination leads to the highest level of technological impact. We test our hypotheses on an extensive dataset, comprised of all USPTO granted patents in the biopharmaceutical industry between 1976 and 2006. Our empirical findings indicate strong evidence for a curvilinear relationship between recombination and impact. In addition, we find that an intermediate level of recombination – formed by a combination of components from local, adjacent and distant knowledge domains – carries the highest level of technological impact of all types of inventions. Finally, we discuss implications for the academic literature and for firms’ innovation strategies.","Inventions,Recombination,Technological impact,Pharmaceutical biotechnology,Breakthroughs","S.Keijla,V.A.Gilsingbc,J.Knobend,G.Duysterse","Research Policy","https://doi.org/10.1016/j.respol.2016.02.008","https://www.sciencedirect.com/science/article/pii/S004873331630021X"
"A282","Leveraging patent landscape analysis and IP competitive intelligence for competitive advantage","Patent landscape and the accompanying IP competitive intelligence involves understanding and anticipating the competitive environment within which a company operates. More specifically, IP competitive intelligence highlights emerging IP risks, provides patent portfolio benchmarking, monitors competitor technology development efforts, and predicts commercialization of technology.This paper provides a framework for patent landscape and IP competitive intelligence as driven by strategic intent. This paper advocates the benefits of both “quantitative” statistical analysis and “qualitative” human intelligence for IP competitive intelligence. Moreover, this paper defines four Levels of IP analysis with pruned examples for effective competitive intelligence.","Patent,Intellectual property,Analysis,Data,Competitive intelligence,Strategy","Yateen R.Pargaonkar","World Patent Information","https://doi.org/10.1016/j.wpi.2016.03.004","https://www.sciencedirect.com/science/article/pii/S0172219016000193"
"A283","Hierarchical Bayesian nonparametric models for knowledge discovery from electronic medical records","Electronic Medical Record (EMR) has established itself as a valuable resource for large scale analysis of health data. A hospital EMR dataset typically consists of medical records of hospitalized patients. A medical record contains diagnostic information (diagnosis codes), procedures performed (procedure codes) and admission details. Traditional topic models, such as latent Dirichlet allocation (LDA) and hierarchical Dirichlet process (HDP), can be employed to discover disease topics from EMR data by treating patients as documents and diagnosis codes as words. This topic modeling helps to understand the constitution of patient diseases and offers a tool for better planning of treatment. In this paper, we propose a novel and flexible hierarchical Bayesian nonparametric model, the word distance dependent Chinese restaurant franchise (wddCRF), which incorporates word-to-word distances to discover semantically-coherent disease topics. We are motivated by the fact that diagnosis codes are connected in the form of ICD-10 tree structure which presents semantic relationships between codes. We exploit a decay function to incorporate distances between words at the bottom level of wddCRF. Efficient inference is derived for the wddCRF by using MCMC technique. Furthermore, since procedure codes are often correlated with diagnosis codes, we develop the correspondence wddCRF (Corr-wddCRF) to explore conditional relationships of procedure codes for a given disease pattern. Efficient collapsed Gibbs sampling is derived for the Corr-wddCRF. We evaluate the proposed models on two real-world medical datasets – PolyVascular disease and Acute Myocardial Infarction disease. We demonstrate that the Corr-wddCRF model discovers more coherent topics than the Corr-HDP. We also use disease topic proportions as new features and show that using features from the Corr-wddCRF outperforms the baselines on 14-days readmission prediction. Beside these, the prediction for procedure codes based on the Corr-wddCRF also shows considerable accuracy.","Bayesian nonparametric models,Correspondence models,Word distances,Disease topics,Readmission prediction,Procedure codes prediction","ChengLi,SantuRana,DinhPhung,SvethaVenkatesh","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2016.02.005","https://www.sciencedirect.com/science/article/pii/S0950705116000836"
"A284","APhA2016 abstracts of contributed papers","","","","Journal of the American Pharmacists Association","https://doi.org/10.1016/S1544-3191(16)30033-4","https://www.sciencedirect.com/science/article/pii/S1544319116300334"
"A285","A distributional approach to open questions in market research","Free-text responses to open questions are a rich and valuable resource in modern-day market research, but often pose problems for a traditional analysis, which requires prohibitively expensive manual coding of topic categories. The Klugator Engine (TKE) is a system for semi-automatic identification, exploration and visualization of topics and sentiment in large collections of such free-text responses or other short text fragments. The system utilizes state-of-the-art techniques of natural language processing and machine learning to transform textual input into a structured corpus, complemented by automatically determined polarity scores for individual responses. Statistical and distributional methods are then applied in order to identify semantic clusters of responses, label each topic cluster with a set of salient keywords, and evaluate the sentiment associated with the topic. This process can run in fully automated fashion, but it also offers the opportunity of interactive parameter tuning and refinement guided by the end user. Results are presented in a concise graphical visualization supported by detailed tables with numerical information. Embedded in RogTCS, the Rogator Text Clustering Solution, TKE enables customers to obtain a good overview of the main topics in a text collection comprising thousands of responses within 20 min of interactive exploration. An evaluation study based on a data set of more than 60,000 word tokens has shown good agreement with the topics identified by manual coding, rendering TKE a powerful tool for the analysis of unstructured textual data.","Topic clustering,Distributional semantics,Sentiment analysis,Market research","StefanEverta,PaulGreinera,João FilipeBaiggerb,BastianLangb","Computers in Industry","https://doi.org/10.1016/j.compind.2015.10.008","https://www.sciencedirect.com/science/article/pii/S016636151530049X"
"A286","Generation of topic evolution trees from heterogeneous bibliographic networks","The volume of the existing research literature is such it can make it difficult to find highly relevant information and to develop an understanding of how a scientific topic has evolved. Prior research on topic evolution has often leveraged refinements to Latent Dirichlet Allocation (LDA) to identify emerging topics. However, such methods do not answer the question of which studies contributed to the evolution of a topic. In this paper we show that meta-paths over a heterogeneous bibliographic network (consisting of papers, authors and venues) can be used to identify the network elements that made the greatest contributions to a topic. In particular, by adding derived edges that capture the contribution of papers, authors, and venues to a topic (using PageRank algorithm), a restricted meta-path over the bibliographic network can be used to restrict the evolution of topics to the context of interest to a researcher. We use such restricted meta-paths to construct a topic evolution tree that can provide researchers with a web-based visualization of the evolution of a scientific topic in the context of interest to them. Compared to baseline networks without restrictions, we find that restricted networks provide more useful topic evolution trees.","Topic evolution,Heterogeneous bibliographic network,Meta-path,Visualization","ScottJensena,XiaozhongLiub,YingyingYuc,StašaMilojevicd","Journal of Informetrics","https://doi.org/10.1016/j.joi.2016.04.002","https://www.sciencedirect.com/science/article/pii/S1751157715302145"
"A287","Using network science and text analytics to produce surveys in a scientific topic","The use of science to understand its own structure is becoming popular, but understanding the organization of knowledge areas is still limited because some patterns are only discoverable with proper computational treatment of large-scale datasets. In this paper, we introduce a framework to combine network-based methodologies and text analytics to construct the taxonomy of science fields. The methodology is illustrated with application to two topics: complex networks (CN) and photonic crystals (PC). We built citation networks using data from the Web of Science and used a community detection algorithm for partitioning to obtain science maps for the two topics. We also created an importance index for text analytics, which is employed to extract keywords that define the communities and, combined with network topology metrics, to generate dendrograms of relatedness among subtopics. Interesting patterns emerging from the analysis included identification of two well-defined communities in PC area, which is consistent with the known existence of two distinct communities of researchers in the area: telecommunication engineers and physicists. With the methodology, it was also possible to assess the interdisciplinary nature and time evolution of subtopics defined by the keywords. The automatic tools described here are potentially useful not only to provide an overview of scientific areas but also to assist scientists in performing systematic research on a specific topic.","Entropy,Networks,Scientific map,Photonic crystals,Pattern recognition","Filipi N.Silvaa,Diego R.Amanciob,MariaBardosovac,Luciano da F.Costaa,Osvaldo N.OliveiraJr.a","Journal of Informetrics","https://doi.org/10.1016/j.joi.2016.03.008","https://www.sciencedirect.com/science/article/pii/S1751157715301966"
"A288","Clay smear: Review of mechanisms and applications","Clay smear is a collection of fault processes and resulting fault structures that form when normal faults deform layered sedimentary sections. These elusive structures have attracted deep interest from researchers interested in subsurface fluid flow, particularly in the oil and gas industry. In the four decades since the association between clay-smear structures and oil and gas accumulations was introduced, there has been extensive research into the fault processes that create clay smear and the resulting effects of that clay smear on fluid flow. We undertake a critical review of the literature associated with outcrop studies, laboratory and numerical modeling, and subsurface field studies of clay smear and propose a comprehensive summary that encompasses all of these elements. Important fault processes that contribute to clay smear are defined in the context of the ratio of rock strength and in situ effective stresses, the geometric evolution of fault systems, and the composition of the faulted section. We find that although there has been progress in all avenues pursued, progress has been uneven, and the processes that disrupt clay smears are mostly overlooked. We highlight those research areas that we think will yield the greatest benefit and suggest that taking these emerging results within a more process-based framework presented here will lead to a new generation of clay smear models.","Clay smear,Fault process,Sedimentary rocks,Experiments,Fluid flow","Peter J.Vrolijka,Janos L.Uraib,MichaelKettermannb","Journal of Structural Geology","https://doi.org/10.1016/j.jsg.2015.09.006","https://www.sciencedirect.com/science/article/pii/S0191814115300390"
"A289","Bibliometric and visualized analysis of emergy research","A bibliometric approach, along with Citespace software, was used to quantitatively and visually evaluate global scientific research on emergy from 1996 to 2014. 637 publications – in accordance with the search criteria from the Science Citation Index Expanded (SCI-Expanded) and Social Science Citation Index (SSCI) of the Web of Science database – were statistically analyzed. The assessments on document type and language, publication year, authorship, subject categories and journals, countries/territories and institutions, most-frequently cited publications and author keywords were conducted with respect to seven categories. The amount of emergy publications per year has sharply increased in recent years. The most productive author was S. Ulgiati with 50 articles, who was also one of the most frequently cited publication authors. China produced 35.95% of all pertinent publications followed by the USA with 25.59% and Italy with 21.66%. Ecological Modeling, Ecological Engineering and Ecological Indicators were the three most common journals in this field. By synthetically analyzing the keywords, the dominant hot spots of emergy research could be concluded as “energy”, “sustainability”, “transformity”, and “indicators”.","Bibliometric analysis,Emergy,Web of Science,Citespace","DanChena,ZhiLiua,ZhaohuiLuob,MichaelWebberc,JingChena","Ecological Engineering","https://doi.org/10.1016/j.ecoleng.2016.01.026","https://www.sciencedirect.com/science/article/pii/S092585741630026X"
"A290","Individual motivation and threat indicators of collaboration readiness in scientific knowledge producing teams: a scoping review and domain analysis","This paper identifies a gap in the team science literature that considers intrapersonal indicators of collaboration as motivations and threats to participating in collaborative knowledge producing teams (KPTs). Through a scoping review process, over 150 resources were consulted to organize 6 domains of motivation and threat to collaboration in KPTs: Resource Acquisition, Advancing Science, Building Relationships, Knowledge Transfer, Recognition and Reward, and Maintenance of Beliefs. Findings show how domains vary in their presentation of depth and diversity of motivation and threat indicators as well as their relationship with each other within and across domains. The findings of 51 indicators resulting from the review provide a psychosocial framework for which to establish a hierarchy of collaborative reasoning for individual engagement in KPTs thus allowing for further research into the mechanism of collaborative engagement. The indicators serve as a preliminary step in establishing a protocol for testing of the psychometric properties of intrapersonal measures of collaboration readiness.","Social sciences,Education,Psychology","Gaetano R.Lotrecchianoab,Trudy R.Mallinsona,TommyLeblanc-Beaudoina,Lisa S.Schwartza,DanielleLazarb,Holly J.Falk-Krzesinskicd","Heliyon","https://doi.org/10.1016/j.heliyon.2016.e00105","https://www.sciencedirect.com/science/article/pii/S2405844016300184"
"A291","A bibliometric analysis of 20 years of research on software product lines","Context: Software product line engineering has proven to be an efficient paradigm to developing families of similar software systems at lower costs, in shorter time, and with higher quality.Objective: This paper analyzes the literature on product lines from 1995 to 2014, identifying the most influential publications, the most researched topics, and how the interest in those topics has evolved along the way.Method: Bibliographic data have been gathered from ISI Web of Science and Scopus. The data have been examined using two prominent bibliometric approaches: science mapping and performance analysis.Results: According to the study carried out, (i) software architecture was the initial motor of research in SPL; (ii) work on systematic software reuse has been essential for the development of the area; and (iii) feature modeling has been the most important topic for the last fifteen years, having the best evolution behavior in terms of number of published papers and received citations.Conclusion: Science mapping has been used to identify the main researched topics, the evolution of the interest in those topics and the relationships among topics. Performance analysis has been used to recognize the most influential papers, the journals and conferences that have published most papers, how numerous is the literature on product lines and what is its distribution over time.","Software product lines,Bibliometrics,Science mapping,Performance analysis","RubenHeradioa,HectorPerez-Moragoa,DavidFernandez-Amorosa,FranciscoJavier Cabrerizoa,EnriqueHerrera-Viedmab","Information and Software Technology","https://doi.org/10.1016/j.infsof.2015.11.004","https://www.sciencedirect.com/science/article/pii/S0950584915001883"
"A292","Citing the world: A geometric data analysis of Swedish literary scholars’ use of foreign critical resources","The academic study of literature constitutes one institutional site for the production and reproduction of conceptions of literature. In a semi-peripheral country such as Sweden, this production partly relies on foreign intellectual goods. To analyze this transnational dimension of Swedish scholarship in a period marked by increasing internationalization, a Geometric Data Analysis (GDA) (Le Roux & Rouanet, 2004) was carried out on the bibliographies of 318 PhD dissertations, defended in the period 1980–2005, at Swedish departments of literary studies (litteraturvetenskap). The analysis of citational choices showed only an insignificant increase in the reliance on foreign sources in this period. The GDA revealed how these privileged references were distributed in a tripolar opposition, reflecting fundamentally different conceptions of literature, interpreted in this study as the three poles of textual singularity, secular particularity and anthropological universality. The analysis of supplementary variables shows that these oppositions are subtended by different geolinguistic orientations and that they correlate strongly with gender, which is overwhelmingly in evidence as one moves from the male-dominated textual pole to the strongly feminist and female social pole of the first axis. The lack of increasing internationalization measured by citations is attributed to the “national cultural mission” of these departments.","Geometric Data Analysis,Citational study,Literary scholarship,Sociology of literature,Conceptions of literature,Internationalization in the humanities","Bo G.Ekelund","Poetics","https://doi.org/10.1016/j.poetic.2015.11.003","https://www.sciencedirect.com/science/article/pii/S0304422X1500090X"
"A293","Topic analysis and forecasting for science, technology and innovation: Methodology with a case study focusing on big data research","The number and extent of current Science, Technology & Innovation topics are changing all the time, and their induced accumulative innovation, or even disruptive revolution, will heavily influence the whole of society in the near future. By addressing and predicting these changes, this paper proposes an analytic method to (1) cluster associated terms and phrases to constitute meaningful technological topics and their interactions, and (2) identify changing topical emphases. Our results are carried forward to present mechanisms that forecast prospective developments using Technology Roadmapping, combining qualitative and quantitative methodologies. An empirical case study of Awards data from the United States National Science Foundation, Division of Computer and Communication Foundation, is performed to demonstrate the proposed method. The resulting knowledge may hold interest for R&D management and science policy in practice.","Topic analysis,Technological forecasting,Text mining,Text clustering,Technical intelligence","YiZhangab,GuangquanZhanga,HongshuChenab,Alan L.Porterc,DonghuaZhub,JieLua","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2016.01.015","https://www.sciencedirect.com/science/article/pii/S0040162516000160"
"A294","Atlas of scientific institutions in food science (Scopus, 2003–2013)","Bibliometric indicators are used to characterize the research activity of institutions worldwide with production in the period 2003–2013 in journals that are indexed in Scopus's Food Science thematic category. Basic, normalized indicators were used to compare the institutions' performances, together with highly cited papers (top-10% and top-1%). An interactive map was generated, displaying the 645 institutions with at least 100 documents produced during this period. The greatest numbers of those institutions are in the United States, South Korea, Spain, and China. National collaboration networks were detected on the East and West Coasts of the United States, and in Canada, Ireland, France, Spain, Holland, Denmark, China, South Korea, Malaysia, Brazil, India, Argentina, and Nigeria. There was no significant research activity in many developing and food exporting countries located in sub-Saharan Africa, North and East Africa, the Middle East, Latin America, the Caribbean, Eastern Europe, Central Asia, and South East Asia. The need to take into account other criteria based on qualitative attributes and the inherent limitations in the bibliometric indicators are discussed.","Food science,Citation analysis,Bibliometric,Research activity,Networks","Vicente P.Guerrero-Botea,CarlosOlmeda-Gómezb,FélixMoya-Anegónc","LWT - Food Science and Technology","https://doi.org/10.1016/j.lwt.2015.11.035","https://www.sciencedirect.com/science/article/pii/S0023643815303273"
"A295","Visualizing and interacting with large-volume biodiversity data using client–server web-mapping applications: The design and implementation of antmaps.org","The rise of informatics has presented new opportunities for analyzing, visualizing, and interacting with data across the sciences, and biodiversity science is no exception. Recently, comprehensive datasets on the geographic distributions of species have been assembled that represent a thorough accounting of a given taxonomic group of species (e.g. birds, mammals, etc.), and which form critical tools for both basic biology and conservation. However, these databases present several challenges for visualization, interaction, and participation for users across a broad range of scientists and the public. In support of the development of a new comprehensive ant biodiversity database containing over 1.7 million records, we developed a new client–server web-mapping application, antmaps.org, to visualize and interact with the geographic distributions of all 15,050 ant species and aggregate patterns of their diversity and biogeography. Our application development approach was based on user-centered design principles of usability engineering, human-computer interaction, and cartography. The resulting application is highly focused on providing efficient and intuitive access to geographic biodiversity data using a client–server interaction that allows users to query and retrieve data on the fly. This is achieved with a backend solution to efficiently work with large volumes of geospatial data. The usability and utility of the final version of the application was measured based on effectiveness, efficiency and user satisfaction, and assessed using questionnaires, usability lab studies and surveys. While the development of antmaps.org was motivated by a particular ant biodiversity dataset, the basic framework, design, and functionality are not specific to ants and could be used to interact with biodiversity data of any taxonomic group.","Ants,Web-mapping,Database,User-centered design,Cartographic design,Client–server,Biodiversity informatics,D3js","JuliaJanickia,NitishNarulaa,MattZieglera,BenoitGuénardab,Evan P.Economoa","Ecological Informatics","https://doi.org/10.1016/j.ecoinf.2016.02.006","https://www.sciencedirect.com/science/article/pii/S1574954116300097"
"A296","Highly-cited papers in software engineering: The top-100","ContextAccording to the search reported in this paper, as of this writing (May 2015), a very large number of papers (more than 70,000) have been published in the area of Software Engineering (SE) since its inception in 1968. Citations are crucial in any research area to position the work and to build on the work of others. Identification and characterization of highly-cited papers are common and are regularly reported in various disciplines.,ObjectiveThe objective of this study is to identify the papers in the area of SE that have influenced others the most as measured by citation count. Studying highly-cited SE papers helps researchers to see the type of approaches and research methods presented and applied in such papers, so as to be able to learn from them to write higher quality papers which will likely receive high citations.,MethodTo achieve the above objective, we conducted a study, comprised of five research questions, to identify and classify the top-100 highly-cited SE papers in terms of two metrics: total number of citations and average annual number of citations.,ResultsBy total number of citations, the top paper is \"A metrics suite for object-oriented design\", cited 1817 times and published in 1994. By average annual number of citations, the top paper is \"QoS-aware middleware for Web services composition\", cited 154.2 times on average annually and published in 2004.,ConclusionIt is concluded that it is important to identify the highly-cited SE papers and also to characterize the overall citation landscape in the SE field. We hope that this paper will encourage further discussions in the SE community towards further analysis and formal characterization of the highly-cited SE papers.","Software engineering,Highly-cited papers,Top cited,Most cited,Most frequently cited,Bibliometrics","VahidGarousia,João M.Fernandesb","Information and Software Technology","https://doi.org/10.1016/j.infsof.2015.11.003","https://www.sciencedirect.com/science/article/pii/S0950584915001871"
"A297","Qualitative research practices and family business scholarship: A review and future research agenda","In spite of various calls for a wider application of qualitative research in the family business field, it is our contention that the full potential of qualitative inquiry is not being fully realized. Part of the reason for this relates to the tendency to promote methods choice and diversity rather than addressing the foundational questions and processes which underlie qualitative research choices. These tendencies obscure attention to the reasons why researchers choose qualitative methods and the kinds of foundational issues about family businesses that are brought to light through qualitative research. To address this, we undertake an analysis of the most-cited articles using qualitative methods from an annotated bibliography of family business studies. From this, we identify the strengths and weaknesses of extant qualitative studies in family business research and argue for the need to re-orientate calls in family business research towards the foundational questions (rather than methods) that underline qualitative inquiry.","Qualitative research,Qualitative methods,Epistemology,Interpretivism,Family business,Future research","DeniseFletchera,Alfredo DeMassisb,MattiasNordqvistc","Journal of Family Business Strategy","https://doi.org/10.1016/j.jfbs.2015.08.001","https://www.sciencedirect.com/science/article/pii/S1877858515000364"
"A298","Identification and monitoring of possible disruptive technologies by patent-development paths and topic modeling","Understanding current technological changes is the basis for better forecasting of technological changes. Because technology is path dependent, monitoring past and current trends of technological development helps managers and decision makers to identify probable future technologies in order to prevent organizational failure. This study suggests a method based on patent-development paths, k-core analysis and topic modeling of past and current trends of technological development to identify technologies that have the potential to become disruptive technologies. We find that within the photovoltaic industry, thin-film technology is likely to replace the dominant technology, namely crystalline silicon. In addition, we identity the hidden technologies, namely multi-junction, dye-sensitized and concentration technologies, that have the potential to become disruptive technologies within the three main technologies of the photovoltaic industry.","Technology monitoring,Technological forecasting,Patent-development paths,Topic modeling,K-core analysis,Disruptive technology,Photovoltaic industry","AbdolrezaMomenia,KatjaRostb","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2015.12.003","https://www.sciencedirect.com/science/article/pii/S0040162515004072"
"A299","Output distributions and topic maps of safety related journals","This paper presents topic maps of six core safety journals, based on analysis of 13,028 articles published in those journals as downloaded from the Web of Science. Bibliometric mapping methods were used to visualize the map of the topics covered in each journal. Analysis was also made of the changes in topics over time. The results show that safety science research in those journals has grown very rapidly over the last half century, with USA as the most productive in total and also in each year in the period. The topic clusters of these journals reveal the focus of each journal, which may be determined by the dominant methodologies used, the activity whose safety is studied or the object of study (e.g. workplace, safety management, regulation, etc.). The different journals also show regional differences in the papers they attract. The field in total is highly multidisciplinary. The topics of Safety Science have been focused on major hazard, transportation and work safety; Journal of Safety Research divides its attention between work and traffic safety, with a smaller cluster on statistics; Accident Analysis and Prevention is concerned almost exclusively with road safety; Injury Prevention is concerned mainly with injury mechanisms, but includes topics not treated by the other 5 journals, such as violence, suicide and other intentional injury and child safety at school and in the home. Reliability Engineering and System Safety and the Journal of Loss Prevention in the Process Industries focus mainly on major hazard, with the latter most concerned with the technology of failure mechanisms and the former on quantitative risk assessment.","Safety science,Safety journals,Topic visualization,Text analysis,VOSviewer","JieLiac,AndrewHalebc","Safety Science","https://doi.org/10.1016/j.ssci.2015.09.004","https://www.sciencedirect.com/science/article/pii/S0925753515002337"
"A300","Trajectory analysis of drug-research trends in pancreatic cancer on PubMed and ClinicalTrials.gov","Increasing interest in developing treatments for pancreatic cancer has led to a surge in publications in the field. Analyses of drug-research trends are needed to minimize risk in anti-cancer drug development. Here, we analyzed publications on anti-cancer drugs extracted from PubMed records and ClinicalTrials datasets. We conducted a drug cluster analysis by proposing the entity Dirichlet Multinomial Regression (eDMR) technique and in-depth network analysis of drug cluster and target proteins. The results show two distinct research clusters in both the ClinicalTrials dataset and the PubMed records. Specifically, various targets associated with anti-cancer drugs are investigated in new drug testing while the diverse chemicals are studied together with a standard therapeutic agent in the academic literature. In addition, our study confirms that drug research published in PubMed is preceded by clinical trials. Although we only evaluate drugs for pancreatic cancer in the present study, our method can be applied to drug-research trends of other diseases.","Pancreatic cancer,Text mining,Bibliometric analysis,Data analysis,Information extraction","Yoo KyungJeonga,Go EunHeoa,Keun YoungKanga,Dong SupYoonb,MinSonga","Journal of Informetrics","https://doi.org/10.1016/j.joi.2016.01.003","https://www.sciencedirect.com/science/article/pii/S1751157715301280"
"A301","Visualizing the intellectual structure of information science (2006–2015): Introducing author keyword coupling analysis","We introduce the author keyword coupling analysis (AKCA) method to visualize the field of information science (2006–2015). We then compare the AKCA method with the author bibliographic coupling analysis (ABCA) method in terms of first- and all-author citation counts. We obtain the following findings: (1) The AKCA method is a new and feasible method for visualizing a discipline's structure, and the ABCA and AKCA methods have their respective strengths and emphases. The relation within the ABCA method is based on the same references (knowledge base), whereas that within the AKCA method is based on the same keywords (lexical linguistic). The AKCA method appears to provide a less detailed picture, and more uneven sub-areas of a discipline structure. The relationships between authors are narrow and direct and feature multiple levels in AKCA. (2) All-author coupling provides a comprehensive picture; thus, a complete view of a discipline structure may require both first- and all-author coupling analyses. (3) Information science evolved continuously during the second decade of the World Wide Web. The KDA (knowledge domain analysis) camp became remarkably prominent, while the IR camp (information retrieval) experienced a further decline in hard IR research, and became significantly smaller; Patent analysis and Open Access emerged during this period. Mapping of Science and Bibliometric evaluation also experienced substantial growth.","Author keyword coupling analysis,Information science,Author bibliographic coupling analysis,Bibliometric mapping","SiluoYangac,RuizhenHana,DietmarWolframb,YuehuaZhaob","Journal of Informetrics","https://doi.org/10.1016/j.joi.2015.12.003","https://www.sciencedirect.com/science/article/pii/S1751157715301103"
"A302","Chapter 3: Visual Analytic Decision-Making Environments for Large-Scale Time-Evolving Graphs","Decision makers in multiple domains are increasingly looking for ways to improve the understanding of real-world phenomena through data collected from Internet devices, including low-cost sensors, smart phones, and online activity. Examples include detecting environmental changes, understanding the impacts of adverse manmade and natural disasters, and obtaining marketing intelligence on company profiles. Real-world observations from streaming data sources such as sensors, click streams, and social media are becoming increasingly common in many domains, including cybersecurity, infectious disease surveillance, social community networks, and web-based recommendation systems. An emerging approach is to leverage graph-based modeling of these events, to understand ongoing trends and predict future ones. Data scientists are faced with the challenge of analyzing large-scale graphs that are changing dynamically, while existing tools and metaphors for data collection, processing, storage, and analysis are not suitable for handling large-scale evolutionary graphs. This chapter describes visual analytics as a cognitive computing approach to improve decision making with large-scale dynamic graphs. We provide a conceptual introduction to time-varying graphs and various components of the visual analytics that affect the performance of decision support systems, including data management, analytics, visualization, and visual interaction. We provide techniques to improve the performance of each of these components in an integrated visual analytics framework. We also describe a visual graph analytics sandbox architecture and sample applications implemented within it.","Visual analytics,Time-evolving graphs,Data streams,Graph visualization,Data warehouse","S.R.Venna,R.N.Gottumukkala,V.V.Raghavan","Handbook of Statistics","https://doi.org/10.1016/bs.host.2016.07.002","https://www.sciencedirect.com/science/article/pii/S0169716116300438"
"A303","2: The Present","In the second part the current altmetric research is presented. This part begins with an overview of scholarly communication on the web, its potential, and current status. This is followed by an overview of some of the sources of these new online metrics. The service providers or aggregators of altmetrics are briefly presented, followed by a discussion of the different stakeholders. There are many stakeholders connected to altmetrics, all of whom can use them somewhat differently and benefit from them in various ways. Some of the earlier research of altmetrics will be presented, research that has pushed the development of altmetrics forward and continues to push it as the web evolves and the way we use the web changes.","scholarly communication,web,internet,data,information dissemination,impact,data,blogs,microblogs,Twitter,social networking sites,social reference managers,social peer review,peer review,recommendation systems,Wikipedia,data repositories,data sharing,service providers,aggregators,stakeholders,researchers,universities,libraries,publishers,funders,public,audience,altmetrics,webometrics,social media,social media metrics,social media analysis,awareness,attention","KimHolmberg","Altmetrics for Information Professionals,Altmetrics for Information Professionals","https://doi.org/10.1016/B978-0-08-100273-5.00002-8","https://www.sciencedirect.com/science/article/pii/B9780081002735000028"
"A304","TRIZ in Science. Reviewing Indexed Publications","The Theory of Inventive Problem Solving (TRIZ) is a toolkit of methods to support systematic creativity. The latter has been the focus of many studies since late 90s, when innovations became a recognized resource for wealth in modern world. The review is based on SCOPUS papers containing “TRIZ” in abstract, title or among keywords. About 1200 retrieved publications where briefly analyzed by co-appearance of other popular and more known tools or terms. Then the detail analysis of 100 most cited papers takes place. The review reveals the most popular TRIZ application fields (product design, information processing), the most popular TRIZ instruments (contradiction analysis) and the most typical way it is used in the reviewed studies (integration to other tools or application/adaptation for a specific field).","TRIZ,science,review,systematic creativity,ideation","LeonidChechurin","Procedia CIRP","https://doi.org/10.1016/j.procir.2016.01.182","https://www.sciencedirect.com/science/article/pii/S2212827116001979"
"A305","Three decades of strategic management research on M&As: Citations, co-citations, and topics","Merger and acquisitions (M&As) strategies have been growingly deployed by firms for their domestic and international expansion, in order to redefine their business scope or take advantage of emerging opportunities. In this paper we conduct a bibliometric study of the extant strategy research on M&As, assessed by the articles published in the main journal for strategic management studies over the period 1984–2010. Results reveal the highest impact works (articles and books), the intellectual ties among authors and theories that form five main clusters of research, and the topics delved into. Performance effects, M&As as diversification strategies, and resource- and capabilities-based topics have dominated the extant research. The study contributes to the existing knowledge on M&As by taking stock of the accumulated knowledge and research direction, complementing other literature reviews with a strategic management perspective. Thus, we provide a rear view of the field, which facilitates detecting untapped gaps that may provide generous avenues for future research.","M10,M19,G34,Keywords,Mergers & acquisitions,M&As,Strategic management research,Bibliometric study","Manuel PortugalFerreiraab,Nuno Rosados Reisc,Cláudia FriasPintod","Global Economics and Management Review","https://doi.org/10.1016/j.gemrev.2015.12.002","https://www.sciencedirect.com/science/article/pii/S2340154016300020"
"A306","An original design approach for stimulating the ideation of new product features","The manuscript illustrates a method, implemented in a computer application, which supports the identification of new product features in the early phases of engineering design cycles. In the practice, such a task is commonly carried out through cognitive techniques that generate random and unstructured stimuli. These approaches and the computer-aided tools that implement them suffer from a scarce exploration of the design space. This criticality is faced by introducing an original classification of value drivers, thus organizing a large set of concepts consisting of stimuli for generating new product ideas. The proposed method combines the concepts belonging to different categories of the classification in order to identify scenarios in which the product can provide unprecedented benefits for customers and other stakeholders. Experiments in academia and industry show the capability of the developed method and prototype software to increase the number and the novelty of ideas, reveal previously overlooked drivers for customer satisfaction and enhance the definition of stimulated design requirements.","Product Planning,Idea stimulation,Product attributes,Value dimensions,Computer-Aided Design,New Product Development","DanieleBacciottia,YuriBorgiannib,FedericoRotinia","Computers in Industry","https://doi.org/10.1016/j.compind.2015.06.004","https://www.sciencedirect.com/science/article/pii/S0166361515300105"
"A307","Chapter 5: Reservoir Engineering","This chapter presents the basic fundamentals useful to practical petroleum engineers. Topics are introduced at a level that can be understood by geologists and engineers who are not expert in this field. Traditional oil- and gas-producing reservoirs have been in reservoirs with primarily sandstone or limestone formations. Sandstone reservoirs prediction models are based on Darcy’s theories of porosity and permeability. Limestone reservoirs are usually highly fractured due to historic basin tectonics. New fractured reservoir prediction models have been successfully developed and are discussed. Also, in the past two decades innovative geologists and engineers have successfully developed a unique cocktail of technologies, namely, horizontal drilling and hydraulic fracturing, to allow commercial produce from reservoirs composed mainly of shale formations. Reservoir engineering covers a broad range of subjects including the occurrence of fluids in a gas- or oil-beating reservoir, movement of those fluids or injected fluids, and evaluation of the factors governing the recovery of oil or gas. The objectives of a reservoir engineer are to maximize production rates and to predict the future commercial volumes of oil and gas that can be obtained from a reservoir. The chapter includes many of the charts and graphs that have been historically used. While illustrating enhanced oil recovery methods, estimation of waterflood residual oil saturation, fluid movements, material balance with volumetric analysis, the chapter also discusses pressure transient testing, recovery of hydrocarbons, and decline curve analysis. Decline curve analysis estimates primary oil recovery for an individual reservoir. The conventional analysis of production decline curves for oil or gas production consists of plotting the log of flow rate versus time on semilog paper. In the case of a decline in the rate of production, the data are extrapolated into the future to provide an estimate of expected production and reserves.","fracture networks,Fracture channels,Types of fractured reservoirs,Fracture aperture,Fracture porosity,In situ stresses,Minimum in situ stress,Maximum in situ stress,Horizontal in situ stress,Vertical in situ stress,Tight gas formation,Tight oil formation,Unconventional reservoirs,Horizontal borehole,Hydraulic,fracturing in horizontal borehole,casing horizontal borehole,kerogen,pore space,nanopore connectivity,morphology","","Standard Handbook of Petroleum and Natural Gas Engineering,Standard Handbook of Petroleum and Natural Gas Engineering (Third Edition)","https://doi.org/10.1016/B978-0-12-383846-9.00005-9","https://www.sciencedirect.com/science/article/pii/B9780123838469000059"
"A308","The intellectual structure of research in hospitality management: A literature review using bibliometric methods of the journal International Journal of Hospitality Management","The purpose of this study is to analyze the existing literature on hospitality management from all the research papers published in The International Journal of Hospitality Management (IJHM) between 2008 and 2014. The authors apply bibliometric methods – in particular, author citation and co-citation analyses (ACA) – to identify the main research lines within this scientific field; in other words, its ‘intellectual structure’. Social network analysis (SNA) is also used to perform a visualization of this structure. The results of the analysis allow us to define the different research lines or fronts which shape the intellectual structure of research on hospitality management.","Hospitality management,Bibliometrics,Citation analysis,Author co-citation analysis (ACA),Social networks analysis (SNA)","FranciscoGarcía-Lillo,MercedesÚbeda-García,BartoloméMarco-Lajara","International Journal of Hospitality Management","https://doi.org/10.1016/j.ijhm.2015.10.007","https://www.sciencedirect.com/science/article/pii/S027843191500167X"
"A309","General Description of Fission Observables: GEF Model Code","The GEF (“GEneral description of Fission observables”) model code is documented. It describes the observables for spontaneous fission, neutron-induced fission and, more generally, for fission of a compound nucleus from any other entrance channel, with given excitation energy and angular momentum. The GEF model is applicable for a wide range of isotopes from Z = 80 to Z = 112 and beyond, up to excitation energies of about 100 MeV. The results of the GEF model are compared with fission barriers, fission probabilities, fission-fragment mass- and nuclide distributions, isomeric ratios, total kinetic energies, and prompt-neutron and prompt-gamma yields and energy spectra from neutron-induced and spontaneous fission. Derived properties of delayed neutrons and decay heat are also considered.The GEF model is based on a general approach to nuclear fission that explains a great part of the complex appearance of fission observables on the basis of fundamental laws of physics and general properties of microscopic systems and mathematical objects. The topographic theorem is used to estimate the fission-barrier heights from theoretical macroscopic saddle-point and ground-state masses and experimental ground-state masses. Motivated by the theoretically predicted early localisation of nucleonic wave functions in a necked-in shape, the properties of the relevant fragment shells are extracted. These are used to determine the depths and the widths of the fission valleys corresponding to the different fission channels and to describe the fission-fragment distributions and deformations at scission by a statistical approach. A modified composite nuclear-level-density formula is proposed. It respects some features in the superfluid regime that are in accordance with new experimental findings and with theoretical expectations. These are a constant-temperature behaviour that is consistent with a considerably increased heat capacity and an increased pairing condensation energy that is consistent with the collective enhancement of the level density. The exchange of excitation energy and nucleons between the nascent fragments on the way from saddle to scission is estimated according to statistical mechanics. As a result, excitation energy and unpaired nucleons are predominantly transferred to the heavy fragment in the superfluid regime. This description reproduces some rather peculiar observed features of the prompt-neutron multiplicities and of the even-odd effect in fission-fragment Z distributions. For completeness, some conventional descriptions are used for calculating pre-equilibrium emission, fission probabilities and statistical emission of neutrons and gamma radiation from the excited fragments. Preference is given to simple models that can also be applied to exotic nuclei compared to more sophisticated models that need precise empirical input of nuclear properties, e.g. spectroscopic information.The approach reveals a high degree of regularity and provides a considerable insight into the physics of the fission process. Fission observables can be calculated with a precision that complies with the needs for applications in nuclear technology without specific adjustments to measured data of individual systems. The GEF executable runs out of the box with no need for entering any empirical data. This unique feature is of valuable importance, because the number of systems and energies of potential significance for fundamental and applied science will never be possible to be measured. The relevance of the approach for examining the consistency of experimental results and for evaluating nuclear data is demonstrated.","","K.-H.Schmidta,B.Juradoa,C.Amourouxb,C.Schmittc","Nuclear Data Sheets","https://doi.org/10.1016/j.nds.2015.12.009","https://www.sciencedirect.com/science/article/pii/S0090375215000745"
"A310","Chapter 3: Molecular-Level Modeling and Simulation in Process Safety","Molecular modeling is the science (or art) of representing molecular structures numerically and simulating their behavior with the equations of quantum and classical physics. Investigating chemical and material problems at an atomistic scale through capturing and understanding molecular interactions requires effective implementation of molecular modeling or computational chemistry techniques. Enabling ourselves to perform modeling at the molecular level empowers us with the ability to dig deeper into the characteristics of hazardous chemicals and processes, which are otherwise difficult and expensive to get through experimental observations. Application of molecular modeling has significantly increased in recent years and among others has been used in design and development of novel materials, drug discovery, protein engineering, microelectronics, and hydrogen storage. In here, we demonstrate how we can benefit from proven molecular modeling techniques for addressing process safety concerns.","Ab initio,Aerosol,Carbon nanotube,Density functional theory (DFT),Dust explosion,First principles,Flammability,Flash point,Graphene,LFL,Molecular dynamics (MD),Nanotoxicity,QNTR,QSAR,QSPR,Quantum mechanics,Reactive hazards,Thermal runaway reaction,UFL,Water reactive chemicals","ArnabChakrabarty,SamMannan,TahirCagin","Multiscale Modeling for Process Safety Applications,Multiscale Modeling for Process Safety Applications","https://doi.org/10.1016/B978-0-12-396975-0.00003-6","https://www.sciencedirect.com/science/article/pii/B9780123969750000036"
"A311","A machine-learning approach to ranking RDF properties","In this paper we address the problem of providing an order of relevance, or ranking, among entities’ properties used in RDF datasets, Linked Data and SPARQL endpoints. We first motivate the importance of ranking RDF properties by providing two killer applications for the problem, namely property tagging and entity visualization. Moved by the desiderata of these applications, we propose to apply Machine Learning to Rank (MLR) techniques to the problem of ranking RDF properties. Our devised solution is based on a deep empirical study of all the dimensions involved: feature selection, MLR algorithm and Model training. The major advantages of our approach are the following: (a) flexibility/personalization, as the properties’ relevance can be user-specified by personalizing the training set in a supervised approach, or set by a novel automatic classification approach based on SWiPE; (b) speed, since it can be applied without computing frequencies over the whole dataset, leveraging existing fast MLR algorithms; (c) effectiveness, as it can be applied even when no ontology data is available by using novel dataset-independent features; (d) precision, which is high both in terms of f-measure and Spearman’s rho. Experimental results show that the proposed MLR framework outperform the two existing approaches found in literature which are related to RDF property ranking.","Semantic web,Machine learning,Fast property ranking,User experience","AndreaDessi,MaurizioAtzori","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2015.04.018","https://www.sciencedirect.com/science/article/pii/S0167739X15001764"
"A312","1: The Past","The first part of the book will discuss the past of altmetrics, its origins, its scientific roots, and its connection with bibliometrics and webometrics. In many aspects the past of altmetrics is also the past of bibliometrics and webometrics, but it needs to be emphasized that the beginning of altmetrics does not mean the end of bibliometrics or webometrics. The three research areas are developing side by side, learning from each other, complementing each other. This part of the book will give an overview of scholarly communication and the research methods involved in “counting, measuring, and weighing” it, namely bibliometrics and more recently, after the advent of the web, webometrics to analyze scholarly communication on the web. The shortcomings and pitfalls of bibliometrics in research evaluation will be discussed and the current standards and practices for most reliable bibliometric analyses will be presented. With that, the technical developments and societal changes that paved the way for altmetrics will be presented. This part will end by focusing on developments in social media, which, as an increasingly important place for scholarly communication, has made altmetrics possible.","scholarly communication,bibliometrics,scientometrics,informetrics,methods,bibliometric laws,citation analysis,co-citation analysis,co-word analysis,social network","KimHolmberg","Altmetrics for Information Professionals,Altmetrics for Information Professionals","https://doi.org/10.1016/B978-0-08-100273-5.00001-6","https://www.sciencedirect.com/science/article/pii/B9780081002735000016"
"A313","The Sectoral Innovation System of the Dutch Vegetable Breeding Industry","In a number of studies, the Dutch vegetable breeding industry has been described as a highly innovative sector, but the root causes for its innovativeness have not yet been analysed systematically. In order to understand the factors that affect innovation and business performance, the Sectoral Innovation System (SIS) framework was used to analyse the linkages and interactions among the different actors in the Dutch vegetable breeding industry. Within SIS, five interacting domains are recognized and analysed: the business domain, the research & education domain, the intermediate organizations, the market demand, and the infrastructure & framework conditions, resulting in an integrated picture of the innovation system. It was found that the business domain, the research & education domain and the intermediate organisations do not only show an outstanding individual performance, but more importantly, they closely collaborate via public-private partnerships (PPP), research consortia, etc. It is shown that especially the cluster characteristics of the Dutch vegetable breeding industry, i.e. the geographical proximity and the high level of intra- and interconnectivity within and between domains, induces an intensive knowledge flow, a key indicator for the innovation level of a sector.","sectoral innovation system,cluster,public-private partnerships,Dutch vegetable breeding industry","ZhenLiuad,Maarten A.Jongsmab,CaichengHuangc,J.J.M. (Hans)Donsa,S.W.F (Onno)Omtaa","NJAS - Wageningen Journal of Life Sciences","https://doi.org/10.1016/j.njas.2015.06.002","https://www.sciencedirect.com/science/article/pii/S1573521415000147"
"A314","Legally binding precautionary and prevention principles: Aspects of epistemic uncertain causation","Legally binding precautionary principles direct societal actions through regulatory laws to prevent future catastrophic or irreversible consequences that can result from human and natural hazards. Those principles connect uncertain cause and effect to public actions and hence must be transparent, scientifically sound and, on the average, demonstrably add to societal wellbeing. Focusing on legally binding forms of precaution and prevention concerning public choices, seen as prospects, we articulate how uncertainty affects causal analyses that must satisfy their legal requirements. The common measure of uncertainty is probability, explicitly used (and framed in various guises) by the three legal systems we study: the People's Republic of China, the European Union, and the United States. Probabilities can represent different forms of uncertainty, their technical differences, but use the same calculus. They occur at the intersection of legal and scientific causation and allow abstracting, from a prospective reality via models and simulations, future catastrophic or irreversible consequences. Probabilistic causal models—e.g., frailty models, power laws, self-organizing criticalities, and scale-free regularities – link environmental and other regulatory choices to reduce exposures likely to cause adverse responses. Thus, this type of causation is the scientific basis of the EU's Precautionary Principle, its Directives and Regulations; US federal regulatory and case law, and Chinese laws regarding the prevention of hazards. We use examples that clarify and guide public policy analysts to better formalize prospective public choices to avoid ambiguities or possibly incorrect results. We find that the scientific basis necessary to the analysis of precautionary and preventive choices is invariant to the jurisdictions that use it. We conclude that precautionary choices characterized by complex causation can be qualitatively assessed through adapting nine classic epidemiological criteria.","Precaution,Causation,Catastrophes,Uncertainty,Dynamics,Law,Risk","Hua-XiaShenga1,Paolo F.Riccib,QinhuaFanga","Environmental Science & Policy","https://doi.org/10.1016/j.envsci.2015.06.016","https://www.sciencedirect.com/science/article/pii/S1462901115300198"
"A315","Dynamic patterns of industry convergence: Evidence from a large amount of unstructured data","Because of the accelerated life cycle in technology and correspondingly rapid technological saturation in markets, firms are not only accelerating the rate of technological innovation but also expanding the scope of their products or services by combining product or service features of other markets, which eventually leads to industry convergence. However, despite the significant impact of industry convergence on the economy, our understanding of the phenomenon is still limited because previous studies explored only a few cases and come largely from the technological perspective. Therefore, it is still questionable whether industry convergence is a general phenomenon that is prevalent across entire industries. In this paper, we analyze the phenomenon in entire U.S. industries, focusing on its trends and patterns. To do so, we conduct a co-occurrence-based analysis of text mining for a large volume of unstructured data – 2 million newspaper articles from 1989 to 2012 – and suggest using an industry convergence (IC) index based on normalized pointwise mutual information (PMI). We find that overall industry convergence is increasing over time. Moreover, the rate of the increase has been greater within industry than between industries at a given industry level. However, when we cluster the dynamic patterns of industry convergence among industry pairs, the patterns are mixed, and, while some industry groups are converging over time, others are stationary. These findings suggest that significant transformation is under way in the economy, but this phenomenon is not yet prevalent across entire industries. In addition, this study provides a method for anticipating the future direction of industry convergence.","Co-occurrence-based analysis,Industry convergence,Industry convergence index,Industry convergence map,Unstructured data","NamilKima,HyeokseongLeeb,WonjoonKimab,HyunjongLeec,Jong HwanSuhd","Research Policy","https://doi.org/10.1016/j.respol.2015.02.001","https://www.sciencedirect.com/science/article/pii/S0048733315000220"
"A316","How synthetic membrane systems contribute to the understanding of lipid-driven endocytosis","Synthetic membrane systems, such as giant unilamellar vesicles and solid supported lipid bilayers, have widened our understanding of biological processes occurring at or through membranes. Artificial systems are particularly suited to study the inherent properties of membranes with regard to their components and characteristics. This review critically reflects the emerging molecular mechanism of lipid-driven endocytosis and the impact of model membrane systems in elucidating the complex interplay of biomolecules within this process. Lipid receptor clustering induced by binding of several toxins, viruses and bacteria to the plasma membrane leads to local membrane bending and formation of tubular membrane invaginations. Here, lipid shape, and protein structure and valency are the essential parameters in membrane deformation. Combining observations of complex cellular processes and their reconstitution on minimal systems seems to be a promising future approach to resolve basic underlying mechanisms. This article is part of a Special Issue entitled: Mechanobiology.","Lipid clustering,Membrane invagination,Lectin,Model membrane system,Shiga toxin,Pathogen","ThomasSchubertab,WinfriedRömerab","Biochimica et Biophysica Acta (BBA) - Molecular Cell Research","https://doi.org/10.1016/j.bbamcr.2015.07.014","https://www.sciencedirect.com/science/article/pii/S0167488915002517"
"A317","Technological advances in the fuel cell vehicle: Patent portfolio management","With the shift from an industry-based society to a knowledge-based one, there has been a gradual increase in the importance of intangible assets such as technologies and information. Patents are a representative intellectual outcome of intangible assets and can be used as an objective measure of the level of technology or innovation of individuals, firms, and countries. In addition, patents can be regarded as a rich source of data for the provision of technological and commercial information. Patent data facilitate research on technological advances and innovation; hence, an analysis of this data can provide important insights into innovation activity and technology management strategies. This paper presents a method for extracting core technologies from core fuel cell vehicle (FCV) patents registered with the United States Patent and Trademark Office by using a data mining technique. Core patents are determined by analyzing patent citations, and the data mining technique identifies those firms with core FCV technologies and reveals the overall research focus of the firms by deriving patent portfolios and and technology recommendations considering the extracted core technologies.","Patent analysis,Patent portfolio,Data mining,Fuel cell vehicle","Sung HoHaa,WeinaLiua,HuneChob,Sang HyunKima","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2015.07.016","https://www.sciencedirect.com/science/article/pii/S0040162515002255"
"A318","Patterns and trends in Building Information Modeling (BIM) research: A Latent Semantic Analysis","Building Information Modeling (BIM) has emerged as one of the key streams in construction and civil engineering research within the last decade. Given this interest in BIM and the rapidly increasing volume of BIM literature, it is important to understand and discern the core themes and trends emerging in BIM research, and its implications for broader research. The previously reported studies to identify the core of BIM research are typically subjective and qualitative, and hence, prone to bias and interpretation of a limited number of reviewed papers. There is a lack of comprehensive, quantified and systematic classification of the BIM literature. This research brings some clarity by synthesizing and labeling a large corpus of BIM research studies published from 2004 through 2014. Latent Semantic Analysis (LSA), a natural language processing technique was applied to the abstracts of 975 academic papers. This objective analysis reveals twelve principal research areas. Various specific research themes associated with each principal area have been identified. These principal research areas and research themes indicate the patterns and trends in BIM research.","BIM,Latent Semantic Analysis,Research trends,Patterns","MehmetYalcinkaya,VishalSingh1","Automation in Construction","https://doi.org/10.1016/j.autcon.2015.07.012","https://www.sciencedirect.com/science/article/pii/S0926580515001557"
"A319","Technology opportunity discovery (TOD) from existing technologies and products: A function-based TOD framework","Research into deriving technology opportunities from existing technologies or products (ETPs) is useful to technology-based firms, which have to expand their technology portfolios with limited resources. Therefore, this study proposes a function-based framework for technology opportunity discovery (TOD) from a firm's ETPs. This framework consists of: (1) a TOD knowledge base that structures information on products, technologies, and their functions, which has been extracted from 223,603 patents in various technical fields, and (2) a TOD logic that derives potential technology opportunities from an ETP using semantic functional similarities between technologies or products. This framework returns technology opportunities in terms of the four types of TOD paths: existing technology (eT) to technologies that can be developed by modifying eT, eT to products that can be produced by using eT, existing product (eP) to products that can be developed by modifying eP, and eP to technologies that can be adopted to improve eP. We implement the proposed framework in a prototype system, and demonstrate TOD cases, using several ETPs. This framework will contribute to creating systematic TOD based on current technological capability over a wide range of technologies, and become a basis for developing future automated technology intelligence systems.","Technology opportunity discovery (TOD),TOD framework,Existing technology,Existing product,Function,Technology intelligence","JanghyeokYoona,HyunseokParkb,WonchulSeoc,Jae-MinLeed,Byoung-youlCohd,JonghwaKima","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2015.04.012","https://www.sciencedirect.com/science/article/pii/S0040162515001055"
"A320","How accounting begins: Object formation and the accretion of infrastructure","Drawing on the case of accounting for the impact of research in UK universities, and building on key contributions to Accounting, Organizations and Society, the paper explores the conditions under which new accounting systems begin and the unfolding dynamics by which vague performance objects becoming operational. Accounting for research impact involves a radical change in the landscape of UK universities. At the centre of this change process is the progressive construction of the Impact Case Study (ICS) as a new unit of performance accountability for UK universities. Inductively, the emergence of the ICS suggests a fourfold developmental schema for accounting origination spanning field and organization level changes: policy object formation, object elaboration, activity orchestration and practice stabilization in infrastructure. Drawing upon existing scholarship, the paper uses the impact accounting setting to explore the dynamics of this developmental schema and its implications for calculation, subjectivization and the structuring of organizational temporalities. The case of impact in UK universities shows that accounting never simply begins but has multiple conditions of possibility which align as drivers for change at both field and organization levels. The case of impact accounting also reveals the significance of managerial infrastructures during accounting origination and this is suggestive of a future research agenda.","Impact,Accounting,Infrastructure,Research,Universities,Evaluation","MichaelPower","Accounting, Organizations and Society","https://doi.org/10.1016/j.aos.2015.10.005","https://www.sciencedirect.com/science/article/pii/S0361368215000938"
"A321","Abstracts","","","","Annals of Allergy, Asthma & Immunology","https://doi.org/10.1016/j.anai.2015.09.021","https://www.sciencedirect.com/science/article/pii/S1081120615006535"
"A322","Visualization analysis of ecological assets/values research by knowledge mapping","Using knowledge mapping tools (CiteSpace), we conducted the visualization analysis on both of international and domestic literatures in relation to ecological assets/values from the Web of Science (WoS) databases and China National Knowledge Infrastructure (CNKI) databases. By combination of the statistical data and visualization mapping, we studied on the research relationship networks and status for the co-authors' institutions, co-authors, co-citation literatures and co-occurring keywords of ecological assets/values based on the sample data from literatures. In the aspects of research on ecological values, our results showed that: (i) main countries of researches on ecological values were the United States, Australia, Canada and China in order, especially the US had the most plenty of literatures in relation to ecological values, and at the same time, literatures from China in this field are in the upper level; (ii) the hotspots of researches on ecological values from the global literatures covered various fields including biodiversity, species richness, ecosystem services, landscape, climate change and dynamic simulation; (iii) as a result of the multidisciplinary integration, the hotspots of researches on ecological values emerge endlessly, so that many high yielding authors and relevant international institutions constantly expanded the research scopes and fields, which promoted the combination of theories and made the significant contribution to themselves; (iv) the mass domestic researches on ecological values began in 1992. The number of posting paper increased obviously and the scopes in relation to ecological value expanded gradually, particularly involved with ecology, economy, even legal and ideology, which illustrated that concepts of “ecological values” had not been only confined to the researches on the traditional science, but also been widely used in many fields of humanity and social science. In the aspect of research on ecological assets, our results showed that: (i) domestic researches on ecological assets had many points in common with ecological values research. In fact, driven from ecological values, researches on ecological assets became gradually characteristic, such as assessment of forest ecological asset, ecological industry and fair value measurement of ecological assets, all of which contained lots of considerable consequences; (ii) the Chinese Academy of Sciences was in the dominant position of domestic research on ecological assets. Other colleges and universities like Beijing Normal University and Nanjing Forestry University were also effective and productive in this field. Their achievements were already improving Chinese academic level; (iii) domestic research teams also changed from different discipline backgrounds to enrich the research scopes of ecological assets. Based on analysis of typical literatures from our results, in the similarity and difference of the concept of “ecological asset” between foreign and domestic literatures, we summarized key points that we should pay attention to: (i) ecological assets included natural resources and ecosystem services; (ii) ecological assets consisted of tangible and intangible parts; (iii) ecological assets were of profitability and public welfare at the same time. Finally, we elucidated that future trend of research on ecological assets would pay more attention to the internal mechanism of changes of ecological assets, determination of the bearing capacity of the ecological environment by such changes, and discovery of accumulation of ecological assets for a stable and sustainable development of the ecosystem, and for harmony between humans and environment.","CiteSpace,Ecological assets,Ecological values,Knowledge mapping,Visualization","ZhuoLina,ChengzhenWuab,WeiHonga","Acta Ecologica Sinica","https://doi.org/10.1016/j.chnaes.2015.07.005","https://www.sciencedirect.com/science/article/pii/S187220321500044X"
"A323","A review of theory and practice in scientometrics","Scientometrics is the study of the quantitative aspects of the process of science as a communication system. It is centrally, but not only, concerned with the analysis of citations in the academic literature. In recent years it has come to play a major role in the measurement and evaluation of research performance. In this review we consider: the historical development of scientometrics, sources of citation data, citation metrics and the “laws” of scientometrics, normalisation, journal impact factors and other journal metrics, visualising and mapping science, evaluation and policy, and future developments.","Altmetrics,Citations,H-index,Impact factor,Normalisation","JohnMingersa,LoetLeydesdorffb","European Journal of Operational Research","https://doi.org/10.1016/j.ejor.2015.04.002","https://www.sciencedirect.com/science/article/pii/S037722171500274X"
"A324","Molecular properties of steroids involved in their effects on the biophysical state of membranes","The activity of steroids on membranes was studied in relation to their ordering, rigidifying, condensing and/or raft promoting ability. The structures of 82 steroids were modeled by a semi-empirical procedure (AM1) and 245 molecular descriptors were next computed on the optimized energy conformations. Principal component analysis, mean contrasting and logistic regression were used to correlate the molecular properties with 212 cases of documented activities. It was possible to group steroids based on their properties and activities, indicating that steroids having similar molecular properties have similar activities on membranes. Steroids having high values of area, partition coefficient, volume, number of rotatable bonds, molar refractivity, polarizability or mass displayed ordering, rigidifying, condensing and/or raft promoting activity on membranes higher than those steroids having low values in such molecular properties. After a variable selection procedure circumventing correlation problems among descriptors, area and log P were found as the most relevant properties in governing and predicting the activity of steroids on membranes. A logistic regression model as a function of the area and log P of the steroids is proposed, which is able to predict correctly 92.5% of the cases. A rationale of the findings is discussed.","PCAprincipal component analysis,PCprincipal component,LRlogistic regression,ULRunivariate logistic regression,MLRmultivariate logistic regression,ORodds ratio,CIconfidence interval,Keywords,Steroid molecular property,Membrane biophysical property,Multivariate analysis","Jorge J.Wenz","Biochimica et Biophysica Acta (BBA) - Biomembranes","https://doi.org/10.1016/j.bbamem.2015.07.017","https://www.sciencedirect.com/science/article/pii/S0005273615002394"
"A325","A synergistic strategy for combining thesaurus-based and corpus-based approaches in building ontology for multilingual search engines","In this article we illustrate a methodology for building cross-language search engine. A synergistic approach between thesaurus-based approach and corpus-based approach is proposed. First, a bilingual ontology thesaurus is designed with respect to two languages: English and Spanish, where a simple bilingual listing of terms, phrases, concepts, and subconcepts is built. Second, term vector translation is used – a statistical multilingual text retrieval techniques that maps statistical information about term use between languages (Ontology co-learning). These techniques map sets of t f id f term weights from one language to another. We also applied a query translation method to retrieve multilingual documents with an expansion technique for phrasal translation. Finally, we present our findings.","Multi-language search engines,Cross-language search engines,Ontologies,Social Networks,Ontology co-learning","LeylaZhuhadar1","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2015.03.021","https://www.sciencedirect.com/science/article/pii/S0747563215002071"
"A326","In the pursuit of a semantic similarity metric based on UMLS annotations for articles in PubMed Central Open Access","MotivationAlthough full-text articles are provided by the publishers in electronic formats, it remains a challenge to find related work beyond the title and abstract context. Identifying related articles based on their abstract is indeed a good starting point; this process is straightforward and does not consume as many resources as full-text based similarity would require. However, further analyses may require in-depth understanding of the full content. Two articles with highly related abstracts can be substantially different regarding the full content. How similarity differs when considering title-and-abstract versus full-text and which semantic similarity metric provides better results when dealing with full-text articles are the main issues addressed in this manuscript.,MethodsWe have benchmarked three similarity metrics – BM25, PMRA, and Cosine, in order to determine which one performs best when using concept-based annotations on full-text documents. We also evaluated variations in similarity values based on title-and-abstract against those relying on full-text. Our test dataset comprises the Genomics track article collection from the 2005 Text Retrieval Conference. Initially, we used an entity recognition software to semantically annotate titles and abstracts as well as full-text with concepts defined in the Unified Medical Language System (UMLS®). For each article, we created a document profile, i.e., a set of identified concepts, term frequency, and inverse document frequency; we then applied various similarity metrics to those document profiles. We considered correlation, precision, recall, and F1 in order to determine which similarity metric performs best with concept-based annotations. For those full-text articles available in PubMed Central Open Access (PMC-OA), we also performed dispersion analyses in order to understand how similarity varies when considering full-text articles.,ResultsWe have found that the PubMed Related Articles similarity metric is the most suitable for full-text articles annotated with UMLS concepts. For similarity values above 0.8, all metrics exhibited an F1 around 0.2 and a recall around 0.1; BM25 showed the highest precision close to 1; in all cases the concept-based metrics performed better than the word-stem-based one. Our experiments show that similarity values vary when considering only title-and-abstract versus full-text similarity. Therefore, analyses based on full-text become useful when a given research requires going beyond title and abstract, particularly regarding connectivity across articles.,AvailabilityVisualization available at ljgarcia.github.io/semsim.benchmark/, data available at http://dx.doi.org/10.5281/zenodo.13323.","Semantic similarity,Scientific publications,Similarity metrics,Semantic annotations,Related articles","Leyla JaelGarcia Castroa,RafaelBerlangaa,AlexanderGarciabc","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2015.07.015","https://www.sciencedirect.com/science/article/pii/S1532046415001550"
"A327","Poster Presentations","","","","International Journal of Gynecology & Obstetrics","https://doi.org/10.1016/S0020-7292(15)30004-7","https://www.sciencedirect.com/science/article/pii/S0020729215300047"
"A328","Development of a patent roadmap through the Generative Topographic Mapping and Bass diffusion model","This paper aims to present a novel concept roadmap—the patent roadmap—and suggest an advanced patent roadmapping process, based on the Generative Topographic Mapping (GTM) and Bass diffusion model. The process for patent roadmapping is composed of two modules: Developing the GTM-based patent map and determining the appearance time of the emerging patent through Bass model. The result of this research is meaningful knowledge from analyzing a vast store of patent data with quantitative methods and automated tools. It can serve as an effective patent planning tool, and proposes a strategic Research and Business Development (R&BD) for both firms and governments.","Patent roadmap,Generative Topographic Mapping (GTM),Bass diffusion model,Patent planning and forecasting,Visualization","YujinJeonga,KeeeunLeea,ByungunYoona,RobPhaalb","Journal of Engineering and Technology Management","https://doi.org/10.1016/j.jengtecman.2015.08.006","https://www.sciencedirect.com/science/article/pii/S0923474815000351"
"A329","The value of indirect ties in citation networks: SNA analysis with OWA operator weights","This paper seeks to advance the theory and practice of the dynamics of complex networks in relation to direct and indirect citations. It applies social network analysis (SNA) and the ordered weighted averaging operator (OWA) to study a patent citations network. So far the SNA studies investigating long chains of patents citations have rarely been undertaken and the importance of a node in a network has been associated mostly with its number of direct ties. In this research OWA is used to analyse complex networks, assess the role of indirect ties, and provide guidance to reduce complexity for decision makers and analysts. An empirical example of a set of European patents published in 2000 in the renewable energy industry is provided to show the usefulness of the proposed approach for the preference ranking of patent citations.","Social network analysis (SNA),Patent citations network,Aggregation operator,Ordered weighted averaging (OWA)","MariannaMarraa,AliEmrouznejadb,WilliamHoc,John S.Edwardsb","Information Sciences","https://doi.org/10.1016/j.ins.2015.02.017","https://www.sciencedirect.com/science/article/pii/S0020025515001103"
"A330","Thirty years of artificial intelligence in medicine (AIME) conferences: A review of research themes","BackgroundOver the past 30 years, the international conference on Artificial Intelligence in MEdicine (AIME) has been organized at different venues across Europe every 2 years, establishing a forum for scientific exchange and creating an active research community. The Artificial Intelligence in Medicine journal has published theme issues with extended versions of selected AIME papers since 1998.,ObjectivesTo review the history of AIME conferences, investigate its impact on the wider research field, and identify challenges for its future.,MethodsWe analyzed a total of 122 session titles to create a taxonomy of research themes and topics. We classified all 734 AIME conference papers published between 1985 and 2013 with this taxonomy. We also analyzed the citations to these conference papers and to 55 special issue papers.,ResultsWe identified 30 research topics across 12 themes. AIME was dominated by knowledge engineering research in its first decade, while machine learning and data mining prevailed thereafter. Together these two themes have contributed about 51% of all papers. There have been eight AIME papers that were cited at least 10 times per year since their publication.,ConclusionsThere has been a major shift from knowledge-based to data-driven methods while the interest for other research themes such as uncertainty management, image and signal processing, and natural language processing has been stable since the early 1990s. AIME papers relating to guidelines and protocols are among the most highly cited.","Artificial Intelligence in Medicine,Literature review,History of science","NielsPeeka,CarloCombib,RoqueMarinc,RiccardoBellazzid","Artificial Intelligence in Medicine","https://doi.org/10.1016/j.artmed.2015.07.003","https://www.sciencedirect.com/science/article/pii/S0933365715000871"
"A331","An approach to improve kernel-based Protein–Protein Interaction extraction by learning from large-scale network data","Protein–Protein Interaction extraction (PPIe) from biomedical literatures is an important task in biomedical text mining and has achieved desirable results on the annotated datasets. However, the traditional machine learning methods on PPIe suffer badly from vocabulary gap and data sparseness, which weakens classification performance. In this work, an approach capturing external information from the web-based data is introduced to address these problems and boost the existing methods. The approach involves three kinds of word representation techniques: distributed representation, vector clustering and Brown clusters. Experimental results show that our method outperforms the state-of-the-art methods on five publicly available corpora. Our code and data are available at: http://chaoslog.com/improving-kernel-based-protein-protein-interaction-extraction-by-unsupervised-word-representation-codes-and-data.html.","Protein–Protein Interaction,Word representation,Distributed representation,Brown clusters","LishuangLi,RuiGuo,ZhenchaoJiang,DegenHuang","Methods","https://doi.org/10.1016/j.ymeth.2015.03.026","https://www.sciencedirect.com/science/article/pii/S1046202315001437"
"A332","Improving similarity measures of relatedness proximity: Toward augmented concept maps","Decision makers relying on web search engines in concept mapping for decision support are confronted with limitations inherent in similarity measures of relatedness proximity between concept pairs. To cope with this challenge, this paper presents research model for augmenting concept maps on the basis of a novel method of co-word analysis that utilizes webometrics web counts for improving similarity measures. Technology assessment serves as a use case to demonstrate and validate our approach for a spectrum of information technologies. Results show that the yielded technology assessments are highly correlated with subjective expert assessments (n = 136; r > 0.879), suggesting that it is safe to generalize the research model to other applications. The contribution of this work is emphasized by the current growing attention to big data.","Augmented concept map,Relatedness proximity,Co-word analysis,Webometrics,Technology assessment","ElanSassona,GiladRavidb,NavaPliskinb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2015.06.003","https://www.sciencedirect.com/science/article/pii/S1751157715000541"
"A333","Identifying entities from scientific publications: A comparison of vocabulary- and model-based methods","The objective of this study is to evaluate the performance of five entity extraction methods for the task of identifying entities from scientific publications, including two vocabulary-based methods (a keyword-based and a Wikipedia-based) and three model-based methods (conditional random fields (CRF), CRF with keyword-based dictionary, and CRF with Wikipedia-based dictionary). These methods are applied to an annotated test set of publications in computer science. Precision, recall, accuracy, area under the ROC curve, and area under the precision-recall curve are employed as the evaluative indicators. Results show that the model-based methods outperform the vocabulary-based ones, among which CRF with keyword-based dictionary has the best performance. Between the two vocabulary-based methods, the keyword-based one has a higher recall and the Wikipedia-based one has a higher precision. The findings of this study help inform the understanding of informetric research at a more granular level.","Entity extraction,Vocabulary,Dictionary,Conditional random fields,Content-aware","ErjiaYan,YongjunZhu","Journal of Informetrics","https://doi.org/10.1016/j.joi.2015.04.003","https://www.sciencedirect.com/science/article/pii/S1751157715000474"
"A334","Insights from hashtag #supplychain and Twitter Analytics: Considering Twitter and Twitter data for supply chain practice and research","Recently, businesses and research communities have paid a lot of attention to social media and big data. However, the field of supply chain management (SCM) has been relatively slow in studying social media and big data for research and practice. In these contexts, this research contributes to the SCM community by proposing a novel, analytical framework (Twitter Analytics) for analyzing supply chain tweets, highlighting the current use of Twitter in supply chain contexts, and further developing insights into the potential role of Twitter for supply chain practice and research. The proposed framework combines three methodologies – descriptive analytics (DA), content analytics (CA) integrating text mining and sentiment analysis, and network analytics (NA) relying on network visualization and metrics – for extracting intelligence from 22,399 #supplychain tweets. Some of the findings are: supply chain tweets are used by different groups of supply chain professionals and organizations (e.g., news services, IT companies, logistic providers, manufacturers) for information sharing, hiring professionals, and communicating with stakeholders, among others; diverse topics are being discussed, ranging from logistics and corporate social responsibility, to risk, manufacturing, SCM IT and even human rights; some tweets carry strong sentiments about companies<U+05F3> delivery services, sales performance, and environmental standards, and risk and disruption in supply chains. Based on these findings, this research presents insights into the use and potential role of Twitter for supply chain practices (e.g., professional networking, stakeholder engagement, demand shaping, new product/service development, supply chain risk management) and the implications for research. Finally, the limitations of the current study and suggestions for future research are presented.","Supply chain management,Twitter,Data analytics,Network analytics,Content analytics,Big data,Social media analytics,Application Programming Interface (API)","Bongsug (Kevin)Chae","International Journal of Production Economics","https://doi.org/10.1016/j.ijpe.2014.12.037","https://www.sciencedirect.com/science/article/pii/S0925527314004319"
"A335","A systematic review of shared visualisation to achieve common ground","This paper reports a systematic review of shared visualisation based on fifteen papers from 2000 to 2013. The findings identified five shared visualisation strategies that represent the ways implemented to process data sharing and knowledge to arrive at the desired level of understanding. Four visualisation techniques were also identified to show how shared cognition is made possible in designing tools for mediating data or knowledge among the users involved. These findings provide research opportunities in integrating rich interactive data visualisation for mobile-based technologies as an effective mean in supporting collaborative work. Finally, social, task and cognitive elements which can be significantly supported by shared visualisation and a guideline for future researchers seeking to design shared visualisation-based systems are presented.","(CoVis)collaborative visualisation,(SMM)shared mental model,(SSC)socially shared cognition,(SSA)shared situation awareness,(HCI)human–computer interaction,Keywords,Shared visualisation,Collaborative design,Teamwork,Human–computer interaction","Nor’ain MohdYusoffa,Siti SalwahSalimb1","Journal of Visual Languages & Computing","https://doi.org/10.1016/j.jvlc.2014.12.003","https://www.sciencedirect.com/science/article/pii/S1045926X1400158X"
"A336","WFC'S 13th Biennial Congress Proceedings Athens, Greece, 10-13, 2013: Abstracts of the Scientific Sessions","The World Federation of Chiropractic (WFC) held its 13th Biennial Congress in Athens, Greece, on May 13 through 16, 2015. The WFC call for abstracts resulted in 237 submissions from 19 countries (Australia, Bahrain, Brazil, Canada, Denmark, Greece, Ireland, Italy, Republic of Korea, Mexico, Netherlands, New Zealand, Norway, South Africa, Spain, Sweden, Switzerland, United Kingdom, and the United States). From these abstracts, a total of 40 platforms and 117 posters were presented at the Congress.","Congresses [Publication Type],Chiropractic","","Journal of Chiropractic Medicine","https://doi.org/10.1016/j.jcm.2015.06.002","https://www.sciencedirect.com/science/article/pii/S1556370715000358"
"A337","A survey on trust and reputation models for Web services: Single, composite, and communities","Web service selection constitutes nowadays a major challenge that is still attracting the research community to work on and investigate. The problem arises since decision makers (1) cannot blindly trust the service or its provider, and (2) ignore the environment within which the service is operating. The fact that no security mechanism is applicable in such a completely open environment, where identities can be easily generated and discarded makes social approaches such as trust and reputation models appealing to apply in the world of Web services. This survey classifies and compares the main findings that contributed in solving problems related to trust and reputation in the context of Web services. First, a high-level classification scheme partitions Web services into three main architectures: single, composite, and communities. Thereafter, a low-level classification within each architecture categorizes the trust and reputation models according to the technique used to build the trust value. Based on this classification, a profound analysis describing the advantages and shortcomings of each class of models is presented; leading to uncover possible topics that need further study and investigation. In particular, we discuss the challenging problem of having active malicious Web services in the composite and community-based architectures. Thus, the paper can be used by the future researchers as a roadmap to explore new trust and reputation models for Web services taking into account the shortcomings of the existing models.","Web service,Architecture,Trust,Reputation,Security,Decision making","Omar AbdelWahaba,JamalBentahara,HadiOtrokab,AzzamMouradc","Decision Support Systems","https://doi.org/10.1016/j.dss.2015.04.009","https://www.sciencedirect.com/science/article/pii/S0167923615000809"
"A338","Domain Analysis of the Research In Professional Competences, Technology and Engineering Cluster","ObjectiveThe paper aims to apply scientific domain analysis and network analysis to research in professional competences and its relationship to technology and engineering.,MethodologyNetwork analysis is a tool of scientific domain analysis. Nowadays it is supported by technology and computer sciences, which allow the generation of network maps in order to process the information.,ResultsThe models of competences proposed for professionals in information technologies have been analyzed together with the importance of developing competency management systems and the support of computer technologies to this field.,ConclusionsDomain analysis facilitates the structuring and organization of information, which is very useful to the analysis of competences and its relation with technology and engineering, being a new subject of study.","Domain analysis,Professional competence,Engineering,Technology","DanteGuerreroa,La RosaGersona,LopezPatriciaa,Bayona AnaLuciaa","Procedia - Social and Behavioral Sciences","https://doi.org/10.1016/j.sbspro.2015.04.752","https://www.sciencedirect.com/science/article/pii/S187704281503027X"
"A339","The patent portfolio value analysis: A new framework to leverage patent information for strategic technology planning","Patents and patent portfolios are valuable assets. Companies need a conceptual structure to assess the value of their patent portfolio. This paper develops a practical and reproducible framework that can support scholars and practitioners to leverage the value of patents and to extract all possible strategic information from patent portfolio. The patent assessment process aims at comparing and contrasting the management of patents to the company's technologic and innovative strategy. The framework employs determinants of patent value that are elicited from patent databases, such as claims, citations, and market coverage, and that are expressed in terms of judgments achieved by interviewing involved managers, such as strategic relevance and economic relevance. The paper examines the main methodological issues in assessing patent portfolio value then, it describes the characteristics of the framework; subsequently, it illustrates the implementation of the proposed framework into two companies which operate in the aerospace and defense sector. The two implementations show that the framework can be used for strategic planning and strategic technology management.","Patent portfolio,Patent analysis,Patent value,Patent value assessment,Strategic technology management,Strategic foresight","MicheleGrimaldia,LivioCricellia,MartinaDi Giovannib,FrancescoRogob","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2014.10.013","https://www.sciencedirect.com/science/article/pii/S0040162514002996"
"A340","Proceedings of the 17th Annual Congress of the European Society for Sexual Medicine, Copenhagen, Denmark, February 5–7, 2015","","","","The Journal of Sexual Medicine","https://doi.org/10.1111/jsm.12872_2","https://www.sciencedirect.com/science/article/pii/S174360951531064X"
"A341","Knowledge combination modeling: The measurement of knowledge similarity between different technological domains","This paper proposes the DB-Combination model that considers three different knowledge combinations in depth (D) and breadth (B) based on similarities of two technological knowledge domains. We also investigate three methodologies A1, A2 and A3 to highlight the three knowledge combinations. To identify technological knowledge domains, citation analysis on patent information was used for A1 and A2 and pre-existing patent classification analysis was used for A3. And to measure the similarity between identified technological knowledge domains, text similarity measurements, existing intra-industrial citation tracing and IPC share similarity comparison were used for A1, A2 and A3 respectively. The usability of the model and methodologies were demonstrated through a case study on technological knowledge of the automobile industry and the aircraft industry. While these methodologies still need to be improved, it was demonstrated that the three measurements can highlight candidates of the three knowledge combination proposed in DB-Combination model. This research contributes to accelerate breadth knowledge recombination in a complex technology industry.","Patent analysis,Citation analysis,Bibliometrics,Breadth search,Knowledge recombination","HirokoNakamuraa1,ShinjiSuzukia1,IchiroSakatab,YuyaKajikawac","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2014.09.009","https://www.sciencedirect.com/science/article/pii/S0040162514002790"
"A342","An integrated framework for securing semi-structured health records","In the last years, the adoption of Electronic Health Records (EHRs) have been widely promoted, with the final aim of improving care quality and patient safety. Yet, sharing patient data in a large distributed and heterogeneous context, such as the healthcare domain, has inherently introduced security and privacy risks, due to the great sensitivity and confidentiality of the patient data and the need of accessing such data by a large number of health care workers with various roles for the patient care. Even though various techniques have been developed to effectively implement fine-grained access control, which allows flexibility in specifying differential access rights of individual users, some unsolved problems can be pointed out with respect to the specification of complex policies over EHRs: (i) the difficulty of forcing narrative text to assume a semi-structured coded form into EHRs in order to build access control policies also working at a section-level; (ii) an overly high-level of theoretical ability required to practically use access control models and policy languages as a whole, due to a scarce integration among them; and (iii) the lack of tools for easily editing and upgrading access control policies over EHRs. In order to face all these open issues, this paper proposes a hybrid framework aimed at enabling and supporting the definition of fine-grained access control policies working on semi-structured EHRs. The key issues of the framework are: (i) a semantic-based method that hybridizes linguistic and statistical techniques in order to give a semi-structured form to a narrative text to be inserted into EHRs, by identifying its specific sections; (ii) a formal role-based authorization model, encoded as a couple of ontologies, to regulate the access to these semi-structured EHRs with respect to their sections; and (iii) a procedural policy language and a set of patterns to simply encode and update access control restrictions in the form of “if–then rules” built on the top of the ontological model formalized. A prototype implementation of this framework is realized in the form of a system offering simple and intuitive interfaces to the security administrators. Finally, an experimental evaluation over real documents contained into EHRs, i.e. discharge summaries, is described, showing the feasibility of the proposed framework and suggesting that its application could simply and proficiently secure the access to healthcare information contained into semi-structured EHRs and, thus, face security and privacy risks in real healthcare scenarios.","Electronic health record,Role-based access control,Policy language,Information structuring,Ontology","FloraAmatoa,GiuseppeDe Pietrob,MassimoEspositob,NicolaMazzoccaa","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2015.02.004","https://www.sciencedirect.com/science/article/pii/S0950705115000362"
"A343","Topic based classification and pattern identification in patents","Patent classification systems and citation networks are used extensively in innovation studies. However, non-unique mapping of classification codes onto specific products/markets and the difficulties in accurately capturing knowledge flows based just on citation linkages present limitations to these conventional patent analysis approaches. We present a natural language processing based hierarchical technique that enables the automatic identification and classification of patent datasets into technology areas and sub-areas. The key novelty of our technique is to use topic modeling to map patents to probability distributions over real world categories/topics. Accuracy and usefulness of our technique are tested on a dataset of 10,201 patents in solar photovoltaics filed in the United States Patent and Trademark Office (USPTO) between 2002 and 2013. We show that linguistic features from topic models can be used to effectively identify the main technology area that a patent's invention applies to. Our computational experiments support the view that the topic distribution of a patent offers a reduced-form representation of the knowledge content in a patent. Accordingly, we suggest that this hidden thematic structure in patents can be useful in studies of the policy–innovation–geography nexus. To that end, we also demonstrate an application of our technique for identifying patterns in technological convergence.","Patents,Topic modeling,Document classification,Technology convergence,Solar photovoltaic,Knowledge flows","SubhashiniVenugopalana,VarunRaibc","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2014.10.006","https://www.sciencedirect.com/science/article/pii/S0040162514002923"
"A344","Mapping teacher education domain: A document co-citation analysis from 1992 to 2012","The aim of the present study is to identify the structure of the research base for teacher education as a scientific discipline and changes in the structure of this domain between 1992 and 2012. The study was carried out using document co-citation analysis, a bibliometric method. Document co-citation analysis shows that the domain of teacher education is characterized by a number of specialties; however, none of them are sufficiently developed to be regarded as the principal trend in the domain.","Teacher education,Bibliometrics,Document co-citation analysis,PFNET analysis","HüseyinÖzçinar","Teaching and Teacher Education","https://doi.org/10.1016/j.tate.2014.12.006","https://www.sciencedirect.com/science/article/pii/S0742051X14001632"
"A345","A survey of general-purpose experiment management tools for distributed systems","In the field of large-scale distributed systems, experimentation is particularly difficult. The studied systems are complex, often nondeterministic and unreliable, software is plagued with bugs, whereas the experiment workflows are unclear and hard to reproduce. These obstacles led many independent researchers to design tools to control their experiments, boost productivity and improve quality of scientific results.Despite much research in the domain of distributed systems experiment management, the current fragmentation of efforts asks for a general analysis. We therefore propose to build a framework to uncover missing functionality of these tools, enable meaningful comparisons between them and find recommendations for future improvements and research.The contribution in this paper is twofold. First, we provide an extensive list of features offered by general-purpose experiment management tools dedicated to distributed systems research on real platforms. We then use it to assess existing solutions and compare them, outlining possible future paths for improvements.","Experimentation,Control of experiments,Large-scale distributed systems,Testbeds,Reproducibility","TomaszBuchertbcd,CristianRuizace,LucasNussbaumbcd,OlivierRichardace","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2014.10.007","https://www.sciencedirect.com/science/article/pii/S0167739X14002003"
"A346","Skin toxicity of surfactants: Structure/toxicity relationships","The skin toxicity of four ionic surfactants and fourteen non-ionic surfactants was investigated so as to disclose structure/toxicity relationships. The skin toxicity was assessed by means of four in vitro assays, MTT and LDH test of cell viability, and detection of the inflammation markers IL-1a and IL-8. Several descriptors of the physicochemical properties of the surfactants were measured in order to find out those molecular descriptors that correlate with the toxicity measured on skin. Principal component analysis and analysis of the matrix of Pearson's correlation coefficients were used for the search of the molecular descriptors having the highest relevance. There was a definite difference between ionic and non-ionic surfactants. Ionic surfactants are the most toxic if they are soluble in water. Crystalline ionic surfactants of low solubility show low toxicity. The sign of the charge, anionic or cationic, does not matter. The value of the CMC that has been put forward as a highly relevant parameter does not account for the full skin toxicities observed; the CMC of non-ionic surfactants is not a parameter of relevance. For non-ionic surfactants, the nature of the chemical bond linking the polar head group and the alkyl chain has a significant impact on skin toxicity; PEG ethers appear more toxic than PEG esters. The results revealed the mildness of polyoxyethylene sorbitan esters whatever be their alkyl chain length. On the other hand, for sucrose ester surfactants, C12 alkyl length resulted in the greatest skin toxicity. Since the molecular parameters of ionic, non-ionic, water-soluble and crystalline surfactants are different, a universal parameter was introduced, the order parameter describing the orientation ordering of surfactant molecules at interfaces. The highly ordered organization of crystalline surfactants associated with their low solubility in water makes them very low-irritant surfactants.","CMCcritical micellar concentration,CTACcetyl trimethyl ammonium chloride,DCdistearyldimonium chloride,EOethylene oxide,HLBhydrophile lipophile balance,ILinterleukin,LDHlactate dehydrogenase,MTT3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide tetrazolium dye,O/Woil in water,PCAprincipal component analysis,PEGpoly(ethylene glycol),PEOpoly(ethylene oxide),RHEreconstructed human epidermis,SCstratum corneum,SLSsodium lauryl sulfate,SSLsodium stearoyl lactylate,TEWLtransepidermal water loss,Keywords,Surfactants,Skin toxicity,CMC,Order parameter,Principal component analysis","EmmanuelleLémeryabcd,StéphanieBriançonabc,YvesChevalierab,ClaireBordesae,ThierryOddosd,AnnieGohierd,Marie-AlexandrineBolzingerabc","Colloids and Surfaces A: Physicochemical and Engineering Aspects","https://doi.org/10.1016/j.colsurfa.2015.01.019","https://www.sciencedirect.com/science/article/pii/S0927775715000382"
"A347","Application of text mining in the biomedical domain","In recent years the amount of experimental data that is produced in biomedical research and the number of papers that are being published in this field have grown rapidly. In order to keep up to date with developments in their field of interest and to interpret the outcome of experiments in light of all available literature, researchers turn more and more to the use of automated literature mining. As a consequence, text mining tools have evolved considerably in number and quality and nowadays can be used to address a variety of research questions ranging from de novo drug target discovery to enhanced biological interpretation of the results from high throughput experiments. In this paper we introduce the most important techniques that are used for a text mining and give an overview of the text mining tools that are currently being used and the type of problems they are typically applied for.","Text mining,Ontology,Natural language processing,Drug discovery,Biomedical research,Automatic information extraction","Wilco W.M.Fleurenab,WynandAlkemaac","Methods","https://doi.org/10.1016/j.ymeth.2015.01.015","https://www.sciencedirect.com/science/article/pii/S1046202315000274"
"A348","APhA2015 abstracts of contributed papers","","","","Journal of the American Pharmacists Association","https://doi.org/10.1331/JAPhA.2015.15515","https://www.sciencedirect.com/science/article/pii/S1544319115300480"
"A349","How to learn about gene function: text-mining or ontologies?","As the amount of genome information increases rapidly, there is a correspondingly greater need for methods that provide accurate and automated annotation of gene function. For example, many high-throughput technologies – e.g., next-generation sequencing – are being used today to generate lists of genes associated with specific conditions. However, their functional interpretation remains a challenge and many tools exist trying to characterize the function of gene-lists. Such systems rely typically in enrichment analysis and aim to give a quick insight into the underlying biology by presenting it in a form of a summary-report. While the load of annotation may be alleviated by such computational approaches, the main challenge in modern annotation remains to develop a systems form of analysis in which a pipeline can effectively analyze gene-lists quickly and identify aggregated annotations through computerized resources. In this article we survey some of the many such tools and methods that have been developed to automatically interpret the biological functions underlying gene-lists. We overview current functional annotation aspects from the perspective of their epistemology (i.e., the underlying theories used to organize information about gene function into a body of verified and documented knowledge) and find that most of the currently used functional annotation methods fall broadly into one of two categories: they are based either on ‘known’ formally-structured ontology annotations created by ‘experts’ (e.g., the GO terms used to describe the function of Entrez Gene entries), or – perhaps more adventurously – on annotations inferred from literature (e.g., many text-mining methods use computer-aided reasoning to acquire knowledge represented in natural languages). Overall however, deriving detailed and accurate insight from such gene lists remains a challenging task, and improved methods are called for. In particular, future methods need to (1) provide more holistic insight into the underlying molecular systems; (2) provide better follow-up experimental testing and treatment options, and (3) better manage gene lists derived from organisms that are not well-studied. We discuss some promising approaches that may help achieve these advances, especially the use of extended dictionaries of biomedical concepts and molecular mechanisms, as well as greater use of annotation benchmarks.","Functional annotation,Text mining,Keyword enhancement,GO term enrichment,Systems biology,Benchmarks","Theodoros G.Soldatosa,NelsonPerdigãob,Nigel P.Brownc,Kenneth S.Sabird,Seán I.O’Donoghuede","Methods","https://doi.org/10.1016/j.ymeth.2014.07.004","https://www.sciencedirect.com/science/article/pii/S1046202314002412"
"A350","Towards content-oriented patent document processing: Intelligent patent analysis and summarization","In this article, we present an operational prototype of a workbench for intelligent patent document analysis and summarization that has been developed in the context of the R&D project TOPAS, partially funded by the European Commission. The workbench uses the GATE environment as infrastructure for document representation and algorithm integration. It contains, apart from several preprocessing tools, five modules for the individual aspects of patent analysis (entity recognition, lexical chain identification, invention composition derivation, segmentation, and claim – description alignment) and a module for patent summarization. The workbench, which has been tested in different application settings, can be used as a standalone engine or as component within a more global patent processing line. Most of its modules can be also used separately.","Entity recognition,Segmentation,Lexical chain identification,Claim description alignment,Summarization,TOPAS,Patent analysis,Document processing","SörenBrügmanna,NadjetBouayad-Aghab,AliciaBurgab,SergueiCarrascosac,AlbertoCiaramellad,MarcoCiaramellad,JoanCodina-Filbab,EnricEscorsac,AlexJudeae,SimonMilleb,AndreasMüllere,HoracioSaggionb,PatrickZieringe,HinrichSchützef,LeoWannergb","World Patent Information","https://doi.org/10.1016/j.wpi.2014.10.003","https://www.sciencedirect.com/science/article/pii/S0172219014001410"
"A351","Exploring technological opportunities by mining the gaps between science and technology: Microalgal biofuels","The interaction between scientific and technological knowledge facilitates exploration of new technological opportunities; however, gaps between them typically impede exploration of these opportunities. Scientific papers and technological patents record modern and advanced knowledge in scientific discovery and technological development; therefore, comparing their statuses can identify the gaps and explore potential technological opportunities. Because microalgal biofuels are a promising alternative energy resource devoid of territorial land use problems, this study applies text mining and an algorithm that can cluster objects of high-dimensional data to microalgal biofuel papers and patents, and explores their potential technological opportunities. The results demonstrate that a text-based clustering approach is appropriate for identifying scientific and technological applications for microalgal biofuels. The results indicate that microalgal photosynthesis and light utilization have abundant scientific outcomes for technological engineers to potentially apply. Technological opportunities exist in synthesis, harvesting, extraction, and lipid conversion. Scientific knowledge underlying biofuels accompanying high-value co-products of production require sustained exploration and reporting through research. These needs represent potential technological opportunities.","Science and technology,Technological opportunity,Text mining,Microalgae,Biofuel,High-dimensional data","Ming-YeuWanga,Shih-ChiehFangbc,Yu-HsuanChangd","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2014.07.008","https://www.sciencedirect.com/science/article/pii/S0040162514002339"
"A352","A systematic literature review of studies on business process modeling quality","ContextBusiness process modeling is an essential part of understanding and redesigning the activities that a typical enterprise uses to achieve its business goals. The quality of a business process model has a significant impact on the development of any enterprise and IT support for that process.,ObjectiveSince the insights on what constitutes modeling quality are constantly evolving, it is unclear whether research on business process modeling quality already covers all major aspects of modeling quality. Therefore, the objective of this research is to determine the state of the art on business process modeling quality: What aspects of process modeling quality have been addressed until now and which gaps remain to be covered?,MethodWe performed a systematic literature review of peer reviewed articles as published between 2000 and August 2013 on business process modeling quality. To analyze the contributions of the papers we use the Formal Concept Analysis technique.,ResultsWe found 72 studies addressing quality aspects of business process models. These studies were classified into different dimensions: addressed model quality type, research goal, research method, and type of research result. Our findings suggest that there is no generally accepted framework of model quality types. Most research focuses on empirical and pragmatic quality aspects, specifically with respect to improving the understandability or readability of models. Among the various research methods, experimentation is the most popular one. The results from published research most often take the form of intangible knowledge.,ConclusionWe believe there is a lack of an encompassing and generally accepted definition of business process modeling quality. This evidences the need for the development of a broader quality framework capable of dealing with the different aspects of business process modeling quality. Different dimensions of business process quality and of the process of modeling still require further research.","Systematic literature review,Business process modeling,Modeling quality","IselMoreno-Montes de Ocaa,MoniqueSnoeckb,Hajo A.Reijersc,AbelRodríguez-Morffia","Information and Software Technology","https://doi.org/10.1016/j.infsof.2014.07.011","https://www.sciencedirect.com/science/article/pii/S0950584914001797"
"A353","Examining open-endedness of expectations in emerging technological fields: The case of cellulosic ethanol","The promises and visions arising from scientific discoveries, technological breakthroughs, and the emergence of technological fields are by nature uncertain and inaccurate. This paper suggests that a reasonable way to expose more accurately the conditions of incomplete knowledge, imperfect inference, and open-endedness surrounding emerging technological fields is to look at actors' shared expectations or common guiding images that function as scenarios. A rigorous theoretical framework and a methodological approach that exposes in a more accurate way foundations and generalizations underlying guiding images in emerging technological fields is developed. We undertake co-classification analysis of patent data, content analysis of patents, and analysis of firm communication in order to map, analytically distinguish generalizations, and judge (using domain experts) the foundations of competing guiding images in the emerging field of cellulosic bioethanol. We uncover two competing guiding images, an ‘expectation-based’ guiding image of ‘cellulose ethanol manufacturing’, and a more radical development, an ‘anticipation-based’ guiding image of ‘plant self-production’. Further, we identify a wild card, that of algae-based photosynthetic ethanol production. Together the exposure and the analysis of the foundations of two competing guiding images and a wild card in the field of cellulose ethanol provide previously unmatched substantiation of open-endedness of expectations in an emergent technological field.","Guiding image,Leitbild,Technological forecasting,Expectations,Anticipation,Generalizations","RobinGustafssonab,OsmoKuusicd,MartinMeyerefg","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2014.02.008","https://www.sciencedirect.com/science/article/pii/S0040162514000572"
"A354","Academic foundations of hospitality management research with an emerging country focus: A citation and co-citation analysis","This study explores the academic foundations of hospitality management research within an emerging country using bibliometric analysis – citation and co-citation analysis. Turkey was chosen as a starting point to assess existing research within an emerging country framework because of the large impact of tourism and hospitality (T/H) on the economy and increasing amount of academic research in the field. A total of 76 hospitality management research articles from 1992 to 2013 were found in leading international T/H journals indexed by SSCI. Findings showed that over one-half of the research comes from publications engaging outside of the T/H field. Patterns emerged between T/H and management, marketing and psychology fields that indicated evolving maturity in the research. An intense dependency on supporting journals for substantiation existed and intra-disciplinary maturity was weak, but growing. Accordingly, referring to the findings related to the study, the article discusses limitations of the study and future steps.","Hospitality,Tourism,Bibliometric analysis,Citation,Co-citation,Turkey,Developing country","Mehmet AliKöseogluab,YasinSehitogluc,JanaCraftd","International Journal of Hospitality Management","https://doi.org/10.1016/j.ijhm.2014.12.004","https://www.sciencedirect.com/science/article/pii/S027843191400190X"
"A355","Analysis of Research Literature of Professional Competency Models with a Cognitive-motivational Approach","Prior studies determined the importance of study of professional competencies under eight approaches: 1)workplace; 2)behavioral theory; 3)business strategy; 4)holistic approach; 5)engineering and technological context; 6)higher education; 7)organizational psychology; and 8)cognitive and motivational approach. The aim to delve deeper the cognitive-motivational aspect is to determine the relationship between these aspects. Thereupon we use techniques of scientific domain analysis as scientific analysis of the patterns of co-occurrence and co-citation in the research literature indexed in Scopus, bibliographic records are analyzed for relating the theories of the most representative authors and key terms found grouped in clusters research to prove that An individual's learning is proportional to the motivation provided to him or her, which means that it is necessary to know the personal aspects of each individual in the formation of professional competencies. Other factors affected by motivation are goals and achievements.","scientific domain analysis,cognitive-motivational","Dante Arturo GuerreroChanduví,Gerson La RosaLama,Natalia DíazMorey","Procedia - Social and Behavioral Sciences","https://doi.org/10.1016/j.sbspro.2015.01.260","https://www.sciencedirect.com/science/article/pii/S1877042815002906"
"A356","Chapter 1: Document Informatics for Scientific Learning and Accelerated Discovery","This chapter presents a concept paper that describes methods to accelerate new materials discovery and optimization, by enabling faster recognition and use of important theoretical, computational, and experimental information aggregated from peer-reviewed and published materials-related scientific documents online. To obtain insights for the discovery of new materials and to study about existing materials, research and development scientists and engineers rely heavily on an ever-growing number of materials research publications, mostly available online, and that date back many decades. So, the major thrust of this concept paper is the use of technology to (i) extract “deep” meaning from a large corpus of relevant materials science documents; (ii) navigate, cluster, and present documents in a meaningful way; and (iii) evaluate and revise the materials-related query responses until the researchers are guided to their information destination. While the proposed methodology targets the interdisciplinary field of materials research, the tools to be developed can be generalized to enhance scientific discoveries and learning across a broad swathe of disciplines. The research will advance the machine-learning area of developing hierarchical, dynamic topic models to investigate trends in materials discovery over user-specified time periods. Also, the field of image-based document analysis will benefit tremendously from machine learning tools such as the use of deep belief networks for classification and text separation from document images. Developing an interactive visualization tool that can display modeling results from a large materials network perspective as well as a time-based perspective is an advancement in visualization studies.","Accelerated discovery,Digital document analysis,Probabilistic topic models,Scientific learning,Visualization","VenuGovindaraju*,IfeomaNwogu*,SrirangarajSetlur*","Handbook of Statistics","https://doi.org/10.1016/B978-0-444-63492-4.00001-0","https://www.sciencedirect.com/science/article/pii/B9780444634924000010"
"A357","Chapter 13: Literature Mining and Ontology Mapping Applied to Big Data","Discovering the network of associations and relationships among diseases, genes, and risk factors is critical in clinical and translational research. The goal of this study was to design a system that would enable strategic reading/filtering and reduce information overload, generate new hypotheses, bridge the knowledge gap, and develop “smart apps.” We present the implementation of a text analytic system, Adaptive Robust and Integrative Analysis for Finding Novel Associations (ARIANA). The system is context-specific, modular, and scalable and able to capture direct and indirect associations among 2,545 biomedical concepts. An easy-to-use Web interface was developed to query, interact, and visualize the results. Empirical studies showed that the system was able to find novel associations and generate new hypotheses. For instance, the system captured the association between the drug hexamethonium and pulmonary fibrosis, which in 2001 caused the tragic death of a healthy volunteer. The software is available with a properly executed end-user licensing agreement at http://www.ARIANAmed.org.","Adaptive,Associations,Biomedical,Interface,Novel,Semantic","VidaAbedi,MohammedYeasin,RaminZand","Application of Big Data for National Security,Application of Big Data for National Security","https://doi.org/10.1016/B978-0-12-801967-2.00013-6","https://www.sciencedirect.com/science/article/pii/B9780128019672000136"
"A358","Chapter 52: Epigenetics of Reproduction","The regulation of the genome outside of the context of the nucleotide sequence is referred to as epigenetics; it is both a stable and dynamic regulator of gene activity and function. Direct modifications of nucleotides via methylation and/or modifications to the histones in the surrounding chromatin constitute the realm of epigenetics markers, which are coordinated via enzymatic modifications. An additional level of transcriptional and translational regulation occurs via noncoding RNAs; many varieties of these are known (i.e., microRNA, piRNA, siRNA etc.) but are only beginning to be appreciated. The centrality of epigenetics to reproduction begins with the critical role of histone and DNA methylation in the early zygote and during formation of new germ cells in order to reset for the next generation, although the transgenerational persistence of some markers reveals the incompleteness of these processes. The silencing of one X chromosome in female mammalian cells and the imprinting of genes in order to control parent-of-origin allelic expression are primary examples of epigenetics in reproduction. More recently, an emphasis on epigenetic changes in the brain have emerged; these appear to be highly dynamic, impacted by steroids and responsive to environmental cues, including positive or adverse experience, toxins, and endocrine-disrupting compounds. The importance of epigenetics to the enduring effects of hormonally mediated sexual differentiation of the brain and behavior and the timing of puberty are emerging areas of interest. A review of current methodological practices is presented as a guide to further understanding in this rapidly changing field.","Acetylation,Bisulfite sequencing,Chromatin,Demethylation,Epigenetic,Histone,Imprinting,Maternal care,Methylation,Methyl-seq,Noncoding RNAs,Puberty,Sexual differentiation,Transgenerational inheritance,Transposon,X-inactivation","Margaret M.McCarthy,Emilie F.Rissman","Knobil and Neill's Physiology of Reproduction,Knobil and Neill's Physiology of Reproduction (Fourth Edition)","https://doi.org/10.1016/B978-0-12-397175-3.00052-1","https://www.sciencedirect.com/science/article/pii/B9780123971753000521"
"A359","1: Discourse domains and their role in knowledge production dissemination and organization","Domain analysis for knowledge organization is the embrace of techniques for discovering the knowledge base of specific communities, for the purpose of informing the science of the order of knowledge and its application in knowledge organization systems. Domain analysis has become a core paradigm within the knowledge organization community in the postmodern environment. The papers that now are seen as catalytical in knowledge organization came from Hjørland and Albrechtsen (1995), which suggested domain analysis as a new approach to information science; a follow-on article Hjørland and Albrechtsen, 1999 focused directly toward the knowledge organization community; Hjørland (2002), which lays out 11 formal techniques; and, a special 2003 issue of Knowledge Organization on domain analysis edited by Hjørland and Hartel. Tennis (2003) defines two axes for the functioning of domain analysis as a methodological paradigm for the discovery of transferable analytical ontology. Just as domain analysis for knowledge organization has incorporated many theoretical perspectives, so has it been demonstrated to be a multimethod paradigm. There are many ways to elicit a terminological or thematic knowledge base by using empirical techniques for documentary analysis or qualitative techniques for ethnographic observation of a domain. Critical theory, semiotics, and discourse analysis provide social and cultural approaches to understanding domain epistemological perspectives. Domain analysis is a multitheoretical, multimethods core paradigm in the science of knowledge organization.","Domain analysis,Knowledge organization,Ontology,Multimethods,Critical theory","Richard P.Smiraglia","Domain Analysis for Knowledge Organization,Domain Analysis for Knowledge Organization","https://doi.org/10.1016/B978-0-08-100150-9.00001-8","https://www.sciencedirect.com/science/article/pii/B9780081001509000018"
"A360","Visualization and quantitative study in bibliographic databases: A case in the field of university–industry cooperation","CiteSpace is a visual document analysis software, by which performances and trends of certain disciplines can be displayed for a given period. Moreover, the evolution of a frontier research can be explored by such software as well. This research focuses on the visualization and quantitative study in bibliographic databases by taking the university–industry collaboration studies as an example. Using the Web of Science (WOS), 587 publications and over 30,000 references were selected for analysis, which produced the following results: (1) Our method can clearly reveal the key elements of certain disciplines, such as the largest share of publications, the most frequently cited authors and journals in the university–industry cooperation research field; (2) The relationships among the frequently cited authors, references, journals and keywords can be explained visually in the university–industry cooperation research field; (3) Of special note is that the potential problems and evolutionary trends of certain research fields such as university–industry cooperation can also be ascertained via our method; (4) In general, according to the case study, our visualization and quantitative method evolved a new research framework to evaluate the performance of some research areas.","Bibliometrics,Visualizing,Quantitative,CiteSpace,University–industry collaboration","FengFenga,LeiyongZhanga,YunengDub,WeiguangWangc","Journal of Informetrics","https://doi.org/10.1016/j.joi.2014.11.009","https://www.sciencedirect.com/science/article/pii/S1751157714001114"
"A361","Visualizing information science: Author direct citation analysis in China and around the world","Author direct citation analysis (ADCA, also called inter-citation or cross citation) is a new feasible and applicable technique for exploring knowledge communication and discovering scientific structure. This study explored ADCA among prolific, highly cited, and core authors in information science in China and around the world. The results revealed the following. (1) The datasets in China and around the world cover overlapping, but also unique topics. Research subjects on information science around the world can be divided into three categories and 10 clusters; meanwhile, that in China can be divided into three categories and 9 clusters. Chinese scholars who are mostly involved in cross subjects and multi-fields are not as specialized and profound as foreign scholars. An obvious imbalance exists in the evolution of discipline structure around the world, indicating the necessity of a synchronous promotion of research specialty and cross comprehensiveness. Chinese scholars concentrate more on topics such as competitive intelligence, information resource management, and information retrieval, and they focus less on information security and user analysis. (2) Knowledge communication between active authors is stronger than the knowledge flow from highly influential authors to active authors around the world; meanwhile, Chinese researchers tend to adopt the knowledge of authoritative literature. The knowledge flow through bidirectional direct citation is related to mutual knowledge communication. Authoritative scholars are produced when prolific authors cite highly cited authors. The level of mutual recognition among Chinese scholars has not reached that among foreign scholars; in the former, less bidirectional flow of knowledge is involved, and unidirectional flow is limited to geographical proximity, cooperation, or teacher–student relationship. (3) In contrast to traditional author co-citation analysis (ACA), ADCA pays more attention to the mutual interaction among currently active scholars and to mainly showing the current research focus.","Author direct citation,Information science,Citation network,Visualization","SiluoYanga,FeifeiWangb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2015.01.001","https://www.sciencedirect.com/science/article/pii/S1751157715000024"
"A362","Subject Index","","","","International Encyclopedia of the Social & Behavioral Sciences (Second Edition)","https://doi.org/10.1016/B978-0-08-097086-8.99039-1","https://www.sciencedirect.com/science/article/pii/B9780080970868990391"
"A363","Chapter 20: The Risk Management Professional","","Communicating,Consultants,Expert Witness,Litigation Support,PSM Professional,Report Writing,Risk Management Professional,Trade Secrets","IanSutton","Process Risk and Reliability Management,Process Risk and Reliability Management (Second Edition)","https://doi.org/10.1016/B978-0-12-801653-4.00020-5","https://www.sciencedirect.com/science/article/pii/B9780128016534000205"
"A364","Chapter 2: Myths about Learning","","70–20–10 rule,creativity,discovery learning,gender differences in mathematics,knowledge obsolescence,knowledge society,learning pyramid,learning style,memory,multiple intelligences,non-verbal communication,problem-based learning","PedroDe Bruyckere,Paul A.Kirschner,Casper D.Hulshof","Urban Myths about Learning and Education,Urban Myths about Learning and Education","https://doi.org/10.1016/B978-0-12-801537-7.00003-2","https://www.sciencedirect.com/science/article/pii/B9780128015377000032"
"A365","Chapter 12: Reference Databases for Disease Associations","","Sequence variation,ClinVar,dbGaP,dbSNP,dbVar,MedGen,phenotype,disease,pathogenicity,web sites,GWAS,ClinGen","Wendy S.Rubinstein1,Deanna M.Church2,Donna R.Maglott1","Clinical Genomics,Clinical Genomics","https://doi.org/10.1016/B978-0-12-404748-8.00012-5","https://www.sciencedirect.com/science/article/pii/B9780124047488000125"
"A366","Visualizing History for Qualitative Explanation of Valuable Events using Tangled String","In this paper, Tangled String, a method for visualizing sequential data is summarized and exemplified for log text of histories given as timeline lists. Valuable events are detected according to the results, on the assumption that the value of an event or an item in history means the essential impact on the past trend or on the future events that can be understood by qualitative explanation. According to the results, valuable events differ for different granularity in segmenting history into subsequences of events, corresponding to our intuitive sense of the impacts of events for human decisions and actions. This paper also aims to suggest evaluation criteria about the value of events and information in general, where their quality cannot be easily replaced by quantity. Humans’ thoughts should be involved in the process of quality evaluation, so a method such as Tangled String is desired to support this process and improve efficiency.","","YukioOhsawa,TeruakiHayashi","Procedia Computer Science","https://doi.org/10.1016/j.procs.2015.08.178","https://www.sciencedirect.com/science/article/pii/S1877050915023054"
"A367","4: Empirical techniques for visualizing domains","Domain analysis in knowledge organization involves extracting knowledge bases from functioning discourse communities. Many studies of domain analysis use a mixture of evidentiary approaches to extract or generate terminology and its ontological context. Empirical techniques are explained in this chapter, with a focus on demonstrating domain coherence—by demarcating group membership, focus, and function—and then on actual extraction of ontological content using citation analysis, coword analysis, author cocitation analysis, and network analysis. The techniques are in wide use in information science, so the focus here will be on their use for domain analysis in knowledge organization and on means of visualizing domain coherence. The techniques include citation analysis, coword analysis, author cocitation analysis, and network analysis.","Knowledge bases,Discourse communities,Evidentiary approaches,Ontological context","Richard P.Smiraglia","Domain Analysis for Knowledge Organization,Domain Analysis for Knowledge Organization","https://doi.org/10.1016/B978-0-08-100150-9.00004-3","https://www.sciencedirect.com/science/article/pii/B9780081001509000043"
"A368","2: Domain analysis as a methodological paradigm in knowledge organization","In domain analysis, the purpose is to reveal the contours of held knowledge, whether that be in the form of live discourse or recorded documentation, by analyzing the elements of specific communities who share a common ontology, or knowledge base. The objectives of domain analysis are to map and visualize the intellectual parameters of shared knowledge in a given community, such that results can be put to use in knowledge organization systems for the furtherance of the community’s own discourse and for its intellectual contributions at large. The evolution of empirical methods can be observed in the literature of the domain, which is found predominantly in the proceedings of international ISKO conferences and in the journal Knowledge Organization. Nearly a 100 studies have been conducted and reported in the domain’s formal literature and summarized here. The majority of analytical studies use empirical methods such as metric or terminological techniques, but large numbers of discourse analyses, genre analyses, and epistemological analyses also are attempted. Fewer critical studies and historical analyses have been generated but some are represented. A wide variety of domains has been analyzed in these studies. Approximately 50 domains have been studied 1–4, and 22 studies reported domain analysis of aspects of knowledge organization.","Held knowledge,Discourse,Recorded documentation,Common ontology,Knowledge bases","Richard P.Smiraglia","Domain Analysis for Knowledge Organization,Domain Analysis for Knowledge Organization","https://doi.org/10.1016/B978-0-08-100150-9.00002-X","https://www.sciencedirect.com/science/article/pii/B978008100150900002X"
"A369","Formal Methods of Cultural Analysis","Our focus is on methods of cultural analysis, and specifically on those methods that are formal in the sense that they rely upon the purposeful gathering (or simulating) of cultural data and a systematic analysis that involves at least some mathematically based technique. The meaning of culture is more complex, as scholars have understood cultural phenomena in very different ways across the decades and across the disciplines. These different goals in cultural analysis give rise to different types or styles of formal methods of cultural analysis. We briefly review the history of these methods in the social sciences and conclude with a description of some of the main arenas within which formal methods of cultural analysis are being deployed and actively developed today.","Analysis, relational analysis,Computational linguistics/Sociology/Humanities,Content analysis,Culture,Field theory,Formal methods,Hermeneutic/Nonhermeneutic,Meaning,Measurement,Natural language processing,Networks,Structuralist analysis of myths,Text coding,Topic models","John W.Mohr,CraigRawlings","International Encyclopedia of the Social & Behavioral Sciences (Second Edition)","https://doi.org/10.1016/B978-0-08-097086-8.10428-3","https://www.sciencedirect.com/science/article/pii/B9780080970868104283"
"A370","Chapter 9: Big Data Driven Natural Language Processing Research and Applications","Due to the inherent complexity of natural languages, many natural language tasks are ill-posed for mathematically precise algorithmic solutions. To circumvent this problem, statistical machine learning approaches are used for natural language processing (NLP) tasks. The emergence of Big Data enables a new paradigm for solving NLP problems—managing the complexity of the problem domain by harnessing the power of data for building high quality models.This chapter provides an introduction to various core NLP tasks and highlights their data-driven solutions. Second, a few representative NLP applications, which are built using the core NLP tasks as the underlying infrastructure, are described. Third, various sources of Big Data for NLP research are discussed. Fourth, Big Data driven NLP research and applications are outlined. Finally, the chapter concludes by indicating trends and future research directions.","Big data,Natural language processing,Statistical models","Venkat N.Gudivada*,DhanaRao†,Vijay V.Raghavan‡","Handbook of Statistics","https://doi.org/10.1016/B978-0-444-63492-4.00009-5","https://www.sciencedirect.com/science/article/pii/B9780444634924000095"
"A371","Chapter 3: Landscape as a Cartographic Icon","","Landscape and map,Landscape and perspective,Cartography and art,David Hockney,Perspective and semiotics of vision,Renaissance cartography,Cristoforo Sorte","EmanuelaCasti","Modern Cartography Series","https://doi.org/10.1016/B978-0-12-803509-2.00003-3","https://www.sciencedirect.com/science/article/pii/B9780128035092000033"
"A372","Visualization of co-readership patterns from an online reference management system","In this paper, we analyze the adequacy and applicability of readership statistics recorded in social reference management systems for creating knowledge domain visualizations. First, we investigate the distribution of subject areas in user libraries of educational technology researchers on Mendeley. The results show that around 69% of the publications in an average user library can be attributed to a single subject area. Then, we use co-readership patterns to map the field of educational technology. The resulting visualization prototype, based on the most read publications in this field on Mendeley, reveals 13 topic areas of educational technology research. The visualization is a recent representation of the field: 80% of the publications included were published within ten years of data collection. The characteristics of the readers, however, introduce certain biases to the visualization. Knowledge domain visualizations based on readership statistics are therefore multifaceted and timely, but it is important that the characteristics of the underlying sample are made transparent.","Relational scientometrics,Topical distribution,Knowledge domain visualization,Mapping,Altmetrics,Readership statistics","PeterKrakera,ChristianSchlöglb,KrisJackc,StefanieLindstaedta","Journal of Informetrics","https://doi.org/10.1016/j.joi.2014.12.003","https://www.sciencedirect.com/science/article/pii/S1751157714001151"
"A373","The rise of Network Ecology: Maps of the topic diversity and scientific collaboration","Network ecologists investigate the structure, function, and evolution of ecological systems using network models and analyses. For example, network techniques have been used to study community interactions (i.e., food-webs, mutualisms), gene flow across landscapes, and the sociality of individuals in populations. The work presented here uses a bibliographic and network approach to (1) document the rise of Network Ecology, (2) identify the diversity of topics addressed in the field, and (3) map the structure of scientific collaboration among contributing scientists. Our aim is to provide a broad overview of this emergent field that highlights its diversity and to provide a foundation for future advances. To do this, we searched the ISI Web of Science database for ecology publications between 1900 and 2012 using the search terms for research areas of Environmental Sciences & Ecology and Evolutionary Biology and the topic ecology. From these records we identified the Network Ecology publications using the topic terms network, graph theory, and web, while controlling for the usage of misleading phrases. The resulting corpus entailed 29,513 publications between 1936 and 2012. We found that Network Ecology spans across more than 1500 sources with core ecological journals being among the top 20 most frequent outlets. We document the rapid rise in Network Ecology publications per year reaching a magnitude of over 5% of the ecological publications in 2012. Drawing topical information from the publication record content (titles, abstracts, keywords) and collaboration information from author listing, our analysis highlights the diversity and clustering of topics addressed within Network Ecology. The largest connected component of the topic network contained 73% of the corpus, and exhibited strong clustering (clustering coefficient 0.93). The co-authorship network revealed that while network ecologists are generally collaborative, the field is deeply fragmented into topic and co-author cliques. The largest component of the co-author network comprised 46% of the authors and contained 149 distinct clusters. We suggest ways to build on the collaborative spirit and reduce the field fragmentation so as to improve the development and spread of ideas. We conclude that Network Ecology will likely continue to grow because the forces driving its increase are likely to persist.","Social network analysis,Bibliographic analysis,Non-trophic interactions,Connectivity,Co-authorship,Network ecology","Stuart R.Borrettac,JamesMoodybc,AchimEdelmannbc","Ecological Modelling","https://doi.org/10.1016/j.ecolmodel.2014.02.019","https://www.sciencedirect.com/science/article/pii/S0304380014001136"
"A374","Text summarization in the biomedical domain: A systematic review of recent research","ObjectiveThe amount of information for clinicians and clinical researchers is growing exponentially. Text summarization reduces information as an attempt to enable users to find and understand relevant source texts more quickly and effortlessly. In recent years, substantial research has been conducted to develop and evaluate various summarization techniques in the biomedical domain. The goal of this study was to systematically review recent published research on summarization of textual documents in the biomedical domain.,Materials and methodsMEDLINE (2000 to October 2013), IEEE Digital Library, and the ACM digital library were searched. Investigators independently screened and abstracted studies that examined text summarization techniques in the biomedical domain. Information is derived from selected articles on five dimensions: input, purpose, output, method and evaluation.,ResultsOf 10,786 studies retrieved, 34 (0.3%) met the inclusion criteria. Natural language processing (17; 50%) and a hybrid technique comprising of statistical, Natural language processing and machine learning (15; 44%) were the most common summarization approaches. Most studies (28; 82%) conducted an intrinsic evaluation.,DiscussionThis is the first systematic review of text summarization in the biomedical domain. The study identified research gaps and provides recommendations for guiding future research on biomedical text summarization.,ConclusionRecent research has focused on a hybrid technique comprising statistical, language processing and machine learning techniques. Further research is needed on the application and evaluation of text summarization in real research or patient care settings.","Text summarization,Intrinsic evaluation,Language processing,Machine learning,Biomedical domain","RashmiMishraa,JiantaoBianab,MarceloFiszmanc,Charlene R.Weirad,SiddharthaJonnalagaddae,JavedMostafaf,GuilhermeDel Fiola","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2014.06.009","https://www.sciencedirect.com/science/article/pii/S1532046414001476"
"A375","Toward a taxonomy of career studies through bibliometric visualization","One of the greatest strengths and liabilities of the career field is its diversity. This diversity allows for wide coverage of relevant career dynamics across the lifespan and across levels of analysis. However, this diversity also reflects fragmentation, with career scholars failing to appreciate how the insights from other thought worlds can advance their own work. Using advanced bibliometric mapping techniques, we provide a systematic review of the 3141 articles on careers published in the management literature between 1990 and 2012. In doing so, we (1) map key terms to create a systematic taxonomy of career studies within the field of management studies, (2) provide a synthetic overview of each topic cluster which extends prior reviews of more limited scope, and (3) identify the most highly influential studies on careers within each cluster. Specifically, six local clusters emerged — i.e., international careers, career management, career choice, career adaptation, individual and relational career success, and life opportunities. To classify a broad range of research opportunities for career scholars, we also create a “global” map of 16,146 career articles from across the social sciences. Specifically, six global clusters emerged — i.e., organizational, individual, education, doctorate careers, high-profile careers, and social policy. We describe and compare the clusters in the map with an emphasis on those avenues career scholars in management have yet to explore.","Careers,Career studies,Career theory,Science maps,Bibliometrics","Colin I.S.G.Leea,WillFelpsb,YehudaBaruchc","Journal of Vocational Behavior","https://doi.org/10.1016/j.jvb.2014.08.008","https://www.sciencedirect.com/science/article/pii/S0001879114001092"
"A376","Leveraging text analytics in patent analysis to empower business decisions – A competitive differentiation of kinase assay technology platforms by I2E text mining software","Leveraging available technologies for high-throughput screening (HTS), to enable the rapid delivery of comprehensive data packages for drug discovery programs, is a primary goal in developing new molecular entities for clinical applications. Pharmaceutical companies like Bristol-Myers Squibb (BMS) must constantly evolve their assay methods to ensure an effective and timely impact to business. This article is focused on a novel three step approach, using Linguamatics I2E text analytics software to mine the full text of patents, to identify (1) kinase assay technology information, and (2) kinase group information that is associated with therapeutic areas for drug screening.","Patent analysis,Drug discovery,Kinase assay,Text analytics,Mining software,Visualization software,Business decisions","Yun YunYang,ThomasKlose,JonathanLippy,Cynthia S.Barcelon-Yang,LitaoZhang","World Patent Information","https://doi.org/10.1016/j.wpi.2014.09.002","https://www.sciencedirect.com/science/article/pii/S0172219014001331"
"A377","Abstract","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2014.10.002","https://www.sciencedirect.com/science/article/pii/S0140670114000356"
"A378","Modeling virtual organizations with Latent Dirichlet Allocation: A case for natural language processing","This paper explores a variety of methods for applying the Latent Dirichlet Allocation (LDA) automated topic modeling algorithm to the modeling of the structure and behavior of virtual organizations found within modern social media and social networking environments. As the field of Big Data reveals, an increase in the scale of social data available presents new challenges which are not tackled by merely scaling up hardware and software. Rather, they necessitate new methods and, indeed, new areas of expertise. Natural language processing provides one such method. This paper applies LDA to the study of scientific virtual organizations whose members employ social technologies. Because of the vast data footprint in these virtual platforms, we found that natural language processing was needed to ‘unlock’ and render visible latent, previously unseen conversational connections across large textual corpora (spanning profiles, discussion threads, forums, and other social media incarnations). We introduce variants of LDA and ultimately make the argument that natural language processing is a critical interdisciplinary methodology to make better sense of social ‘Big Data’ and we were able to successfully model nested discussion topics from forums and blog posts using LDA. Importantly, we found that LDA can move us beyond the state-of-the-art in conventional Social Network Analysis techniques.","Natural language processing,Latent Dirichlet Allocation,Big Data,Social media,Virtual organizations","AlexanderGrossa,DhirajMurthyb","Neural Networks","https://doi.org/10.1016/j.neunet.2014.05.008","https://www.sciencedirect.com/science/article/pii/S0893608014001075"
"A379","Unmoderated Posters","","","","Urology","https://doi.org/10.1016/S0090-4295(14)01020-6","https://www.sciencedirect.com/science/article/pii/S0090429514010206"
"A380","Analyzing future communities in growing citation networks","Citation networks contain temporal information about what researchers are interested in at a certain time. A community in such a network is built around either a renowned researcher or a common research field; either way, analyzing how the community will change in the future will give insight into the research trend in the future. The paper views the research community as a Social Web where the communication is through academic papers. The paper proposes methods to analyze how communities change over time in the citation network graph without additional external information and based on node and link prediction and community detection. Different combinations of the proposed methods are also analyzed. The identified communities are classified using key term labeling. Experiments show that the proposed methods can identify the changes in citation communities multiple years in the future with performance differing according to the analyzed time span. Furthermore, the method is shown to produce higher performance when analyzing communities to be disbanded and to be formed in the future.","Community,Topic detection,Link prediction,Citation network,Community detection","SukhwanJung,AvivSegev","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2014.04.036","https://www.sciencedirect.com/science/article/pii/S095070511400166X"
"A381","Cyber situational awareness – A systematic review of the literature","Cyber situational awareness is attracting much attention. It features prominently in the national cyber strategies of many countries, and there is a considerable body of research dealing with it. However, until now, there has been no systematic and up-to-date review of the scientific literature on cyber situational awareness.This article presents a review of cyber situational awareness, based on systematic queries in four leading scientific databases. 102 articles were read, clustered, and are succinctly described in the paper. The findings are discussed from the perspective of both national cyber strategies and science, and some directions for future research are examined.","Situational awareness,Cyber security,National cyber strategies,Research strategy,Literature review","UlrikFranke,JoelBrynielsson","Computers & Security","https://doi.org/10.1016/j.cose.2014.06.008","https://www.sciencedirect.com/science/article/pii/S0167404814001011"
"A382","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2014.08.002","https://www.sciencedirect.com/science/article/pii/S0140670114000277"
"A383","Topic knowledge map and knowledge structure constructions with genetic algorithm, information retrieval, and multi-dimension scaling method","This work presents a novel automated approach to construct topic knowledge maps with knowledge structures, followed by its application to an internationally renowned journal. Knowledge structures are diagrams showing the important components of knowledge in study. Knowledge maps identify the locations of objects and illustrate the relationship among objects. In our study, the important components derived from knowledge structures are used as objects to be spotted in a topic knowledge map. The purpose of our knowledge structures is to find out the major topics serving as subjects of article collections as well as related methods employed in the published papers. The purpose of topic knowledge maps is to transform high-dimensional objects (topic, paper, and cited frequency) into a 2-dimensional space to help understand complicated relatedness among high-dimensional objects, such as the related degree between an article and a topic.First, we adopt independent chi-square test to examine the independence of topics and apply genetic algorithm to choose topics selection with best fitness value to construct knowledge structures.Additionally, high-dimensional relationships among objects are transformed into a 2-dimensional space using the multi-dimension scaling method. The optimal transformation coordinate matrix is also determined by using a genetic algorithm to preserve the original relations among objects and construct appropriate topic knowledge maps.","Knowledge structure,Topic knowledge map,Information retrieval,Genetic algorithm,Independent chi-square,Multi-dimension scaling","Deng-YivChiu,Ya-ChenPan","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2014.03.008","https://www.sciencedirect.com/science/article/pii/S0950705114000914"
"A384","Mining opinion components from unstructured reviews: A review","Opinion mining is an interesting area of research because of its applications in various fields. Collecting opinions of people about products and about social and political events and problems through the Web is becoming increasingly popular every day. The opinions of users are helpful for the public and for stakeholders when making certain decisions. Opinion mining is a way to retrieve information through search engines, Web blogs and social networks. Because of the huge number of reviews in the form of unstructured text, it is impossible to summarize the information manually. Accordingly, efficient computational methods are needed for mining and summarizing the reviews from corpuses and Web documents. This study presents a systematic literature survey regarding the computational techniques, models and algorithms for mining opinion components from unstructured reviews.","Opinion mining,Sentiment analysis,Information retrieval,Text mining,Web mining","KhairullahKhana,BaharumBaharudina,AurnagzebKhanb,AshrafUllahb","Journal of King Saud University - Computer and Information Sciences","https://doi.org/10.1016/j.jksuci.2014.03.009","https://www.sciencedirect.com/science/article/pii/S131915781400010X"
"A385","Group regulation and social-emotional interactions observed in computer supported collaborative learning: Comparison between good vs. poor collaborators","This study explored what social interactions students exhibited during collaborative learning, and analyzed how the social interactions evolved in a computer-supported collaborative learning (CSCL) environment. Six groups (n = 28) from an undergraduate online course were observed during a semester. Students' interactions were analyzed in two perspectives: group regulation and socioemotional. Cluster analysis was conducted to identify collaboration patterns of the groups. The analysis identified three collaborator clusters: one good and two poor. The good collaborators (named Early Active Collaborator) demonstrated: (1) intensive interactions among group members in the early collaboration phase, (2) positive socio-emotional interactions continuously, and (3) adaptive selections of group regulatory behaviors. The others showed dormant interactions throughout the projects and least socio-emotional interactions (named Passive Task-oriented Collaborator) and did not coordinate group process in a timely manner (named Late Collaborator). Comparisons of the interaction pattern and instructor intervention were discussed.","Computer-mediated communication,Collaborative learning,Teaching/learning strategies,Distributed learning environments","KyungbinKwona,Ying-HsiuLiub1,LaShaune P.Johnsonc2","Computers & Education","https://doi.org/10.1016/j.compedu.2014.06.004","https://www.sciencedirect.com/science/article/pii/S0360131514001377"
"A386","Automatic multi-partite graph generation from arbitrary data","In this paper we present a generic model for automatic generation of basic multi-partite graphs obtained from collections of arbitrary input data following user indications. The paper also presents GraphGen, a tool that implements this model. The input data is a collection of complex objects composed by a set or list of heterogeneous elements. Our tool provides a simple interface for the user to specify the types of nodes that are relevant for the application domain in each case. The nodes and the relationships between them are derived from the input data through the application of a set of derivation rules specified by the user. The resulting graph can be exported in the standard GraphML format so that it can be further processed with other graph management and mining systems. We end by giving some examples in real scenarios that show the usefulness of this model.","Graph processing and analysis,Automatic graph generation","SandraÁlvarez-Garcíaa,RicardoBaeza-Yatesb,Nieves R.Brisaboaa,Josep-LluisLarriba-Peyc,OscarPedreiraa","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2014.03.022","https://www.sciencedirect.com/science/article/pii/S0164121214000715"
"A387","A systematic review of software architecture visualization techniques","ContextGiven the increased interest in using visualization techniques (VTs) to help communicate and understand software architecture (SA) of large scale complex systems, several VTs and tools have been reported to represent architectural elements (such as architecture design, architectural patterns, and architectural design decisions). However, there is no attempt to systematically review and classify the VTs and associated tools reported for SA, and how they have been assessed and applied.,ObjectiveThis work aimed at systematically reviewing the literature on software architecture visualization to develop a classification of VTs in SA, analyze the level of reported evidence and the use of different VTs for representing SA in different application domains, and identify the gaps for future research in the area.,MethodWe used systematic literature review (SLR) method of the evidence-based software engineering (EBSE) for reviewing the literature on VTs for SA. We used both manual and automatic search strategies for searching the relevant papers published between 1 February 1999 and 1 July 2011.,ResultsWe selected 53 papers from the initially retrieved 23,056 articles for data extraction, analysis, and synthesis based on pre-defined inclusion and exclusion criteria. The results from the data analysis enabled us to classify the identified VTs into four types based on the usage popularity: graph-based, notation-based, matrix-based, and metaphor-based VTs. The VTs in SA are mostly used for architecture recovery and architectural evolution activities. We have also identified ten purposes of using VTs in SA. Our results also revealed that VTs in SA have been applied to a wide range of application domains, among which “graphics software” and “distributed system” have received the most attention.,ConclusionSA visualization has gained significant importance in understanding and evolving software-intensive systems. However, only a few VTs have been employed in industrial practice. This review has enabled us to identify the following areas for further research and improvement: (i) it is necessary to perform more research on applying visualization techniques in architectural analysis, architectural synthesis, architectural implementation, and architecture reuse activities; (ii) it is essential to pay more attention to use more objective evaluation methods (e.g., controlled experiment) for providing more convincing evidence to support the promised benefits of using VTs in SA; (iii) it is important to conduct industrial surveys for investigating how software architecture practitioners actually employ VTs in architecting process and what are the issues that hinder and prevent them from adopting VTs in SA.","Software architecture,Software architecture visualization,Visualization techniques","MojtabaShahinab,PengLiangac,Muhammad AliBabard","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2014.03.071","https://www.sciencedirect.com/science/article/pii/S0164121214000831"
"A388","Visualization of ranking data: Geographical signatures in international collaboration, leadership and research impact","In this work we address the comprehensive Scimago Institutions Ranking 2012, proposing a data visualization of the listed bibliometric indicators for the 509 Higher Education Institutions among the 600 largest research institutions ranked according to their outputs. We focus on research impact, internationalization and leadership indicators, which became important benchmarks in a worldwide discussion about research quality and impact policies for universities. Our data visualization reveals a qualitative difference between the behavior of Northern American and Western European Higher Education Institutions concerning International collaboration levels. Chinese universities show still a systematic low international collaboration levels which are positively linked to the low research impact. The data suggests that research impact can be related directly to internationalization only to rather low values for both indicators. Above world average, other determinants may become relevant in fostering further impact. The leadership indicator provides further insights to the collaborative environment of universities in different geographical regions, as well as the optimized collaboration portfolio for enhancing research impact.","Institutional rankings,International collaboration,Research impact","Edmilson J.T.Manganoteab,Mariana S.Araujoc,Peter A.Schulzc","Journal of Informetrics","https://doi.org/10.1016/j.joi.2014.05.005","https://www.sciencedirect.com/science/article/pii/S1751157714000534"
"A389","Disambiguation and co-authorship networks of the U.S. patent inventor database (1975–2010)","Research into invention, innovation policy, and technology strategy can greatly benefit from an accurate understanding of inventor careers. The United States Patent and Trademark Office does not provide unique inventor identifiers, however, making large-scale studies challenging. Many scholars of innovation have implemented ad-hoc disambiguation methods based on string similarity thresholds and string comparison matching; such methods have been shown to be vulnerable to a number of problems that can adversely affect research results. The authors address this issue contributing (1) an application of the Author-ity disambiguation approach (Torvik et al., 2005, Torvik and Smalheiser, 2009) to the US utility patent database, (2) a new iterative blocking scheme that expands the match space of this algorithm while maintaining scalability, (3) a public posting of the algorithm and code, and (4) a public posting of the results of the algorithm in the form of a database of inventors and their associated patents. The paper provides an overview of the disambiguation method, assesses its accuracy, and calculates network measures based on co-authorship and collaboration variables. It illustrates the potential for large-scale innovation studies across time and space with visualizations of inventor mobility across the United States. The complete input and results data from the original disambiguation are available at (http://dvn.iq.harvard.edu/dvn/dv/patent); revised data described here are at (http://funglab.berkeley.edu/pub/disamb_no_postpolishing.csv); original and revised code is available at (https://github.com/funginstitute/disambiguator); visualizations of inventor mobility are at (http://funglab.berkeley.edu/mobility/).","Disambiguation,Patents,Networks,Inventors,Careers","Guan-ChengLia,RonaldLaib,AlexanderD’Amourc,David M.Doolind,YeSune,Vetle I.Torvikf,Amy Z.Yug,LeeFlemingh","Research Policy","https://doi.org/10.1016/j.respol.2014.01.012","https://www.sciencedirect.com/science/article/pii/S0048733314000225"
"A390","A regression analysis of researchers’ social network metrics on their citation performance in a college of engineering","Previous research shows that researchers’ social network metrics obtained from a collaborative output network (e.g., joint publications or co-authorship network) impact their performance determined by g-index. We use a richer dataset to show that a scholar's performance should be considered with respect to position in multiple networks. Previous research using only the network of researchers’ joint publications shows that a researcher's distinct connections to other researchers, a researcher's number of repeated collaborative outputs, and a researchers’ redundant connections to a group of researchers who are themselves well-connected has a positive impact on the researchers’ performance, while a researcher's tendency to connect with other researchers who are themselves well-connected (i.e., eigenvector centrality) had a negative impact on the researchers’ performance. Our findings are similar except that we find that eigenvector centrality has a positive impact on the performance of scholars. Moreover, our results demonstrate that a researcher's tendency toward dense local neighborhoods and the researchers’ demographic attributes such as gender should also be considered when investigating the impact of the social network metrics on the performance of researchers.","Collaborative networks,Social network analysis,Poisson regression,Self-reported data,Citation-based research performance","OguzCimenlera,Kingsley A.Reevesa,JohnSkvoretzb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2014.06.004","https://www.sciencedirect.com/science/article/pii/S1751157714000571"
"A391","Creating patents on the new technology using analogy-based patent mining","Patents on the new technology–a technology not yet commercialized and in an early stage of its life cycle–give firms many benefits. However, existing methods are inadequate because of dependencies on customers and physical prototypes. And there is lack of systems, focused on a problem identification process or an inter-technological comparison. In this research, to remedy existing limitations, analogy-based patent mining system is suggested. The system is developed based on an assumption that similar problems would occur in technologies that have similar properties or functions. So, the system is focused on identification of a Problem Solved Concept (PSC), which describes what problem is solved in the patent. At the first part of the system, the mature technology–a technology relatively matured than the new technology–is described with a property and a function; one of the property or the function should be similar to which of the new technology considered. And the system extract PSCs, construct patent map, and evaluate PSCs utilizing patents on the new and the mature technologies. As a result, the PSCs with high opportunities are revealed and patents related to the PSCs are examined. Then users of this system select some patents as resources for analogy. The system is tested by a case study of wireless charger technology. For the case study, 352 patents on wireless router technology and 227 patents on wireless charger technology are used. At the final, patents related to ‘handoff’, showed a high opportunity score and one of the patents is introduced to show the possibility of patent creation through analogy.","Analogy,New technology,Problem solved concept,Patent mining,Patent mapping,Patent similarity","CheolhyunJeong,KwangsooKim","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2013.11.045","https://www.sciencedirect.com/science/article/pii/S0957417413009871"
"A392","Bioimage Informatics in the context of Drosophila research","Modern biological research relies heavily on microscopic imaging. The advanced genetic toolkit of Drosophila makes it possible to label molecular and cellular components with unprecedented level of specificity necessitating the application of the most sophisticated imaging technologies. Imaging in Drosophila spans all scales from single molecules to the entire populations of adult organisms, from electron microscopy to live imaging of developmental processes. As the imaging approaches become more complex and ambitious, there is an increasing need for quantitative, computer-mediated image processing and analysis to make sense of the imagery. Bioimage Informatics is an emerging research field that covers all aspects of biological image analysis from data handling, through processing, to quantitative measurements, analysis and data presentation. Some of the most advanced, large scale projects, combining cutting edge imaging with complex bioimage informatics pipelines, are realized in the Drosophila research community. In this review, we discuss the current research in biological image analysis specifically relevant to the type of systems level image datasets that are uniquely available for the Drosophila model system. We focus on how state-of-the-art computer vision algorithms are impacting the ability of Drosophila researchers to analyze biological systems in space and time. We pay particular attention to how these algorithmic advances from computer science are made usable to practicing biologists through open source platforms and how biologists can themselves participate in their further development.","Image analysis,Registration,Processing,Segmentation,Tracking,Drosophila","FlorianJuga1,TobiasPietzscha1,StephanPreibischbc,PavelTomancaka","Methods","https://doi.org/10.1016/j.ymeth.2014.04.004","https://www.sciencedirect.com/science/article/pii/S1046202314001480"
"A393","Document clustering method using dimension reduction and support vector clustering to overcome sparseness","Many studies on developing technologies have been published as articles, papers, or patents. We use and analyze these documents to find scientific and technological trends. In this paper, we consider document clustering as a method of document data analysis. In general, we have trouble analyzing documents directly because document data are not suitable for statistical and machine learning methods of analysis. Therefore, we have to transform document data into structured data for analytical purposes. For this process, we use text mining techniques. The structured data are very sparse, and hence, it is difficult to analyze them. This study proposes a new method to overcome the sparsity problem of document clustering. We build a combined clustering method using dimension reduction and K-means clustering based on support vector clustering and Silhouette measure. In particular, we attempt to overcome the sparseness in patent document clustering. To verify the efficacy of our work, we first conduct an experiment using news data from the machine learning repository of the University of California at Irvine. Second, using patent documents retrieved from the United States Patent and Trademark Office, we carry out patent clustering for technology forecasting.","Document clustering,Sparseness problem,Patent clustering,Dimension reduction,K-means clustering based on support vector clustering,Silhouette measure","SunghaeJuna,Sang-SungParkb,Dong-SikJangc","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2013.11.018","https://www.sciencedirect.com/science/article/pii/S0957417413009305"
"A394","Summary report of CALPHAD XLII – San Sebastian, Spain, 2013","175 scientists from 25 countries participated in CALPHAD XLII Conference. It was held in San Sebastian, Spain, May 26–31, 2013, with 83 oral presentations, 84 posters and 4 software demonstrations. The topics covered during the conference were gathered in nine categories: Modeling and Software; Diffusion; Ab initio; CALPHAD Assessments and Experiments; Modeling of Al, Mg and Ni Materials; Metallic Glass, Liquid and Nano Materials; Phase field; Slags, oxides and nuclear materials; and Modeling of Fe Alloys. In this brief summary, highlights of the conference are presented with titles and abstracts of all presentations.","Modeling software,Kinetics,Microstructure,CALPHAD assessments","TomásGómez-Acebo","Calphad","https://doi.org/10.1016/j.calphad.2013.11.003","https://www.sciencedirect.com/science/article/pii/S0364591613001144"
"A395","A systematic literature review of software requirements prioritization research","ContextDuring requirements engineering, prioritization is performed to grade or rank requirements in their order of importance and subsequent implementation releases. It is a major step taken in making crucial decisions so as to increase the economic value of a system.,ObjectiveThe purpose of this study is to identify and analyze existing prioritization techniques in the context of the formulated research questions.,MethodSearch terms with relevant keywords were used to identify primary studies that relate requirements prioritization classified under journal articles, conference papers, workshops, symposiums, book chapters and IEEE bulletins.,Results73 Primary studies were selected from the search processes. Out of these studies; 13 were journal articles, 35 were conference papers and 8 were workshop papers. Furthermore, contributions from symposiums as well as IEEE bulletins were 2 each while the total number of book chapters amounted to 13.,ConclusionPrioritization has been significantly discussed in the requirements engineering domain. However, it was generally discovered that, existing prioritization techniques suffer from a number of limitations which includes: lack of scalability, methods of dealing with rank updates during requirements evolution, coordination among stakeholders and requirements dependency issues. Also, the applicability of existing techniques in complex and real setting has not been reported yet.","Stakeholders,Requirements,Prioritization,Software systems,Requirement engineering","PhilipAchimugu,AliSelamat,RolianaIbrahim,Mohd Naz’riMahrin","Information and Software Technology","https://doi.org/10.1016/j.infsof.2014.02.001","https://www.sciencedirect.com/science/article/pii/S0950584914000354"
"A396","RETRACTED: The 2013 International Conference on Nuclear Data for Science and Technology","","","","Nuclear Data Sheets","https://doi.org/10.1016/j.nds.2014.04.146","https://www.sciencedirect.com/science/article/pii/S0090375214001835"
"A397","Evolution of social networks","Modeling the evolution of networks is central to our understanding of large communication systems, and more general, modern economic and social systems. The research on social and economic networks is truly interdisciplinary and the number of proposed models is huge. In this survey we discuss a small selection of modeling approaches, covering classical random graph models, and game-theoretic models to analyze the evolution of social networks. Based on these two basic modeling paradigms, we introduce co-evolutionary models of networks and play as a potential synthesis.","Evolution of networks,Game theory,Stochastic processes,Random graphs","TimHellmann,MathiasStaudigl","European Journal of Operational Research","https://doi.org/10.1016/j.ejor.2013.08.022","https://www.sciencedirect.com/science/article/pii/S0377221713006875"
"A398","Detecting research fronts using different types of weighted citation networks","In this paper, we investigate the performance of different types of weighted citation networks for detecting emerging research fronts by a comparative study. Three citation patterns including direct citation, co-citation and bibliographic coupling, have been tested in three research domains including gallium nitride, complex networks, and nano-carbon. These three patterns of citation networks are constructed for each research domain, and the papers in those domains are divided into clusters to detect the research front. Additionally, we apply some measures to weighted citations like difference in publication years between citing and cited papers and similarities of keywords between them, which are expected to be able to effectively to detect emerging research fronts. To investigate the performance of different types of weighted citation networks for detecting emerging research fields, we evaluate the performance of each approach by using the following measures of extracted research fronts: visibility, speed, and topological and textual relevance.","O3,Keywords,Research front,Citation network analysis,Bibliometrics,Decision support","KatsuhideFujitaa,YuyaKajikawab,JunichiroMoric,IchiroSakatad","Journal of Engineering and Technology Management","https://doi.org/10.1016/j.jengtecman.2013.07.002","https://www.sciencedirect.com/science/article/pii/S0923474813000398"
"A399","Finding linkage between technology and social issue: A Literature Based Discovery approach","This paper investigates Literature Based Discovery (LBD) approach to reveal linkages between technology and social issue to elucidate plausible contribution of science and technology for solving social issues. Robotics and gerontology were selected as an example in our analysis. The result shows various technological options of robotics contributing to healthcare and well-being of elderly people, mainly in surgery, rehabilitation, and companionship. In addition, we comparatively evaluated effectiveness of semantic similarity measures to extract these linkages from bibliographic database. Our methodology can be utilized as a decision support tool for managers and policy makers to extract and design promising research targets.","Literature Based Discovery,Text mining,Link mining,Citation analysis,Innovation","VitavinIttipanuvatab,KatsuhideFujitac,IchiroSakatad,YuyaKajikawabe","Journal of Engineering and Technology Management","https://doi.org/10.1016/j.jengtecman.2013.05.006","https://www.sciencedirect.com/science/article/pii/S0923474813000362"
"A400","Legal aspects of text mining","“Text mining” covers a range of techniques that allow software to extract information from text documents. It is not a new technology, but it has recently received spotlight attention due to the emergence of Big Data. The applications of text mining are very diverse and span multiple disciplines, ranging from biomedicine to legal, business intelligence and security. From a legal perspective, text mining touches upon several areas of law, including contract law, copyright law and database law. This contribution discusses the legal issues encountered during the assembly of texts into so-called “corpora”, as well as the use of such corpora.","Copyright,Text mining,Data mining,Reproduction right,Databases","MaartenTruyensa1,PatrickVan Eeckeabc1","Computer Law & Security Review","https://doi.org/10.1016/j.clsr.2014.01.009","https://www.sciencedirect.com/science/article/pii/S0267364914000260"
"A401","Mapping altruism","A great deal of work has been done to understand how science contributes to technological innovation and medicine. This is no surprise given the amount of money invested annually in R&D. However, what is not well known is that US science (R&D) investment is only one-sixth that of the annual revenue received by non-profit organizations (NPOs) in the US. The large majority of NPO revenues are devoted to the remaining landscape of altruistic causes – those not relying as heavily on scientific inquiry. Given this broader context, one might reasonably expect the non-profit world to have been as well characterized as that of scientific research. The unfortunate truth is that no map of altruistic missions and causes exists; the landscape of altruistic activity is virtually unknown. In this paper, we present the first maps of altruistic mission space. These maps were created using the text from websites of 125,000 non-profit organizations (NPOs) in the US. The maps consist of 357 topics covering areas such as religion, education, sports, culture, human services, public policy and medical care. The role of science in this altruistic landscape is examined. Possible applications are discussed.","Altruism,Non-profit organizations,Topic modeling,Science mapping","RichardKlavansa,Kevin W.Boyackb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2014.02.002","https://www.sciencedirect.com/science/article/pii/S1751157714000285"
"A402","Optimizing SCImago Journal & Country Rank classification by community detection","Subject classification arises as an important topic for bibliometrics and scientometrics, searching to develop reliable and consistent tools and outputs. Such objectives also call for a well delimited underlying subject classification scheme that adequately reflects scientific fields. Within the broad ensemble of classification techniques, clustering analysis is one of the most successful.Two clustering algorithms based on modularity – the VOS and Louvain methods – are presented here for the purpose of updating and optimizing the journal classification of the SCImago Journal & Country Rank (SJR) platform. We used network analysis and Pajek visualization software to run both algorithms on a network of more than 18,000 SJR journals combining three citation-based measures of direct citation, co-citation and bibliographic coupling. The set of clusters obtained was termed through category labels assigned to SJR journals and significant words from journal titles.Despite the fact that both algorithms exhibited slight differences in performance, the results show a similar behaviour in grouping journals. Consequently, they are deemed to be appropriate solutions for classification purposes. The two newly generated algorithm-based classifications were compared to other bibliometric classification systems, including the original SJR and WoS Subject Categories, in order to validate their consistency, adequacy and accuracy. In addition to some noteworthy differences, we found a certain coherence and homogeneity among the four classification systems analysed.","Community detection,Clustering,SCImago Journal & Country Rank,Journal classification,Citation-based network","Antonio J.Gómez-Núñeza,VladimirBatageljb,BenjamínVargas-Quesadace,FélixMoya-Anegónde,ZaidaChinchilla-Rodríguezde","Journal of Informetrics","https://doi.org/10.1016/j.joi.2014.01.011","https://www.sciencedirect.com/science/article/pii/S1751157714000182"
"A403","Approximation to the Study of Scientific Production of AEIPRO's International Congresses in Engineering and Project Management","The paper shows the results from the analysis of scientific activity developed at Engineering International Congresses and Project Management organized by the Asociación Española de Dirección e Ingeniería de Proyectos (AEIPRO) (Spanish Association of Engineering and Management Project). Through the visualization of the scientific domain and by network analysis, we intend to provide a different perspective to the study of convergent relationships of literature developed at these international events.The results allow to approximate the scientific knowledge foundation in Project Engineering developed at AEIPRO International congresses between 1998 and 2012, providing descriptive results of the degree of research integration, the distribution of international contribution, the scientific collaboration between universities, professional and scientific institutions, and also identifying scientific research fronts in order to promote scientific research in this field of science, which is relevant due to its scope and implication in different environments. Copyright © 2014 Elsevier Science Ltd. All rights reserved.","Information visualization,scientific domain analysis,network analysis","DanteGuerreroab,JesúsMartínez-Almelacd,José L.Yagüee,GersonLa Rosaa,CatherinGiróna,KarenZatána","Procedia - Social and Behavioral Sciences","https://doi.org/10.1016/j.sbspro.2014.03.089","https://www.sciencedirect.com/science/article/pii/S1877042814021806"
"A404","Special Issue on Advances in Computer Supported Collaboration: Systems and Technologies","","","AnnaDivoli(Guest Editors),DomenicoPotena,ClaudiaDiamantini,Waleed W.Smari","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2013.11.001","https://www.sciencedirect.com/science/article/pii/S0167739X13002549"
"A405","Chapter Four: Nature of the Resistive Switching Phenomena in TiO2 and SrTiO3: Origin of the Reversible Insulator–Metal Transition","The review is devoted to the elucidation of the nature of the resistive switching (RS) phenomena in prototypical band-insulating transition metal oxides, single crystals of TiO2 and SrTiO3. Our analysis focuses on the related insulator–metal transition under the influence of different stimuli, such as chemical gradient, electrical gradient, or combination of these. We have collected evidence, including new fundamental experiments, that this reversible insulator–metal transition is a highly local process on the nanometer scale. Important factors are: (1) the mass and charge transport along dislocations, (2) the special role of the surface region with a network of dislocations, and (3) the reversible transformation of Ti-rich oxides with the general form TinO2n- 1. It is demonstrated that the current flow in stoichiometric single crystals of TiO2 and SrTiO3 is channeled along the network of dislocations and that the insulator–metal transition occurs predominantly in the skin region of the crystals in connection with a heterogeneous chemical restructuring. We show that the filamentary transport through the crystals and chemical restructuring at the oxide/metal interface also lies at the heart of the electrodegradation and RS. The concept that the real crystals of TiO2 and SrTiO3 should be regarded as composite materials, consisting of a perfect dielectric matrix acting as a spectator and extended defects constituting active nanowires, leads to a paradigm change in the interpretation of the nature of the electric transport phenomena for these materials and allows to disentangle the very complex effects giving rise to RS.","Resistive RAM,Transition-metal oxide,Extended defect,Insulator–metal transition,Electronic transport,Electrodegradation,Resistive switching","KrzysztofSzot*§,GustavBihlmayer*†,WolfgangSpeier‡","Solid State Physics","https://doi.org/10.1016/B978-0-12-800175-2.00004-2","https://www.sciencedirect.com/science/article/pii/B9780128001752000042"
"A406","Chapter 1: Introduction","This chapter reveals that psychology has a major explanatory problem. Psychologists do not agree on how to explain their findings. Unlike mature sciences that are organized around principles, psychology is organized around individuals who have proposed different ways to explain psychological and behavioral phenomena. Clinicians have an evidence–theory knowledge gap in that they have developed treatments that work based on their personal and professional lives but cannot explain how they work in principled scientific terms. Some psychologists see this as healthy diversity while others see it as corrosive disunity. Psychologists are as reluctant to use other people’s theories as they are to use their toothbrushes. Psychologists are also theory shy. Moreover, their preferred biopsychosocial model is shown to be a simple list of ingredients that carry no explanatory value. Box and arrow and statistical models impute causality but do not provide causal mechanism information. They can’t because there are no psychological mechanisms because there is no psychological substrate for them to operate on. Psychology can either ignore this anomaly or embrace reductionistic neuroscience and some form of emergent network theory. Reductionism provides but half of a complete explanation. Emergence provides the other explanatory half. The proposed Bio<U+2194>Psychology Network Theory combines emergence and reductionism.","anomalies,disunification,emergence,explanation,explanatory complement,reductionism","Warren W.Tryon","Cognitive Neuroscience and Psychotherapy,Cognitive Neuroscience and Psychotherapy","https://doi.org/10.1016/B978-0-12-420071-5.00001-6","https://www.sciencedirect.com/science/article/pii/B9780124200715000016"
"A407","6.04: Text Mining","It is becoming increasingly difficult to keep up with the amount of information published in the scientific literature, both for domain experts and for the sake of maintaining up-to-date biological databases based on manual curation of articles. This issue has been addressed with the help of text mining technologies specifically adapted to the biomedical domain. The aim of these strategies is to be more efficient in the retrieval and classification of relevant documents and the detection of bio-entities in text. Text mining is used for the automatic extraction of interactions between and functional annotations of biological substances and links articles with existing objects in the annotation databases. This chapter provides a general overview of the main tasks in biomedical text mining and natural language processing, introducing the underlying methods and existing applications tailored to handle the rapidly growing amount of literature data.","BioCreative,Biomedical literature,Information extraction,Information retrieval,Natural language processing,Text categorization,Text mining","M.Krallinger,F.Leitner,M.Vazquez,A.Valencia","Comprehensive Biomedical Physics","https://doi.org/10.1016/B978-0-444-53632-7.01107-2","https://www.sciencedirect.com/science/article/pii/B9780444536327011072"
"A408","91: Cancer of the Breast","","","Antonio C.Wolff,Susan M.Domchek,Nancy E.Davidson,VirgilioSacchini,BerylMcCormick","Abeloff's Clinical Oncology,Abeloff's Clinical Oncology (Fifth Edition)","https://doi.org/10.1016/B978-1-4557-2865-7.00091-6","https://www.sciencedirect.com/science/article/pii/B9781455728657000916"
"A409","Part IV: Information Architecture","","Information architecture,data architecture,data governance,business data glossary architecture,data ownership architecture,data access rights architecture,ETL data masking architecture,canned report access architecture,data stewardship,data discovery,semantic modeling,architecture governance component registry,data governance dashboard,data obfuscation architecture,data modeling architecture,reference data management—product master,reference data management—code tables,reference data management—external files,data in motion architecture,data virtualization architecture,ETL architecture,ESB architecture,CEP architecture,content management architecture,master data management,MDM,logical data architecture,LDA,code tables,external files,operational workflow,reference data,activity data,initial business setup,conducting business,analyzing business,business data glossary,business metadata,identifying the source of data,extracting data to a landing zone,data profiling,data standardization,data integration,data ownership,data access rights,sensitive data,masked,encrypted,canned report with variable data,canned report with fixed data,treaty zone,jurisdictional level,authority document level,data steward level,data discovery architecture,data landscape,Big Data,ontology,document management,taxonomy of legislative jurisdictions,administration,document development,approval process,production use,metrics,data obfuscation,data access restrictions,data masking,data encryption,data at rest,DAR,data in motion,DIM,protection of business communications,SSN,data modeling,conceptual data model,logical data model,physical data model,normalization,1NF,2NF,3NF,4NF,5NF,6NF,7NF,DKNF,BCNF,weaknesses or normalization,abstraction,rules of data abstraction,class words,1AF,2AF,3AF,4AF,transaction path analysis,TAPA,reference data management,product master management,metadata,code tables management,ISO,International Organization for Standardization,external files management,A.M Best,Bank of Canada,Bank of England,Dun & Bradstreet,Equifax,Experian,Fitch,Moody’s,Morningstar,United Nations,ETL,ESB,CEP,FTP,XML,data streaming,data virtualization,ODS,data warehouse,extract transform and load,ETL CASE tool,enterprise service bus,SOAP,service-oriented architecture protocol,complex event processing,content management","James V.Luisi","Pragmatic Enterprise Architecture,Pragmatic Enterprise Architecture","https://doi.org/10.1016/B978-0-12-800205-6.00004-4","https://www.sciencedirect.com/science/article/pii/B9780128002056000044"
"A410","Chapter 5: Education and Innovation","","Curriculum,Design,Digital Technologies,Independent Learning,Innovation,MOOCs","RonaldoMota,DavidScott","Education for Innovation and Independent Learning,Education for Innovation and Independent Learning","https://doi.org/10.1016/B978-0-12-800847-8.00005-3","https://www.sciencedirect.com/science/article/pii/B9780128008478000053"
"A411","2: Changing knowledge ecologies and the transformation of the scholarly journal","This chapter is an overview of the current state of scholarly journals, not (just) as an activity to be described in terms of its changing business processes but more fundamentally as the pivot point in a broader knowledge system that is itself in a process of transformation. After locating journals in what we characterize as a process of knowledge design, the chapter goes on to discuss some of the deeply disruptive aspects of the contemporary moment. These not only portend potential transformations in the form of the journal, but possibly also in the knowledge systems that the journal in its heritage form has supported. These disruptive forces are represented by changing technological, economic, distributional, geographic, interdisciplinary and social relations to knowledge.The chapter goes on to examine three specific breaking points. The first breaking point is in business models – the unsustainable costs and inefficiencies of traditional commercial publishing, the rise of open access and the challenge of developing sustainable publishing models. The second potential breaking point is the credibility of the peer-review system: its accountability, its textual practices, the validity of its measures and its exclusionary network effects. The third breaking point is post-publication evaluation, centred primarily on citation analysis as a proxy for impact. We argue that the prevailing system of impact analysis is deeply flawed. Its validity as a measure of knowledge is questionable, as is the reliability of the data used as evidence.The chapter ends with suggestions intended to contribute to discussion about the transformation of the academic journal and the creation of new knowledge systems: sustainable publishing models, frameworks for guardianship of intellectual property, criterion-referenced peer review, greater reflexivity in the review process, incremental knowledge refinement, more widely distributed sites of knowledge production and inclusive knowledge cultures, new types of scholarly text, and more reliable impact metrics.","academic journals,knowledge ecologies,publishing technologies,journal publishing business models,open access publishing,peer review,knowledge evaluation,citation analyses,impact metrics,impact factor","BillCope,MaryKalantzis","The Future of the Academic Journal,The Future of the Academic Journal (Second edition)","https://doi.org/10.1533/9781780634647.9","https://www.sciencedirect.com/science/article/pii/B9781843347835500021"
"A412","Visual topical analysis of Chinese and American Library and Information Science research institutions","Research institutions play an important role in scientific research and technical innovation. The topical analysis of research institutions in different countries can facilitate mutual learning and promote potential collaboration. In this study, we illustrate how an unsupervised artificial neural network technique Self-Organizing Map (SOM) can be used to visually analyze the research fields of research institutions. A novel SOM display named Compound Component Plane (CCP) was presented and applied to determine the institutions which made significant contributions to the salient research fields. Eighty-seven Chinese and American LIS institutions and the technical LIS fields were taken as examples. Potential international and domestic collaborators were identified based upon their research similarities. An approach of dividing research institutions into clusters was proposed based on their geometric distances in the SOM display, the U-matrix values and the most salient research topics they involved. The concepts of swarm institutions, pivots and landmarks were also defined and their instances were identified.","Self-Organizing Map,Compound Component Plane,Topical analysis,Research institution","LuAna,ChuanmingYub,GangLia","Journal of Informetrics","https://doi.org/10.1016/j.joi.2013.12.002","https://www.sciencedirect.com/science/article/pii/S1751157713001119"
"A413","Research dynamics: Measuring the continuity and popularity of research topics","Dynamic development is an intrinsic characteristic of research topics. To study this, this paper proposes two sets of topic attributes to examine topic dynamic characteristics: topic continuity and topic popularity. Topic continuity comprises six attributes: steady, concentrating, diluting, sporadic, transforming, and emerging topics; topic popularity comprises three attributes: rising, declining, and fluctuating topics. These attributes are applied to a data set on library and information science publications during the past 11 years (2001–2011). Results show that topics on “web information retrieval”, “citation and bibliometrics”, “system and technology”, and “health science” have the highest average popularity; topics on “h-index”, “online communities”, “data preservation”, “social media”, and “web analysis” are increasingly becoming popular in library and information science.","Topic analysis,Networks,Popularity,Continuity,Dynamics","ErjiaYan","Journal of Informetrics","https://doi.org/10.1016/j.joi.2013.10.010","https://www.sciencedirect.com/science/article/pii/S1751157713000874"
"A414","Chapter 5: Geometric Representations in Biomedical Informatics: Applications in Automated Text Analysis","This chapter is concerned with geometric representations of biomedical data. In it, we discuss how data elements with multiple features can be considered as vectors in a high-dimensional space, enabling the application of distance metrics as a means to estimate their similarity or relatedness for the purpose of information retrieval, exploration, or classification. In terms of applications, the emphasis in this chapter is on the representation of biomedical text. However, the methods are broadly applicable, and examples from other cases of biomedical research will at times be provided to illustrate this point.","Geometric representations,Information retrieval,Latent semantic indexing,Random Indexing,Distributional semantics","TrevorCohena,DominicWiddowsb","Methods in Biomedical Informatics,Methods in Biomedical Informatics","https://doi.org/10.1016/B978-0-12-401678-1.00005-1","https://www.sciencedirect.com/science/article/pii/B9780124016781000051"
"A415","Content-based author co-citation analysis","Author co-citation analysis (ACA) has long been used as an effective method for identifying the intellectual structure of a research domain, but it relies on simple co-citation counting, which does not take the citation content into consideration. The present study proposes a new method for measuring the similarity between co-cited authors by considering author's citation content. We collected the full-text journal articles in the information science domain and extracted the citing sentences to calculate their similarity distances. We compared our method with traditional ACA and found out that our approach, while displaying a similar intellectual structure for the information science domain as the other baseline methods, also provides more details about the sub-disciplines in the domain than with traditional ACA.","Author co-citation analysis,Citation content analysis,Bibliometrics,Information science,Citation analysis","Yoo KyungJeonga,MinSonga,YingDingb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2013.12.001","https://www.sciencedirect.com/science/article/pii/S1751157713001107"
"A416","Chapter 5: Human-Computer Interaction for Medical Visualization","To efficiently support tasks in clinical practice, visual computing algorithms need to be integrated in a carefully designed user interface. The goal of regular clinical use requires to adopt a user-centered design approach. This comprises an in-depth analysis of the tasks to be solved and the target user group. Task analysis methods, such as observation and interviews, are discussed to enable readers to identify, which diagnostic or treatment processes are essential, which decisions have to be taken, which criteria are essential for such decisions, which information is needed to support such decisions, and how this information shall be displayed.The design and development of prototypes should be carried out only based on verified assumptions about the essential usage scenarios. This process usually starts with some kind of representation of the current solution, e.g., a workflow diagram or, more informally, a set of user stories. The process continues with a representation of user needs and their priorities as well as a representation of the envisioned solution. Thus, user interface design is much more than a nice visual wrap-up for some algorithms. It is instead a complex and highly iterative process, which requires early and continuous feedback from the target user group and other relevant stakeholders. Users of medical visualization systems are medical doctors from a specific discipline, such as radiology, surgery, nuclear medicine or radiation treatment, who use such tools for diagnosis support, treatment planning, and follow-up studies to evaluate the success of treatment.There are, of course, strong differences between research settings, where requirements may be vague, and more product-oriented developments, where precise functional goals and usability goals drive the whole process. We cover both situations but slightly focus on research projects. Among the many interaction techniques developed so far, 3D interaction is particularly relevant for medical visualization. Thus, we discuss 3D selection, 3D transformation and navigation. While in current practice, most medical visualization systems are operated with keyboard and mouse, more advanced input and output devices, e.g., 3D input devices, have great potential. Thus, we give an overview of such devices and the experiences gained in medical applications. A specially challenging situation for medical visualization is intraoperative use, where devices need to be sterile and surgeons need to focus on the patient. Interaction techniques and devices for these settings are also described. Finally, we discuss the evaluation of interaction techniques and user interfaces.","Task analysis,Scenario-based design,Workflows,Prototyping,Metaphors,User experience,Input devices,User studies,Mobile computing","BernhardPreim,CharlBotha","Visual Computing for Medicine,Visual Computing for Medicine (Second Edition)","https://doi.org/10.1016/B978-0-12-415873-3.00005-5","https://www.sciencedirect.com/science/article/pii/B9780124158733000055"
"A417","Differentiating language usage through topic models","Sociologists wishing to employ topic models in their research need a helpful guide that describes the variety of topic modeling procedures, their issues, and various means of resolving them so as to convincingly answer sociological questions. We present this overview by recounting a series of our prior collaborative projects that have employed and developed various forms of topic models to understand language differentiation in academe. With each project, we encountered a variety of model-specific issues concerning the validity of topics and their suitability to our data and research questions. We developed a variety of novel visualization techniques to make sense of topic-solutions and used a variety of techniques to validate our results. In addition, we created a variety of new topic modeling techniques and procedures suitable to different kinds of data and research questions.","Topic models,Language differentiation,Text,Domains,Culture,Sociology","Daniel A.McFarlanda,DanielRamageb,JasonChuangc,JeffreyHeerc,Christopher D.Manningd,DanielJurafskye","Poetics","https://doi.org/10.1016/j.poetic.2013.06.004","https://www.sciencedirect.com/science/article/pii/S0304422X13000442"
"A418","Visualizing of the structure of subject trends in Persian articles published during 2008–2012 in information organization domain","This research investigates structure of the subject trends in the Persian articles published during the period of 2008–2012 about “information organization” in Iranian journals and creates a semantic map for this domain. This structure has been considered in two sections: First, the weight of each subject term used in articles was indicated, and then the relationships amounts of terms were measured. Content analysis and weighting were used in the first section. The Vector Space Model formula was used in order to weight terms. In the second section, Co-term analysis was used, that is, the number of co-occurrence of any two terms in the same article. Then the term/document occurrence matrix of these terms was created and at last the relations significant between terms were measured by Pearson Correlation Coefficient. To illustrate the structure of information organization domain, Ucinet software was used. Findings show that high-weight categories in Persian articles are: “cataloging”, “information retrieval”, “information systems” and “authority files”. Furthermore through weighting, determined that in trends rate aspect, the terms “ontologies”, “cataloging”, “evaluation”, “Dewey Decimal Classification”, “fields”, “libraries and information centers” and “descriptors”, “Functional Requirements for Bibliographic Records”, “metadata elements” and “National library and archives of I.R. of Iran” are 10 highest-weight terms. Research findings about the relationships of terms show attention to “cataloging” by “IFLA” and “National library and archives of Iran” and critical approach to this subject. Some other findings about this show: “indexing” are considered by cataloging and thesauri, “metadata” are considered in web-based and information retrieval points of view, “ontologies” term is considered in approach of basic concepts, tools and relevance, and attention to some organizations such as “IFLA” and “National library and archives organization of Iran” besides “users” and their information needs. In terms of weighting and relationships between the subject terms in Persian articles, “cataloging” is in the center of information organization domain. The semantic map of information organization in Persian articles illustrates three region of subject area including: 1. Cataloging, 2. Ontologies, thesauri and information retrieval, and 3. Metadata and information retrieval.","Information organization,Semantic map,Term weighting,Co-term analysis,Term relationships,Subject trends,Information visualization,Cataloging,Ontologies,Information retrieval","MaryamMousavizadeha,MasumeBagherib,MansureBagheria,MasumeKarbala aghaie Kamrana","The International Information & Library Review","https://doi.org/10.1016/j.iilr.2013.10.005","https://www.sciencedirect.com/science/article/pii/S1057231713000258"
"A419","Formal Concept Analysis in knowledge processing: A survey on models and techniques","This is the first part of a large survey paper in which we analyze recent literature on Formal Concept Analysis (FCA) and some closely related disciplines using FCA. We collected 1072 papers published between 2003 and 2011 mentioning terms related to Formal Concept Analysis in the title, abstract and keywords. We developed a knowledge browsing environment to support our literature analysis process. We use the visualization capabilities of FCA to explore the literature, to discover and conceptually represent the main research topics in the FCA community. In this first part, we zoom in on and give an extensive overview of the papers published between 2003 and 2011 on developing FCA-based methods for knowledge processing. We also give an overview of the literature on FCA extensions such as pattern structures, logical concept analysis, relational concept analysis, power context families, fuzzy FCA, rough FCA, temporal and triadic concept analysis and discuss scalability issues.","Formal Concept Analysis (FCA),Knowledge discovery in databases,Text mining,Data analysis models,Systematic literature overview","JonasPoelmansab,Sergei O.Kuznetsovb,Dmitry I.Ignatovb,GuidoDedeneac","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2013.05.007","https://www.sciencedirect.com/science/article/pii/S0957417413002935"
"A420","Citation analysis: A social and dynamic approach to knowledge organization","Knowledge organization (KO) and bibliometrics have traditionally been seen as separate subfields of library and information science, but bibliometric techniques make it possible to identify candidate terms for thesauri and to organize knowledge by relating scientific papers and authors to each other and thereby indicating kinds of relatedness and semantic distance. It is therefore important to view bibliometric techniques as a family of approaches to KO in order to illustrate their relative strengths and weaknesses. The subfield of bibliometrics concerned with citation analysis forms a distinct approach to KO which is characterized by its social, historical and dynamic nature, its close dependence on scholarly literature and its explicit kind of literary warrant. The two main methods, co-citation analysis and bibliographic coupling represent different things and thus neither can be considered superior for all purposes. The main difference between traditional knowledge organization systems (KOSs) and maps based on citation analysis is that the first group represents intellectual KOSs, whereas the second represents social KOSs. For this reason bibliometric maps cannot be expected ever to be fully equivalent to scholarly taxonomies, but they are – along with other forms of KOSs – valuable tools for assisting users’ to orient themselves to the information ecology. Like other KOSs, citation-based maps cannot be neutral but will always be based on researchers’ decisions, which tend to favor certain interests and views at the expense of others.","Approaches to knowledge organization,Information organization,Bibliometrics,Citation analysis,Epistemology","BirgerHjørland","Information Processing & Management","https://doi.org/10.1016/j.ipm.2013.07.001","https://www.sciencedirect.com/science/article/pii/S0306457313000733"
"A421","Patent citation network analysis for the domain of organic photovoltaic cells: Country, institution, and technology field","The goal of this work is to understand the structure and characteristics of technological knowledge flows between countries, institutions, and technology fields in the field of organic photovoltaic cells. This study was conducted in three stages: data collection, network creation, and network analysis. For network analysis, network visualization, network topological analysis, and node centrality analysis were performed in sequence. The network topological analysis revealed that all three citation networks, i.e., countries, institutions, and technology fields, are scale-free networks that follow the power law and display, to a greater or lesser extent, a more efficient knowledge transfer capability than a random network of the same size. The node centrality analysis showed that the United States, Japan, and Germany are the most important citation centers in the country citation network, while Boeing, Konarka Technologies, Eastman Kodak, and Sharp are the most important in the institution citation network, and the U.S. patent classification (USPC) classes of 136, 257, and 428 are the most important in the technology field citation network, each playing critical roles in each the network as core nodes. In this study, we applied various concepts of centrality to the analysis of individual nodes and found that the results from the network topological analysis and the node centrality analysis are not significantly different. The proposed analysis framework in this paper is applicable to different science and technology domains.","EPFLÉcole Polytechnique Fédérale de Lausanne,GHGGreenhouse gas,USPCU.S. patent classification,USPTOU.S. Patent and Trademark Office,SET-Planthe Strategic Energy Technology Plan,TOETon of Oil Equivalent,Keywords,Patent citation network,Social network analysis,Node centrality,Organic photovoltaic cell","HochullChoeab,Duk HeeLeeb,Il WonSeob,Hee DaeKimc","Renewable and Sustainable Energy Reviews","https://doi.org/10.1016/j.rser.2013.05.037","https://www.sciencedirect.com/science/article/pii/S1364032113003407"
"A422","Social network and social capital in leadership and management research: A review of causal methods","This paper surveys the methods underlying the burgeoning body of leadership and management research on social networks and social capital (SNSC). A social network is a social structure made up of nodes connected by a set of ties. Social capital, in turn, refers to the structure, content, and perception of one's social relationships in the network. This paper presents an in-depth survey of the methods of using SNSC in leadership and management research. I first review how network scholars determine network boundaries, choose sampling techniques, and collect network data. I follow with a comprehensive survey of the statistical tools and analytical strategies prevalent in SNSC research. I then investigate the methodological rigor of 110 SNSC empirical studies in leadership and other management fields. My results show that 8.1% (3/37) specified network boundaries, 43.2% (49/103) used surveys to collect network data, and 52.3% (58/110) implemented at least one reviewed method. A further assessment reveals that only 39.7% (23/58) of papers somewhat justified the appropriateness of using such methods. The frequency distribution of coding criteria was similar across journals and over time. This review also includes several future research directives for SNSC leadership and management researchers.","Social networks,Social capital,Causal methods,Network dynamics,Instrumental variables","MingxiangLi","The Leadership Quarterly","https://doi.org/10.1016/j.leaqua.2013.04.005","https://www.sciencedirect.com/science/article/pii/S1048984313000398"
"A423","The role of pattern recognition in creative problem solving: A case study in search of new mathematics for biology","Rosen classified sciences into two categories: formalizable and unformalizable. Whereas formalizable sciences expressed in terms of mathematical theories were highly valued by Rutherford, Hutchins pointed out that unformalizable parts of soft sciences are of genuine interest and importance. Attempts to build mathematical theories for biology in the past century was met with modest and sporadic successes, and only in simple systems. In this article, a qualitative model of humans' high creativity is presented as a starting point to consider whether the gap between soft and hard sciences is bridgeable. Simonton's chance-configuration theory, which mimics the process of evolution, was modified and improved. By treating problem solving as a process of pattern recognition, the known dichotomy of visual thinking vs. verbal thinking can be recast in terms of analog pattern recognition (non-algorithmic process) and digital pattern recognition (algorithmic process), respectively. Additional concepts commonly encountered in computer science, operations research and artificial intelligence were also invoked: heuristic searching, parallel and sequential processing. The refurbished chance-configuration model is now capable of explaining several long-standing puzzles in human cognition: a) why novel discoveries often came without prior warning, b) why some creators had no ideas about the source of inspiration even after the fact, c) why some creators were consistently luckier than others, and, last but not least, d) why it was so difficult to explain what intuition, inspiration, insight, hunch, serendipity, etc. are all about. The predictive power of the present model was tested by means of resolving Zeno's paradox of Achilles and the Tortoise after one deliberately invoked visual thinking. Additional evidence of its predictive power must await future large-scale field studies. The analysis was further generalized to constructions of scientific theories in general. This approach is in line with Campbell's evolutionary epistemology. Instead of treating science as immutable Natural Laws, which already existed and which were just waiting to be discovered, scientific theories are regarded as humans' mental constructs, which must be invented to reconcile with observed natural phenomena. In this way, the pursuit of science is shifted from diligent and systematic (or random) searching for existing Natural Laws to firing up humans' imagination to comprehend Nature's behavioral pattern. The insights gained in understanding human creativity indicated that new mathematics that is capable of handling effectively parallel processing and human subjectivity is sorely needed. The past classification of formalizability vs. non-formalizability was made in reference to contemporary mathematics. Rosen's conclusion did not preclude future inventions of new biology-friendly mathematics.","Creativity,Pattern recognition,Sequential processing,Parallel processing,Heuristic search,Visual thinking","Felix T.Hong","Progress in Biophysics and Molecular Biology","https://doi.org/10.1016/j.pbiomolbio.2013.03.017","https://www.sciencedirect.com/science/article/pii/S007961071300031X"
"A424","The impact of university–industry collaboration networks on innovation in nanobiopharmaceuticals","This paper investigates the effects of multiplicative interaction between clustering and reach on members' knowledge creation and patent value based on complex network analysis in nanobiopharmaceuticals field. In order to avoid the high skew of patent value among patents, we use the weighted patent value as a proxy index of the invention's innovation performance rather than simple patent counts. The university–industry collaboration networks in the emerging and rapidly evolving interdisciplinary field are examined at firm-level. We further detect the impact of small world properties as well as the size of largest component on patent value and find that small-world structure has parabolical effect on patent value at firm-level. We add new evidence to the literature on this topic with an empirical investigation for the university–industry patent collaboration in the nanobiopharmaceutical field. The findings broaden and enrich the existing literature and can contribute to policy makers and relevant managers when making decisions for university and firm locality as well as the choices of the collaborators.","Nanobiopharmaceuticals,University–industry collaboration,S-curve models,Small world networks","JianchengGuanab1,QingjunZhaob1","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2012.11.013","https://www.sciencedirect.com/science/article/pii/S0040162512002995"
"A425","Scientific competency questions as the basis for semantically enriched open pharmacological space development","","","KamalAzzaoui1,EdgarJacoby14,StefanSenger2,Emiliano CuadradoRodríguez3,MabelLoza3,BarbaraZdrazil4,MartaPinto4,Antony J.Williams5,Victorde la Torre6,JordiMestres7,ManuelPastor7,OlivierTaboureau8,MatthiasRarey9,ChristineChichester10,StevePettifer11,NiklasBlomberg12a,LeeHarland13,BrynWilliams-Jones13,Gerhard F.Ecker4","Drug Discovery Today","https://doi.org/10.1016/j.drudis.2013.05.008","https://www.sciencedirect.com/science/article/pii/S1359644613001542"
"A426","Epilepsy, behavior, and art (Epilepsy, Brain, and Mind, part 1)","Epilepsy is both a disease of the brain and the mind. Brain diseases, structural and/or functional, underlie the appearance of epilepsy, but the notion of epilepsy is larger and cannot be reduced exclusively to the brain. We can therefore look at epilepsy from two angles. The first perspective is intrinsic: the etiology and pathophysiology, problems of therapy, impact on the brain networks, and the “mind” aspects of brain functions — cognitive, emotional, and affective. The second perspective is extrinsic: the social interactions of the person with epilepsy, the influence of the surrounding environment, and the influences of epilepsy on society. All these aspects reaching far beyond the pure biological nature of epilepsy have been the topics of two International Congresses of Epilepsy, Brain, and Mind that were held in Prague, Czech Republic, in 2010 and 2012 (the third Congress will be held in Brno, Czech Republic on April 3–5, 2014; www.epilepsy-brain-mind2014.eu). Here, we present the first of two papers with extended summaries of selected presentations of the 2012 Congress that focused on epilepsy, behavior, and art.","Epilepsy,Art,Music,Behavior,Mind,Psychiatry,Hallucinations,Cognition,Stress,Crime","IvanRektora,Steven C.Schachterb,ShaharArzyc,Stavros J.Baloyannisd,CarlBazile,MilanBrázdila,JeromeEngelJr.f,GerhardHelmstaedterg,Dale C.Hesdorfferh,MarilynJones-Gotmani,LadislavKesnerj,VladimírKomárekk,GünterKrämerl,Ilo E.Leppikm,Michael W.Mannn,MarcoMulao,Gail L.Rissem,Guy W.Stokerp,…,Amos D.Korczyns","Epilepsy & Behavior","https://doi.org/10.1016/j.yebeh.2013.03.011","https://www.sciencedirect.com/science/article/pii/S1525505013001509"
"A427","The distribution of references across texts: Some implications for citation analysis","In citation network analysis, complex behavior is reduced to a simple edge, namely, node A cites node B. The implicit assumption is that A is giving credit to, or acknowledging, B. It is also the case that the contributions of all citations are treated equally, even though some citations appear multiply in a text and others appear only once. In this study, we apply text-mining algorithms to a relatively large dataset (866 information science articles containing 32,496 bibliographic references) to demonstrate the differential contributions made by references. We (1) look at the placement of citations across the different sections of a journal article, and (2) identify highly cited works using two different counting methods (CountOne and CountX). We find that (1) the most highly cited works appear in the Introduction and Literature Review sections of citing papers, and (2) the citation rankings produced by CountOne and CountX differ. That is to say, counting the number of times a bibliographic reference is cited in a paper rather than treating all references the same no matter how many times they are invoked in the citing article reveals the differential contributions made by the cited works to the citing paper.","Content-based citation analysis,Citation,Mentioning,Citation analysis","YingDing,XiaozhongLiu,ChunGuo,BlaiseCronin","Journal of Informetrics","https://doi.org/10.1016/j.joi.2013.03.003","https://www.sciencedirect.com/science/article/pii/S1751157713000230"
"A428","Decomposing social and semantic networks in emerging “big data” research","This paper examines the structural patterns of networks of internationally co-authored SCI papers in the domain of research driven by big data and provides an empirical analysis of semantic patterns of paper titles. The results based on data collected from the DVD version of the 2011 SCI database identify the U.S. as the most central country, followed by the U.K., Germany, France, Italy, Australia, the Netherlands, Canada, and Spain, in that order. However, some countries (e.g., Portugal) with low degree centrality occupied relatively central positions in terms of betweenness centrality. The results of the semantic network analysis suggest that internationally co-authored papers tend to focus on primary technologies, particularly in terms of programming and related database issues. The results show that a combination of words and locations can provide a richer representation of an emerging field of science than the sum of the two separate representations.","Data science,Big data,International co-authorship,Social network analysis,SCI,Semantic network","Han WooParka,LoetLeydesdorffb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2013.05.004","https://www.sciencedirect.com/science/article/pii/S1751157713000473"
"A429","Key principles for developing industrially relevant strategic technology management toolkits","When considering the potential uptake and utilization of technology management tools by industry, it must be recognized that companies face the difficult challenges of selecting, adopting and integrating individual tools into a toolkit that must be implemented within their current organizational processes and systems. This situation is compounded by the lack of sound advice on integrating well-founded individual tools into a robust toolkit that has the necessary degree of flexibility such that they can be tailored for application to specific problems faced by individual organizations. As an initial stepping stone to offering a toolkit with empirically proven utility, this paper provides a conceptual foundation to the development of toolkits by outlining an underlying philosophical position based on observations from multiple research and commercial collaborations with industry. This stance is underpinned by a set of operationalized principles that can offer guidance to organizations when deciding upon the appropriate form, functions and features that should be embodied by any potential tool/toolkit. For example, a key objective of any tool is to aid decision-making and a core set of powerful, flexible, scaleable and modular tools should be sufficient to allow users to generate, explore, shape and implement possible solutions across a wide array of strategic issues. From our philosophical stance, the preferred mode of engagement is facilitated workshops with a participatory process that enables multiple perspectives and structures the conversation through visual representations in order to manage the cognitive load in the collaborative environment. The generic form of the tools should be configurable for the given context and utilized in a lightweight manner based on the premise of ‘start small and iterate fast’.","Technology management,Strategic planning,Management tool,Roadmapping","CliveKerr,ClareFarrukh,RobertPhaal,DavidProbert","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2012.09.006","https://www.sciencedirect.com/science/article/pii/S0040162512002181"
"A430","A patent intelligence system for strategic technology planning","Patent intelligence—the transformation of content found in multiple patents into technical, business, and legal insight—is considered a key factor in gaining a competitive advantage in technologically competitive business environments. Although keyword-based patent intelligence tools are widely used due to their simplicity and ease of use, they are limited in that they cannot represent key technological concepts and inventive knowledge by relying only on the frequency of occurrence of defined keywords. As a remedy, this paper proposes a Subject–Action–Object (SAO)-based patent intelligence system. SAO structures that can be extracted from textual patent information are known as the expertise and inventive findings of the relevant patent. On the basis of semantic analysis of patent SAO structures, our proposed intelligence system constructs patent maps and patent networks. Building on the maps and networks, the system provides specific functionalities including identification of technology trends and significant patents, detection of novel technologies, and identification of potential infringement. This paper describes the architecture of our proposed patent intelligence system in detail, and illustrates the system’s functionalities using case studies. We anticipate that our proposed system will be incorporated into the technology planning process to assist experts in the formulation of technology strategies.","Technology intelligence,Technology planning,Subject–Action–Object,SAO,Function,Patent map,Patent network,Patent mining,Intelligence system","HyunseokParka,KwangsooKimb,SungchulChoic,JanghyeokYoond","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2012.10.073","https://www.sciencedirect.com/science/article/pii/S0957417412012092"
"A431","Can’t see the forest for the leaves: Similarity and distance measures for hierarchical taxonomies with a patent classification example","Current measures of technological distance or similarity typically ignore a great deal of the information contained within the classification taxonomies upon which they are based. In this paper, I introduce two modifications which enable various common management research methods to fully make use of hierarchical classification data. Although the methods presented have broad applications, an extensive example exploring various measures of technological similarity based on the USPTO patent classification system is included. In addition to the general benefit of allowing the use of taxonomical data and thus more accurately reflecting the theoretical complexity of any underlying phenomenon, this methodology offers a number of other benefits specific to the patent context. These include the ability to model technological space within fields, since it correctly uses USPTO subclass level data, as well as the ability to accurately analyze similarity at the patent-to-patent dyadic level, since it calculates conceptual overlaps at the lowest level of the classification taxonomy. I explore the performance of these methods in two research contexts: (1) a patent-to-patent level sample within a single technological field and (2) an organization-to-organization level sample across industries. The results show that taxonomical methods generate more meaningful distributions of similarity scores within both samples and that similarity scores calculated via taxonomical methods have a more consistent relationship with citation likelihood and number of citations. Suggestions are provided for variants of this methodology for various technological and industrial classification systems and implications are drawn for future research in a wide range of domains.","Technological space,Patent data,Jaffe's distance measure,Classification,Taxonomy,Hierarchy,Similarity,Distance,Overlap,Knowledge flows,Knowledge recombination","Robert C.McNamee","Research Policy","https://doi.org/10.1016/j.respol.2013.01.006","https://www.sciencedirect.com/science/article/pii/S0048733313000115"
"A432","Unexpected novelty and familiarity orienting responses in lateral parietal cortex during recognition judgment","The role of lateral parietal cortex during recognition memory is heavily debated. We examined parietal activation during an Explicit Memory Cueing recognition paradigm that biases participants towards expecting novel or familiar stimuli on a trial-by-trial basis using anticipatory cues (“Likely Old”, “Likely New”), compared to trials with neutral cues (“????”). Three qualitatively distinct patterns were observed in the left lateral parietal cortex. An unexpected novelty response occurred in left anterior intraparietal cortex (IPS)/post-central gyrus (PoCG) in which greater activation was observed for new vs. old materials following the “Likely Old” cue, but not following the “Likely New” cue. In contrast, anterior angular gyrus demonstrated an unexpected familiarity response with greater activation for old vs. new materials following the “Likely New” cue, but not the “Likely Old” cue. Thus these two regions demonstrated increased responses that were selective for either new or old materials respectively, but only when they were unexpected. In contrast, a mid IPS area demonstrated greater response for whichever class of memoranda was unanticipated given the cue condition (an unexpected memory response). Analogous response patterns in regions outside of parietal cortex, and the results of a resting state connectivity analysis, suggested these three response patterns were associated with visuo-spatial orienting following unexpected novelty, source monitoring operations following unexpected familiarity, and general executive control processes following violated expectations. These findings support a Memory Orienting Model of the left lateral parietal cortex in which the region is linked to the investigation of unexpected novelty or familiarity in the environment.","Episodic memory,Parietal cortex,Prefrontal cortex,Decision biasing,External cues","AntonioJaegerab1,AlexKonkela1,Ian G.Dobbinsa","Neuropsychologia","https://doi.org/10.1016/j.neuropsychologia.2013.02.018","https://www.sciencedirect.com/science/article/pii/S0028393213000687"
"A433","A survey on socio-semantic information retrieval","The rise of the Social Web and advances in the Semantic Web provides unprecedented possibilities for the development of novel methods to enhance the information retrieval (IR) process by including varying degrees of semantics. We shed light on the corresponding notion of semantically-enhanced information retrieval by presenting state-of-the art techniques in related research areas. We describe techniques based on the main processes of a typical IR workflow and map them onto three main types of semantics, which vary from formal semantic knowledge representations and content-based semantics to social semantics emerging through usage and user interactions.","Information retrieval,Personalized search,Emergent semantics,Formal semantics,Content semantics","KarinSchoefeggera,TanelTammetb,MichaelGranitzerc","Computer Science Review","https://doi.org/10.1016/j.cosrev.2013.03.001","https://www.sciencedirect.com/science/article/pii/S1574013713000099"
"A434","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2013.03.002","https://www.sciencedirect.com/science/article/pii/S0140670113000118"
"A435","Discovering role-based virtual knowledge flows for organizational knowledge support","In knowledge-intensive work environments, workers need task-relevant knowledge and documents to support the execution of tasks. A knowledge flow (KF) represents an individual's or group's knowledge-needs and referencing behavior of codified knowledge during the performance of organizational tasks. Through knowledge flows, organizations can provide workers with task-relevant knowledge to satisfy their knowledge-needs. In teamwork environments, knowledge workers with different roles and task functions usually have diverse knowledge-needs, but conventional KF models cannot satisfy such needs. In a previous work, we proposed a novel concept and theoretical model called Knowledge Flow View (KFV). Based on workers' diverse knowledge-needs, the KFV model abstracts knowledge nodes of partial KFs and generates virtual knowledge nodes through a knowledge concept generalization procedure. However, the KFV model did not consider the diverse knowledge-needs of workers who play different roles in a team. Therefore, in this work, we propose a role-based KFV model that discovers role-based virtual knowledge flows to satisfy the knowledge-needs of different roles. First, we analyze the level of knowledge required by workers to fulfill various roles. Then, we develop role-based knowledge flow abstraction methods that generate appropriate virtual knowledge nodes to provide sufficient knowledge for each role. The proposed role-based KFV model enhances the efficiency of KF usage, as well as the effectiveness of knowledge sharing and knowledge support in organizations.","Knowledge flow,Knowledge flow view,Knowledge support,Knowledge management,Role,Ontology","Duen-RenLiu,Chih-WeiLin,Hui-FangChen","Decision Support Systems","https://doi.org/10.1016/j.dss.2012.11.018","https://www.sciencedirect.com/science/article/pii/S0167923613000316"
"A436","Collective dynamics in knowledge networks: Emerging trends analysis","This paper addresses emerging trends in the collective dynamics found in knowledge networks, those networks composed of the relationships among knowledge sources, such as citation networks and keyword networks. In studying the formation and detection of new trends in the process of knowledge evolution, we use the collective dynamics approach to construct a network of knowledge clusters based on citation clustering. This approach explores the processes and rules of new trends emerging in knowledge clusters by examining the continuous changes in keyword vectors found in the interaction and coordination between evolving knowledge clusters. In direct citation networks, the collective dynamics approach is found to be superior to the baseline method, especially in predicting small knowledge fields with less data and more uncertainties.","Knowledge networks,Dynamical network,Collective dynamics,Emerging trends,Research front","XiangLiuab,TingtingJianga,FeichengMaa","Journal of Informetrics","https://doi.org/10.1016/j.joi.2013.01.003","https://www.sciencedirect.com/science/article/pii/S1751157713000059"
"A437","A graph-based recovery and decomposition of Swanson’s hypothesis using semantic predications","ObjectivesThis paper presents a methodology for recovering and decomposing Swanson’s Raynaud Syndrome–Fish Oil hypothesis semi-automatically. The methodology leverages the semantics of assertions extracted from biomedical literature (called semantic predications) along with structured background knowledge and graph-based algorithms to semi-automatically capture the informative associations originally discovered manually by Swanson. Demonstrating that Swanson’s manually intensive techniques can be undertaken semi-automatically, paves the way for fully automatic semantics-based hypothesis generation from scientific literature.,MethodsSemantic predications obtained from biomedical literature allow the construction of labeled directed graphs which contain various associations among concepts from the literature. By aggregating such associations into informative subgraphs, some of the relevant details originally articulated by Swanson have been uncovered. However, by leveraging background knowledge to bridge important knowledge gaps in the literature, a methodology for semi-automatically capturing the detailed associations originally explicated in natural language by Swanson, has been developed.,ResultsOur methodology not only recovered the three associations commonly recognized as Swanson’s hypothesis, but also decomposed them into an additional 16 detailed associations, formulated as chains of semantic predications. Altogether, 14 out of the 19 associations that can be attributed to Swanson were retrieved using our approach. To the best of our knowledge, such an in-depth recovery and decomposition of Swanson’s hypothesis has never been attempted.,ConclusionIn this work therefore, we presented a methodology to semi-automatically recover and decompose Swanson’s RS-DFO hypothesis using semantic representations and graph algorithms. Our methodology provides new insights into potential prerequisites for semantics-driven Literature-Based Discovery (LBD). Based on our observations, three critical aspects of LBD include: (1) the need for more expressive representations beyond Swanson’s ABC model; (2) an ability to accurately extract semantic information from text; and (3) the semantic integration of scientific literature and structured background knowledge.","Literature-Based Discovery (LBD),Swanson’s hypothesis,Semantic predications,Semantic associations,Subgraph creation,Background knowledge","DelroyCamerona,OlivierBodenreiderc,HimaYalamanchilib,TuDanhb,SreeramVallabhanenib,KrishnaprasadThirunarayana,Amit P.Shetha,Thomas C.Rindfleschc","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2012.09.004","https://www.sciencedirect.com/science/article/pii/S1532046412001517"
"A438","Nanometal plasmonpolaritons","A nanometal is a nanometric metallic structure. A plasmon is a collective excitation of an electron gas. A plasmon polariton is a plasmon coupled to an electromagnetic wave. Whereas plasmons in bulk metal do not couple to light fields, a thin metal film can sustain surface polaritons when excited by light. This can be achieved via an evanescent prism coupling, the help of surface corrugations to ensure momentum matching, etc. Such surface polaritons propagate as coherent electron oscillations parallel to the metal surface and decay exponentially perpendicular to it. Thus, the electromagnetic energy is confined to dimensions below the diffraction limit perpendicular to the metal surface. Corrugations can further act as light scattering centers for surface plasmons, allowing for the fabrication of interesting optical devices such as an all-optical transistor. This surface science report reviews the present literature on surface polaritons in nanostructures and waveguides. Models, computer simulations and experiments are reviewed and illustrated by simple comprehensive examples. Experimental and theoretical studies of short and long range sensing using plasmonic nanostructures are in particular considered. Some applications for nanometals are outlined. The interactions between metallic particles and films due to the interactions between several localized and delocalized surface plasmons are among the examples. Applications to fluorescence extraction in the interaction between near-field and matter are also included here. Nevertheless this report cannot be an exhaustive one. This would be an endless task. It leaves space for future Surface Science Reports issues by colleagues whose achievements do not appearhere.","Polariton,Plasmon,Nanometal,Transmission,Filter,Multiplexer,Fano resonance,Biosensor,Near-field,Fluorescence","AbdellatifAkjouja,Gae¨tanLévêquea,SabineSzuneritsb,YanPenneca,BahramDjafari-Rouhania,RabahBoukherroubb,LeonardDobrzynskia","Surface Science Reports","https://doi.org/10.1016/j.surfrep.2012.10.001","https://www.sciencedirect.com/science/article/pii/S0167572912000428"
"A439","Efficient semantic network construction with application to PubMed search","Exploring PubMed to find relevant information is challenging and time-consuming because PubMed typically returns a long list of articles as a result of query. Semantic network helps users to explore a large document collection and to capture key concepts and relationships among the concepts. The semantic network also serves to broaden the user’s knowledge and extend query keyword by detecting and visualizing new related concepts or relations hidden in the retrieved documents. The problem of existing semantic network techniques is that they typically produce many redundant relationships, which prevents users from quickly capturing the underlying relationships among concepts. This paper develops an online PubMed search system, which displays semantic networks having no redundant relationships in real-time as a result of query. To do so, we propose an efficient semantic network construction algorithm, which prevents producing redundant relationships during the network construction. Our extensive experiments on actual PubMed data show that the proposed method (COMPACT) is significantly faster than the method removing redundant relationships afterward. Our method is implemented and integrated into a relevance-feedback PubMed search engine, called RefMed, “http://dm.postech.ac.kr/refmed”.","Semantic network construction,Redundant relationship removal,PubMed,Algorithm,Information retireval engine","JinohOha,TaehoonKima,SunParka,HwanjoYua,Young HoLeeb","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2012.10.019","https://www.sciencedirect.com/science/article/pii/S0950705112003085"
"A440","Data mining of social networks represented as graphs","In this survey we review the literature and concepts of the data mining of social networks, with special emphasis on their representation as a graph structure. The survey is divided into two principal parts: first we conduct a survey of the literature which forms the ‘basis’ and background for the field; second we define a set of ‘hot topics’ which are currently in vogue in congresses and the literature. The ‘basis’ or background part is divided into four major themes: graph theory, social networks, online social networks and graph mining. The graph mining theme is organized into ten subthemes. The second, ‘hot topic’ part, is divided into five major themes: communities, influence and recommendation, models metrics and dynamics, behaviour and relationships, and information diffusion.","Graphs,Online social networks,Graph mining,Data mining,Statistical analysis,Data modelling","David F.Nettleton","Computer Science Review","https://doi.org/10.1016/j.cosrev.2012.12.001","https://www.sciencedirect.com/science/article/pii/S1574013712000445"
"A441","Exploring the E-science Knowledge Base through Co-citation Analysis","E-Science is the “science of this age”; it is realized through collaborative scientific enquiry which requires utilization of non-trivial amounts of computing resources and massive data sets. In this paper we explore the e-Science knowledge base through co-citation analysis of extant literature. Our objective is to use the knowledge domain visualization software CiteSpace to identifying the turning point articles and authors. In other words, our analysis is not solely based on tabulating the frequency of co-cited articles and authors, but the identification of landmark articles and authors irrespective of their co-citation count. The dataset for this analysis is downloaded from the ISI Web of Science and includes approx. 1000 articles. It is expected that this paper will be an important source of reference for academics and researchers working in the area of e-Science and its three technology enablers - grid computing, desktop grids and cloud computing.","e-Science,co-citation analysis,grid computing,desktop grid computing,cloud computing","NavonilMustafeea,NikBessisb,Simon J.E.Taylorc,SteliosSotiriadisb","Procedia Computer Science","https://doi.org/10.1016/j.procs.2013.06.078","https://www.sciencedirect.com/science/article/pii/S1877050913006868"
"A442","Putting “Human Crowds” in the Loop of Bibliography Evaluation: A Collaborative Working Environment for CSCW Publications","The current impact of financial crisis on societal and scientific frameworks has raised the need to harvest and evaluate vast volumes of data in a socially-mediated interaction context to reduce knowledge gaps and accelerate innovation at a global scale. Existing mechanisms are inefficient for a single human to classify and transform data into knowledge patterns from a large number of publications. This time-consuming and computationally difficult activity requires a substantial cognitive effort grounded on scientific metrics and theoretical foundations to produce quality metadata through different knowledge representations. This paper reports on a work in progress community self-organizing bibliographic information system for semantic analytics focused on what scientific research data mean, and how they can be best interpreted through a division of intellectual labor among social, computer, and citizen scientists. Such a crowd labor ecosystem should be not restricted to traditional bibliometric approaches, attempting to uncover patterns and trends in publication data sets whilst intellectual connections can be examined to demonstrate how a scientific field is conceptually, intellectually, and socially structured.","Crowdsourcing,CSCW,groupware,human computation,bibliographic information systems,scientific data repositories,scientometrics,socially-mediated bibliography evaluation","AntónioCorreiaa,JorgeSantosa,DiogoAzevedoa,HugoParedesab,BenjamimFonsecaab","Procedia Technology","https://doi.org/10.1016/j.protcy.2013.12.064","https://www.sciencedirect.com/science/article/pii/S2212017313002181"
"A443","5: We are not alone but part of the linked data environment","The very essence of the concept of linked open data is that one’s local data points to other data, i.e. to external sources, and that those other data have one’s data as a target. Yet it is not enough to link within one’s community. This chapter therefore describes the processes by which the library community reaches out towards other communities, such as those of museums and archives as part of the cultural heritage sector and the publishing and rights management community. It also describes the potential of controlled vocabularies or authoritative sources of information which can be shared, reused, and function as nodes of linked data not only by libraries but also by other communities. In the final part of the chapter the impact that the users of social networks as well as machines have on generating metadata as linked open data will be discussed.","harmonization,CIDOC CRM,FRBRoo,EAD,ONIX,RDA/ONIX Framework,value vocabularies,user generated metadata","MirnaWiller,GordonDunsire","Bibliographic Information Organization in the Semantic Web,Bibliographic Information Organization in the Semantic Web","https://doi.org/10.1016/B978-1-84334-731-6.50005-3","https://www.sciencedirect.com/science/article/pii/B9781843347316500053"
"A444","2: Semantic web and linked open data","To understand the new technological environment of the Semantic Web and linked open data, and to develop bibliographic services within it, it is necessary to understand some basic concepts and terms. A practical illustration of the state of the art of information retrieval using bibliographic control that preceded the Internet is followed by a brief description of the layering of the World Wide Web on top of the Internet, and the Semantic Web on top of that. Technical concepts relevant to Universal Bibliographic Control are described and illustrated with library examples, covering: the Internet, World Wide Web and Semantic Web; Resource Description Framework, the structural foundation of the Semantic Web, the expression of metadata statements as triples, and Uniform Resource Identifiers and namespaces; mathematical graphs as representations of triples; ontologies and application profiles as ways of expressing metadata schema; the open world assumption; the importance of metadata provenance; mapping, alignment and harmonization of metadata using different schema; and linked open data and the linking data cloud.","Semantic Web,linked open data,Resource Description Framework,triples,mapping,harmonization,datasets,value vocabularies,element sets","MirnaWiller,GordonDunsire","Bibliographic Information Organization in the Semantic Web,Bibliographic Information Organization in the Semantic Web","https://doi.org/10.1016/B978-1-84334-731-6.50002-8","https://www.sciencedirect.com/science/article/pii/B9781843347316500028"
"A445","Mining diversity subgraph in multidisciplinary scientific collaboration networks: A meso perspective","This paper proposes a framework to analyze the interdisciplinary collaboration in a coauthorship network from a meso perspective using topic modeling: (1) a customized topic model is developed to capture and formalize the interdisciplinary feature; and (2) the two algorithms Diversity Subgraph Extraction (DSE) and Constraint-based Diversity Subgraph Extraction (CDSE) are designed and implemented to extract a meso view, i.e. a diversity subgraph of the interdisciplinary collaboration. The proposed framework is demonstrated using a coauthorship network in the field of computer science. A comparison between DSE and Breadth First Search (BSF)-based subgraph extraction favors DSE in capturing the diversity in interdisciplinary collaboration. Potential possibilities for studying various research topics based on the proposed framework of analysis are discussed.","Scientific collaboration,Network analysis,Subgraph detection","BingHea,YingDinga,JieTangc,VigneshReguramalingamb,JohanBollenb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2012.09.005","https://www.sciencedirect.com/science/article/pii/S1751157712000806"
"A446","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2012.12.002","https://www.sciencedirect.com/science/article/pii/S0140670112000537"
"A447","Chapter 4: Group 15 (N, P, As, Sb and Bi) Alkaline Earth Compounds","","","R.C.Ropp","Encyclopedia of the Alkaline Earth Compounds,Encyclopedia of the Alkaline Earth Compounds","https://doi.org/10.1016/B978-0-444-59550-8.00004-1","https://www.sciencedirect.com/science/article/pii/B9780444595508000041"
"A448","5: The semantic search in life sciences","For researchers and scientists, Web 3.0 technologies are mainly visible in the form of semantic technologies embedded into biomedical databases. In this chapter, we explore how the famous Medline can be searched through alternative smart interfaces, and how a semantic approach changes the search experience. PubMed offers a rich and popular search engine for Medline and yet its interface seems not to be very user-friendly. Indeed, a large majority of scientists keep on using PubMed like Google without taking into account any filters or metadata like MeSH terms. Nonetheless, scientists need more efficient tools to explore large amounts of data in a methodical way. One wonders if there is a way to offer both ease of use and richness in a single interface. That is the aim of semantic search interfaces that provide contextual filters and a relevant selection of metadata to improve the user browsing experience. Some large STM publishers have now widely adopted such semantic interfaces in order to meet customers’ expectations and gain new markets.","PubMed,alternative interface,semantic search interface,information research,Medline,MeSH thesaurus,STM publishers","HervéBasset,FrançoisBoutin","From Science 2.0 to Pharma 3.0,From Science 2.0 to Pharma 3.0","https://doi.org/10.1016/B978-1-84334-709-5.50005-3","https://www.sciencedirect.com/science/article/pii/B9781843347095500053"
"A449","International knowledge spillover through co-inventors: An empirical study using Chinese assignees' patent data","Knowledge spillover is a widespread phenomenon among main economic entities of the world. Most of prior studies adopt patent citation data to indicate the traces of knowledge flows. However, patent citation is a noisy indicator in reflecting technology diffusion and has limitation in identifying knowledge flows induced by personal contacts. In this paper, we propose a method for the construction of international knowledge spillover networks by incorporating patent citations with co-inventors information so as to detect the change of network structure induced by social ties of co-inventors and reflect both explicit and tacit knowledge diffusions across national frontiers. We apply the proposed method to a sample of power system related patents granted to Chinese assignees by USPTO during 2000–2007. Our results confirm that patent citation is not an adequate indicator of knowledge flows since it reflects very few knowledge exchanging channel. However, co-invented relationships which provide trace of tacit knowledge flows can complement the patent citation data to produce a fuller picture of international knowledge spillover. The incorporation of co-inventors data helps produce a Sino-American spillover network with a structure changed from extremely loose to loosely-tied in whole but cohesive locally. The cohesive subgroups contribute much to knowledge spillover from U.S. to China and dissipate internally among Chinese firms.","Knowledge spillover,Patent citation network,Network structure,Cohesive cluster,Power system","Xi-YaoXianga,HongCaib,ShuiLamc,Yun-LongPeib","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2012.07.003","https://www.sciencedirect.com/science/article/pii/S0040162512001722"
"A450","A review of EO image information mining","We analyze the state of the art of content-based retrieval in Earth observation image archives focusing on complete systems showing promise for operational implementation. The different paradigms at the basis of the main system families are introduced. The approaches taken are considered, focusing in particular on the phases after primitive feature extraction. The solutions envisaged for the issues related to feature simplification and synthesis, indexing, semantic labeling are reviewed. The methodologies for query specification and execution are evaluated. Conclusions are drawn on the state of published research in Earth observation (EO) mining.","Remote sensing,Databases,Content-based image retrieval,EO mining,Information retrieval","MarcoQuartulli,IgorG. Olaizola","ISPRS Journal of Photogrammetry and Remote Sensing","https://doi.org/10.1016/j.isprsjprs.2012.09.010","https://www.sciencedirect.com/science/article/pii/S0924271612001797"
"A451","FaBiO and CiTO: Ontologies for describing bibliographic resources and citations","Semantic publishing is the use of Web and Semantic Web technologies to enhance the meaning of a published journal article, to facilitate its automated discovery, to enable its linking to semantically related articles, to provide access to data within the article in actionable form, and to facilitate integration of data between articles. Recently, semantic publishing has opened the possibility of a major step forward in the digital publishing world. For this to succeed, new semantic models and visualization tools are required to fully meet the specific needs of authors and publishers. In this article, we introduce the principles and architectures of two new ontologies central to the task of semantic publishing: FaBiO, the FRBR-aligned Bibliographic Ontology, an ontology for recording and publishing bibliographic records of scholarly endeavours on the Semantic Web, and CiTO, the Citation Typing Ontology, an ontology for the characterization of bibliographic citations both factually and rhetorically. We present those two models step by step, in order to emphasise their features and to stress their advantages relative to other pre-existing information models. Finally, we review the uptake of FaBiO and CiTO within the academic and publishing communities.","OWL,Publication characterization,Scholarly reference,Semantic publishing","SilvioPeronia,DavidShottonb","Journal of Web Semantics","https://doi.org/10.1016/j.websem.2012.08.001","https://www.sciencedirect.com/science/article/pii/S1570826812000790"
"A452","Abstract Book","","","","Annals of Allergy, Asthma & Immunology","https://doi.org/10.1016/j.anai.2012.09.018","https://www.sciencedirect.com/science/article/pii/S1081120612007442"
"A453","Detecting the temporal gaps of technology fronts: A case study of smart grid field","This study aims to propose a methodology that describes the technology fronts evolution and compares the temporal gaps between two specialties. Using the patent documents of a local country, the United States (US), as well as the global context in the smart grid technology as the example, highly cited patents were collected from 2001 to 2010 and divided into a series of overlapping snapshots in which patent citation networks were constructed through bibliographic coupling (BC) analysis. A rolling clustering and features extraction procedure were applied for segmenting networks into clusters and then mapping these clusters into the technology trajectory maps. Next we describe the state of global and the US smart grid development, and then place the US trajectories in the global context to explore the temporal relationship between them. Technology fronts in this study can be categorized into four types – frontrunner, follower, uniquer, and behinder – according to the matching criteria and the temporal gap index. The results show that a high percentage of US technology fronts can be classified as frontrunners or uniquers; the nation occupies a leading position worldwide in developing each sub-domain of smart grid technology.","Patent analysis,Bibliographic coupling,Technology front,Technology trajectory,Smart grid","Ssu-HanChena,Mu-HsuanHuangb,Dar-ZenChena,Siou-ZihLinc","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2012.06.005","https://www.sciencedirect.com/science/article/pii/S0040162512001527"
"A454","Trust in collaborative web applications","Collaborative functionality is increasingly prevalent in web applications. Such functionality permits individuals to add–and sometimes modify–web content, often with minimal barriers-to-entry. Ideally, large bodies of knowledge can be amassed and shared in this manner. However, such software also provide a medium for nefarious persons to operate. By determining the extent to which participating content/agents can be trusted, one can identify useful contributions. In this work, we define the notion of trust for collaborative web applications and survey the state-of-the-art for calculating, interpreting, and presenting trust values. Though techniques can be applied broadly, Wikipedia’s archetypal nature makes it a focal point for discussion.","Collaborative web applications,Trust,Reputation,Wikipedia","Andrew G.West,JianChang,Krishna K.Venkatasubramanian,InsupLee","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2011.02.007","https://www.sciencedirect.com/science/article/pii/S0167739X11000100"
"A455","Learning the “Whys”: Discovering design rationale using text mining — An algorithm perspective","Collecting design rationale (DR) and making it available in a well-organized manner will better support product design, innovation and decision-making. Many DR systems have been developed to capture DR since the 1970s. However, the DR capture process is heavily human involved. In addition, with the increasing amount of DR available in archived design documents, it has become an acute problem to research a new computational approach that is able to capture DR from free textual contents effectively. In our previous study, we have proposed an ISAL (issue, solution and artifact layer) model for DR representation. In this paper, we focus on algorithm design to discover DR from design documents according to the ISAL modeling. For the issue layer of the ISAL model, we define a semantic sentence graph to model sentence relationships through language patterns. Based on this graph, we improve the manifold-ranking algorithm to extract issue-bearing sentences. To discover solution–reason bearing sentences for the solution layer, we propose building up two sentence graphs based on candidate solution-bearing sentences and reason-bearing sentences respectively, and propagating information between them. For artifact information extraction, we propose two term relations, i.e. positional term relation and mutual term relation. Using these relations, we extend our document profile model to score the candidate terms. The performance and scalability of the algorithms proposed are tested using patents as research data joined with an example of prior art search to illustrate its application prospects.","Design rationale,Rationale representation,Rationale discovery,Text Mining,Patent mining","YanLianga,YingLiub,Chun KitKwonga,Wing BunLeea","Computer-Aided Design","https://doi.org/10.1016/j.cad.2011.08.002","https://www.sciencedirect.com/science/article/pii/S0010448511001904"
"A456","A visual analysis approach to validate the selection review of primary studies in systematic reviews","ContextSystematic Literature Reviews (SLRs) are an important component to identify and aggregate research evidence from different empirical studies. Despite its relevance, most of the process is conducted manually, implying additional effort when the Selection Review task is performed and leading to reading all studies under analysis more than once.,ObjectiveWe propose an approach based on Visual Text Mining (VTM) techniques to assist the Selection Review task in SLR. It is implemented into a VTM tool (Revis), which is freely available for use.,MethodWe have selected and implemented appropriate visualization techniques into our approach and validated and demonstrated its usefulness in performing real SLRs.,ResultsThe results have shown that employment of VTM techniques can successfully assist in the Selection Review task, speeding up the entire SLR process in comparison to the conventional approach.,ConclusionVTM techniques are valuable tools to be used in the context of selecting studies in the SLR process, prone to speed up some stages of SLRs.","Systematic Literature Review (SLR),Visual Text Mining (VTM),Information visualization,Content document map,Citation document map","Katia R.Felizardo,Gabriel F.Andery,Fernando V.Paulovich,RosaneMinghim,José C.Maldonado","Information and Software Technology","https://doi.org/10.1016/j.infsof.2012.04.003","https://www.sciencedirect.com/science/article/pii/S0950584912000742"
"A457","A framework for automatic TRIZ level of invention estimation of patents using natural language processing, knowledge-transfer and patent citation metrics","Patents provide a wealth of information about design concepts, their physical realization, and their relationship to prior designs in the form of citations. Patents can provide useful input for several goals of next-generation computer-aided design (CAD) systems, yet more efficient tools are needed to facilitate patent search and ranking. In this paper, a novel framework is presented and implemented for classifying patents according to level of invention (LOI) as defined in the theory of inventive problem solving (TRIZ). Level of invention characterizes the creativity of a design concept based on the resolution of a design conflict and the disciplines used in resolving the conflict. The assessment of LOI for a series of patents provides a useful input for screening and ranking patents in databases to identify high-impact patents. However, the manual effort required for assigning LOI to each patent is laborious and time-consuming. In this paper, a novel method that combines text mining, natural language processing, creation of knowledge-transfer metrics, and application of machine learning approaches is presented and implemented for classifying patents according to LOI. Two case studies are presented in which LOI data is compiled for patents: dynamic magnetic information storage or retrieval using Giant Magnetoresistive (GMR) or Colossal Magnetoresistive (CMR) sensors formed of multiple thin films (USPC 360/324) and arbitration for access to a channel (USPC 370/462). The peak performance in 5-fold stratified cross-validation was found to be 73.38% in the first case study and 77.12% for the second.","Computer-aided Design (CAD),Level of invention (LOI),Data mining,Machine learning,Theory of inventive problem solving (TRIZ),Natural language processing (NLP)","ZhenLia,DerrickTatea,ChristopherLanea,ChristopherAdamsb","Computer-Aided Design","https://doi.org/10.1016/j.cad.2011.12.006","https://www.sciencedirect.com/science/article/pii/S0010448511003228"
"A458","Mining term networks from text collections for crime investigation","An efficient term mining method to build a general term network is presented. The resulting term network can be used for entity relation visualization and exploration, which is useful in many text-mining applications such as crime exploration and investigation from vast piles of crime news or official criminal records. In the proposed method, terms from each document in a text collection are first identified. They are subjected to an analysis for pairwise association weights. The weights are then accumulated over all the documents to obtain final similarity for each term pair. Based on the resulting term similarity, a general term network for the collection is built with terms as nodes and non-zero similarities as links. In application, a list of predefined terms having similar attributes was selected to extract the desired sub-network from the general term network for entity relation visualization. This text analysis scenario based on the collective terms of the similar type or from the same topic enables evidence-based relation exploration. Some practical instances of crime exploration and investigation are demonstrated. Our application examples show that term relations, be it causality, subordination, coupling, or others, can be effectively revealed by our method and easily verified by the underlying text collection. This work contributes by presenting an integrated term-relationship mining and exploration approach and demonstrating the feasibility of the term network to the increasingly important application of crime exploration and investigation.","Co-occurrence analysis,Term relations,Visualization,Network analysis,Knowledge discovery","Yuen-HsienTsenga,Zih-PingHoa,Kai-ShengYangb,Chun-ChengChenc","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2012.02.052","https://www.sciencedirect.com/science/article/pii/S0957417412002965"
"A459","Reference architecture, metamodel, and modeling principles for architectural knowledge management in information technology services","Capturing and sharing design knowledge such as architectural decisions is becoming increasingly important in firms providing professional Information Technology (IT) services such as enterprise application development and strategic outsourcing. Methods, models, and tools supporting explicit knowledge management strategies have been proposed in recent years; however, several challenges remain unaddressed. In this paper, we extend our previous work to overcome these challenges and to satisfy the requirements of an additional user group, presales architects that are responsible for IT service solution proposals. In strategic outsourcing, such solution proposals require complex, contractually relevant design decisions concerning many different resources such as IT infrastructures, people, and real estate. To support both presales and project architects, we define a common reference architecture and a decision process-oriented metamodel. We also present a tool implementation of these concepts and discuss their application to outsourcing proposals and application development projects. Finally, we establish twelve decision modeling principles and practices that capture the practical experience gained and lessons learned during the application of our decision modeling concepts to both proposal development and architecture design work on projects.","Architectural decisions,Architectural principles,DSL,Knowledge management,Model-driven engineering,Outsourcing,SOA,Workflow","OlafZimmermannab,ChristophMiksovica,Jochen M.Küstera","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2012.05.003","https://www.sciencedirect.com/science/article/pii/S0164121212001343"
"A460","Knowledge flows – Analyzing the core literature of innovation, entrepreneurship and science and technology studies","This paper applies network analysis to a citation database that combines the key references in the fields of Entrepreneurship (ENT), Innovation Studies (INN) and Science and Technology Studies (STS). We find that citations between the three fields are relatively scarce, as compared to citations within the fields. As a result of this tendency, a cluster analysis of the publications in the database yields a partition that is largely the same as the a priori division into the three fields. We take this as evidence that the three fields, although they share research topics and themes, have developed largely on their own and in relative isolation from one another. We also apply a so-called ‘main path’ analysis aimed at outlining the main research trajectories in the field. Here we find important differences between the fields. In STS, we find a cumulative trajectory that develops in a more or less linear fashion over time. In INN, we find a major shift of attention in the main trajectory, from macroeconomic issues to business-oriented research. ENT develops relatively late, and shows a trajectory that is still in its infancy.","Innovation studies,Entrepreneursip,Science and technology studies,Citation networks,Network analysis","SamyuktaBhupatirajua,ÖnderNomalerb,GiorgioTriulzia,BartVerspagena","Research Policy","https://doi.org/10.1016/j.respol.2012.03.011","https://www.sciencedirect.com/science/article/pii/S0048733312000728"
"A461","Identifying and visualizing technology evolution: A case study of smart grid technology","This paper attempts to illustrate the technology evolution for describing the emergence, development, or demise of a technology field. The basic idea is to divide a technology field into tight-knit communities over time and track their inter-year continuity. Then the evolving trajectories are presented through visualizing the timeline plot where each community is drawn as a function of its size, average age, and time. Analyzing a set of patents related to smart grid, we found that this technology consists of several trajectories. Among them, the subjects of network management and e-commerce are relatively young and active. The power system recently has emerged owing to the joining of integration and management concepts. As aging subjects, wireless communication system receives more attention than wired one does. The proposed timeline plot gives insights into evolving trajectories, from which the structure of the technology could be investigated and certain emerging subjects might be figured out. Such understandings are essential information to experts who endeavor to profile technology development and keep up with current trends.","Technology evolution,Timeline plot,Community detection,Patent citation network analysis,Smart grid","Ssu-HanChena,Mu-HsuanHuangb,Dar-ZenChena","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2011.12.011","https://www.sciencedirect.com/science/article/pii/S0040162511002897"
"A462","An experimental investigation of kernels on graphs for collaborative recommendation and semisupervised classification","This paper presents a survey as well as an empirical comparison and evaluation of seven kernels on graphs and two related similarity matrices, that we globally refer to as “kernels on graphs” for simplicity. They are the exponential diffusion kernel, the Laplacian exponential diffusion kernel, the von Neumann diffusion kernel, the regularized Laplacian kernel, the commute-time (or resistance-distance) kernel, the random-walk-with-restart similarity matrix, and finally, a kernel first introduced in this paper (the regularized commute-time kernel) and two kernels defined in some of our previous work and further investigated in this paper (the Markov diffusion kernel and the relative-entropy diffusion matrix). The kernel-on-graphs approach is simple and intuitive. It is illustrated by applying the nine kernels to a collaborative-recommendation task, viewed as a link prediction problem, and to a semisupervised classification task, both on several databases. The methods compute proximity measures between nodes that help study the structure of the graph. Our comparisons suggest that the regularized commute-time and the Markov diffusion kernels perform best on the investigated tasks, closely followed by the regularized Laplacian kernel.","Kernels on graphs,Graph mining,Collaborative recommendation,Semisupervised classification","FrançoisFouss,KevinFrancoisse,LuhYen,AlainPirotte,MarcoSaerens","Neural Networks","https://doi.org/10.1016/j.neunet.2012.03.001","https://www.sciencedirect.com/science/article/pii/S0893608012000822"
"A463","Physical approach to complex systems","Typically, complex systems are natural or social systems which consist of a large number of nonlinearly interacting elements. These systems are open, they interchange information or mass with environment and constantly modify their internal structure and patterns of activity in the process of self-organization. As a result, they are flexible and easily adapt to variable external conditions. However, the most striking property of such systems is the existence of emergent phenomena which cannot be simply derived or predicted solely from the knowledge of the systems’ structure and the interactions among their individual elements. This property points to the holistic approaches which require giving parallel descriptions of the same system on different levels of its organization. There is strong evidence–consolidated also in the present review–that different, even apparently disparate complex systems can have astonishingly similar characteristics both in their structure and in their behaviour. One can thus expect the existence of some common, universal laws that govern their properties.Physics methodology proves helpful in addressing many of the related issues. In this review, we advocate some of the computational methods which in our opinion are especially fruitful in extracting information on selected–but at the same time most representative–complex systems like human brain, financial markets and natural language, from the time series representing the observables associated with these systems. The properties we focus on comprise the collective effects and their coexistence with noise, long-range interactions, the interplay between determinism and flexibility in evolution, scale invariance, criticality, multifractality and hierarchical structure. The methods described either originate from “hard” physics–like the random matrix theory–and then were transmitted to other fields of science via the field of complex systems research, or they originated elsewhere but turned out to be very useful also in physics — like, for example, fractal geometry. Further methods discussed borrow from the formalism of complex networks, from the theory of critical phenomena and from nonextensive statistical mechanics. Each of these methods is helpful in analyses of specific aspects of complexity and all of them are mutually complementary.","Complex systems,Complexity measures,Correlations,Asymmetric correlations,Coexistence of collectivity and noise,Random matrix theory,Time series analysis,Fractals,Multifractals,Critical phenomena,Complex networks,Financial markets,Human brain,Quantitative linguistics","JaroslawKwapiena,StanislawDrozdzab","Physics Reports","https://doi.org/10.1016/j.physrep.2012.01.007","https://www.sciencedirect.com/science/article/pii/S0370157312000166"
"A464","Survey of PCT search reports and the importance of the internet as a source of non-patent literature","Previous studies of the internet as prior art in patentability searching have concentrated on the difficulty of establishing a date of publication and a stable form of citation. The current work examines whether the internet is actually contributing new prior art, or merely replicating non-patent literature which can be obtained by other means. A sample of PCT international applications published in 2007 provides some evidence that certain ISAs are more effective in locating and citing internet-based non-patent literature than others. The sample also reinforces the widespread perception that non-patent literature forms a higher proportion of total citations in distinct technical fields. Some recommendations are made about bibliographic control of internet disclosures, and the methods of citation in search reports which are the most helpful for third parties wishing to locate the cited work.","PCT application,International search Authority,Search report,Non-patent literature,Internet,Field of search","StephenAdams","World Patent Information","https://doi.org/10.1016/j.wpi.2012.01.003","https://www.sciencedirect.com/science/article/pii/S0172219012000282"
"A465","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2012.04.002","https://www.sciencedirect.com/science/article/pii/S0140670112000197"
"A466","Interactive overlays: A new method for generating global journal maps from Web-of-Science data","Recent advances in methods and techniques enable us to develop interactive overlays to a global map of science based on aggregated citation relations among the 9162 journals contained in the Science Citation Index and Social Science Citation Index 2009. We first discuss the pros and cons of the various options: cited versus citing, multidimensional scaling versus spring-embedded algorithms, VOSViewer versus Gephi, and the various clustering algorithms and similarity criteria. Our approach focuses on the positions of journals in the multidimensional space spanned by the aggregated journal–journal citations. Using VOSViewer for the resulting mapping, a number of choices can be left to the user; we provide default options reflecting our preferences. Some examples are also provided; for example, the potential of using this technique to assess the interdisciplinarity of organizations and/or document sets.","Map,Journal,Overlay,VOSViewer,Gephi","LoetLeydesdorffa,IsmaelRafolsb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2011.11.003","https://www.sciencedirect.com/science/article/pii/S1751157711001027"
"A467","Indices of novelty for emerging topic detection","Emerging topic detection is a vital research area for researchers and scholars interested in searching for and tracking new research trends and topics. The current methods of text mining and data mining used for this purpose focus only on the frequency of which subjects are mentioned, and ignore the novelty of the subject which is also critical, but beyond the scope of a frequency study. This work tackles this inadequacy to propose a new set of indices for emerging topic detection. They are the novelty index (NI) and the published volume index (PVI). This new set of indices is created based on time, volume, frequency and represents a resolution to provide a more precise set of prediction indices. They are then utilized to determine the detection point (DP) of new emerging topics. Following the detection point, the intersection decides the worth of a new topic. The algorithms presented in this paper can be used to decide the novelty and life span of an emerging topic in a specific field. The entire comprehensive collection of the ACM Digital Library is examined in the experiments. The application of the NI and PVI gives a promising indication of emerging topics in conferences and journals.","Topic detection and tracking,Text mining,Information retrieval,Novelty index,Published volume index,Aging theory","Yi-NingTua,Jia-LangSengb","Information Processing & Management","https://doi.org/10.1016/j.ipm.2011.07.006","https://www.sciencedirect.com/science/article/pii/S0306457311000768"
"A468","The long history of iron in the Universe and in health and disease","BackgroundNot long after the Big Bang, iron began to play a central role in the Universe and soon became mired in the tangle of biochemistry that is the prima essentia of life. Since life's addiction to iron transcends the oxygenation of the Earth's atmosphere, living things must be protected from the potentially dangerous mix of iron and oxygen. The human being possesses grams of this potentially toxic transition metal, which is shuttling through his oxygen-rich humor. Since long before the birth of modern medicine, the blood—vibrant red from a massive abundance of hemoglobin iron—has been a focus for health experts.,Scope of reviewWe describe the current understanding of iron metabolism, highlight the many important discoveries that accreted this knowledge, and describe the perils of dysfunctional iron handling.,General significanceIsaac Newton famously penned, “If I have seen further than others, it is by standing upon the shoulders of giants”. We hope that this review will inspire future scientists to develop intellectual pursuits by understanding the research and ideas from many remarkable thinkers of the past.,Major conclusionsThe history of iron research is a long, rich story with early beginnings, and is far from being finished. This article is part of a Special Issue entitled Transferrins: Molecular mechanisms of iron transport and disorders.","Transferrin,Heme,Iron–sulfur cluster,Mitochondrion,Anemia,Hemochromatosis","Alex D.Sheftela,Anne B.Masonb,PremPonkacde","Biochimica et Biophysica Acta (BBA) - General Subjects","https://doi.org/10.1016/j.bbagen.2011.08.002","https://www.sciencedirect.com/science/article/pii/S0304416511001851"
"A469","Learning biases predict a word order universal","How recurrent typological patterns, or universals, emerge from the extensive diversity found across the world’s languages constitutes a central question for linguistics and cognitive science. Recent challenges to a fundamental assumption of generative linguistics—that universal properties of the human language acquisition faculty constrain the types of grammatical systems which can occur—suggest the need for new types of empirical evidence connecting typology to biases of learners. Using an artificial language learning paradigm in which adult subjects are exposed to a mix of grammatical systems (similar to a period of linguistic change), we show that learners’ biases mirror a word-order universal, first proposed by Joseph Greenberg, which constrains typological patterns of adjective, numeral, and noun ordering. We briefly summarize the results of a probabilistic model of the hypothesized biases and their effect on learning, and discuss the broader implications of the results for current theories of the origins of cross-linguistic word-order preferences.","Learning biases,Typology,Word order,Artificial Language Learning,Bayesian models,Universals","JenniferCulbertson,PaulSmolensky,GéraldineLegendre","Cognition","https://doi.org/10.1016/j.cognition.2011.10.017","https://www.sciencedirect.com/science/article/pii/S0010027711002745"
"A470","4: Locating scholarly papers of interest online","Discovering the existence of scholarly papers in an online environment has been possible since the middle of the last century and the retrieval of their full text reliably possible only in the last quarter of the century. Since then several public web-based scholarly search engines have become available and directly compete with the older proprietary database search services to aid scholars and researchers. This chapter compares three public services, Google Scholar, Academic Search and Scirus, with two proprietary services, Web of Science and Scopus, in their effectiveness as tools for communicating and raising awareness of scholarship. It examines the three main functions required at different times by scholars – the discovery and retrieval of scholarly literature, the analysis of journals for publishing decisions and citation analysis for mapping collaborative scholarly networks and communities.","search engines,scholarly communication,bibliometrics,information visualization","MaureenHenninger","Social Media for Academics,Social Media for Academics","https://doi.org/10.1016/B978-1-84334-681-4.50004-9","https://www.sciencedirect.com/science/article/pii/B9781843346814500049"
"A471","Research Trends in Non Point Source during 1975-2010","According to the samples of 2924 articles about non point source of SCI and SSCI databases from 1975 to 2010, this study analysed the articles in the growth trend of article outputs, subject categories and journals, international collaborations, geographic distribution and scientific research issues by using bibliometric analysis. The results showed that non point source research steadily increased over the past 35 years and the annual number of articles published in 2010 was 79 times of that in 1975. Non point source was involved into 67 kinds of subjects and appeared in 451 journals. The main study area was concentrated in North America and Europe, following by East Asia. There were 79 countries/territories participated in non point source research, and USA was the largest contributor in non point source research and had a central position in collaboration networks. A keyword analysis indicated that water quality, non point pollutions, and watershed were the hottest issues of non point source research; “GIS, “watershed management”, “modeling”, “simulation”, “monitoring”, and “remote sensing” were the most popular research methods; and “agriculture”, “land use”, “runoff”, and “pollution” were the leading causes of non point pollution.","non point source,bibliometric analysis,analysis,research trends","ZhuangYanhua,NguyenThuminh,NiuBeibei,Shaoei,HongSong","Physics Procedia","https://doi.org/10.1016/j.phpro.2012.05.041","https://www.sciencedirect.com/science/article/pii/S1875389212013545"
"A472","3: LIQUIDS","","","Prof. Dr.Alexander Ya.Malkin,Prof. Dr.Avraam IIsayev","Rheology Concepts, Methods, and Applications,Rheology Concepts, Methods, and Applications (Second Edition)","https://doi.org/10.1016/B978-1-895198-49-2.50008-6","https://www.sciencedirect.com/science/article/pii/B9781895198492500086"
"A473","Chapter 18: Fluorescence Correlation Methods for Imaging Cellular Behavior of Sphingolipid-Interacting Probes","For cell biologists interested in the properties of cell membranes, their composition, and dynamics, the realization that sphingolipids and cholesterol have the capacity to self-organize into ordered domains has given rise to a need to visualize these lipids in actual living cell membranes. In order to find out how various classes of lipids distribute in the membrane and what their behaviors are, it is extremely useful to apply fluorescent probes that either interact with these lipids, or that themselves behave like naturally occurring lipids. At the same time, imaging modalities to observe their behaviors require the appropriate spatial and temporal resolution, on the milli- or microsecond timescale. Knowledge of membrane organization and how it changes during processes like cell signaling and invasion by pathogens will undoubtedly be relevant to our understanding of the action of infectious diseases, bacterial toxins, and even disease pathologies like prion and Alzheimer's disease, where glycosphingolipids (GSL) and sphingolipid-rich domains act as membrane receptors or docking sites. In such cases, membrane composition and dynamics will clearly play a role in infectivity. The present challenge is in coming up with high-resolution and non-invasive approaches to observing these dynamic and structural features of sphingolipid-containing membrane domains. This chapter will discuss several variants and applications of fluorescence correlation spectroscopy as well as probes that can be used to study sphingolipid dynamics.","Analog,Correlation,Diffusion,Domain,Perturbation,Sphingolipid","RachelKraut*,NirmalyaBag†,ThorstenWohland†","Methods in Cell Biology","https://doi.org/10.1016/B978-0-12-386487-1.00018-3","https://www.sciencedirect.com/science/article/pii/B9780123864871000183"
"A474","2: Integrative Mining of Traditional Chinese Medicine Literature and MEDLINE for Functional Gene Networks","","","ZhaohuiWu,HuajunChen,XiaohongJiang","Modern Computational Approaches to Traditional Chinese Medicine","https://doi.org/10.1016/B978-0-12-398510-1.00002-9","https://www.sciencedirect.com/science/article/pii/B9780123985101000029"
"A475","The educational use of social annotation tools in higher education: A literature review","This paper presents a literature review of empirical research related to the use and effect of online social annotation (SA) tools in higher education settings. SA technology is an emerging educational technology that has not yet been extensively used and examined in education. As such, the research focusing on this technology is still very limited. The literature review has aimed at presenting a comprehensive list of SA empirical studies not limited to a particular research method or study domain. Out of more than 90 articles that were initially found, only 16 studies met the inclusion criteria. Among the included studies were eight experimental or quasi-experimental studies and eight evaluation/survey studies. The SA empirical research has provided some evidence regarding the potential effectiveness of integrating social annotation tools into learning activities. Findings from the gathered literature were synthesized to provide recommendations for using SA technology in educational settings.","Social annotation technology,Online learning,Higher education,Literature review","ElenaNovaka,RimRazzouka1,Tristan E.Johnsonb2","The Internet and Higher Education","https://doi.org/10.1016/j.iheduc.2011.09.002","https://www.sciencedirect.com/science/article/pii/S109675161100056X"
"A476","Topics in dynamic research communities: An exploratory study for the field of information retrieval","Research topics and research communities are not disconnected from each other: communities and topics are interwoven and co-evolving. Yet, scientometric evaluations of topics and communities have been conducted independently and synchronically, with researchers often relying on homogeneous unit of analysis, such as authors, journals, institutions, or topics. Therefore, new methods are warranted that examine the dynamic relationship between topics and communities. This paper examines how research topics are mixed and matched in evolving research communities by using a hybrid approach which integrates both topic identification and community detection techniques. Using a data set on information retrieval (IR) publications, two layers of enriched information are constructed and contrasted: one is the communities detected through the topology of coauthorship network and the other is the topics of the communities detected through the topic model. We find evidence to support the assumption that IR communities and topics are interwoven and co-evolving, and topics can be used to understand the dynamics of community structures. We recommend the use of the hybrid approach to study the dynamic interactions of topics and communities.","Community,Knowledge discovery,Coauthorship,Network,Latent Dirichlet Allocation","ErjiaYan,YingDing,StašaMilojevic,Cassidy R.Sugimoto","Journal of Informetrics","https://doi.org/10.1016/j.joi.2011.10.001","https://www.sciencedirect.com/science/article/pii/S1751157711000976"
"A477","Chapter 1: The History of Text Mining","","","","Practical Text Mining and Statistical Analysis for Non-structured Text Data Applications,Practical Text Mining and Statistical Analysis for Non-structured Text Data Applications","https://doi.org/10.1016/B978-0-12-386979-1.00001-3","https://www.sciencedirect.com/science/article/pii/B9780123869791000013"
"A478","Nanostructured electrodes for lithium-ion and lithium-air batteries: the latest developments, challenges, and perspectives","The urgency for clean and secure energy has stimulated a global resurgence in searching for advanced electrical energy storage systems. For now and the foreseeable future, batteries remain the most promising electrical energy storage systems for many applications, from portable electronics to emerging technologies such as electric vehicles and smart grids, by potentially offering significantly improved performance, energy efficiencies, reliability, and energy security while also permitting a drastic reduction in fuel consumption and emissions. The energy and power storage characteristics of batteries critically impact the commercial viability of these emerging technologies. For example, the realization of electric vehicles hinges on the availability of batteries with significantly improved energy and power density, durability, and reduced cost. Further, the design, performance, portability, and innovation of many portable electronics are limited severely by the size, power, and cycle life of the existing batteries. Creation of nanostructured electrode materials represents one of the most attractive strategies to dramatically enhance battery performance, including capacity, rate capability, cycling life, and safety. This review aims at providing the reader with an understanding of the critical scientific challenges facing the development of advanced batteries, various unique attributes of nanostructures or nano-architectures applicable to lithium-ion and lithium-air batteries, the latest developments in novel synthesis and fabrication procedures, the unique capabilities of some powerful, in situ characterization techniques vital to unraveling the mechanisms of charge and mass transport processes associated with battery performance, and the outlook for future-generation batteries that exploit nanoscale materials for significantly improved performance to meet the ever-increasing demands of emerging technologies.","Nanostructured electrodes,Lithium-ion batteries,Lithium-air batteries,Metal-air batteries,Lithium batteries,In situ characterization","Min-KyuSonga1,SoojinParkb1,Faisal M.Alamgira,JaephilChob,MeilinLiua","Materials Science and Engineering: R: Reports","https://doi.org/10.1016/j.mser.2011.06.001","https://www.sciencedirect.com/science/article/pii/S0927796X11000593"
"A479","Abstracts","","","","Annals of Allergy, Asthma & Immunology","https://doi.org/10.1016/j.anai.2011.09.019","https://www.sciencedirect.com/science/article/pii/S108112061100768X"
"A480","Degree centrality for semantic abstraction summarization of therapeutic studies","Automatic summarization has been proposed to help manage the results of biomedical information retrieval systems. Semantic MEDLINE, for example, summarizes semantic predications representing assertions in MEDLINE citations. Results are presented as a graph which maintains links to the original citations. Graphs summarizing more than 500 citations are hard to read and navigate, however. We exploit graph theory for focusing these large graphs. The method is based on degree centrality, which measures connectedness in a graph. Four categories of clinical concepts related to treatment of disease were identified and presented as a summary of input text. A baseline was created using term frequency of occurrence. The system was evaluated on summaries for treatment of five diseases compared to a reference standard produced manually by two physicians. The results showed that recall for system results was 72%, precision was 73%, and F-score was 0.72. The system F-score was considerably higher than that for the baseline (0.47).","Automatic summarization,Natural language processing,Graph theory,Degree centrality,Semantic processing,Disease treatment","HanZhangab,MarceloFiszmanb,DongwookShinb,Christopher M.Millerb,GracielaRosemblatb,Thomas C.Rindfleschb","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2011.05.001","https://www.sciencedirect.com/science/article/pii/S1532046411000773"
"A481","Community detection: Topological vs. topical","The evolution of the Web has promoted a growing interest in social network analysis, such as community detection. Among many different community detection approaches, there are two kinds that we want to address: one considers the graph structure of the network (topology-based community detection approach); the other one takes the textual information of the network nodes into consideration (topic-based community detection approach). This paper conducted systematic analysis of applying a topology-based community detection approach and a topic-based community detection approach to the coauthorship networks of the information retrieval area and found that: (1) communities detected by the topology-based community detection approach tend to contain different topics within each community; and (2) communities detected by the topic-based community detection approach tend to contain topologically-diverse sub-communities within each community. The future community detection approaches should not only emphasize the relationship between communities and topics, but also consider the dynamic changes of communities and topics.","Community detection,Topics,Communities,Coauthor network","YingDing","Journal of Informetrics","https://doi.org/10.1016/j.joi.2011.02.006","https://www.sciencedirect.com/science/article/pii/S1751157711000319"
"A482","Passage retrieval based hidden knowledge discovery from biomedical literature","Biomedical literature is growing at a double-exponential pace and automatic extraction of the implicit biological relationship from biomedical literature contributes to building the biomedical hypothesis that can be explored further experimentally. This paper presents a passage retrieval based method which can explore the hidden connection from MEDLINE records. In this method, the MeSH concepts are retrieved from the sentence-level windows and are therefore more relevant with the starting term. This method is tested on three classical implicit connections: Alzheimer’s disease and indomethacin, Migraine and Magnesium, Schizophrenia and Calcium-independent phospholipase A2 in the open discovery. In our experiments, three computational methods for scoring and ranking the MeSH terms are explored: z-score, TFIDF (Term Frequency Inverse Document Frequency) and PMI (pointwise mutual information). Experimental results show this method can significantly improve the hidden knowledge discovery performance.","Concept retrieval,Passage retrieval,Knowledge discovery","RanChen,HongfeiLin,ZhihaoYang","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2011.02.034","https://www.sciencedirect.com/science/article/pii/S0957417411002405"
"A483","How to design and utilize online customer center to support new product concept generation","Websites can be effective vehicles for firms to communicate with their customers but the use of websites has been limited to pacifying complaint customers. To better use a website’s information, this research presents a framework for extracting customer opinions from websites and transforming them into product specification data. For the purpose, firstly, customer opinions were collected from an online customer center and then transformed into customer needs using text-mining. Then, after customers were segmented into several groups based on their needs, relations among their needs were visualized by co-word analysis and product specifications to meet those needs t analyzed by decision tree. Lastly, a final target product specification for new products were determined and a target market was identified based on customer profile data. The suggested framework enables to incorporate customer opinions efficiently with new product development processes and to design online customer centers to better collect and analyze useful information.","Online customer center,Customer opinions,New product development,Concept generation,Text-mining,Decision tree","YongtaeParka,SungjooLeeb","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2011.02.125","https://www.sciencedirect.com/science/article/pii/S0957417411003320"
"A484","Extracting multilayered Communities of Interest from semantic user profiles: Application to group modeling and hybrid recommendations","A Community of Interest is a specific type of Community of Practice. It is formed by a group of individuals who share a common interest or passion. These people exchange ideas and thoughts about the given passion. However, they are often not aware of their membership to the community, and they may know or care little about each other outside of this clique. This paper describes a proposal to automatically identify Communities of Interest from the tastes and preferences expressed by users in personal ontology-based profiles. The proposed strategy clusters those semantic profile components shared by the users, and according to the clusters found, several layers of interest networks are built. The social relations of these networks might then be used for different purposes. Specifically, we outline here how they can be used to model group profiles and make semantic content-based collaborative recommendations.","Communities of Practice,Communities of Interest,Ontology,User profile,Group modeling,Content-based collaborative filtering","IvánCantador,PabloCastells","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2010.07.027","https://www.sciencedirect.com/science/article/pii/S0747563210002232"
"A485","Identifying missing relevant patent citation links by using bibliographic coupling in LED illuminating technology","This study uses bibliographic coupling to identify missing relevant patent links, in order to construct a comprehensive citation network. Missing citation links can be added by taking the missing relevant patent links into account. The Pareto principle is used to determine the threshold of bibliographic coupling strength, in order to identify the missing relevant patent links. Comparisons between the original patent citation network and the comprehensive patent citation network with the missing relevant patent links are illustrated at both the patent and assignee levels. Light emitting diode (LED) illuminating technology is chosen as the case study. The relationships between the patents and the assignees are obviously enhanced after adding the missing relevant patent links. The results show that the growth rates on both the total number and the average number of links have apparently improved at the patent level. At the assignee level, the number of linked assignees and the average number of links between two assignees are increased. The differences between the two citation networks are further examined by means of the Freeman vertex betweenness centrality and Johnson's hierarchical clustering. The patents with more new links to other patents have distinct results in terms of the Freeman vertex betweenness centrality. The enhancement of links among patents also results in different clustering.","Patent citation network,Hidden relevant patent,Citation time lag,Bibliographical coupling,Pareto principle","Dar-ZenChena,Mu-HsuanHuangb,Hui-ChenHsiehc,Chang-PinLind","Journal of Informetrics","https://doi.org/10.1016/j.joi.2011.02.005","https://www.sciencedirect.com/science/article/pii/S1751157711000307"
"A486","Domain-driven KDD for mining functionally novel rules and linking disjoint medical hypotheses","IntroductionAn important quality of association rules is novelty. However, evaluating rule novelty is AI-hard and has been a serious challenge for most data mining systems.,ObjectiveIn this paper, we introduce functional novelty, a new non-pairwise approach to evaluating rule novelty. A functionally novel rule is interesting as it suggests previously unknown relations between user hypotheses.,MethodsWe developed a novel domain-driven KDD framework for discovering functionally novel association rules. Association rules were mined from cardiovascular data sets. At post-processing, domain knowledge-compliant rules were discovered by applying semantic-based filtering based on UMLS ontology. Their knowledge compliance scores were computed against medical knowledge in Pubmed literature. A cardiologist explored possible relationships between several pairs of unknown hypotheses. The functional novelty of each rule was computed based on its likelihood to mediate these relationships.,ResultsHighly interesting rules were successfully discovered. For instance, common rules such as diabetes mellitus<U+21D4>coronary arteriosclerosis was functionally novel as it mediated a rare association between von Willebrand factor and intracardiac thrombus.,ConclusionThe proposed post-mining domain-driven rule evaluation technique and measures proved to be useful for estimating candidate functionally novel rules with the results validated by a cardiologist.","Association rules,Data mining methods,Interactive data exploration and discovery,Medical knowledge support systems,Rule interestingness","Y.Sebastian,Patrick H.H.Then","Knowledge-Based Systems","https://doi.org/10.1016/j.knosys.2011.01.008","https://www.sciencedirect.com/science/article/pii/S0950705111000207"
"A487","A surface science perspective on TiO2 photocatalysis","The field of surface science provides a unique approach to understanding bulk, surface and interfacial phenomena occurring during TiO2 photocatalysis. This review highlights, from a surface science perspective, recent literature that provides molecular-level insights into photon-initiated events occurring at TiO2 surfaces. Seven key scientific issues are identified in the organization of this review. These are: (1) photon absorption, (2) charge transport and trapping, (3) electron transfer dynamics, (4) the adsorbed state, (5) mechanisms, (6) poisons and promoters, and (7) phase and form. This review ends with a brief examination of several chemical processes (such as water splitting) in which TiO2 photocatalysis has made significant contributions in the literature.","TiO2 photocatalysis","Michael A.Henderson","Surface Science Reports","https://doi.org/10.1016/j.surfrep.2011.01.001","https://www.sciencedirect.com/science/article/pii/S0167572911000100"
"A488","Research Report Abstracts","","","","Physiotherapy","https://doi.org/10.1016/j.physio.2011.04.002","https://www.sciencedirect.com/science/article/pii/S0031940611000691"
"A489","Abstracts","","","","Journal of Thoracic Oncology","https://doi.org/10.1097/01.JTO.0000399289.73317.3d","https://www.sciencedirect.com/science/article/pii/S1556086415336108"
"A490","A multi-faceted and automatic knowledge elicitation system (MAKES) for managing unstructured information","Management of unstructured information, such as emails, is vital for supporting knowledge work in professional services. However, the conventional way for managing unstructured information is inadequate as the knowledge work and associated tasks are becoming more complex, are dynamically changing with time and involve multiple concepts. This paper attempts to address the inadequacy, deficiency and limitations of the methods presently used to elicit knowledge from masses of unstructured information. These methods rely heavily on manpower, are time consuming and costly. With the development of a multi-faceted and automatic knowledge elicitation system (MAKES) manpower, time and cost can be dramatically reduced. The MAKES integrates the processes of collecting data, classifying unstructured information, modelling knowledge flow and social network analysis, and makes all of these actions into a connected process to audit unstructured information automatically. This audit is based on specific search criteria, search keywords, and the user behaviours of the knowledge workers. The unstructured information is automatically organized, classified and presented in a multi-facet taxonomy map. New concepts and knowledge are uncovered, analyzed and updated continuously from the incoming unstructured information, using a purpose-built knowledge elicitation algorithm named self-associated concept mapping (SACM). The capability and advantages of the MAKES are demonstrated through a successful trial implementation and a verification test conducted in an electronics trading company. Encouraging results have been achieved and a number of potential advantages have been realized. The area of application in this first deployment is based on an email-intensive organization and the proposed study will contribute to the advancement of methods and tools for managing other kinds of unstructured information.","Multi-facet,Taxonomy,Automatic,Unstructured information,Auditing,Knowledge management,Professional services,Self-associated concept mapping,Knowledge elicitation,Knowledge mining","C.F.Cheung,W.B.Lee,W.M.Wang,Y.Wang,W.M.Yeung","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2010.10.033","https://www.sciencedirect.com/science/article/pii/S0957417410011772"
"A491","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2011.04.002","https://www.sciencedirect.com/science/article/pii/S0140670111000154"
"A492","Monitoring trends of technological changes based on the dynamic patent lattice: A modified formal concept analysis approach","The strategic importance of monitoring technological changes is highlighted given the ever faster pace and increasing complexity of technological innovation. In this respect, patent citation analysis has been the most frequently adopted tool among others. However, patent citation analysis is subject to certain drawbacks that stem from only consideration of citing-cited information and time lags between citing and cited patents. This study proposes a formal concept analysis (FCA)-based approach to developing a dynamic patent lattice that can analyze complex relations among patents and monitor trends of technological changes. The FCA is a mathematical tool for grouping objects with shared properties based on the lattice theory. The distinct strengths of FCA, vis-á-vis other methods, lie in structuring and displaying the relations among objects from a massive amount of data. For the purpose of technology monitoring, the FCA is modified to take into account time periods and changes of patent keywords. A patent context is first constructed with the aid of domain experts and text mining technique. Two types of dynamic patent lattices are then developed by executing the modified FCA algorithm. A case study of laser technology in lithography for semiconductor manufacturing shows that the suggested dynamic patent lattice has considerable advantages over conventional patent citation maps in terms of visualization and informative power.","Technology monitoring,Technology intelligence,Patent analysis,Formal concept analysis,Dynamic patent lattice","ChangyongLee,JeonghwanJeon,YongtaePark","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2010.11.010","https://www.sciencedirect.com/science/article/pii/S004016251000274X"
"A493","The COST 731 Action: A review on uncertainty propagation in advanced hydro-meteorological forecast systems","Quantifying uncertainty in flood forecasting is a difficult task, given the multiple and strongly non-linear model components involved in such a system. Much effort has been and is being invested in the quest of dealing with uncertain precipitation observations and forecasts and the propagation of such uncertainties through hydrological and hydraulic models predicting river discharges and risk for inundation. The COST 731 Action is one of these and constitutes a European initiative which deals with the quantification of forecast uncertainty in hydro-meteorological forecast systems. COST 731 addresses three major lines of development: (1) combining meteorological and hydrological models to form a forecast chain, (2) propagating uncertainty information through this chain and make it available to end users in a suitable form, (3) advancing high-resolution numerical weather prediction precipitation forecasts by using non-conventional observations from, for instance, radar to determine details in the initial conditions on scales smaller than what can be resolved by conventional observing systems. Recognizing the interdisciplinarity of the challenge COST 731 has organized its work forming Working Groups at the interfaces between the different scientific disciplines involved, i.e. between observation and atmospheric (and hydrological) modelling (WG-1), between atmospheric and hydrologic modelling (WG-2) and between hydrologic modelling and end-users (WG-3).This paper summarizes the COST 731 activities and its context, provides a review of the recent progress made in dealing with uncertainties in flood forecasting, and sets the scene for the papers of this Thematic Issue. In particular, a bibliometric analysis highlights the strong recent increase in addressing the uncertainty analysis in flood forecasting from an integrated perspective. Such a perspective necessarily involves the area of meteorology, hydrology, and decision making in order to take operational advantage of the scientific progress, an aspect in which COST 731 is successfully contributing to furthering the flood damage mitigation capabilities in Europe.","Uncertainty,Flood forecasting,Radar,NWP,EPS,COST,MAP D-PHASE","AndreaRossaa,KatharinaLiechtib,MassimilianoZappab,MichaelBruenc,UrsGermannd,GüntherHaasee,ChristianKeilfg,PeterKraheh","Atmospheric Research","https://doi.org/10.1016/j.atmosres.2010.11.016","https://www.sciencedirect.com/science/article/pii/S0169809510003303"
"A494","Supporting geographically-aware web document foraging and sensemaking","This paper reports on the development and application of strategies and tools for geographic information seeking and knowledge building that leverages unstructured text resources found on the web. Geographic knowledge building from unstructured web sources starts with web document foraging during which the quantity, scope and diversity of web-based information create incredible cognitive burdens on an analyst’s or researcher’s ability to judge information relevancy. Determining information relevancy is ultimately a process of sensemaking. In this paper, we present our research on visually supporting web document foraging and sensemaking. In particular, we present the Sense-of-Place (SensePlace) analytic environment. The scientific goal of SensePlace is to visually and computationally support analyst sensemaking with text artifacts that have potential place, time, and thematic relevance to an analytical problem through identification and visual highlighting of named entities (people, places, times, and organizations) in documents, automated inference to determine document relevance using stored knowledge, and a visual interface with coupled geographic map, timeline, and concept graph displays that are used to contextualize the contexts of potentially relevant documents. We present the results of a case study analysis using SensePlace to uncover potential population migration, geopolitical, and other infectious disease dynamics drivers for measles and other epidemics in Niger. Our analysis allowed us to demonstrate how our approach can support analysis of complex situations along (a) multi-scale geographic dimensions (i.e., vaccine coverage areas), (b) temporal dimensions (i.e., seasonal population movement and migrations), and (c) diverse thematic dimensions (effects of political upheaval, food security, transient movement, etc.).","Visual analytics,Sensemaking,Information foraging,Geographic information retrieval,Infectious disease dynamics,Niger","BrianTomaszewskia,JustineBlanfordb1,KevinRossb1,ScottPezanowskib1,Alan M.MacEachrenb1","Computers, Environment and Urban Systems","https://doi.org/10.1016/j.compenvurbsys.2011.01.003","https://www.sciencedirect.com/science/article/pii/S0198971511000068"
"A495","A Practical Guide to Research: Design, Execution, and Publication","","","JónKarlssonM.D., Ph.D.(Editor),Robert G.MarxM.D., M.Sc., F.R.C.S.C.(Editor),NorimasaNakamuraM.D., Ph.D.(Editor),MohitBhandariM.D., Ph.D., F.R.C.S.C.(Editor)","Arthroscopy: The Journal of Arthroscopic & Related Surgery","https://doi.org/10.1016/j.arthro.2011.02.001","https://www.sciencedirect.com/science/article/pii/S074980631100123X"
"A496","A bibliometric investigation of research performance in emerging nanobiopharmaceuticals","The three important research domains, nanotechnology, biotechnology and pharmaceuticals, integratedly breed a promising multidisciplinary domain in the post-genomic age, which was recently defined by the term “nanobiopharmaceuticals”. In this paper, we firstly investigate its general development profiles, and then implement cross-country comparisons in its research performances, with the focus on the world share, relative research effort, impact and quality of five productive countries. Furthermore, from the science mapping perspective, we build the co-word and co-citation networks respectively for detecting its intellectual structure as well as evolution footprints of intellectual turning points. The growth examinations based on the datasets from WoS, MEDLINE and BIOSIS Review confirm the exponential growth of publications and citations in nanobiopharm-research. The cross-country comparisons show that USA is the leading country, and China is an up-and-coming contributor. The visual mapping structures by co-occurrence analyses show that nanobiopharm-research is currently focused on the drug development for improving biodistribution, bioavailability and pharmacokinetics, and the drug delivery for improving delivery of existing drugs. Some pivot publications is identified by CiteSpace, which work as structural holes, research fronts and intellectual bases for the nanobiopharm-research development in the given time window.","Nanobiopharmaceutics,Growth pattern,Cross-country comparisons,Intellectual structure and evolutions,Bibliometric study,Co-occurrence analysis,Visual mapping","KaihuaChena1,JianchengGuanb1","Journal of Informetrics","https://doi.org/10.1016/j.joi.2010.10.007","https://www.sciencedirect.com/science/article/pii/S1751157710000945"
"A497","Memory, autonoetic consciousness, and the self","Memory is a general attribute of living species, whose diversification reflects both evolutionary and developmental processes. Episodic-autobiographical memory (EAM) is regarded as the highest human ontogenetic achievement and as probably being uniquely human. EAM, autonoetic consciousness and the self are intimately linked, grounding, supporting and enriching each other’s development and cohesiveness. Their development is influenced by the socio-cultural–linguistic environment in which an individual grows up or lives. On the other hand, through language, textualization and social exchange, all three elements leak into the world and participate to the dynamic shaping and re-shaping of the cultural scaffolding of the self, mental time traveling and EAM formation. Deficits in self-related processing, autonetic consciousness, emotional processing and mental time traveling can all lead to or co-occur with EAM disturbances, as we illustrate by findings from EAM impairments associated with neurological or psychiatric disorders.","Dissociative amnesia,Self-consciousness,Emotion,Episodic-autobiographical memory (EAM),Perspective taking,Time","Hans J.Markowitschab,AngelicaStaniloiua","Consciousness and Cognition","https://doi.org/10.1016/j.concog.2010.09.005","https://www.sciencedirect.com/science/article/pii/S1053810010001716"
"A498","Using patent data to analyze trends and the technological strategies of the amorphous silicon thin-film solar cell industry","With the shortage of raw materials for the production of crystalline silicon solar cells, the next generation of solar cells has reached the perfect stage for development. While in the past, researchers have emphasized the development of crystalline silicon solar cells, the application of the next generation of crystalline silicon solar cells is different. Of the thin-film solar cells (TFSCs), the most widely recognized is the amorphous silicon (a-Si) TFSC. It has the greatest potential to be developed, and many manufacturers have already invested in its research and development (R&D). In this study, we employed a set of indicators to analyze the technological development of the a-Si TFSC, and found that the major technology field has reached the mature stage in the technology life cycle of this product; moreover, four patent strategic clusters were identified. The results regarding the company and technology levels of the clusters were integrated with profile data and developmental progress information to understand the patent performance, technologic capacity, and R&D background of the a-Si TFSC.","Patent portfolio,Patent analysis,Technological strategy,a-Si thin-film solar cell","Fang-MeiTseng,Chih-HungHsieh,Ya-NiPeng,Yi-WeiChu","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2010.10.010","https://www.sciencedirect.com/science/article/pii/S0040162510002490"
"A499","Detecting emerging research fronts in regenerative medicine by the citation network analysis of scientific publications","In this paper, we detect emerging research fronts in a huge number of academic papers related to regenerative medicine, a field of radically innovative research. We divide citation networks into clusters using the topological clustering method, track the positions of papers in each cluster, and visualize citation networks with characteristic terms for each cluster. Analyzing the clustering results with the average published year and parent–child relationship of each cluster could be helpful in detecting recent trends. In addition, tracking topological measures, within-cluster degree z and participation coefficient P, enables us to determine whether there are emerging knowledge clusters. Our results show the success of our method in detecting emerging research fronts in regenerative medicine, and these results are confirmed as reasonable by experts. Finally, we predict the future core papers, with the potential of many citations, via the betweenness centralities in the citation network of the research into adult and somatic stem cells.","Citation analysis,Emerging topic detection,Research front,Regenerative medicine,Embryonic stem cells,Induced pluripotent stem cells","NaokiShibataa,YuyaKajikawaa,YoshiyukiTakedab,IchiroSakatac,KatsumoriMatsushimaa","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2010.07.006","https://www.sciencedirect.com/science/article/pii/S004016251000154X"
"A500","Mining group-based knowledge flows for sharing task knowledge","In an organization, knowledge is the most important resource in the creation of core competitive advantages. It is circulated and accumulated by knowledge flows (KFs) in the organization to support workers' task needs. Because workers accumulate knowledge of different domains, they may cooperate and participate in several task-based groups to satisfy their needs. In this paper, we propose algorithms that integrate information retrieval and data mining techniques to mine and construct group-based KFs (GKFs) for task-based groups. A GKF is expressed as a directed knowledge graph which represents the knowledge referencing behavior, or knowledge flow, of a group of workers with similar task needs. Task-related knowledge topics and their relationships (flows) can be identified from the knowledge graph so as to fulfill workers' task needs and promote knowledge sharing for collaboration of group members. Moreover, the frequent knowledge referencing path can be identified from the knowledge graph to indicate the frequent knowledge flow of the workers. To demonstrate the efficacy of the proposed methods, we implement a prototype of the GKF mining system. Our GKF mining methods can enhance organizational learning and facilitate knowledge management, sharing, and reuse in an environment where collaboration and teamwork are essential.","Knowledge flow,Group-based knowledge flow,Knowledge graph,Knowledge sharing,Data mining,Topic,Task","Duen-RenLiu,Chin-HuiLai","Decision Support Systems","https://doi.org/10.1016/j.dss.2010.09.004","https://www.sciencedirect.com/science/article/pii/S0167923610001739"
"A501","Global Environmental Impact Assessment Research Trends (1973-2009)","According to the samples of 1781 literatures about environmental impact assessment (EIA) of SCI and SSCI databases from 1973 to 2009, this paper analyzes the literatures in their trend of growth, subject categories and journals, International collaborations, geographic distribution of publications and scientific research issues by using bibliometrics analysis. The result shows that EIA research steadily increases over the past 40 years and the annual number of papers published in 2009 is 50 times than that in 1973. EIA was involved into 130 kinds of subjects and appeared in 587 journals. The main study area with strong scientific research capabilities distributed in USA and European Union, while the USA was the largest contributor in EIA research and had a central position in collaboration networks. A keyword analysis found that the priority in assessment would gradually change from project environmental impact assessment to Strategic Environmental Assessment (SEA) and Plan Environmental Impact Assessment (PEIA); EIA research would focus on using and improving new techniques and methods, such as “life cycle assessment (LCA)”, “geographic information system (GIS)” and “modeling” etc.; “biodiversity” and “climate change” would attract more attention and will be the emphasis of EIA; the improvement of developing countries’ EIA system became popular research. This study reveals patterns in scientific outputs and academic collaborations and serves as an alternative and innovative way of identifying global research trends in EIA.","Environmental impact assessment (EIA),strategic environmental assessment (SEA),bibliometric analysis,keywords analysis,Research Trends","ZhuangYanhua,HongSong,LinHongyan,NiuBeibei","Procedia Environmental Sciences","https://doi.org/10.1016/j.proenv.2011.12.226","https://www.sciencedirect.com/science/article/pii/S1878029611010498"
"A502","Chapter 11: The Explorer","","","Ian H.Witten,EibeFrank,Mark A.Hall","Data Mining: Practical Machine Learning Tools and Techniques,Data Mining: Practical Machine Learning Tools and Techniques (Third Edition)","https://doi.org/10.1016/B978-0-12-374856-0.00011-0","https://www.sciencedirect.com/science/article/pii/B9780123748560000110"
"A503","Bionics in patents – semantic-based analysis for the exploitation of bionic principles in patents","In this paper we present a sophisticated method to exploit bionic inventions in patents with the help of semantic patent analysis. This method enables users to visualize similarities in patent content in a semantic patent map. These maps could be used for strategic decision-making, e.g. for developing technologies and commercial usage and – no less important – for providing new insights to researchers and practitioners involved in bionics. A case study of US-based patents between 1976 and 2006 clearly shows that most bionic inventions are patented as medical applications in the area of surgery. Other fields of technological applications, however, apparently do not make use of bionic ideas for solving inventive problems. As a result, bionics may provide great potential for solving technical problems that needs to be exploited, e.g. perhaps to be carried out with the help of TRIZ.","Bionics,Inventions of nature,Patents,Patent map,Semantic patent analysis","LotharWalter,RalfIsenmann,Martin G.Moehrle","Procedia Engineering","https://doi.org/10.1016/j.proeng.2011.03.147","https://www.sciencedirect.com/science/article/pii/S1877705811001640"
"A504","Approaches to understanding and measuring interdisciplinary scientific research (IDR): A review of the literature","Interdisciplinary scientific research (IDR) extends and challenges the study of science on a number of fronts, including creating output science and engineering (S&E) indicators. This literature review began with a narrow search for quantitative measures of the output of IDR that could contribute to indicators, but the authors expanded the scope of the review as it became clear that differing definitions, assessment tools, evaluation processes, and measures all shed light on different aspects of IDR. Key among these broader aspects is (a) the importance of incorporating the concept of knowledge integration, and (b) recognizing that integration can occur within a single mind as well as among a team. Existing output measures alone cannot adequately capture this process. Among the quantitative measures considered, bibliometrics (co-authorships, co-inventors, collaborations, references, citations and co-citations) are the most developed, but leave considerable gaps in understanding of the social dynamics that lead to knowledge integration. Emerging measures in network dynamics (particularly betweenness centrality and diversity), and entropy are promising as indicators, but their use requires sophisticated interpretations. Combinations of quantitative measures and qualitative assessments being applied within evaluation studies appear to reveal IDR processes but carry burdens of expense, intrusion, and lack of reproducibility year-upon-year. This review is a first step toward providing a more holistic view of measuring IDR, although research and development is needed before metrics can adequately reflect the actual phenomenon of IDR.","Interdisciplinary,Science,Research,Indicators,Bibliometrics,Evaluation","Caroline S.Wagnera,J. DavidRoessnera,KamauBobba,Julie ThompsonKleinb,Kevin W.Boyackc,JoannKeytond,IsmaelRafolse,KatyBörnerf","Journal of Informetrics","https://doi.org/10.1016/j.joi.2010.06.004","https://www.sciencedirect.com/science/article/pii/S1751157710000581"
"A505","5.15: Nanotechnology, Society, and Environment","","Equity,Governance,Health,Imaginaries,Nanotechnology discourse,Nanotechnology ethics,Nanotechnology and society,Risk,Science and naturescience communication science","P.Murphy,D.Munshi,P.A.Kurian,A.Lakhtakia,R.V.Bartlett","Comprehensive Nanoscience and Technology,Comprehensive Nanoscience and Technology","https://doi.org/10.1016/B978-0-12-374396-1.00145-8","https://www.sciencedirect.com/science/article/pii/B9780123743961001458"
"A506","Interruption of ß-catenin suppresses the EGFR pathway by blocking multiple oncogenic targets in human glioma cells","Malignant gliomas are the most common type of intrinsic central nervous system (CNS) tumors with high mortality and morbidity. ß-catenin is overexpressed in human glioblastoma and knockdown of ß-catenin inhibits glioblastoma cell proliferation and invasive ability, and induces apoptotic cell death. Furthermore, treating the nude mice carrying established subcutaneous LN229 gliomas with siRNA targeting ß-catenin intratumorally also delayed the tumor growth. However, the mechanisms of down-regulation of ß-catenin that represses glioblastoma malignancy behavior remain to be elucidated. We utilized text-mining of MEDLINE abstracts with natural language processing to establish the ß-catenin biologic association network, and identified several interactions of this network with the EGFR pathway. In both in vitro and in vivo studies, our results confirmed down-regulation of ß-catenin induced reduced expression of EGFR, STAT3 and AKT1 mRNA and protein, besides, the level of phosphorylated Akt also decreased. A similar reduction in expression of CyclinD1, MMP2 and MMP9, downstream genes of the EGFR pathway, was observed. These results suggest that the Wnt/ß-catenin pathway regulates glioma cell proliferation and invasion, in part via the EGFR pathway.","Glioma,ß-catenin,EGFR,Signaling pathway,Abbreviations,EGFRepidermal growth factor receptor,STAT3signal transducer and activator of transcription 3,AKTAKT protein family, which members are also called protein kinases B,MMP2matrix metalloproteinase-2,MMP9matrix metalloproteinase-9,VEGFVascular endothelial growth factor","XiaoYueabc1,FengMingLanabc1,WeidongYangb1,YangYangabc,LeiHanabc,AnlingZhangabc,JilongLiud,HuazongZengd,TaoJiange,PeiyuPuabc,ChunshengKangabc","Brain Research","https://doi.org/10.1016/j.brainres.2010.10.032","https://www.sciencedirect.com/science/article/pii/S0006899310023012"
"A507","Leadership, levels of analysis, and déjà vu: Modest proposals for taxonomy and cladistics coupled with replication and visualization","In the inaugural issue of LQ's Yearly Review of Leadership, Hunt and Dodge (2000, p. 442) note that, “Within the last two decades, one of the crucial developments in organizational research in general, and in leadership research specifically, is the articulation of specific levels of analysis and their implications for theory building, measurement, and observation.” Their original observations are updated by extending the inferential logic of Yammarino, Dionne, Chun and Dansereau (2005) to determine if any increase in the utilization of a level of analysis perspective has occurred in the last five years. The possible evolution of leadership theory and analysis is discussed, especially with reference to Relational Leadership Theory, Leader–Member Exchange, and Individualized Dyadic Theory. Proposals incorporating taxonomic and visualization tools as a means to help bridge the stakeholder gap are also offered.","Leader–Member Exchange,Vertical dyadic leadership,Multilevel,Levels of analysis,Cladistics,Scientific visualization,Covariance theorem,Superstructure,Meso,Relational Leadership Theory,Contextualization,Contextual analysis,LMX,S-LMX,VDL,RLT,IDT,DM-LMX,Organizational visualization,Dyadic visualization,Bubble chart","Steven E.Markham","The Leadership Quarterly","https://doi.org/10.1016/j.leaqua.2010.10.011","https://www.sciencedirect.com/science/article/pii/S1048984310001487"
"A508","Patinformatics as a business process: A guideline through patent research tasks and tools","Since Trippe [1] introduced the term ‘patinformatics’ a lot of progress has been made in this particular field of information science. However, there is still need for a more comprehensive framework to structure the variety of tasks related to ‘patinformatics’, to highlight essential functions within the patinformatics process and to identify those process parts, which are supported by currently available software tools, and others, which are not. In this paper we apply business process modeling to describe the patinformatics process for supporting managerial decision making. The process model enables an overview of major tasks within patinformatics and links them to currently available tools. This paper provides a guideline through patent research for most users of patent information. It may also be employed as a fundamental model for the comparison of patinformatics software applications and approaches.","Patinformatics,Patent research tasks,Patent research tool,Process modeling,Event-driven process chain,Pre-processing,Patent analysis,Discovered knowledge","Martin G.Moehrle,LotharWalter,IsumoBergmann,SebastianBobe,SvenjaSkrzipale","World Patent Information","https://doi.org/10.1016/j.wpi.2009.11.003","https://www.sciencedirect.com/science/article/pii/S0172219009001380"
"A509","EPR dosimetry with tooth enamel: A review","When tooth enamel is exposed to ionizing radiation, radicals are formed, which can be detected using electron paramagnetic resonance (EPR) techniques. EPR dosimetry using tooth enamel is based on the (presumed) correlation between the intensity or amplitude of some of the radiation-induced signals with the dose absorbed in the enamel. In the present paper a critical review is given of this widely applied dosimetric method. The first part of the paper is fairly fundamental and deals with the main properties of tooth enamel and some of its model systems (e.g., synthetic apatites). Considerable attention is also paid to the numerous radiation-induced and native EPR signals and the radicals responsible for them. The relevant methods for EPR detection, identification and spectrum analyzing are reviewed from a general point of view. Finally, the needs for solid-state modelling and studies of the linearity of the dose response are investigated. The second part is devoted to the practical implementation of EPR dosimetry using enamel. It concerns specific problems of preparation of samples, their irradiation and spectrum acquisition. It also describes how the dosimetric signal intensity and dose can be retrieved from the EPR spectra. Special attention is paid to the energy dependence of the EPR response and to sources of uncertainties. Results of and problems encountered in international intercomparisons and epidemiological studies are also dealt with. In the final section the future of EPR dosimetry with tooth enamel is analyzed.","EPR,ESR,Tooth enamel,Dosimetry","PaolaFattibenea,FreddyCallensb","Applied Radiation and Isotopes","https://doi.org/10.1016/j.apradiso.2010.05.016","https://www.sciencedirect.com/science/article/pii/S0969804310002356"
"A510","Mediating debate through on-line large-scale argumentation: Evidence from the field","Web 2.0 technologies, such as forums and wikis, are enabling an explosion of global knowledge sharing through distributed large-scale conversations, but they seem to be less successful at supporting collaborative deliberation around complex and controversial questions. In order to cope with this limitation, many scholars have proposed to adopt on-line argumentation platforms to improve information visualization, organization and reuse. However, such research has mostly focused on the design of adequate argument-based knowledge formalisms. Less attention has been paid to the empirical analysis of actual interactions mediated by argumentation technology with reasonably large user communities. In this paper, we present an in-depth analysis of the data obtained in the empirical test of an argumentation platform where a 160-member community created, in 3 weeks, what is to our knowledge the largest single online argument map ever built (around 5000 posts). Our results show that (i) users were able to quickly and comprehensively explore and map the debate on the selected discussion topic; (ii) substantial moderation was needed to ensure that the argument map was well-organized and users were confident with the argumentation formalism; (iii) considerable out-of-the map communication occurred, possibly as a way to allow for conversational flows inhibited by the argumentation formalism, (iv) formal rating of contributions favored exploration of the map, understanding the debate structure, and improving the quality of content.","Large scale argumentation,On-line deliberation,Collaborative technologies,Collective intelligence","AliGürkana1,LucaIandolib,MarkKleinc,GiuseppeZollob","Information Sciences","https://doi.org/10.1016/j.ins.2010.06.011","https://www.sciencedirect.com/science/article/pii/S0020025510002616"
"A511","The development of an AI journal ranking based on the revealed preference approach","This study presents a ranking of 182 academic journals in the field of artificial intelligence. For this, the revealed preference approach, also referred to as a citation impact method, was utilized to collect data from Google Scholar. This list was developed based on three relatively novel indices: h-index, g-index, and hc-index. These indices correlated almost perfectly with one another (ranging from 0.97 to 0.99), and they correlated strongly with Thomson's Journal Impact Factors (ranging from 0.64 to 0.69). It was concluded that journal longevity (years in print) is an important but not the only factor affecting an outlet's ranking position. Inclusion in Thomson's Journal Citation Reports is a must for a journal to be identified as a leading A+ or A level outlet. However, coverage by Thomson does not guarantee a high citation impact of an outlet. The presented list may be utilized by scholars who want to demonstrate their research output, various academic committees, librarians and administrators who are not familiar with the AI research domain.","Artificial intelligence,Journal ranking,Academic journal,Google scholar,Citation impact,h-Index,g-Index,hc-Index","AlexanderSerenko","Journal of Informetrics","https://doi.org/10.1016/j.joi.2010.04.001","https://www.sciencedirect.com/science/article/pii/S1751157710000349"
"A512","Business, market and intellectual property analysis of polymer solar cells","The business potential of polymer solar cells is reviewed and the market opportunities analyzed on the basis of the currently reported and projected performance and manufacturing cost of polymer solar cells. Possible new market areas are identified and described. An overview of the present patent and intellectual property situation is also given and a patent map of polymer solar cells is drawn in a European context. It is found that the business potential of polymer solar cells is large when taking the projections for future performance into account while the currently available performance and manufacturing cost leaves little room for competition on the thin film photovoltaic market. However, polymer solar cells do enable the competitive manufacture of low cost niche products and is viewed as financially viable in its currently available form in a large volume approximation. Finally, it is found that the polymer solar cell technology is very poorly protected in Europe with the central patents being valid in only France, Germany, the Netherlands and the United Kingdom. Several countries with a large potential for PV such as Portugal and Greece are completely open and have apparently no relevant patents. This is viewed as a great advantage for the possible commercialization of polymer solar cells in a European setting as the competition for the market will be based on the manufacturing performance rather than domination by a few patent stakeholders.","Business analysis,Market analysis,IPR analysis,Intellectual property analysis,Polymer solar cells,Organic solar cells,OPV,Roll-to-roll processing,Polymer solar cell modules,Patents","Torben D.Nielsena,CraigCruickshankb,SørenFogedc,JesperThorsenc,Frederik C.Krebsa","Solar Energy Materials and Solar Cells","https://doi.org/10.1016/j.solmat.2010.04.074","https://www.sciencedirect.com/science/article/pii/S0927024810002746"
"A513","Posters September, 30th","","","","European Geriatric Medicine","https://doi.org/10.1016/j.eurger.2010.07.008","https://www.sciencedirect.com/science/article/pii/S1878764910001567"
"A514","Abstracts","","","","European Journal of Surgical Oncology (EJSO)","https://doi.org/10.1016/S0748-7983(10)00156-3","https://www.sciencedirect.com/science/article/pii/S0748798310001563"
"A515","Extracting the commercialization gap between science and technology — Case study of a solar cell","In this paper, we compared structures of the citation network of scientific publications with those of patents, and discussed the differences between them. A case study was performed in a solar cell to develop a method of detecting gaps between science and technology. Scientific research has tended to be more basic, especially in terms of cell design, whereas patents have focused on more applied technology used in solar cell modules. Of the major citation clusters of scientific publications, only two, namely silicon and compound solar cells, corresponded semantically with patent clusters. Conversely, there were no patent clusters corresponding to the other two scientific research fronts, namely dye-sensitized and polymer solar cells. These research areas could be regarded as opportunities for industrial commercialization because scientific activities exist but not technological applications. Our results could offer an intellectual basis for discovering potential opportunities for industrial commercialization.","R&D management,Technology roadmap,Research front,Bibliometrics,Citation analysis,Patent analysis","NaokiShibataa,YuyaKajikawaa,IchiroSakatab","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2010.03.008","https://www.sciencedirect.com/science/article/pii/S0040162510000600"
"A516","Text mining for traditional Chinese medical knowledge discovery: A survey","Extracting meaningful information and knowledge from free text is the subject of considerable research interest in the machine learning and data mining fields. Text data mining (or text mining) has become one of the most active research sub-fields in data mining. Significant developments in the area of biomedical text mining during the past years have demonstrated its great promise for supporting scientists in developing novel hypotheses and new knowledge from the biomedical literature. Traditional Chinese medicine (TCM) provides a distinct methodology with which to view human life. It is one of the most complete and distinguished traditional medicines with a history of several thousand years of studying and practicing the diagnosis and treatment of human disease. It has been shown that the TCM knowledge obtained from clinical practice has become a significant complementary source of information for modern biomedical sciences. TCM literature obtained from the historical period and from modern clinical studies has recently been transformed into digital data in the form of relational databases or text documents, which provide an effective platform for information sharing and retrieval. This motivates and facilitates research and development into knowledge discovery approaches and to modernize TCM. In order to contribute to this still growing field, this paper presents (1) a comparative introduction to TCM and modern biomedicine, (2) a survey of the related information sources of TCM, (3) a review and discussion of the state of the art and the development of text mining techniques with applications to TCM, (4) a discussion of the research issues around TCM text mining and its future directions.","Text mining,Traditional Chinese medicine,Review","XuezhongZhoua,YonghongPengb,BaoyanLiuc","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2010.01.002","https://www.sciencedirect.com/science/article/pii/S1532046410000031"
"A517","A generalized model of relational similarity","This paper introduces two principles for relational similarity, and based on these principles it proposes a novel geometric representation for similarity. The first principle generalizes earlier measures of similarity such as Pearson-correlation and structural equivalence: while correlation and structural equivalence measure similarity by the extent to which the actors have similar relationships to other actors or objects, the proposed model views two actors similar if they have similar relationships to similar actors or objects. The second principle emphasizes consistency among similarities: not only are actors similar if they have similar relationships to similar objects, but at the same time objects are similar if similar actors relate to them similarly. We examine the behavior of the proposed similarity model through simulations, and re-analyze two classic datasets: the Davis et al. (1941) data on club membership and the roll-call data of the U.S. Senate. We find that the generalized model of similarity is especially useful if (1) the dimensions of comparison are not independent, or (2) the data are sparse, or (3) the boundaries between clusters are not clear.","Relational similarity,Geometrical representations,Correlation,Blockmodeling","BalázsKovács","Social Networks","https://doi.org/10.1016/j.socnet.2010.02.001","https://www.sciencedirect.com/science/article/pii/S0378873310000031"
"A518","Multi-way association extraction and visualization from biological text documents using hyper-graphs: Applications to genetic association studies for diseases","ObjectivesBiological research literature, as in many other domains of human endeavor, represents a rich, ever growing source of knowledge. An important form of such biological knowledge constitutes associations among biological entities such as genes, proteins, diseases, drugs and chemicals, etc. There has been a considerable amount of recent research in extraction of various kinds of binary associations (e.g., gene–gene, gene–protein, protein–protein, etc.) using different text mining approaches. However, an important aspect of such associations (e.g., “gene A activates protein B”) is identifying the context in which such associations occur (e.g., “gene A activates protein B in the context of disease C in organ D under the influence of chemical E”). Such contexts can be represented appropriately by a multi-way relationship involving more than two objects (e.g., objects A, B, C, D, E) rather than usual binary relationship (objects A and B).,MethodsSuch multi-way relations naturally lead to a hyper-graph representation of the knowledge rather than a binary graph. The hyper-graph based multi-way knowledge extraction from biological text literature represents a computationally difficult problem (due to its combinatorial nature) which has not received much attention from the Bioinformatics research community. In this paper, we describe and compare two different approaches to such multi-way hyper-graph extraction: one based on an exhaustive enumeration of all multi-way hyper-edges and the other based on an extension of the well-known A Priori algorithm for structured data to the case unstructured textual data. We also present a representative graph based approach towards visualizing these genetic association hyper-graphs.,ResultsTwo case studies are conducted for two biomedical problems (related to the diseases of lung cancer and colorectal cancer respectively), illustrating that the latter approach (using the text-based A Priori method) identifies the same hyper-edges as the former approach (the exhaustive method), but at a much less computational cost. The extracted hyper-relations are presented in the paper as cognition-rich representative graphs, representing the corresponding hyper-graphs.,ConclusionsThe text-based A Priori algorithm is a practical, useful method to extract hyper-graphs representing multi-way associations among biological objects. These hyper-graphs and their visualization using representative graphs can provide important contextual information for understanding gene–gene associations relevant to specific diseases.","Hyper-graphs,Representative graphs,A Priori algorithm,Vector space model,Genetic associations,Lung cancer,Colorectal cancer","SnehasisMukhopadhyay,MathewPalakal,KalyanMaddu","Artificial Intelligence in Medicine","https://doi.org/10.1016/j.artmed.2010.03.002","https://www.sciencedirect.com/science/article/pii/S0933365710000291"
"A519","Visualizing search results and document collections using topic maps","This paper explores visualizations of document collections, which we call topic maps. Our topic maps are based on a topic model of the document collection, where the topic model is used to determine the semantic content of each document. Using two collections of search results, we show how topic maps reveal the semantic structure of a collection and visually communicate the diversity of content in the collection. We describe techniques for assessing the validity and accuracy of topic maps, and discuss the challenge of producing useful two-dimensional maps of documents.","Topic modelling,Visualizing document collections,Clustering,Dimensionality reduction","DavidNewmana1,TimothyBaldwinab,LawrenceCavedona,EricHuanga,SarvnazKarimia,DavidMartineza,FalkScholera,JustinZobelab","Web Semantics: Science, Services and Agents on the World Wide Web","https://doi.org/10.1016/j.websem.2010.03.005","https://www.sciencedirect.com/science/article/pii/S1570826810000211"
"A520","Natural world physical, brain operational, and mind phenomenal space–time","Concepts of space and time are widely developed in physics. However, there is a considerable lack of biologically plausible theoretical frameworks that can demonstrate how space and time dimensions are implemented in the activity of the most complex life-system — the brain with a mind. Brain activity is organized both temporally and spatially, thus representing space–time in the brain. Critical analysis of recent research on the space–time organization of the brain's activity pointed to the existence of so-called operational space–time in the brain. This space–time is limited to the execution of brain operations of differing complexity. During each such brain operation a particular short-term spatio-temporal pattern of integrated activity of different brain areas emerges within related operational space–time. At the same time, to have a fully functional human brain one needs to have a subjective mental experience. Current research on the subjective mental experience offers detailed analysis of space–time organization of the mind. According to this research, subjective mental experience (subjective virtual world) has definitive spatial and temporal properties similar to many physical phenomena. Based on systematic review of the propositions and tenets of brain and mind space–time descriptions, our aim in this review essay is to explore the relations between the two. To be precise, we would like to discuss the hypothesis that via the brain operational space–time the mind subjective space–time is connected to otherwise distant physical space–time reality.","Spatial,Temporal,Consciousness,Cognition,Operation,Architectonics,EEG,Field,Metastability,Physics,Coordinative dynamics,Self-organization,Cortex","Andrew A.Fingelkurts,Alexander A.Fingelkurts,Carlos F.H.Neves","Physics of Life Reviews","https://doi.org/10.1016/j.plrev.2010.04.001","https://www.sciencedirect.com/science/article/pii/S1571064510000370"
"A521","Data clustering: 50 years beyond K-means","Organizing data into sensible groupings is one of the most fundamental modes of understanding and learning. As an example, a common scheme of scientific classification puts organisms into a system of ranked taxa: domain, kingdom, phylum, class, etc. Cluster analysis is the formal study of methods and algorithms for grouping, or clustering, objects according to measured or perceived intrinsic characteristics or similarity. Cluster analysis does not use category labels that tag objects with prior identifiers, i.e., class labels. The absence of category information distinguishes data clustering (unsupervised learning) from classification or discriminant analysis (supervised learning). The aim of clustering is to find structure in data and is therefore exploratory in nature. Clustering has a long and rich history in a variety of scientific fields. One of the most popular and simple clustering algorithms, K-means, was first published in 1955. In spite of the fact that K-means was proposed over 50 years ago and thousands of clustering algorithms have been published since then, K-means is still widely used. This speaks to the difficulty in designing a general purpose clustering algorithm and the ill-posed problem of clustering. We provide a brief overview of clustering, summarize well known clustering methods, discuss the major challenges and key issues in designing clustering algorithms, and point out some of the emerging and useful research directions, including semi-supervised clustering, ensemble clustering, simultaneous feature selection during data clustering, and large scale data clustering.","Data clustering,User’s dilemma,Historical developments,Perspectives on clustering,King-Sun Fu prize","Anil K.Jain","Pattern Recognition Letters","https://doi.org/10.1016/j.patrec.2009.09.011","https://www.sciencedirect.com/science/article/pii/S0167865509002323"
"A522","Personalised news and scientific literature aggregation","Content-based filtering can be deployed for personalised information dissemination on the web, but this is a possibility that has been largely ignored. Nowadays, there are no successful content-based filtering applications available online. Nootropia is an immune-inspired user profiling model for content-based filtering. It has the advantageous property to be able to represent a user’s multiple interests and adapt to a variety of changes in them. In this paper we describe our early efforts to develop real world personalisation services based on Nootropia. We present, the architecture, implementation, usage and evaluation of the personalised news and paper aggregator, which aggregates news and papers that are relevant to an individual’s interests. Our user study shows that Nootropia can effectively learn a user’s interests and identify relevant information. It also indicates that information filtering is a complicated task with many factors affecting its successful application in a real situation.","User profiling,Adaptive information filtering,Personalisation","NikolaosNanasa,ManolisVavalisab,EliasHoustisab","Information Processing & Management","https://doi.org/10.1016/j.ipm.2009.07.005","https://www.sciencedirect.com/science/article/pii/S0306457309000855"
"A523","Thursday Abstracts","","","","Biological Psychiatry","https://doi.org/10.1016/j.biopsych.2010.03.007","https://www.sciencedirect.com/science/article/pii/S0006322310002350"
"A524","Anticipating converging industries using publicly available data","Industry convergence, described as the blurring of boundaries between industries, plays an increasingly pivotal role in shaping markets and industries. Traditionally, this phenomenon has been discussed in respect to telecommunications, information technologies and electronics, but more recently also the chemical and its related industries find themselves affected by a larger convergence process. With the primary example of phytosterols in the two converging industries of Cosmeceuticals and of Nutraceuticals and Functional Foods, we analyze 7455 scientific and patent references in respect to first indicators for signs of convergence. Furthermore, we present and discuss a multiple indicator concept for monitoring convergence in an R&D-intensive field on the basis of publicly available data.","Converging industries,Patent analysis,Nutraceuticals and Functional Foods,Cosmeceuticals,Phytosterols,Chemical industry,Bibliometrics","Clive-StevenCurrana,StefanieBröringb,JensLekera","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2009.10.002","https://www.sciencedirect.com/science/article/pii/S0040162509001425"
"A525","Quantitative mapping of patented technology — The case of electrical conducting polymer nanocomposite","This study aims to obtain global technology evolution by constructing and analyzing patent citation network and patent citation map for the field of electrical conducting polymer nanocomposite. A total of 1421 patents are retrieved from USPTO patent database and patent citation network is established by combing both patent citation and social network analysis. Network properties, e.g. Degree Centrality, Betweenness Centrality, and Closeness Centrality, are calculated for representing several technology evolution mechanisms that first proposed in this study. Also, a distance-based patent citation map is constructed by calculating relative distances and positions of patents in the patent citation network. Quantitative ways of exploring technology evolution are investigated in this study to unveil important or emerging techniques as well as to demonstrate dynamics and visualization of technology evolutions.","Network analysis,Technology evolution,Mapping,Patent citation,Quantitative analysis","Pei-ChunLeeab1,Hsin-NingSub,Feng-ShangWua2","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2009.08.006","https://www.sciencedirect.com/science/article/pii/S0040162509001309"
"A526","Debugging complex software systems by means of pathfinder networks","This paper introduces a new methodology based on the use of Pathfinder networks (PFNETs) for the debugging of multi-agent systems (MASs). This methodology is specifically designed to develop a forensic analysis (i.e. a debugging process performed on previously recorded data of the MAS run) of MASs showing complex tissues of relationships between agents (i.e. a high complexity in their social level). Like previous works in the field of forensic analysis of MASs, our approach is performed by considering displays of the system activity which aim to be understandable by human beings. These displays allow us to understand the social behavior of the system, discover emergent behaviors, and debug possible undesirable behaviors. However, it is well known that the visualization of information in a humanly comprehensible way becomes a complex task when large amounts of information have to be represented, as is the case of the social behavior of large-scale MASs. Our methodology tackles this problem through the use of PFNETs, which are considered to reduce the data complexity in order to obtain simple representations that show only the most important global interactions in the system. In addition, the proposed methodology is customizable thanks to the use of two thresholds allowing the user to define the desired specificity level in the display. The proposal is illustrated with a detailed case study considering a complex customer–seller MAS.","Multi-agent systems,Debugging,Forensic analysis,Pathfinder networks,Complex systems","EmilioSerranoa,ArnaudQuirinb,JuanBotiaa,OscarCordónb","Information Sciences","https://doi.org/10.1016/j.ins.2009.11.007","https://www.sciencedirect.com/science/article/pii/S0020025509004691"
"A527","Literature listing","","","","World Patent Information","https://doi.org/10.1016/j.wpi.2009.10.001","https://www.sciencedirect.com/science/article/pii/S0172219009001306"
"A528","Chapter 6: Metadata: Elements of organization","Metadata, often described as data about data, is critical to all forms of organized digital content. Metadata is generally taken to be structured information about a particular information resource. The objects of description have also evolved, to include varied media, and, in museums, a panoply of diverse physical objects. There are several approaches to classifying metadata, depending on its source, purpose, audience, and format. Many file formats contain embedded metadata that needs to be extracted from the file before it can used to organize items in a digital library. The central issue is whether the file format is clearly documented and available for inspection. Anyone working with digital libraries needs to know about the different standard methods for representing document metadata. The use of standardized records allows for great efficiencies in metadata creation and also facilitates the construction of so-called union catalogs that combine metadata from several libraries. The Creator might be a photographer, an illustrator, or an author. The Subject is typically expressed as a keyword or phrase that describes the topic or the content of the resource. The Description might be an abstract of a textual document, or a textual account of a non-textual resource, such as a picture or an animation.","","Ian H.Witten,DavidBainbridge,David M.Nichols","How to Build a Digital Library,How to Build a Digital Library (Second Edition)","https://doi.org/10.1016/B978-0-12-374857-7.00006-2","https://www.sciencedirect.com/science/article/pii/B9780123748577000062"
"A529","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2009.12.004","https://www.sciencedirect.com/science/article/pii/S0140670109000459"
"A530","Chapter 1: Applications in Data-Intensive Computing","The total quantity of digital information in the world is growing at an alarming rate. Scientists and engineers are contributing heavily to this data “tsunami” by gathering data using computing and instrumentation at incredible rates. As data volumes and complexity grow, it is increasingly arduous to extract valuable information from the data and derive knowledge from that data. Addressing these demands of ever-growing data volumes and complexity requires game-changing advances in software, hardware, and algorithms. Solution technologies also must scale to handle the increased data collection and processing rates and simultaneously accelerate timely and effective analysis results. This need for ever faster data processing and manipulation as well as algorithms that scale to high-volume data sets have given birth to a new paradigm or discipline known as “data-intensive computing.” In this chapter, we define data-intensive computing, identify the challenges of massive data, outline solutions for hardware, software, and analytics, and discuss a number of applications in the areas of biology, cyber security, and atmospheric research.","Data-intensive computing,Compute-intensive problems,Software architectures,Scientific applications","Anuj R.Shah,Joshua N.Adkins,Douglas J.Baxter,William R.Cannon,Daniel G.Chavarria-Miranda,SutanayChoudhury,IanGorton,Deborah K.Gracio,Todd D.Halter,Navdeep D.Jaitly,John R.Johnson,Richard T.Kouzes,Matthew C.Macduff,AndresMarquez,Matthew E.Monroe,Christopher S.Oehmen,William A.Pike,ChadScherrer,…,NinoZuljevic","Advances in Computers","https://doi.org/10.1016/S0065-2458(10)79001-X","https://www.sciencedirect.com/science/article/pii/S006524581079001X"
"A531","12.21: Computational Toxicology","","computational,data mining,developmental,informatics,knowledgebase,ontology,structure–activity relationship,text mining,toxicology,ACToRAggregated Computational Toxicology Resource,BDSMBirth Defects Systems Manager,BioPAXBiological Pathway Exchange,CDER(US FDA) Center for Drug Evaluation and Research,CDKChemistry Development Kit,CEBSChemical Effects of Biological Systems,CMLChemical Markup Language,CRADACooperative Research and Development Agreement,DARTDevelopmental and Reproductive Toxicology Database,DERData Evaluation Record,EBIEuropean Bioinformatics Institute,EMAPEdinburgh Mouse Atlas Project,EPAUS Environmental Protection Agency,EUEuropean Union,FDAUS Food and Drug Administration,FOBfunctional observation battery,GEOGene Expression Omnibus,HTShigh-throughput screening,ICSAS(US FDA CDER) Informatics and Computational Safety Analysis Staff,ILSIInternational Life Science Institute Research Foundation,KEGGKyoto Encyclopedia of Genes and Genomes,kwkeyword,LOELLowest No Observed Effect Level,MedDRAMedical Dictionary for Regulatory Activities,NCBINational Center for Biotechnology Information,NCCT(US EPA) National Center for Computational Toxicology,NCTRERDSSTox: US FDA National Center for Toxicological Research Estrogen Receptor Data File,NIHNational Institutes of Health,NLMNational Library of Medicine,NOELNo Observed Effect Level,NRCNational Research Council,NTPNational Toxicology Program,OBOOpen Biomedical Ontologies,OPP(US EPA) Office of Pesticide Programs,OWLWeb Ontology Language,PATOPhenotypic Attribute Trait Ontology,PBPKphysiologically based pharmacokinetic,PMIDPubMed unique Identifier,QSARquantitative structure–activity relationship,REACHRegistration, Evaluation, and Authorization of Chemicals,ROSreactive oxygen species,R-scorerelevance score,RSIRisk Science Institute,RTECSRegistry of Toxicological Effects of Chemical Substances,SARstructure–activity relationship,SBMLSystems Biology Markup Language,SIFSimple Interaction Format,TERISTeratogen Information System,TOXCSTDSSTox: Research Chemical Inventory for EPA’s ToxCast Program,ToxRefDBToxicity Reference Database,TSCA(US EPA) Toxic Substances Control Act,UniProtUniversal Protein Resource,URLUniform Resource Locator,v-EmbryoVirtual Embryo,XGMMLeXtensible Graph Markup and Modeling Language","A.V.Singh,R.J.Kavlock,A.M.Richard,C.Yang","Comprehensive Toxicology,Comprehensive Toxicology (Second Edition)","https://doi.org/10.1016/B978-0-08-046884-6.01529-3","https://www.sciencedirect.com/science/article/pii/B9780080468846015293"
"A532","Chapter 9: Visions: Future, past, and present","This chapter examines the history of 25 centuries of physical libraries. Digital libraries have certain obvious practical advantages over physical ones and seem to offer the promise of far greater universality. Library traditions have long been influenced by the belief that libraries should serve democracy. As part of their mission to serve as resource centers for citizens, public libraries maintain collections of records, policy statements, government documents, and so on. Digital libraries have the potential to be far more flexible than conventional ones. Another example of working within the digital library is Metadata Offer New Knowledge (MONK). MONK provides an environment within which humanities scholars can analyze texts and visualize the results. Software components for text-mining and Web-based data presentation are integrated into the digital library and configured to run on the fly, as needed. Libraries link the past and the future, and preservation has always been a key function. Whatever forms the cultural record is in, libraries ensure that it is preserved and made available for later use.","","Ian H.Witten,DavidBainbridge,David M.Nichols","How to Build a Digital Library,How to Build a Digital Library (Second Edition)","https://doi.org/10.1016/B978-0-12-374857-7.00010-4","https://www.sciencedirect.com/science/article/pii/B9780123748577000104"
"A533","Chapter 2: Active Sites and their Chemical Properties","This chapter reviews the basic features of enzymes and their active sites, including the forces governing protein structure and substrate, cofactor, and inhibitor binding. An account of the functional groups supplied by enzymes, those provided by coenzymes and those generated through posttranslational rearrangement of active-site residues, are also included. The reaction mechanisms of organic chemistry as well as phosphate ester and anhydride chemistry, in addition to the roles of metal ions therein, are then considered in the context of enzyme catalysis. Metal ions and oxidation–reduction reactions are also discussed, as so many enzymes employ these. An enzyme active site may be operationally defined as the region that binds the substrate(s), mediates catalysis, and releases the product(s). Active sites need not be limited to a single polypeptide chain and are frequently found at subunit–subunit interfaces. Enzyme catalysis obeys the same chemical principles that govern solution-phase organic and inorganic reactions, except that enzymes are generally far more efficient. Enzyme mechanisms involve displacement or substitution reactions, addition/elimination reactions, radical reactions, and/or redox reactions, the latter requiring redox coenzymes or redox-active metals. Enzyme catalysis also obeys the very same chemical principles that govern solution-phase organic and inorganic reactions, except that enzymes are generally far more efficient. Therefore, to comprehend enzyme catalysis, one must understand the principles of organic and inorganic chemistry as well as the approaches used to discriminate among rival reaction mechanisms.","","Daniel L.Purich","Enzyme Kinetics: Catalysis & Control,Enzyme Kinetics: Catalysis & Control","https://doi.org/10.1016/B978-0-12-380924-7.10002-X","https://www.sciencedirect.com/science/article/pii/B978012380924710002X"
"A534","Intelligent scientific authoring tools: Interactive data mining for constructive uses of citation networks","Many powerful methods and tools exist for extracting meaning from scientific publications, their texts, and their citation links. However, existing proposals often neglect a fundamental aspect of learning: that understanding and learning require an active and constructive exploration of a domain. In this paper, we describe a new method and a tool that use data mining and interactivity to turn the typical search and retrieve dialogue, in which the user asks questions and a system gives answers, into a dialogue that also involves sense-making, in which the user has to become active by constructing a bibliography and a domain model of the search term(s). This model starts from an automatically generated and annotated clustering solution that is iteratively modified by users. The tool is part of an integrated authoring system covering all phases from search through reading and sense-making to writing. Two evaluation studies demonstrate the usability of this interactive and constructive approach, and they show that clusters and groups represent identifiable sub-topics.","[H.2.8] Database management – database applications – data mining,[H.3.7] Information storage and retrieval – digital libraries – user issues,[H.3.3] Information storage and retrieval – information search and retrieval – search process, information filtering,[H.3.5] Information storage and retrieval – online information services – Web-based services,[K.3.2] Computers and education – computer and information science education – literacy,Citation analysis","B.Berendta,B.Krauseb,S.Kolbe-Nusserc","Information Processing & Management","https://doi.org/10.1016/j.ipm.2009.08.002","https://www.sciencedirect.com/science/article/pii/S0306457309000880"
"A535","Research intelligence involving information retrieval – An example of conferences and journals","This paper reports a work that was intended to reveal the connection between topics investigated by conference papers and journal papers. This work selected hundreds of papers in data mining and information retrieval from well-known databases and showed that the topics covered by conference papers in a year often leads to similar topics covered by journal papers in the subsequent year and vice versa. This study used some existing algorithms and combination of these algorithms to proposed a new detective procedure for the researchers to detect the new trend and get the academic intelligence from conferences and journals.The goal of this research is fourfold: First, the research investigates if the conference papers’ themes lead the journal papers’. Second, the research examines how the new research themes can be identified from the conference papers. Third, the research looks at a specific area such as information retrieval and data mining as an illustration. Fourth, the research studies any inconsistencies of the correlation between the conference papers and the journal papers.This study explores the connections between the academic publications. The methodologies of information retrieval and data mining can be exploited to discover the relationships between published papers among all topics. By discovering the connections between conference papers and journal papers, researchers can improve the effectiveness of their research by identifying academic intelligence.This study discusses how conference papers and journal papers are related. The topics of conference papers are identified to determine whether they represent new trend discussed in journal papers. An automatic examination procedure based on information retrieval and data mining is also proposed to minimize the time and human resources required to predict further research developments. This study develops a new procedure and collects a dataset to verify those problems. Analytical results demonstrate that the conference papers submitted to journals papers are similar each year. Conference papers certainly affect the journal papers published over three years. About 87.23% of data points from papers published in 1991–2007 support our assumption. The research is intended to help researchers identify new trend in their research fields, and focus on the urgent topics. This is particularly valuable for new researchers in their field, or those who wish to perform cross-domain studies.","Citation analysis,Scientific web intelligence,Topic discovery and tracking,Data mining,Information retrieval,Academic intelligence","Yi-NingTua,Jia-LangSengb1","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2009.03.015","https://www.sciencedirect.com/science/article/pii/S0957417409002668"
"A536","Phenomics: the systematic study of phenotypes on a genome-wide scale","Phenomics is an emerging transdiscipline dedicated to the systematic study of phenotypes on a genome-wide scale. New methods for high-throughput genotyping have changed the priority for biomedical research to phenotyping, but the human phenome is vast and its dimensionality remains unknown. Phenomics research strategies capable of linking genetic variation to public health concerns need to prioritize development of mechanistic frameworks that relate neural systems functioning to human behavior. New approaches to phenotype definition will benefit from crossing neuropsychiatric syndromal boundaries, and defining phenotypic features across multiple levels of expression from proteome to syndrome. The demand for high throughput phenotyping may stimulate a migration from conventional laboratory to web-based assessment of behavior, and this offers the promise of dynamic phenotyping—the iterative refinement of phenotype assays based on prior genotype-phenotype associations. Phenotypes that can be studied across species may provide greatest traction, particularly given rapid development in transgenic modeling. Phenomics research demands vertically integrated research teams, novel analytic strategies and informatics infrastructure to help manage complexity. The Consortium for Neuropsychiatric Phenomics at UCLA has been supported by the National Institutes of Health Roadmap Initiative to illustrate these principles, and is developing applications that may help investigators assemble, visualize, and ultimately test multi-level phenomics hypotheses. As the transdiscipline of phenomics matures, and work is extended to large-scale international collaborations, there is promise that systematic new knowledge bases will help fulfill the promise of personalized medicine and the rational diagnosis and treatment of neuropsychiatric syndromes.","phenotype,genetics,genomics,informatics,cognition,psychiatry,Abbreviations,ADHDattention deficit/hyperactivity disorder,CNPConsortium for Neuropsychiatric Phenomics,Gpr6G protein-coupled receptor 6 gene,GWASgenome wide association studies,LA2Kstudy of 2000 community volunteers in Los Angeles,SNPsingle nucleotide polymorphism","R.M.Bilderabe,F.W.Sabbae,T.D.Cannonabe,E.D.Londonace,J.D.Jentschbe,D. StottParkerd,R.A.Poldrackbe,C.Evansae,N.B.Freimerae","Neuroscience","https://doi.org/10.1016/j.neuroscience.2009.01.027","https://www.sciencedirect.com/science/article/pii/S0306452209000487"
"A537","Citation network analysis of organic LEDs","The field of organic light-emitting diodes (OLEDs) is an emergent research domain because of both scientific interest in chemistry and condensed matter physics and industrial importance as flat panel displays. In this paper, we analyzed a citation network of OLED papers and used a topological clustering method to investigate the structure of research and to detect emerging research domains. We found that most papers belong to two main clusters: organics and polymers. These two clusters have distinctive differences in subcluster structures and journals where papers are published. Supposing this discrepancy to indicate research progress, organics are in the applied research stage, while polymers are in the basic research stage.","Citation network,Bibliometrics,Research front,Research evaluation,Organic light-emitting diodes","YuyaKajikawa,YoshiyukiTakeda","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2009.04.004","https://www.sciencedirect.com/science/article/pii/S0040162509000560"
"A538","Abstracts","","","","Journal of Thoracic Oncology","https://doi.org/10.1097/JTO.0b013e3181b9c77e","https://www.sciencedirect.com/science/article/pii/S155608641533608X"
"A539","Mining meaning from Wikipedia","Wikipedia is a goldmine of information; not just for its many readers, but also for the growing community of researchers who recognize it as a resource of exceptional scale and utility. It represents a vast investment of manual effort and judgment: a huge, constantly evolving tapestry of concepts and relations that is being applied to a host of tasks.This article provides a comprehensive description of this work. It focuses on research that extracts and makes use of the concepts, relations, facts and descriptions found in Wikipedia, and organizes the work into four broad categories: applying Wikipedia to natural language processing; using it to facilitate information retrieval and information extraction; and as a resource for ontology building. The article addresses how Wikipedia is being used as is, how it is being improved and adapted, and how it is being combined with other structures to create entirely new resources. We identify the research groups and individuals involved, and how their work has developed in the last few years. We provide a comprehensive list of the open-source software they have produced.","Wikipedia,Text mining,Wikipedia mining,NLP,Information retrieval,Information extraction,Ontologies,Semantic web","OlenaMedelyan,DavidMilne,CatherineLegg,Ian H.Witten","International Journal of Human-Computer Studies","https://doi.org/10.1016/j.ijhcs.2009.05.004","https://www.sciencedirect.com/science/article/pii/S1071581909000561"
"A540","Untangling the web of e-Research: Towards a sociology of online knowledge","e-Research is a rapidly growing research area, both in terms of publications and in terms of funding. In this article we argue that it is necessary to reconceptualize the ways in which we seek to measure and understand e-Research by developing a sociology of knowledge based on our understanding of how science has been transformed historically and shifted into online forms. Next, we report data which allows the examination of e-Research through a variety of traces in order to begin to understand how knowledge in the realm of e-Research has been and is being constructed. These data indicate that e-Research has had a variable impact in different fields of research. We argue that only an overall account of the scale and scope of e-Research within and between different fields makes it possible to identify the organizational coherence and diffuseness of e-Research in terms of its socio-technical networks, and thus to identify the contributions of e-Research to various research fronts in the online production of knowledge.","e-Research,e-Science,Cyberinfrastructure,Sociology of knowledge,Sociology of science","Eric T.Meyer,RalphSchroeder","Journal of Informetrics","https://doi.org/10.1016/j.joi.2009.03.006","https://www.sciencedirect.com/science/article/pii/S1751157709000273"
"A541","Discrete and continuous conceptualizations of science: Implications for knowledge domain visualization","Visual depiction of the structure and evolution of science has been proposed as a key strategy for dealing with the large, complex, and increasingly interdisciplinary records of scientific communication. While every such visualization assumes the existence of spatial structures within the system of science, new methods and tools are rarely linked to thorough reflection on the underlying spatial concepts. Meanwhile, geographic information science has adopted a view of geographic space as conceptualized through the duality of discrete objects and continuous fields. This paper argues that conceptualization of science has been dominated by a view of its constituent elements (e.g., authors, articles, journals, disciplines) as discrete objects. It is proposed that, like in geographic information science, alternative concepts could be used for the same phenomenon. For example, one could view an author as either a discrete object at a specific location or as a continuous field occupying all of a discipline. It is further proposed that this duality of spatial concepts can extend to the methods by which low-dimensional geometric models of high-dimensional scientific spaces are created and used. This can result in new methods revealing different kinds of insights. This is demonstrated by a juxtaposition of two visualizations of an author's intellectual evolution on the basis of either a discrete or continuous conceptualization.","Visualization,Conceptualization,Spatial concepts,Geographic information science,Knowledge domain visualization,Geography","AndréSkupin","Journal of Informetrics","https://doi.org/10.1016/j.joi.2009.03.002","https://www.sciencedirect.com/science/article/pii/S1751157709000261"
"A542","Towards an explanatory and computational theory of scientific discovery","We propose an explanatory and computational theory of transformative discoveries in science. The theory is derived from a recurring theme found in a diverse range of scientific change, scientific discovery, and knowledge diffusion theories in philosophy of science, sociology of science, social network analysis, and information science. The theory extends the concept of structural holes from social networks to a broader range of associative networks found in science studies, especially including networks that reflect underlying intellectual structures such as co-citation networks and collaboration networks. The central premise is that connecting otherwise disparate patches of knowledge is a valuable mechanism of creative thinking in general and transformative scientific discovery in particular. In addition, the premise consistently explains the value of connecting people from different disciplinary specialties. The theory not only explains the nature of transformative discoveries in terms of the brokerage mechanism but also characterizes the subsequent diffusion process as optimal information foraging in a problem space. Complementary to epidemiological models of diffusion, foraging-based conceptualizations offer a unified framework for arriving at insightful discoveries and optimizing subsequent pathways of search in a problem space. Structural and temporal properties of potentially high-impact scientific discoveries are derived from the theory to characterize the emergence and evolution of intellectual networks of a field. Two Nobel Prize winning discoveries, the discovery of Helicobacter pylori and gene targeting techniques, and a discovery in string theory demonstrated such properties. Connections to and differences from existing approaches are discussed. The primary value of the theory is that it provides not only a computational model of intellectual growth, but also concrete and constructive explanations of where one may find insightful inspirations for transformative scientific discoveries.","Theory of scientific discovery,Transformative scientific discoveries,Theory of structural holes,Intellectual brokerage,Knowledge diffusion,Information foraging","ChaomeiChenab,YueChenb,MarkHorowitza,HaiyanHoub,ZeyuanLiub,DonaldPellegrinoa","Journal of Informetrics","https://doi.org/10.1016/j.joi.2009.03.004","https://www.sciencedirect.com/science/article/pii/S1751157709000236"
"A543","Communities, knowledge creation, and information diffusion","In this paper, we examine how patterns of scientific collaboration contribute to knowledge creation and diffusion. Recent studies have shown that scientists can benefit from their position within collaborative networks by being able to receive more information of better quality in a timely fashion, and by presiding over communication between collaborators. Here we focus on the tendency of scientists to cluster into tightly knit communities, and discuss the implications of this tendency for scientific production. We begin by reviewing a new method for finding communities, and we then assess its benefits in terms of computation time and accuracy. While communities often serve as a taxonomic scheme to map knowledge domains, they also affect the way scientists engage in the creation of new knowledge. By drawing on the longstanding debate on the relative benefits of social cohesion and brokerage, we discuss the conditions that facilitate collaborations among scientists within or across communities. We show that highly cited scientific production occurs within communities, when scientists have cohesive collaborations with others from the same knowledge domain, and across communities, when scientists intermediate among otherwise disconnected collaborators from different knowledge domains. We also discuss the implications of communities for information diffusion, and show how traditional epidemiological approaches need to be refined to take knowledge heterogeneity into account and preserve the system’s ability to promote creative processes of novel recombinations of ideas.","Communities,Scientific creativity,Social cohesion,Brokerage,Information diffusion","R.Lambiottea,P.Panzarasab","Journal of Informetrics","https://doi.org/10.1016/j.joi.2009.03.007","https://www.sciencedirect.com/science/article/pii/S1751157709000248"
"A544","A review of auditing methods applied to the content of controlled biomedical terminologies","Although controlled biomedical terminologies have been with us for centuries, it is only in the last couple of decades that close attention has been paid to the quality of these terminologies. The result of this attention has been the development of auditing methods that apply formal methods to assessing whether terminologies are complete and accurate. We have performed an extensive literature review to identify published descriptions of these methods and have created a framework for characterizing them. The framework considers manual, systematic and heuristic methods that use knowledge (within or external to the terminology) to measure quality factors of different aspects of the terminology content (terms, semantic classification, and semantic relationships). The quality factors examined included concept orientation, consistency, non-redundancy, soundness and comprehensive coverage. We reviewed 130 studies that were retrieved based on keyword search on publications in PubMed, and present our assessment of how they fit into our framework. We also identify which terminologies have been audited with the methods and provide examples to illustrate each part of the framework.","Terminology,Auditing method,Quality factor,Knowledge source,Manual,Automated,Systematic,Heuristic","XinxinZhua,Jung-WeiFana,David M.Baortob,ChunhuaWenga,James J.Ciminoac","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2009.03.003","https://www.sciencedirect.com/science/article/pii/S1532046409000434"
"A545","An approach to discovering new technology opportunities: Keyword-based patent map approach","This paper proposes an approach for creating and utilizing keyword-based patent maps for use in new technology creation activity. The proposed approach comprises the following sub-modules. First, text mining is used to transform patent documents into structured data to identify keyword vectors. Second, principal component analysis is employed to reduce the numbers of keyword vectors to make suitable for use on a two-dimensional map. Third, patent ‘vacancies’, defined as blank areas in the map that are sparse in patent density but large in size, are identified. The validity of the vacancy is then tested against such criteria as technological criticality and technological trends. If a vacancy is judged as meaningful, its technological features are investigated in detail to identify the potential for new technology creation. The procedure of the proposed approach is described in detail by employing an illustrative patent database and is implemented into an expert system for new technology creation.","Keyword-based,Text-mining,PCA,New technology creation,Patent information,Patent map,Technology vacancy","SungjooLeea,ByungunYoonb,YongtaeParkc","Technovation","https://doi.org/10.1016/j.technovation.2008.10.006","https://www.sciencedirect.com/science/article/pii/S0166497208001326"
"A546","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2009.04.004","https://www.sciencedirect.com/science/article/pii/S0140670109000137"
"A547","Connecting GEON: Making sense of the myriad resources, researchers and concepts that comprise a geoscience cyberinfrastructure","Simply placing electronic geoscience resources such as datasets, methods, ontologies, workflows and articles in a digital library or cyberinfrastructure does not mean that they will be used successfully by other researchers or educators. It is also necessary to provide the means to locate potentially useful content, and to understand it. Without suitable provision for these needs, many useful resources will go undiscovered, or else will be found but used inappropriately. In this article, we describe an approach to discovering, describing and understanding e-resources based on the notion that meaning is carried in the interconnections between resources and the actors in the cyberinfrastructure (including individuals, groups, organizations), as well as by ontologies and conventional metadata. Navigation around this universe is achieved by implementing the idea of perspectives as dynamic, conceptual views (defined by SPARQL-like queries against an OWL schema) that not only act as filters, but also dynamically promote and demote concepts, relationships and properties according to their immediate relevance. We describe a means to represent a wide variety of interactions between resources using the notion of a knowledge nexus, and we illustrate its use with resources and actors from the Geosciences Network (GEON) cyberinfrastructure community. We also closely link browsing and visualizing strategies to our nexus, drawing on ideas from semiotics to move resources and connections not currently of interest from the foreground to the background, and vice versa, using a new form of adaptive perspective. We illustrate our ideas via ConceptVista, an open-source concept mapping application that provides rich, visual depictions of the resources, cyber-community and myriad connections between them. Examples are presented that show how geoscientific knowledge can be explored not only via ontological structure, but also by use cases, social networks, citation graphs and organization charts; all of which may carry some aspects of meaning for the user.","Cyberinfrastructure,Knowledge browsing,Ontology,GEON,Semantics,Perspectives","MarkGaheganab,JunyanLuob,Stephen D.Weaverb,WilliamPikec,TawanBanchuenb","Computers & Geosciences","https://doi.org/10.1016/j.cageo.2008.09.006","https://www.sciencedirect.com/science/article/pii/S0098300408002690"
"A548","Synthetic hybrid indicators based on scientific collaboration to quantify and evaluate individual research results","Governmental initiatives around scientific policy have progressively raised collaboration to priority status. In this context, a need has arisen to broaden the traditional approach to the analysis and study of research results by descending to the group or even the individual scale and supplementing the output-, productivity-, visibility- and impact-based focus with new measures that emphasize collaboration from the vantage of structural analysis. To this end, the present paper proposes new hybrid indicators for the analysis and evaluation of individual research results, popularity and prestige, that combine bibliometric and structural aspects. A case study was conducted of the nine most productive departments in Carlos III University of Madrid. The findings showed hybridization to be a tool sensitive to traditional indicators, but also to the new demands of modern science as a self-organized system of interaction among individuals, furnishing information on researchers’ environments and the behaviour and attitudes adopted within those environments.","Scientific collaboration,Bibliometric analysis,Network analysis,Hybrid indicators","AntonioPerianes-Rodríguezad,ZaidaChinchilla-Rodríguezcd,BenjamínVargas-Quesadabd,CarlosOlmeda Gómezad,FélixMoya-Anegóncd","Journal of Informetrics","https://doi.org/10.1016/j.joi.2008.12.001","https://www.sciencedirect.com/science/article/pii/S1751157708000722"
"A549","Empirical distributional semantics: Methods and biomedical applications","Over the past 15 years, a range of methods have been developed that are able to learn human-like estimates of the semantic relatedness between terms from the way in which these terms are distributed in a corpus of unannotated natural language text. These methods have also been evaluated in a number of applications in the cognitive science, computational linguistics and the information retrieval literatures. In this paper, we review the available methodologies for derivation of semantic relatedness from free text, as well as their evaluation in a variety of biomedical and other applications. Recent methodological developments, and their applicability to several existing applications are also discussed.","Distributional semantics,Methodological review,Latent semantic analysis,Natural language processing,Semantic similarity,Random indexing,Context vectors","TrevorCohena,DominicWiddowsb","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2009.02.002","https://www.sciencedirect.com/science/article/pii/S1532046409000227"
"A550","Graph nodes clustering with the sigmoid commute-time kernel: A comparative study","This work addresses the problem of detecting clusters in a weighted, undirected, graph by using kernel-based clustering methods, directly partitioning the graph according to a well-defined similarity measure between the nodes (a kernel on a graph). The proposed algorithms are based on a two-step procedure. First, a kernel or similarity matrix, providing a meaningful similarity measure between any couple of nodes, is computed from the adjacency matrix of the graph. Then, the nodes of the graph are clustered by performing a kernel clustering on this similarity matrix. Besides the introduction of a prototype-based kernel version of the gaussian mixtures model and Ward’s hierarchical clustering, in addition to the already known kernel k-means and fuzzy k-means, a new kernel, called the sigmoid commute-time kernel (KCTS) is presented. The joint use of the KCTS kernel matrix and kernel clustering appears to be quite effective. Indeed, this methodology provides the best results on a systematic comparison with a selection of graph clustering and communities detection algorithms on three real-world databases. Finally, some links between the proposed hierarchical kernel clustering and spectral clustering are examined.","Kernel clustering,Graph mining,Kernel hierarchical clustering,Laplacian matrix,Fiedler vector,Commute-time distance,Resistance distance,Community detection","LuhYena,FrancoisFoussb,ChristineDecaesteckerc1,PascalFrancqd,MarcoSaerensa","Data & Knowledge Engineering","https://doi.org/10.1016/j.datak.2008.10.006","https://www.sciencedirect.com/science/article/pii/S0169023X0800147X"
"A551","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2009.02.001","https://www.sciencedirect.com/science/article/pii/S0140670109000022"
"A552","Chapter 3: Development of Toxicoinformatics","Toxicology information systems have evolved swiftly from early, library-based bibliographic tools to advanced packages utilizing sophisticated computer and telecommunication technologies. These systems have evolved concurrently with the rapid expansion of the science of toxicology itself. Bibliographic files such as TOXLINE represent first attempts to handle the toxicology literature through online retrieval. Subsequent approaches applied the use of computers to provide literature-derived data, as in the HSDB or RTECS databanks, or to capture data directly from the laboratory. More advanced systems are utilizing computational and analytical approaches to extract knowledge from the laboratory data to predict outcomes. Societal concerns about hazardous substances, manifested in legislation and regulations, have been responsible for the generation of much toxicity information and the impetus to systematically collect and disseminate these data. Scientific progress in molecular biology, chemistry, and bioinformatics combined with advances in information technologies are also impacting the supply of toxicology information. The amount of information has risen dramatically over the years and it is more accessible and current than ever before. However, in order to derive meaning from the mounds of data and information, the field must rise to the challenge of fostering data accessibility, promoting data standards, and ensuring data quality.","","StephanieHolmgren","Information Resources in Toxicology,Information Resources in Toxicology (Fourth Edition)","https://doi.org/10.1016/B978-0-12-373593-5.00003-3","https://www.sciencedirect.com/science/article/pii/B9780123735935000033"
"A553","Genome Sequence Databases: Types of Data and Bioinformatic Tools","","database genomic analysis,microarray,multiple sequence analysis,nucleotide databases,phylogeny,protein databases,protein function,protein structure,proteomics,regulatory elements,RNA function,RNA secondary structure,BBHbidirectional best hit,BLASTBasic Local Alignment and Search Tool,CAMERACyberinfrastructure for Advanced Marine Microbial Ecology Research and Analysis,CDDconserved domain database,CGHcomparative genomic hybridization,CIBEXCentre for Information Biology Gene Expression,CMRComprehensive Microbial Resource,COGCluster of Orthologous Groups of Proteins,DBTBSDatabase of Transcriptional regulation in B. subtilis,DDBJDNA Data Bank of Japan,EMBL-EBIEuropean Molecular Biology Laboratory-European Bioinformatics Institute,GEOGene Expression Omnibus,GOGene Ontology,GOLDGenomes Online Database,HGTHorizontal gene transfer,HMMhidden Markov model,IMG/MIntegrated Microbial Genomes/Metagenomes,INFERNALinference of RNA Alignment,iTOLInteractive Tree Of Life,KEGGThe Kyoto Encyclopaedia of Genes and Genomes,LSUlarge subunit sequence,MAMMOTHMatching molecular models obtained from theory,MASTMotif Alignment and Search Tool,MBDBsMolecular Biology Databases,MCMCMarkov chain Monte Carlo,MEMEMultiple EM for Motif Elicitation,MeSHMedical Subject Heading,MLMaximum Likelihood,MPMaximum Parsimony,MSAMultiple Sequence Alignment,MStAMultiple Structure Alignments,MUSCLEmultiple Sequence Comparison by Log-Expectation,NCBINational Center for Biotechnology Information,ncRNAsnoncoding RNAs,NJNeighbor Joining,OMSSAOpen Mass Spectrometry Search Algorithm,OPDOpen Proteomics Database,ORFOpen Reading Frame,OTUOperational Taxonomic Unit,PAMLPhylogenetic analysis using maximum likelihood,PDBProtein Data Bank,PHYLIPphylogeny Inference Package,PIRProtein Information Resource,PRFProtein Research Foundation,PRIDEProteomics Identification Database,PSI-BLASTPosition-Specific Iterated BLAST,PSSM-basedPosition Specific Scoring Matrix-based,RFLPsrestriction fragment length polymorphisms,rRNAribosomal RNA,RSARegulatory Sequence Analysis,SCFGsstochastic context-free grammars,SCOPStructure Classification of Proteins,SIDDstress-induced duplex destabilization,SMARTSimple Modular Architecture Research Tool,SMDStanford Microarray Database,SSUsmall subunit sequence,TFtranscription factor,TRstranscriptional regulator,UniProtUniversal Protein Resource,UPGMAUnweighted Pair Group Method with Arithmetic mean,WGSWhole Genome Shotgun","A.G-Preciado,M.Peimbert,E.Merino","Encyclopedia of Microbiology,Encyclopedia of Microbiology (Third Edition)","https://doi.org/10.1016/B978-012373944-5.00027-4","https://www.sciencedirect.com/science/article/pii/B9780123739445000274"
"A554","Chapter 9 Application of Paleoseismic Data to Seismic Hazard Assessment and Neotectonic Research","Paleoseismic data can be used in the research of neotectonic investigations and can provide relatively short-term geologic data that complements longer-term geological, geophysical, and seismological data on regional fault behavior and deformation style. However, most paleoseismic studies provide input for seismic hazard assessments (SHAs). A key element of an SHA is seismic source characterization—that is, the assignment of magnitudes and recurrence rates for large, potentially damaging earthquakes that could be generated by active faults near a site. An SHA is required to describe the largest earthquake that could occur within each identified seismic source zone. If a time interval or exposure time for the occurrence of such an earthquake is specified, the earthquake is termed the maximum earthquake. If no time limit is specified, then the maximum credible earthquake (MCE) is the largest earthquake that appears capable of occurring in an area or along a fault. Two types of SHAs are discussed in the chapter: deterministic and probabilistic.","","James P.McCalpin","International Geophysics","https://doi.org/10.1016/S0074-6142(09)95009-4","https://www.sciencedirect.com/science/article/pii/S0074614209950094"
"A555","Subject Index","","","","International Encyclopedia of Human Geography,International Encyclopedia of Human Geography","https://doi.org/10.1016/B978-008044910-4.09007-6","https://www.sciencedirect.com/science/article/pii/B9780080449104090076"
"A556","Chapter 7: Segmentation with Neural Networks","","","AxelWismueller","Handbook of Medical Image Processing and Analysis,Handbook of Medical Image Processing and Analysis (Second Edition)","https://doi.org/10.1016/B978-012373904-9.50015-5","https://www.sciencedirect.com/science/article/pii/B9780123739049500155"
"A557","Bibliography issue","","","","Public Relations Review","https://doi.org/10.1016/j.pubrev.2008.09.004","https://www.sciencedirect.com/science/article/pii/S0363811108001203"
"A558","The thematic and citation landscape of Data and Knowledge Engineering (1985–2007)","The thematic and citation structures of Data and Knowledge Engineering (DKE) (1985–2007) are identified based on text analysis and citation analysis of the bibliographic records of full papers published in the journal. Temporal patterns are identified by detecting abrupt increases of frequencies of noun phrases extracted from titles and abstracts of DKE papers over time. Conceptual structures of the subject domain are identified by clustering analysis. Concept maps and network visualizations are presented to illustrate salient patterns and emerging thematic trends. A variety of statistics are reported to highlight key contributors and DKE papers that have made profound impacts.","Structural and temporal patterns,Domain analysis,Scientometrics,CiteSpace,Thematic analysis,DKE","ChaomeiChena,Il-YeolSonga,XiaojunYuanb,JianZhanga","Data & Knowledge Engineering","https://doi.org/10.1016/j.datak.2008.05.004","https://www.sciencedirect.com/science/article/pii/S0169023X08000700"
"A559","Analyzing unstructured text data: Using latent categorization to identify intellectual communities in information systems","The Information Systems field is structured by the research topics emphasized by communities of journals. The Latent Categorization Method categorized and automatically named IS research topics in 14,510 abstracts from 65 Information Systems journals. These topics were clustered into seven intellectual communities based on publication patterns. The technique develops categories from the data itself, it is replicable, is relatively insensitive to the size of the text units, and it avoids many of the problems that frequently accompany human categorization. As such LCM provides a new approach to analyzing a wide array of textual data.","Latent Categorization Method,Unstructured data analysis,Organization of information systems,Research communities,Subfields,Research topics","Kai R.Larsen,David E.Monarchi,Dirk S.Hovorka,Christopher N.Bailey","Decision Support Systems","https://doi.org/10.1016/j.dss.2008.02.009","https://www.sciencedirect.com/science/article/pii/S0167923608000444"
"A560","Detecting emerging research fronts based on topological measures in citation networks of scientific publications","In this paper, we performed a comparative study in two research domains in order to develop a method of detecting emerging knowledge domains. The selected domains are research on gallium nitride (GaN) and research on complex networks, which represent recent examples of innovative research. We divided citation networks into clusters using the topological clustering method, tracked the positions of papers in each cluster, and visualized citation networks with characteristic terms for each cluster. Analyzing the clustering results with the average age and parent–children relationship of each cluster may be helpful in detecting emergence. In addition, topological measures, within-cluster degree z and participation coefficient P, succeeded in determining whether there are emerging knowledge clusters. There were at least two types of development of knowledge domains. One is incremental innovation as in GaN and the other is branching innovation as in complex networks. In the domains where incremental innovation occurs, papers changed their position to large z and large P. On the other hand, in the case of branching innovation, they moved to a position with large z and small P, because there is a new emerging cluster, and active research centers shift rapidly. Our results showed that topological measures are beneficial in detecting branching innovation in the citation network of scientific publications.","R&D management,Research front,Bibliometrics,Citation network,Topological clustering","NaokiShibata,YuyaKajikawa,YoshiyukiTakeda,KatsumoriMatsushima","Technovation","https://doi.org/10.1016/j.technovation.2008.03.009","https://www.sciencedirect.com/science/article/pii/S0166497208000436"
"A561","Abstracts of the 16th Cochrane Colloquium","","","","Zeitschrift für Evidenz, Fortbildung und Qualität im Gesundheitswesen","https://doi.org/10.1016/j.zefq.2008.06.015","https://www.sciencedirect.com/science/article/pii/S1865921708001657"
"A562","Navigating information spaces: A case study of related article search in PubMed","The concept of an “information space” provides a powerful metaphor for guiding the design of interactive retrieval systems. We present a case study of related article search, a browsing tool designed to help users navigate the information space defined by results of the PubMed® search engine. This feature leverages content-similarity links that tie MEDLINE® citations together in a vast document network. We examine the effectiveness of related article search from two perspectives: a topological analysis of networks generated from information needs represented in the TREC 2005 genomics track and a query log analysis of real PubMed users. Together, data suggest that related article search is a useful feature and that browsing related articles has become an integral part of how users interact with PubMed.","MEDLINE,TREC genomics,Browsing,Interactive IR","JimmyLinab,MichaelDiCucciob,VahanGrigoryanb,W. JohnWilburb","Information Processing & Management","https://doi.org/10.1016/j.ipm.2008.04.002","https://www.sciencedirect.com/science/article/pii/S0306457308000502"
"A563","Measuring science–technology interaction using rare inventor–author names","The relationship between science and technology has been extensively studied from both theoretical and quantitative perspectives. Quantitative studies typically use patents as proxy for technology and scientific papers as proxy for science, and investigate the relationship between the two. Most such studies have been limited to a single discipline or country. In this paper, we investigate science–technology interaction over a broad range of science and technology by identifying and validating a set of 18,251 inventor–authors through matching of rare names obtained from paper and patent data. These inventor–authors are listed as inventors on nearly 56,000 US patents between 2002 and 2006. Analysis of the distribution of these patents over classes shows that this 6.7% sample is a suitable sample for further analysis. In addition, a map of 290 IPC patent subclasses was created, showing the relationship between patent classes and industries as well as the distribution of patent classes with high science orientation and low science orientation.","Science–technology interaction,Inventor–author matching,Patent mapping,Patent distributions,Rare names","Kevin W.Boyacka,RichardKlavansb","Journal of Informetrics","https://doi.org/10.1016/j.joi.2008.03.001","https://www.sciencedirect.com/science/article/pii/S1751157708000151"
"A564","On the development of a technology intelligence tool for identifying technology opportunity","Technology intelligence tools have come to be regarded as vital components in planning for technology development and formulating technology strategies. However, most such tools currently focus on providing graphical frameworks and databases to support the process of technology analysis. Techpioneer, the proposed tool in this paper, aims to offer decisive information in order to identify technology opportunities. To this end, the system uses textual information from technological document databases and applies morphology analysis to derive promising alternatives and conjoint analysis to evaluate their priority. In addition, the method used in developing a technology dictionary is presented, employing clustering and network analysis. This system also has the ability to communicate with experts in order to estimate the value of existing patents, which is inevitable for the priority-setting of alternatives, construct a morphological matrix and so on. This paper presents the system architecture and functions of this tool and moreover, illustrates the prototype implementation and case study of the same.","Morphology analysis,Text mining,Technology intelligence tool,Technology opportunity analysis","ByungunYoon","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2007.06.022","https://www.sciencedirect.com/science/article/pii/S0957417407002175"
"A565","Extracting interactions between proteins from the literature","During the last decade, biomedicine has witnessed a tremendous development. Large amounts of experimental and computational biomedical data have been generated along with new discoveries, which are accompanied by an exponential increase in the number of biomedical publications describing these discoveries. In the meantime, there has been a great interest with scientific communities in text mining tools to find knowledge such as protein–protein interactions, which is most relevant and useful for specific analysis tasks. This paper provides a outline of the various information extraction methods in biomedical domain, especially for discovery of protein–protein interactions. It surveys methodologies involved in plain texts analyzing and processing, categorizes current work in biomedical information extraction, and provides examples of these methods. Challenges in the field are also presented and possible solutions are discussed.","Information extraction,Biomedicine,Computational linguistics,Machine learning,Text mining,Protein–protein interactions","DeyuZhou,YulanHe","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2007.11.008","https://www.sciencedirect.com/science/article/pii/S1532046407001451"
"A566","Towards content-oriented patent document processing","In this article, we present ongoing work on an advanced patent processing service PATExpert. The central assumption underlying PATExpert is that in order to meet the needs of the users of patent processing services, recourse must be made to the content of patent material. We introduce a content representation schema for patent documentation and sketch the design of techniques that facilitate the integration of this schema into the patent processing cycle. Two types of techniques are discussed. Techniques of the first type facilitate the access to the content of patent documentation provided in a textual format – be it by the human reader or by the machine – in that they rephrase and summarize the documentation and map it onto a formal semantic representation. Techniques of the second type operate on the content representation. At this stage, PATExpert is explored in two technology areas – optical recording devices and machine tools. The work is being carried out in the framework of an R&D-project partially funded by the European Commission.","Patent content representation,Patent retrieval,Content extraction,Paraphrasing,Summarization,Visualization,Navigation,Valuing,PATExpert,Classification,Translation,Documentation ontologies,Knowledge base","LeoWannerac,RicardoBaeza-Yatesac,SörenBrügmannb,JoanCodinac,BarrouDiallod,EnricEscorsae,MarkGierethf,YiannisKompatsiarisg,SymeonPapadopoulosg,EmanuelePiantah,GemmaPiellac,IngoPuhlmanni,GautamRaoe,MartinRotardf,PiaSchoesteri,LucianoSerafinih,VasilikiZervakig","World Patent Information","https://doi.org/10.1016/j.wpi.2007.03.008","https://www.sciencedirect.com/science/article/pii/S0172219007000762"
"A567","Virus Databases","","Bioinformatics,Comparative genomics,Curation,Database,Database,flat file,Database,hierarchical,Database,relational,Database schema,Genome,Viral genome,XML","E.J.Lefkowitz,M.R.Odom,C.Upton","Encyclopedia of Virology,Encyclopedia of Virology (Third Edition)","https://doi.org/10.1016/B978-012374410-4.00719-6","https://www.sciencedirect.com/science/article/pii/B9780123744104007196"
"A568","Informetrics at the beginning of the 21st century—A review","This paper reviews developments in informetrics between 2000 and 2006. At the beginning of the 21st century we witness considerable growth in webometrics, mapping and visualization and open access. A new topic is comparison between citation databases, as a result of the introduction of two new citation databases Scopus and Google Scholar. There is renewed interest in indicators as a result of the introduction of the h-index. Traditional topics like citation analysis and informetric theory also continue to develop. The impact factor debate, especially outside the informetric literature continues to thrive. Ranked lists (of journal, highly cited papers or of educational institutions) are of great public interest.","Informetrics,Bibliometrics,Scientometrics,Webometrics","JuditBar-Ilan","Journal of Informetrics","https://doi.org/10.1016/j.joi.2007.11.001","https://www.sciencedirect.com/science/article/pii/S1751157707000740"
"A569","3.3: Some Relevant Aspects of Network Analysis and Graph Theory","This chapter presents some recent developments in a field which is perhaps most appropriately called “network analysis”. An alternative name for this field is “graph theory”. A graph is a simple object: a set of nodes, connected by links—which are directed or symmetric. The latter may often be justifiably called social networks—since the overlay (logical) links are laid down by people. An excellent example of this is the “email address network”. It is this logical graph which determines how a computer virus may be spread over the physical network; hence it is worth studying for that reason. To this end it is useful to find the eigenvector centrality (EVC) of the nodes (when the graph is undirected), and then obtain from the EVC a very coarse-grained topographical view of the network, in terms of a few “mountains” (regions), with bridging links crossing the valleys. In spite of this simplicity, graphs are extremely useful in describing a huge variety of phenomena involving connections. There are fundamental and nontrivial differences between a directed graph (such as the email graph) and an undirected graph. In particular, they are useful for describing and managing networks of computers, including logical or overlay networks which are built on top of the physical network. Introducing a direction to the links of a network can have profound effects on the properties of that network.","","Geoffrey S.Canright,KenthEngø-Monsen","Handbook of Network and System Administration,Handbook of Network and System Administration","https://doi.org/10.1016/B978-044452198-9.50017-3","https://www.sciencedirect.com/science/article/pii/B9780444521989500173"
"A570","Investigating ontology development for engineering design support","Ontologies are now in widespread use as a means of formalizing domain knowledge in a way that makes it accessible, shareable and reusable. Nevertheless, to many, the nature and use of ontologies are unfamiliar. This paper takes a practical approach – through the use of example – to clarifying what ontologies are and how they might be useful in an important and representative phase of the engineering design process, that of design requirement development and capture.The paper consists of two parts. In the first part ontologies and their use are discussed, and a methodology for developing ontologies is explored. In the second part, three very different types of ontology are developed in accordance with the methodology. Each of the ontologies captures a different conceptual facet of the engineering design domain, described at a quite different level of abstraction than the others. The process of developing ontologies is illustrated in a practical way and the application of these ontologies for supporting the capture of the engineering design requirement is described as a means of demonstrating the general potential of ontologies.","","M.J.Darlington,S.J.Culley","Advanced Engineering Informatics","https://doi.org/10.1016/j.aei.2007.04.001","https://www.sciencedirect.com/science/article/pii/S1474034607000237"
"A571","POLYPHONET: An advanced social network extraction system from the Web","Social networks play important roles in the Semantic Web: knowledge management, information retrieval, ubiquitous computing, and so on. We propose a social network extraction system called POLYPHONET, which employs several advanced techniques to extract relations of persons, to detect groups of persons, and to obtain keywords for a person. Search engines, especially Google, are used to measure co-occurrence of information and obtain Web documents.Several studies have used search engines to extract social networks from the Web, but our research advances the following points: first, we reduce the related methods into simple pseudocodes using Google so that we can build up integrated systems. Second, we develop several new algorithms for social network mining such as those to classify relations into categories, to make extraction scalable, and to obtain and utilize person-to-word relations. Third, every module is implemented in POLYPHONET, which has been used at four academic conferences, each with more than 500 participants. We overview that system. Finally, a novel architecture called Iterative Social Network Mining is proposed. It utilizes simple modules using Google and is characterized by scalability and relate–identify processes: identification of each entity and extraction of relations are repeated to obtain a more precise social network.","Social network,Search engine,Web mining","YutakaMatsuoa,JunichiroMorib,MasahiroHamasakia,TakuichiNishimuraa,HideakiTakedab,KoitiHasidaa,MitsuruIshizukab","Journal of Web Semantics","https://doi.org/10.1016/j.websem.2007.09.002","https://www.sciencedirect.com/science/article/pii/S1570826807000340"
"A572","Summarizing court decisions","In the field of law there is an absolute need for summarizing the texts of court decisions in order to make the content of the cases easily accessible for legal professionals. During the SALOMON and MOSAIC2 projects we investigated the summarization and retrieval of legal cases. This article presents some of the main findings while integrating the research results of experiments on legal document summarization by other research groups. In addition, we propose novel avenues of research for automatic text summarization, which we currently exploit when summarizing court decisions in the ACILA3 project. Techniques for automated concept learning and argument recognition are here the most challenging.","Summarization,Legal document management","Marie-FrancineMoens1","Information Processing & Management","https://doi.org/10.1016/j.ipm.2007.01.005","https://www.sciencedirect.com/science/article/pii/S0306457307000283"
"A573","Global mapping of gene/protein interactions in PubMed abstracts: A framework and an experiment with P53 interactions","Gene/protein interactions provide critical information for a thorough understanding of cellular processes. Recently, considerable interest and effort has been focused on the construction and analysis of genome-wide gene networks. The large body of biomedical literature is an important source of gene/protein interaction information. Recent advances in text mining tools have made it possible to automatically extract such documented interactions from free-text literature. In this paper, we propose a comprehensive framework for constructing and analyzing large-scale gene functional networks based on the gene/protein interactions extracted from biomedical literature repositories using text mining tools. Our proposed framework consists of analyses of the network topology, network topology–gene function relationship, and temporal network evolution to distill valuable information embedded in the gene functional interactions in the literature. We demonstrate the application of the proposed framework using a testbed of P53-related PubMed abstracts, which shows that the literature-based P53 networks exhibit small-world and scale-free properties. We also found that high degree genes in the literature-based networks have a high probability of appearing in the manually curated database and genes in the same pathway tend to form local clusters in our literature-based networks. Temporal analysis showed that genes interacting with many other genes tend to be involved in a large number of newly discovered interactions.","Network analysis,Gene functional network,Text mining","XinLia,HsinchunChena,ZanHuangb,HuaSua,Jesse D.Martinezc","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2007.01.001","https://www.sciencedirect.com/science/article/pii/S1532046407000044"
"A574","Text mining techniques for patent analysis","Patent documents contain important research results. However, they are lengthy and rich in technical terminology such that it takes a lot of human efforts for analyses. Automatic tools for assisting patent engineers or decision makers in patent analysis are in great demand. This paper describes a series of text mining techniques that conforms to the analytical process used by patent analysts. These techniques include text segmentation, summary extraction, feature selection, term association, cluster generation, topic identification, and information mapping. The issues of efficiency and effectiveness are considered in the design of these techniques. Some important features of the proposed methodology include a rigorous approach to verify the usefulness of segment extracts as the document surrogates, a corpus- and dictionary-free algorithm for keyphrase extraction, an efficient co-word analysis method that can be applied to large volume of patents, and an automatic procedure to create generic cluster titles for ease of result interpretation. Evaluation of these techniques was conducted. The results confirm that the machine-generated summaries do preserve more important content words than some other sections for classification. To demonstrate the feasibility, the proposed methodology was applied to a real-world patent set for domain analysis and mapping, which shows that our approach is more effective than existing classification systems. The attempt in this paper to automate the whole process not only helps create final patent maps for topic analyses, but also facilitates or improves other patent analysis tasks such as patent classification, organization, knowledge sharing, and prior art searches.","Summarization,Phrase extraction,Co-word analysis,Clustering,Topic mapping","Yuen-HsienTsenga,Chi-JenLinb,Yu-ILinc","Information Processing & Management","https://doi.org/10.1016/j.ipm.2006.11.011","https://www.sciencedirect.com/science/article/pii/S0306457306002020"
"A575","Goldschmidt Abstracts 2007- L","","","","Geochimica et Cosmochimica Acta","https://doi.org/10.1016/j.gca.2007.06.020","https://www.sciencedirect.com/science/article/pii/S0016703707003213"
"A576","One century of progress in neuroscience founded on Golgi and Cajal's outstanding experimental and theoretical contributions","Since the discovery and mapping of the neuronal circuits of the brain by Golgi and Cajal neuroscientists have clearly spelled the fundamental questions which should be answered to delineate the arena for a scientific understanding of brain function:• How neurons communicate with each other in a network?• Is there some basic principle according to which brain networks are organised?• Is it possible to map out brain regions specialised in carrying out some specific task?As far as the first point is concerned it is well known that Golgi and Cajal had opposite views on the interneuronal communication. Golgi suggested protoplasmic continuity and/or electrotonic spreading of currents between neurons. Cajal proposed the so-called “neuron doctrine”, which maintained that neurons could communicate only via a specialised region of contiguity, namely the synapse.The present paper has the first and second points as main topics and last century progresses in these fields are viewed as developments of Golgi and Cajal's findings and above all, hypotheses. Thus, we will briefly discuss these topics moving from the transmitter based mapping, which brought neurochemistry into the Golgi–Cajal mapping of the brain with silver impregnation techniques. The mapping of transmitter-identified neurons in the brain represents one of the major foundations for neuropsychopharmacology and a reference frame for the biochemical and behavioural investigations of brain function. Biochemical techniques allowed giving evidence for multiple transmission lines in synapses interacting via receptor–receptor interactions postulated to be based on supramolecular aggregates, called receptor mosaics. Immunocytochemical and autoradiographic mapping techniques allowed the discovery of extra-synaptic receptors and of transmitter–receptor mismatches leading to the introduction of the volume transmission concept by Agnati–Fuxe teams. The Volume Transmission theory proposed the existence of a three-dimensional diffusion of e.g. transmitter and ion signals, released by any type of cell, in the extra-cellular space and the cerebrospinal fluid of the brain. Thus, a synthesis between Golgi and Cajal's views became possible, by considering two main modes of intercellular communication: volume transmission (VT) and wiring transmission (WT) (a prototype of the latter one is synaptic transmission) and two types of networks (cellular and molecular networks) in the central nervous system. This was the basis for the suggestion of two fundamental principles in brain morphological and functional organisation, the miniaturisation and hierarchic organisation.Finally, moving from Apathy's work, a new model of brain networks has recently been proposed. In fact, it has been proposed that a network of fibrils enmeshes the entire CNS forming a global molecular network (GMN) superimposed on the cellular networks.","CAcatecholamines,CCNcomplex cellular network,DAdopamine,ECMextracellular matrix,GMNglobal molecular network,HMNhorizontal molecular network,KMNkernel molecular network,RRIreceptor–receptor interaction,VMNvertical molecular network,VTvolume transmission,WTwiring transmission,Keywords,Golgi and Cajal,Interneuronal communication,Volume transmission,Wiring transmission,Trophic unit,Global molecular network","Luigi F.Agnatia,SusannaGenedania,GiuseppinaLeoa,AliciaRiverab,DiegoGuidolinc,KjellFuxed","Brain Research Reviews","https://doi.org/10.1016/j.brainresrev.2007.03.004","https://www.sciencedirect.com/science/article/pii/S0165017307000409"
"A577","Taxonomy visualization in support of the semi-automatic validation and optimization of organizational schemas","Never before in history has mankind produced and had access to so much data, information, knowledge, and expertise as today. To organize, access, and manage these valuable assets effectively, we use taxonomies, classification hierarchies, ontologies, controlled vocabularies, and other approaches. We create directory structures for our files. We use organizational hierarchies to structure our work environment. However, the design and continuous update of these organizational schemas with potentially thousands of class nodes organizing millions of entities is challenging for any human being.The taxonomy visualization and validation (TV) tool introduced in this paper supports the semi-automatic validation and optimization of organizational schemas such as file directories, classification hierarchies, taxonomies, or other structures imposed on a data set for organization, access, and naming. By showing the “goodness of fit” for a schema and the potentially millions of entities it organizes, the TV tool eases the identification and reclassification of misclassified information entities, the identification of classes that grow too large, the evaluation of the size and homogeneity of existing classes, the examination of the “well-formedness” of an organizational schema, and more. As a demonstration, the TV tool is applied to display and examine the United States Patent and Trademark Office patent classification, which organizes more than three million patents into about 160,000 distinct patent classes. The paper concludes with a discussion and an outlook to future work.","Patents,Taxonomy,Ontology,Classification hierarchy,Visualization","KatyBörnera,ElishaHardya,BruceHerra,ToddHollowayb,W. BradfordPaleyc","Journal of Informetrics","https://doi.org/10.1016/j.joi.2007.03.002","https://www.sciencedirect.com/science/article/pii/S1751157707000375"
"A578","Storylines: Visual exploration and analysis in latent semantic spaces","Tasks in visual analytics differ from typical information retrieval tasks in fundamental ways. A critical part of a visual analytics is to ask the right questions when dealing with a diverse collection of information. In this article, we introduce the design and application of an integrated exploratory visualization system called Storylines. Storylines provides a framework to enable analysts visually and systematically explore and study a body of unstructured text without prior knowledge of its thematic structure. The system innovatively integrates latent semantic indexing, natural language processing, and social network analysis. The contributions of the work include providing an intuitive and directly accessible representation of a latent semantic space derived from the text corpus, an integrated process for identifying salient lines of stories, and coordinated visualizations across a spectrum of perspectives in terms of people, locations, and events involved in each story line. The system is tested with the 2006 VAST contest data, in particular, the portion of news articles.","Latent semantic indexing,Social network analysis,Visual analytics","WeizhongZhu,ChaomeiChen","Computers & Graphics","https://doi.org/10.1016/j.cag.2007.01.025","https://www.sciencedirect.com/science/article/pii/S0097849307000568"
"A579","Visual text mining using association rules","In many situations, individuals or groups of individuals are faced with the need to examine sets of documents to achieve understanding of their structure and to locate relevant information. In that context, this paper presents a framework for visual text mining to support exploration of both general structure and relevant topics within a textual document collection. Our approach starts by building a visualization from the text data set. On top of that, a novel technique is presented that generates and filters association rules to detect and display topics from a group of documents. Results have shown a very consistent match between topics extracted using this approach to those actually present in the data set.","Visual text mining,Association rules,Data mining,Information visualization","A.A.Lopes,R.Pinho,F.V.Paulovich,R.Minghim","Computers & Graphics","https://doi.org/10.1016/j.cag.2007.01.023","https://www.sciencedirect.com/science/article/pii/S0097849307000544"
"A580","The information system of plans approach: Using and making plans for landscape protection","This paper outlines a framework for accessing multiple plans in an information system of plans (ISoP) for use in land use planning and deliberation. Using such a system can help planners analyze potential changes to urban and rural landscapes and make decisions through access to information about the intentions and related actions of others. It can also be used to focus attention on gaps in current plans and regulations. In the pilot project reported here, an ISoP was used to facilitate a planning process for resource protection in a rapidly urbanizing county in the Chicago, Illinois (USA) region. In addition to cataloging and displaying plans, we illustrate how an ISoP can be used to develop understanding of the goals and intents of multiple government agencies and interest groups, identify congruence and conflict among plans and facilitate discussion. Successes and challenges in developing a robust and usable ISoP are reported, including gathering information about plans, encoding the content of plans, accessing information in useful form and recognizing alternatives and conflicts among plans.","Land use,Regional planning,Comparison analysis,Resource protection,Chicago metropolitan region (USA)","DonovanFinn,Lewis D.Hopkins,MatthewWempe1","Landscape and Urban Planning","https://doi.org/10.1016/j.landurbplan.2006.11.006","https://www.sciencedirect.com/science/article/pii/S0169204606002672"
"A581","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2007.04.002","https://www.sciencedirect.com/science/article/pii/S0140670107000124"
"A582","American Association for the Study of Liver Disease (AASLD) Abstracts","","","","Gastroenterology","https://doi.org/10.1016/S0016-5085(07)60010-9","https://www.sciencedirect.com/science/article/pii/S0016508507600109"
"A583","Abstracts","","","","Fuel and Energy Abstracts","https://doi.org/10.1016/j.fueleneab.2006.12.002","https://www.sciencedirect.com/science/article/pii/S014067010600066X"
"A584","Designing Networked Handheld Devices to Enhance School Learning","Handheld devices, especially networked handheld devices, are growing in importance in education, largely because their affordability and accessibility create an opportunity for educators to transition from occasional, supplemental use of computers, to frequent and integral use of portable computational technology. Why and how might these new devices enhance school learning? We begin by discussing a simple but important factor: networked handhelds can allow a 1:1 student:device ratio for the first time, enabling ready-at-hand access to technology throughout the school day and throughout the learner's personal life. We argue that designers need to understand the capabilities of the new generation of handheld computers and wireless networks that are most relevant for learning. We follow this with a discussion of Learning Science theories that connect those capabilities to enhanced learning. The capabilities and features feed into design practices. We describe a set of example applications that are arising from the capabilities, theories and design practices previously described. Finally, we close with a discussion of the challenge of scale.","","JeremyRoschelle,CharlesPatton,DeborahTatar","Advances in Computers","https://doi.org/10.1016/S0065-2458(06)70001-8","https://www.sciencedirect.com/science/article/pii/S0065245806700018"
"A585","Mapping the contemporary terrorism research domain","A systematic view of terrorism research to reveal the intellectual structure of the field and empirically discern the distinct set of core researchers, institutional affiliations, publications, and conceptual areas can help us gain a deeper understanding of approaches to terrorism. This paper responds to this need by using an integrated knowledge-mapping framework that we developed to identify the core researchers and knowledge creation approaches in terrorism. The framework uses three types of analysis: (a) basic analysis of scientific output using citation, bibliometric, and social network analyses, (b) content map analysis of large corpora of literature, and (c) co-citation analysis to analyse linkages among pairs of researchers. We applied domain visualization techniques such as content map analysis, block-modeling, and co-citation analysis to the literature and author citation data from the years 1965 to 2003. The data were gathered from ten databases such as the ISI Web of Science. The results reveal: (1) the names of the top 42 core terrorism researchers (e.g., Brian Jenkins, Bruce Hoffman, and Paul Wilkinson) as well as their institutional affiliations; (2) their influential publications; (3) clusters of terrorism researchers who work in similar areas; and (4) that the research focus has shifted from terrorism as a low-intensity conflict to a strategic threat to world powers with increased focus on Osama Bin Laden.","Terrorism,Visualization,Bibliometrics,Co-citation analysis,Intellectual structure","Edna F.Reid,HsinchunChen","International Journal of Human-Computer Studies","https://doi.org/10.1016/j.ijhcs.2006.08.006","https://www.sciencedirect.com/science/article/pii/S1071581906001273"
"A586","CHAPTER 3: MEET THE WEB","","","Ian H.Witten,MarcoGori,TeresaNumerico","Web Dragons,Web Dragons","https://doi.org/10.1016/B978-012370609-6/50006-0","https://www.sciencedirect.com/science/article/pii/B9780123706096500060"
"A587","How something can be said about telling more than we can know: On choice blindness and introspection","The legacy of Nisbett and Wilson’s classic article, Telling More Than We Can Know: Verbal Reports on Mental Processes (1977), is mixed. It is perhaps the most cited article in the recent history of consciousness studies, yet no empirical research program currently exists that continues the work presented in the article. To remedy this, we have introduced an experimental paradigm we call choice blindness [Johansson, P., Hall, L., Sikström, S., & Olsson, A. (2005). Failure to detect mismatches between intention and outcome in a simple decision task. Science, 310(5745), 116–119.]. In the choice blindness paradigm participants fail to notice mismatches between their intended choice and the outcome they are presented with, while nevertheless offering introspectively derived reasons for why they chose the way they did. In this article, we use word-frequency and latent semantic analysis (LSA) to investigate a corpus of introspective reports collected within the choice blindness paradigm. We contrast the introspective reasons given in non-manipulated vs. manipulated trials, but find very few differences between these two groups of reports.","Introspection,Verbal report,Confabulation,Choice blindness,Change blindness,Word-frequency analysis,Latent Semantic Analysis","PetterJohansson,LarsHall,SverkerSikström,BettyTärning,AndreasLind","Consciousness and Cognition","https://doi.org/10.1016/j.concog.2006.09.004","https://www.sciencedirect.com/science/article/pii/S1053810006000936"
"A588","Philosophy enters the optics laboratory: Bell's theorem and its first experimental tests (1965–1982)","This paper deals with the ways that the issue of completing quantum mechanics was brought into laboratories and became a topic in mainstream quantum optics. It focuses on the period between 1965, when Bell published what we now call Bell's theorem, and 1982, when Aspect published the results of his experiments. Discussing some of those past contexts and practices, I show that factors in addition to theoretical innovations, experiments, and techniques were necessary for the flourishing of this subject, and that the experimental implications of Bell's theorem were neither suddenly recognized nor quickly highly regarded by physicists. Indeed, I will argue that what was considered good physics after Aspect's 1982 experiments was once considered by many a philosophical matter instead of a scientific one, and that the path from philosophy to physics required a change in the physics community's attitude about the status of the foundations of quantum mechanics.","History of physics,Quantum physics,Bell's theorem,Entanglement,Hidden-variables,Scientific controversies","OlivalFreireJr.","Studies in History and Philosophy of Science Part B: Studies in History and Philosophy of Modern Physics","https://doi.org/10.1016/j.shpsb.2005.12.003","https://www.sciencedirect.com/science/article/pii/S1355219806000463"
"A589","Data mining and clinical data repositories: Insights from a 667,000 patient data set","Clinical repositories containing large amounts of biological, clinical, and administrative data are increasingly becoming available as health care systems integrate patient information for research and utilization objectives. To investigate the potential value of searching these databases for novel insights, we applied a new data mining approach, HealthMiner®, to a large cohort of 667,000 inpatient and outpatient digital records from an academic medical system. HealthMiner® approaches knowledge discovery using three unsupervised methods: CliniMiner®, Predictive Analysis, and Pattern Discovery. The initial results from this study suggest that these approaches have the potential to expand research capabilities through identification of potentially novel clinical disease associations.","Clinical data repository,Complex data sets,Large patient cohort,FANO,HealthMiner®,Search tools","Irene M.Mullinsa,Mir S.Siadatya,JasonLymana,KenScullya,Carleton T.Garrettb,W.Greg Millerb,RudyMullerb,BarryRobsonc,ChidAptec,SholomWeissc,IsidoreRigoutsosc,DanielPlattc,SimonaCohend,William A.Knausa1","Computers in Biology and Medicine","https://doi.org/10.1016/j.compbiomed.2005.08.003","https://www.sciencedirect.com/science/article/pii/S0010482505001046"
"A590","Building a scientific knowledge web portal: The NanoPort experience","There has been a tremendous growth in the amount of information and resources on the World Wide Web that are useful to researchers and practitioners in science domains. While the Web has made the communication and sharing of research ideas and results among scientists easier and faster than ever, its dynamic and unstructured nature also makes the scientists faced with such problems as information overload, vocabulary difference, and lack of analysis tools. To address these problems, it is highly desirable to have an integrated, “one-stop shopping” Web portal to support effective information searching and analysis as well as to enhance communication and collaboration among researchers in various scientific fields. In this paper, we review existing information retrieval techniques and related literature, and propose a framework for developing integrated Web portals that support information searching and analysis for scientific knowledge. Our framework incorporates collection building, meta-searching, keyword suggestion, and various content analysis techniques such as document summarization, document clustering, and topic map visualization. Patent analysis techniques such as citation analysis and content map analysis are also incorporated. To demonstrate the feasibility of our approach, we developed based on our architecture a knowledge portal, called NanoPort, in the field of nanoscale science and engineering. We report our experience and explore the various issues of relevance to developing a Web portal for scientific domains. The system was compared to other search systems in the field and several design issues were identified. An evaluation study was conducted and the results showed that subjects were more satisfied with the NanoPort system than with Scirus, a leading search engine for scientific articles. Through our prototype system, we demonstrated the feasibility of using such an integrated approach and the study brought insight into applying the proposed domain-independent architecture to different areas of science and engineering in the future.","Web portals,Design,Web spiders,Meta-search,Document summarization,Document clustering,Self-organizing maps,Patent analysis,Visualization,Nanotechnology","MichaelChaua,ZanHuangb,JialunQinc,YiluZhouc,HsinchunChenc","Decision Support Systems","https://doi.org/10.1016/j.dss.2006.01.004","https://www.sciencedirect.com/science/article/pii/S016792360600008X"
"A591","Modelling discourse in contested domains: A semiotic and cognitive framework","This paper examines the representational requirements for interactive, collaborative systems intended to support sensemaking and argumentation over contested issues. We argue that a perspective supported by semiotic and cognitively oriented discourse analyses offers both theoretical insights and motivates representational requirements for the semantics of tools for contesting meaning. We introduce our semiotic approach, highlighting its implications for discourse representation, before describing a research system (ClaiMaker) designed to support the construction of scholarly argumentation by allowing analysts to publish and contest ‘claims’ about scientific contributions. We show how ClaiMaker's representational scheme is grounded in specific assumptions concerning the nature of explicit modelling, and the evolution of meaning within a discourse community. These characteristics allow the system to represent scholarly discourse as a dynamic process, in the form of continuously evolving structures. A cognitively oriented discourse analysis then shows how the use of a small set of cognitive relational primitives in the underlying ontology opens possibilities for offering users advanced forms of computational service for analysing collectively constructed argumentation networks.","Argumentation,Discourse representation,Coherence relations,Ontologies,Semantic annotation,Semantic web,Semiotics","ClaraMancini,Simon J.Buckingham Shum","International Journal of Human-Computer Studies","https://doi.org/10.1016/j.ijhcs.2006.07.002","https://www.sciencedirect.com/science/article/pii/S1071581906001091"
"A592","National Academy of Neuropsychology. Abstracts from the 26th Annual Meeting, San Antonio, Texas, October 25-28, 2006","","","","Archives of Clinical Neuropsychology","https://doi.org/10.1016/j.acn.2006.07.001","https://www.sciencedirect.com/science/article/pii/S0887617706000904"
"A593","Graph theoretic modeling of large-scale semantic networks","During the past several years, social network analysis methods have been used to model many complex real-world phenomena, including social networks, transportation networks, and the Internet. Graph theoretic methods, based on an elegant representation of entities and relationships, have been used in computational biology to study biological networks; however they have not yet been adopted widely by the greater informatics community. The graphs produced are generally large, sparse, and complex, and share common global topological properties. In this review of research (1998–2005) on large-scale semantic networks, we used a tailored search strategy to identify articles involving both a graph theoretic perspective and semantic information. Thirty-one relevant articles were retrieved. The majority (28, 90.3%) involved an investigation of a real-world network. These included corpora, thesauri, dictionaries, large computer programs, biological neuronal networks, word association networks, and files on the Internet. Twenty-two of the 28 (78.6%) involved a graph comprised of words or phrases. Fifteen of the 28 (53.6%) mentioned evidence of small-world characteristics in the network investigated. Eleven (39.3%) reported a scale-free topology, which tends to have a similar appearance when examined at varying scales. The results of this review indicate that networks generated from natural language have topological properties common to other natural phenomena. It has not yet been determined whether artificial human-curated terminology systems in biomedicine share these properties. Large network analysis methods have potential application in a variety of areas of informatics, such as in development of controlled vocabularies and for characterizing a given domain.","Small world network,Scale-free network,Graph theory,Language,Linguistics,Semantics,Terminology,Review literature","Michael E.Bales,Stephen B.Johnson","Journal of Biomedical Informatics","https://doi.org/10.1016/j.jbi.2005.10.007","https://www.sciencedirect.com/science/article/pii/S1532046405001103"
"A594","Combining mining and visualization tools to discover the geographic structure of a domain","Science monitoring is a core issue in the new world of business and research. Companies and institutes need to monitor the activities of their competitors, get information on the market, changing technologies or government policies. This paper presents the Tétralogie platform that is aimed at allowing a user to interactively discover trends in scientific research and communities from large textual collections that include information about geographical location. Tétralogie consists of several agents that communicate with each other on users’ demands in order to deliver results to them. Metadata and document content are extracted before being mined. Results are displayed in the form of histograms, networks and geographical maps; these complementary types of presentations increase the possibilities of analysis compared to the use of these tools separately. We illustrate the overall process through a case study of scientific literature analysis and show how the different agents can be combined to discover the structure of a domain. The system correctly predicts the country contribution to a field in future years and allows exploration of the relationships between countries.","Information mining,Data analysis,Domain knowledge,Knowledge discovery,Information visualization,Geographical maps","JosianeMothe,ClaudeChrisment,TaoufiqDkaki,BernardDousset,SaïdKarouach","Computers, Environment and Urban Systems","https://doi.org/10.1016/j.compenvurbsys.2005.09.004","https://www.sciencedirect.com/science/article/pii/S0198971505000827"
"A595","Tool use in computer-based learning environments: towards a research framework","Computer-based learning environments often confront learners with a number of tools, i.e. non-embedded support devices. Such environments assume learners to be good judges of their own learning needs. However, research indicates that students do not always make adequate choices for their learning process. This especially becomes an issue with the use of open learning environments, which are assumed to foster the acquisition of complex problem solving skills. Such open learning environments offer students tools to support their learning. Consequently, it is needed to understand factors that influence tool use and acquire insight in learning effects of tool use. Both issues are addressed in this contribution.A review of the existing literature has been undertaken by performing a search on the Web of Science and the PsycInfo database. Results indicate that there is some evidence for learner, tool and task characteristics to influence tool use. No clear indication was found for a learning effect of tool use. The conclusion proposes a research framework for the systematic study of tools.","Computer-based learning environments,Tool use,Literature review","GeraldineClarebout,JanElen","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2004.09.007","https://www.sciencedirect.com/science/article/pii/S0747563204001281"
"A596","The basis for bibliomining: Frameworks for bringing together usage-based data mining and bibliometrics through data warehousing in digital library services","Over the past few years, data mining has moved from corporations to other organizations. This paper looks at the integration of data mining in digital library services. First, bibliomining, or the combination of bibliometrics and data mining techniques to understand library services, is defined and the concept explored. Second, the conceptual frameworks for bibliomining from the viewpoint of the library decision-maker and the library researcher are presented and compared. Finally, a research agenda to resolve many of the common bibliomining issues and to move the field forward in a mindful manner is developed. The result is not only a roadmap for understanding the integration of data mining in digital library services, but also a template for other cross-discipline data mining researchers to follow for systematic exploration in their own subject domains.","Data mining,Data warehousing,Digital libraries,Bibliomining,Evaluation,Theory,Library measurement,Library evaluation","ScottNicholson","Information Processing & Management","https://doi.org/10.1016/j.ipm.2005.05.008","https://www.sciencedirect.com/science/article/pii/S0306457305000658"
"A597","Sensemaking tools for understanding research literatures: Design, implementation and user evaluation","This paper describes the work undertaken in the Scholarly Ontologies Project. The aim of the project has been to develop a computational approach to support scholarly sensemaking, through interpretation and argumentation, enabling researchers to make claims: to describe and debate their view of a document's key contributions and relationships to the literature. The project has investigated the technicalities and practicalities of capturing conceptual relations, within and between conventional documents in terms of abstract ontological structures. In this way, we have developed a new kind of index to distributed digital library systems. This paper reports a case study undertaken to test the sensemaking tools developed by the Scholarly Ontologies project. The tools used were ClaiMapper, which allows the user to sketch argument maps of individual papers and their connections, ClaiMaker, a server on which such models can be stored and saved, which provides interpretative services to assist the querying of argument maps across multiple papers and ClaimFinder, a novice interface to the search services in ClaiMaker.","Modelling interfaces,Search interfaces,User studies","VictoriaUren,SimonBuckingham Shum,MichelleBachler,GangminLi1","International Journal of Human-Computer Studies","https://doi.org/10.1016/j.ijhcs.2005.09.004","https://www.sciencedirect.com/science/article/pii/S1071581905001709"
"A598","Friday Abstracts","","","","Biological Psychiatry","https://doi.org/10.1016/j.biopsych.2006.03.006","https://www.sciencedirect.com/science/article/pii/S0006322306003076"
"A599","Thursday Abstracts","","","","Biological Psychiatry","https://doi.org/10.1016/j.biopsych.2006.03.005","https://www.sciencedirect.com/science/article/pii/S0006322306003064"
"A600","Mining web navigations for intelligence","The Internet is one of the fastest growing areas of intelligence gathering. We present a statistical approach, called principal clusters analysis, for analyzing millions of user navigations on the Web. This technique identifies prominent navigation clusters on different topics. Furthermore, it can determine information items that are useful starting points to explore a topic, as well as key documents to explore the topic in greater detail. Trends can be detected by observing navigation prominence over time. We apply this technique on a large popular website. The results show promise in web intelligence mining.","Principal clusters analysis,Intelligence,Mining,Trend analysis,Navigation analysis,Information overload,Web community","HarrisWua,MichaelGordonb,KurtisDeMaagdb,WeiguoFanc","Decision Support Systems","https://doi.org/10.1016/j.dss.2004.06.011","https://www.sciencedirect.com/science/article/pii/S0167923604001320"
"A601","Poster presentations","","","","Schizophrenia Research","https://doi.org/10.1016/j.schres.2006.01.006","https://www.sciencedirect.com/science/article/pii/S092099640600017X"
"A602","Natural Language Processing: Overview","","automatic summarization,document retrieval,information extraction,natural language processing,question answering,search engines,text categorization,text mining","P.Jackson,F.Schilder","Encyclopedia of Language & Linguistics (Second Edition)","https://doi.org/10.1016/B0-08-044854-2/00927-5","https://www.sciencedirect.com/science/article/pii/B0080448542009275"
"A603","Chapter 6: The Association-Oriented Research Strategy","","","Glenn M.HymelEdD, LMT","Research Methods for Massage and Holistic Therapies,Research Methods for Massage and Holistic Therapies","https://doi.org/10.1016/B978-032303292-6.50016-X","https://www.sciencedirect.com/science/article/pii/B978032303292650016X"
"A604","6: Bioinformatics Packages for Sequence Analysis","","","YeisooYu*,Leah A.Santat†,SangdunChoi§¶","Applied Mycology and Biotechnology","https://doi.org/10.1016/S1874-5334(06)80009-2","https://www.sciencedirect.com/science/article/pii/S1874533406800092"
"A605","Local Structure Comparison of Proteins","Protein local structure comparison aims to recognize structural similarities between parts of proteins. It is an active topic in bioinformatics research, integrating computer science concepts in computational geometry and graph theory with empirical observations and physical principles from biochemistry. It has important biological applications, including protein function prediction. In this chapter, we provide an introduction to the protein local structure comparison problem including challenges and applications. Current approaches to the problem are reviewed. Particular consideration is given to the discovery of local structure common to a group of related proteins. We present a new algorithm for this problem that uses a graph-based representation of protein structure and finds recurring subgraphs among a group of protein graphs.","","JunHuan,JanPrins,WeiWang","Advances in Computers","https://doi.org/10.1016/S0065-2458(06)68005-4","https://www.sciencedirect.com/science/article/pii/S0065245806680054"
"A606","Subject Index","","","","Encyclopedia of Language & Linguistics (Second Edition)","https://doi.org/10.1016/B0-08-044854-2/09085-4","https://www.sciencedirect.com/science/article/pii/B0080448542090854"
"A607","P1460 – P1884","","","","Clinical Microbiology and Infection","https://doi.org/10.1111/j.1470-9465.2006.12_4_1431.x","https://www.sciencedirect.com/science/article/pii/S1198743X15300069"
"A608","CHAPTER 11: Just Environmental Decisions, Please","","","Daniel A.ValleroPh.D.","Paradigms Lost,Paradigms Lost","https://doi.org/10.1016/B978-075067888-9/50014-4","https://www.sciencedirect.com/science/article/pii/B9780750678889500144"
"A609","Abstracts","","","","Sleep Medicine","https://doi.org/10.1016/j.sleep.2005.08.002","https://www.sciencedirect.com/science/article/pii/S1389945705001899"
"A610","How thematic maps can assist collection management: A qualitative assessment of Journals' thematic focus","We present a method for mapping the content of a text collection. This method uses linguistic analysis to relate terms extracted from the texts and clusters them into thematic topics mapped onto a 2D space. While the graphic display of domain topics is useful for several information-driven tasks, the focus of the paper is more on the comparison of journal ranking by productivity (number of published papers in the collection) and by content representativity (ranking by number of terms and clusters). The results show that the two rankings are not identical, thus pointing to possible discrepancies between pure productivity and terminological density.","Journal collection management,Content analysis,Data analysis,Thematic maps,Query refinement","FideliaIbekwe-SanJuan","Library Collections, Acquisitions, and Technical Services","https://doi.org/10.1016/j.lcats.2005.08.004","https://www.sciencedirect.com/science/article/pii/S146490550500059X"
"A611","Using data mining as a strategy for assessing asynchronous discussion forums","The purpose of this paper is to show how data mining may offer promise as a strategy for discovering and building alternative representations for the data underlying asynchronous discussion forums. Presently, the instructor's view of the output of a threaded forum is limited to reviewing a transcript or print version of the written dialogue produced by participants. With potentially hundreds of contributions to review for an entire online course, the instructor lacks a comprehensive view of the information embedded in the transcript. In this context, the authors attempt to sort out the question, “what is data from an online forum?” among other key questions. The present work seeks to intersect the information (i.e., participation indicators) an instructor may wish to extract from the forum with viewable and useful information that the system could produce from the instructor's query. Temporal participation indicators are used to show how using data and text mining techniques in the query process could improve the instructor's ability to evaluate the progress of a threaded discussion.","Collaborative learning,Computer-mediated communications,Teaching-learning strategies,Distributed learning environments,Distance education and telelearning","Laurie P.Dringus,TimothyEllis","Computers & Education","https://doi.org/10.1016/j.compedu.2004.05.003","https://www.sciencedirect.com/science/article/pii/S0360131504000788"
"A612","Effects of information and machine learning algorithms on word sense disambiguation with small datasets","Current approaches to word sense disambiguation use (and often combine) various machine learning techniques. Most refer to characteristics of the ambiguity and its surrounding words and are based on thousands of examples. Unfortunately, developing large training sets is burdensome, and in response to this challenge, we investigate the use of symbolic knowledge for small datasets. A naïve Bayes classifier was trained for 15 words with 100 examples for each. Unified Medical Language System (UMLS) semantic types assigned to concepts found in the sentence and relationships between these semantic types form the knowledge base. The most frequent sense of a word served as the baseline. The effect of increasingly accurate symbolic knowledge was evaluated in nine experimental conditions. Performance was measured by accuracy based on 10-fold cross-validation. The best condition used only the semantic types of the words in the sentence. Accuracy was then on average 10% higher than the baseline; however, it varied from 8% deterioration to 29% improvement. To investigate this large variance, we performed several follow-up evaluations, testing additional algorithms (decision tree and neural network), and gold standards (per expert), but the results did not significantly differ. However, we noted a trend that the best disambiguation was found for words that were the least troublesome to the human evaluators. We conclude that neither algorithm nor individual human behavior cause these large differences, but that the structure of the UMLS Metathesaurus (used to represent senses of ambiguous words) contributes to inaccuracies in the gold standard, leading to varied performance of word sense disambiguation techniques.","Word sense disambiguation,Machine learning,Naïve Bayes,Decision tree,Neural network,UMLS","GondyLeroya,Thomas C.Rindfleschb","International Journal of Medical Informatics","https://doi.org/10.1016/j.ijmedinf.2005.03.013","https://www.sciencedirect.com/science/article/pii/S1386505605000262"
"A613","The Glossary of Prosthodontic Terms","","","","The Journal of Prosthetic Dentistry","https://doi.org/10.1016/j.prosdent.2005.03.013","https://www.sciencedirect.com/science/article/pii/S0022391305001757"
"A614","A new perspective to automatically rank scientific conferences using digital libraries","Citation analysis is performed in order to evaluate authors and scientific collections, such as journals and conference proceedings. Currently, two major systems exist that perform citation analysis: Science Citation Index (SCI) by the Institute for Scientific Information (ISI) and CiteSeer by the NEC Research Institute. The SCI, mostly a manual system up until recently, is based on the notion of the ISI Impact Factor, which has been used extensively for citation analysis purposes. On the other hand the CiteSeer system is an automatically built digital library using agents technology, also based on the notion of ISI Impact Factor. In this paper, we investigate new alternative notions besides the ISI impact factor, in order to provide a novel approach aiming at ranking scientific collections. Furthermore, we present a web-based system that has been built by extracting data from the Databases and Logic Programming (DBLP) website of the University of Trier. Our system, by using the new citation metrics, emerges as a useful tool for ranking scientific collections. In this respect, some first remarks are presented, e.g. on ranking conferences related to databases.","Citation analysis,Ranking,Digital libraries,Impact factor","AntonisSidiropoulos,YannisManolopoulos","Information Processing & Management","https://doi.org/10.1016/j.ipm.2003.09.002","https://www.sciencedirect.com/science/article/pii/S0306457303000803"
"A615","A systematic approach for identifying technology opportunities: Keyword-based morphology analysis","Morphology analysis (MA), a representative qualitative technique in technology forecasting (TF), has been utilized to identify technology opportunities. However, conventional MA is subject to limitations in that there is no scientific or systematic way in establishing the morphology of technology, and it is difficult to prioritize the alternatives. As a remedy, we propose a keyword-based MA that is supported by a systematic procedure and quantitative data for concluding the morphology of technology. To this end, a technology dictionary is developed by factor analysis for keywords that are extracted from patent documents through text mining. Then, the morphology of patents is identified based on the technology dictionary. By listing the occupied configurations of collected patents, the unoccupied territory of configurations are suggested as technology opportunities. Moreover, the priority of alternatives is concluded, and similar and substitutive technologies can be analyzed for the purpose of extending morphology structure. Technical and managerial strategy for in-house R&D or cross-licensing can also be supported by examining the morphology portfolio of technologies. A thin film transistor–liquid crystal display (TFT-LCD) case is exemplified to illustrate the detailed procedure of this brand-new MA.","Morphology analysis,Technology opportunity analysis,Text mining,Technology dictionary","ByungunYoon,YongtaePark","Technological Forecasting and Social Change","https://doi.org/10.1016/j.techfore.2004.08.011","https://www.sciencedirect.com/science/article/pii/S0040162504001155"
"A616","Chapter 1: SOME PHILOSOPHICAL ASPECTS OF SCIENTIFIC RESEARCH","","","JaroslavŠesták","Science of Heat and Thermophysical Studies,Science of Heat and Thermophysical Studies","https://doi.org/10.1016/B978-044451954-2/50001-1","https://www.sciencedirect.com/science/article/pii/B9780444519542500011"
"A617","Chapter 8 Cybercartography and the new economy: Collaborative research in action","As envisioned cybercartography is compiled by teams of individuals from different disciplines and involves new research partnerships among academia, government, civil society, and the private sector. Collaboration and integration of research require deliberate and directed effort to manage and coordinate to enable all partners, collaborators, students, and stakeholders to fully participate and contribute to the research process. This chapter explores collaboration with the use of concepts from organizational theory, transdisciplinary research, and methods to measure collaboration. The chapter describes the Cybercartography and the New Economy (CANE) project as an organization of researchers, developers, users, and stakeholders who are collectively engaged in creating cybercartographic products and theoretical constructs. The Cybercartography project is viewed as an organized process that is structured to integrate research from various academic disciplines.","","Tracey P.Lauriault,D.R.Fraser Taylor(Distinguished Research Professor in International Affairs)","Modern Cartography Series","https://doi.org/10.1016/S1363-0814(05)80011-5","https://www.sciencedirect.com/science/article/pii/S1363081405800115"
"A618","Presence of taiwan on the world wide web in south korea: dynamics of digital and geographical presence on cyberspace","This paper examines the way in which Taiwan is connected to on the World Wide Web in South Korea. The Web may represent a new channel for the communication among a global society's members and a reflection of international relations. Thus, it is necessary to explore the distribution of relations formed and maintained on the Web and the contents of those relations as well. This paper traced South Korean Web pages hyperlinking pages hosted in Taiwan, using a search engine. The context in which Taiwan appears in South Korean pages was also examined. Specifically, the structure of hyperlink connectivity from South Korea and Taiwan was analyzed. It was found that the hyperlink network was very sparsely connected in terms of the number of South Korean Web pages hyperlinking to the pages of the other country. The contents of hyperlink-connected information were categorized and analyzed. The most often occurring content category was ‘Computers & Internet’ in Taiwan. This suggests that South Korean Web users including organizations are more interested in computer-related products in Taiwan than any other things. The implication of this paper is to examine the state and form of international information flow from South Korea to Taiwan based on the patterns of hyperlink relations inscribed on South Korean Web pages and the type and content of information.","","Han WooPark1","The International Information & Library Review","https://doi.org/10.1016/j.iilr.2003.12.001","https://www.sciencedirect.com/science/article/pii/S1057231703000602"
"A619","AGA abstracts W1190–W1748","","","","Gastroenterology","https://doi.org/10.1016/S0016-5085(04)80015-5","https://www.sciencedirect.com/science/article/pii/S0016508504800155"
"A620","When means become ends: considering the impact of patent strategy on innovation","The patent is supposed to be a means to an end, that end being innovation. Whether the innovation comes from the protection the patent affords the inventor, or from the dissemination of the information of invention the patent allows, the patent is not meant to be an end in itself. This seems to be changing, the patent acquiring a strategic value increasingly independent of innovation. If this development has gone largely unnoticed, it may be because the patent system tends to be viewed from the entrenched perspectives of lawyers and economists, and of a number of interest groups that justify their reliance on the system in terms of the innovation it is supposed to encourage. These groups have never included small firms and developing countries in whose name they frequently defend the patent system. They may have some difficulty justifying a system whose strategic value is so divorced from its value for innovation.","O31,O32,O33,O38,Keywords,Patent,Innovation,Strategy,Policy","StuartMacdonald","Information Economics and Policy","https://doi.org/10.1016/j.infoecopol.2003.09.008","https://www.sciencedirect.com/science/article/pii/S016762450300057X"
"A621","Ave atque Vale","","051","P.WHawkes","Ultramicroscopy","https://doi.org/10.1016/S0304-3991(03)00120-7","https://www.sciencedirect.com/science/article/pii/S0304399103001207"
"A622","Chapter 5 (Crystalline) materials under high pressure","A material can be described using its macroscopic and microscopic properties. The phenomena manifested by materials at pressures prevalent at the depths of the Earth are not only first-rank problems of geosciences, but stand at the forefront of modem condensed matter physics. The core states in an atom remain sharp delta-function-like states. These states are raised or lowered relative to their positions in isolated atoms. The shifts are mainly because of the screened Coulomb potential from the rest of the atoms in a crystal. The description of the former properties is obtained from its thermodynamic behavior. Through the elucidation of the Boyle's theory, the pressure, volume, and temperature relationship is established in the chapter. The microscopic description of the properties of minerals, as other crystalline solids, is governed by quantum mechanics, which governs the behavior of electrons and nuclei in solids. Much information on the bulk properties of solids at high temperatures and pressures and on single-crystal elasticity and strength anisotropy may be obtained by integrating high-pressure techniques, the scope of which is presented in the chapter.","","","Developments in Geochemistry","https://doi.org/10.1016/S0921-3198(04)80007-3","https://www.sciencedirect.com/science/article/pii/S0921319804800073"
"A623","Modeling & Analysis","","","","NeuroImage","https://doi.org/10.1016/S1053-8119(05)70018-5","https://www.sciencedirect.com/science/article/pii/S1053811905700185"
"A624","InfoGrid: providing information integration for knowledge discovery","Many scientific experiments produce large amounts of data using high-throughput devices. Knowledge Discovery systems are used in order to analyse this type of data. However, generic laboratory systems do not provide any contextual information about the system that is being studied. In these situations, Knowledge Discovery can be aided and validated by the use of Information integration tools. In this paper, we introduce InfoGrid, a data integration middleware engine, designed to operate under a Grid framework. It focuses on providing information access services and offers all users a query system which is able to retain the familiarity with their specific scientific applications while being diverse, flexible and open at the same time. The assumption here is that defining a common language for all queries is not desirable.Using this design, we show how the InfoGrid architecture can be used to provide contextual features for a data table to be used for analysis (i.e. the Annotation Problem). We also show how it can be used to find relevant background knowledge for a user (i.e. the Information Comprehension Problem). Both of these issues are very often encountered in Knowledge Discovery tasks, which we illustrate by means of a real-world example.","Grids,Distributed querying,Heterogeneous information resources,Wrappers,Annotating information,Information referencing,Knowledge discovery,Data integration","NikolaosGiannadakis,AnthonyRowe,MoustafaGhanem,Yi-keGuo","Information Sciences","https://doi.org/10.1016/S0020-0255(03)00170-1","https://www.sciencedirect.com/science/article/pii/S0020025503001701"
"A625","Patinformatics: Tasks to tools","This article starts with an overview of the field of patinformatics––the science of analyzing patent information to discover relationships and trends. This is followed by a survey of many common analysis tasks in this field, and many of the software tools available to tackle these tasks. The survey is set out under the tasks of list cleanup and grouping of concepts; list generation; co-occurrency matrices and circle graphs; clustering of structured data; clustering of unstructured data; mapping document clusters; adding temporal component to cluster map; citation analysis; subject/action/object functions. The author concludes that patinformatics has developed very rapidly over the last few years, and provides continuing challenges and opportunities in making optimal use of the resources available to achieve reliable and meaningful results. Useful tables summarizing aspects of this survey are included.","Patinformatics,Patent information analysis,Software analysis tools,Patent intelligence,List cleanup,Concept grouping,List generation,Co-occurrency matrices,Circle graphs,Data clustering,Mapping document clusters,Citation analysis","Anthony J.Trippe","World Patent Information","https://doi.org/10.1016/S0172-2190(03)00079-6","https://www.sciencedirect.com/science/article/pii/S0172219003000796"
"A626","Information landscaping: information mapping, charting, querying and reporting techniques for total quality knowledge management","Information landscaping––an integration of information mapping, charting, querying and reporting techniques––has been developed to enable the construction of a total quality knowledge management system focusing on a particular subject information field. The techniques apply five major parameters of the Fuzzy commonality model (FCM) including unionization, quantity, continuity or stability, changeability, and critical probability, to construct a series of information maps (infomaps) and a set of chronological-statistical charts (infocharts). The infomaps and infocharts are used as the blueprints and navigation agents for building and developing a web-based subject experts depository and query–report system. Focusing on the subject experts/expertise, this system enables a researcher to expedite a query search through infomaps (qualitative reference) and infocharts (quantitative reference). The entropy measurement and the entropy constant (the square root of the average entropy measure) are calculated to compare with the critical probability of the FCM. This leads to the finding of a set of regression straight lines and the establishment of an information oscillogram. The tropics (upper limit, middle range, lower limit), and the potential/solstitial population and its growth rate within a subject information domain during a particular time period can be determined. They can effectively and efficiently guide librarians and information professionals towards the construction and the continuous development of an electronic collection. The cultivation of a virtual learning and referencing environment can also be created by utilizing this data.","Bibliometrics and informetrics,Citation mining,Information landscaping,Information mapping,Knowledge management","Bor-shengTsai","Information Processing & Management","https://doi.org/10.1016/S0306-4573(02)00098-5","https://www.sciencedirect.com/science/article/pii/S0306457302000985"
"A627","The future of text mining in genome-based clinical research","Efficient information retrieval and extraction is a major challenge in molecular biology and genome-based clinical research. In addition, there is an increasing demand to combine information from different resources and across different disciplines in life sciences. Unfortunately, a large proportion of this information is only available in scientific articles. Moreover, the volume of literature is growing almost exponentially. Text mining provides methods to retrieve and extract information contained in free-text automatically. Here, we discuss the challenges and limitations of text mining in biology and medicine, including unsolved problems and necessary developments.","Text mining,information extraction,information retrieval,ontology,molecular biology,clinical research,Text mining,information extraction,information retrieval,ontology,molecular biology,clinical research","ChristianGieger,HartwigDeneke,JulianeFluck","BIOSILICO","https://doi.org/10.1016/S1478-5382(03)02336-9","https://www.sciencedirect.com/science/article/pii/S1478538203023369"
"A628","Abtracts Diagnosis, assessment, and reviews","","","","The Journal of Pain","","https://www.sciencedirect.com/science/article/pii/S1526590003000026"
"A629","Appendix A: Overview of 25 Valuation and Measurement Methods","","","","Making Sense of Intellectual Capital,Making Sense of Intellectual Capital","https://doi.org/10.1016/B978-0-7506-7774-5.50011-0","https://www.sciencedirect.com/science/article/pii/B9780750677745500110"
"A630","CHAPTER 7: Exploring and Finding Information","","","PeterPirolli","HCI Models, Theories, and Frameworks,HCI Models, Theories, and Frameworks","https://doi.org/10.1016/B978-155860808-5/50007-1","https://www.sciencedirect.com/science/article/pii/B9781558608085500071"
"A631","Index","","","","Mining the Web,Mining the Web","https://doi.org/10.1016/B978-155860754-5/50012-4","https://www.sciencedirect.com/science/article/pii/B9781558607545500124"
"A632","References","","","","Mining the Web,Mining the Web","https://doi.org/10.1016/B978-155860754-5/50011-2","https://www.sciencedirect.com/science/article/pii/B9781558607545500112"
"A633","Chapter 5: Supervised Learning","In modern times, the task of organizing knowledge into systematic structures is studied by ontologists and library scientists, resulting in such well-known structures as the Dewey decimal system, the Library of Congress catalog, the AlMS Mathematics Subject Classification, and the U.S. Patent Office subject classification. Learning to assign objects to classes given examples is called classification or supervised learning. In supervised learning, the learner first receives training data in which each item is marked with a label or class from a discrete finite set. The learning algorithm is trained using this data. It is common to “hold out” part of the labeled data to tune various parameters used in the classifier. Once the classifier is trained, it is given unlabeled “test” data and has to guess the label. Supervised learning has been intensively studied for several decades in AI, machine learning, and pattern recognition, and of late in data warehousing and mining. In those domains, the data is usually more “structured” than text or hypertext. Structured data usually comes in relational tables with well-defined data types for a moderate number of columns. Furthermore, the semantic connection between these columns and the class label is often well understood. The chapter studies supervised learning specifically for text and hypertext documents. Text, as compared to structured data, has a very large number of potential features, of which many are irrelevant.","","SoumenChakrabarti","Mining the Web,Mining the Web","https://doi.org/10.1016/B978-155860754-5/50006-9","https://www.sciencedirect.com/science/article/pii/B9781558607545500069"
"A634","Chapter 4: Similarity and Clustering","Similarity is fundamental to many search and mining operations on hypertext. This chapter studies how measures of similarity are used to cluster a collection of documents into groups within which inter-document similarity is large compared to the similarity between documents chosen from different groups. The utility of clustering for text and hypertext information retrieval lies in the so-called cluster hypothesis. The cluster hypothesis is not limited to documents alone. If documents are similar because they share terms, terms can also be represented as bit-vectors representing the documents in which they occur, and these bit-vectors can be used to cluster the terms. As with terms and documents, one can set up a bipartite relation for people liking documents, and use this to cluster both people and documents, with the premise that similar people like similar documents, and vice versa. This important ramification of clustering is called collaborative filtering. This chapter provides an overview of basic formulations and approaches to clustering. It describes two important clustering paradigms: a bottom-up agglomerative technique, which collects similar documents into larger and larger groups; and a top-down partitioning technique, which divides a corpus into topic-oriented partitions. These are followed by a slew of clustering techniques that can be broadly classified as embeddings of the corpus in a low-dimensional space to bring out the clustering present in the data. The chapter also discusses probabilistic models and algorithms and concludes with a discussion of collaborative filtering.","","SoumenChakrabarti","Mining the Web,Mining the Web","https://doi.org/10.1016/B978-155860754-5/50005-7","https://www.sciencedirect.com/science/article/pii/B9781558607545500057"
"A635","Genetics and molecular biology of rhythms in Drosophila and other insects","Application of genetic variants (Sections II–IV, VI, and IX) and molecular manipulations of rhythm-related genes (Sections V–X) have been used experimentally to investigate features of insect chronobiology that might not have been experimentally accessible otherwise. Most such tests of mutants and molecular-genetic experiments have been performed in Drosophila melanogaster. Results from applying visual-system variants have revealed that environmental inputs to the circadian clock in adult flies are mediated by external photoreceptive structures (Section II) and also by direct light reception that occurs in certain brain neurons (Section IX). The relevant light-absorbing molecules are rhodopsins and “blue-receptive” cryptochrome (Sections II and IX). Variations in temperature are another clock input (Section IV), as has been analyzed in part by use of molecular techniques and transgenes involving factors functioning near the heart of the circadian clock (Section VIII). At that location within the fly's chronobiological system, approximately a half-dozen-perhaps up to as many as 10-clock genes encode functions that act and interact to form the circadian pacemaker (Sections III and V). This entity functions in part by transcriptional control of certain clock genes' expression, which result in the production of key proteins that feed back negatively to regulate their own mRNA production. This occurs in part by interactions of such proteins with others that function as transcriptional activators (Section V). The implied feedback loop operates such that there are daily variations in the abunances of products put out by about one-half of the core clock genes. Thus, the normal expression of these genes defines circadian rhythms of their own, paralleling the effects of mutations at the corresponding genetic loci (Section III), which are to disrupt or apparently eliminate clock functioning. The fluctuations in the abudance of gene products are controlled transcriptionally and posttranscriptionally. These clock mechanisms are being analyzed in ways that are increasingly complex and occassionally obscure; not all panels of this picture are comprehensive or clear, including problems revolving round the biological meaning of a given features of all this molecular cycling (Section V). Among the complexities and puzzles that have recently arisen, phenomena that stand out are posttranslational modifications of certain proteins that are circadianly regulated and regulating; these biochemical events form an ancillary component of the clock mechanism, as revealed in part by genetic identification of factors (Section III) that turned out to encode protein kinases whose substrates include other pacemaking polypeptides (Section V). Outputs from insect circadian clocks have been long defined on formalistic and in some cases concrete criteria, related to revealed rhythms such as periodic eclosion and daily fluctuations of locomotion (Sections II and III). Based on the reasoning that if clock genes can regulate circadian cyclings of their own products, they can do the same for genes that function along output pathways; thus clock-regulated genes have been identified in part by virtue of their products' oscillations (Section X). Those studied most intensively have their expression influenced by circadian-pacemaker mutations. The clock-regulated genes discovered on molecular criteria have in some instances been analyzed further in their mutant forms and found to affect certain features of overt whole-organismal rhythmicity (Sections IV and X). Insect chronogenetics touches in part on naturally occurring gene variations that affect biological rhythmicity or (in some cases) have otherwise informed investigators about certain features of the organism's rhythm system (Section VII). Such animals include at least a dozen insect species other than D. melanogaster in which rhythm variants have been encountered (although usually not looked for systematically). The chronobiological “system” in the fruit fly might better be graced with a plural appellation because ther is a myriad of temporally related phenomena that have come under the sway of one kind of putative rhythm variant or the other (Section IV). These phenotypes, which range well beyond the bedrock eclosion and locomotor circadian rhythms, unfortunately lead to the creation of a laundry list of underanalyzed or occult phenomena that may or may not be inherently real, whether or not they might be meaningfully defective under the influence of a given chronogenetic variant. However, such mutants seem to lend themselves to the interrogation of a wide variety of time-based attributes—those that fall within the experimental confines of conventionally appreciated circadian rhythms (Sections II, III, VI, and X); and others that consist of 24-hr or nondaily cycles defined by many kinds of biological, physiological, or biochemical parameters (Section IV).","","Jeffrey CHall","Advances in Genetics","https://doi.org/10.1016/S0065-2660(03)48000-0","https://www.sciencedirect.com/science/article/pii/S0065266003480000"
"A636","Reasoning for Web document associations and its applications in site map construction","Recently, there is an interest in using associations between Web pages in providing users with pages relevant to what they are currently viewing. We believe that, to enable intelligent decisions, we need to answer the question “for a given set of pages, find out why they are associated”. We present a framework for reasoning about Web document associations. We start from the observation that the reasons of the Web page associations are implicitly embedded in the content of the pages as well as the links connecting them. The association reasoning scheme we propose is based on a random walk algorithm. This algorithm can take both link structure and contents into consideration and allows users to specify a focus. We then show how the proposed algorithm, combined with a logical domain identification technique, can be used for Web site summarization and Web site map construction to help users navigate through complex corporate sites. We see that, to achieve this goal, it is essential to recover the Web authors' intentions and superimpose it with the users' retrieval contexts in summarizing Web sites. Therefore, we present a framework, which uses logical neighborhoods, entry pages, and associations of entry pages, in creating context-sensitive summaries and maps of complex Web sites.","Reasoning about associations,Link analysis,Random walk,WWW,Topic distillation,Connectivity","K.SelçukCandan1,Wen-SyanLi","Data & Knowledge Engineering","https://doi.org/10.1016/S0169-023X(02)00053-8","https://www.sciencedirect.com/science/article/pii/S0169023X02000538"
"A637","Automated extraction and visualization of information for technological intelligence and forecasting","Empirical technology forecasting (TF) is not well utilized in technology management. Three factors could enhance managerial utilization: capability to exploit huge volumes of available information, ways to do so very quickly, and informative representations that help manage emerging technologies. This paper reports on efforts to address these three factors via partially automated processes to generate helpful knowledge from text quickly and graphically. We first illustrate a process to generate a family of technology maps that help convey emphases, players, and patterns in the development of a target technology. Second, we exemplify the generation of particular “innovation indicators” that measure particular facets of R&D activity to relate these to technological maturation, contextual influences, and market potential. Both technology mapping and innovation indicators rely upon searches in huge, easily accessible, abstract databases and text mining software. We augment these through “macros” (programming scripts) that automatically sequence the necessary steps to generate particular desired information products. These analytical findings can be tailored to the needs of particular technology managers.","Competitive technological intelligence,Technology forecasting,Text mining,Innovation indicators,Technology maps","DonghuaZhua,Alan L.Porterbc","Technological Forecasting and Social Change","https://doi.org/10.1016/S0040-1625(01)00157-3","https://www.sciencedirect.com/science/article/pii/S0040162501001573"
"A638","AGA abstracts W1054-81","","","","Gastroenterology","https://doi.org/10.1016/S0016-5085(02)83888-4","https://www.sciencedirect.com/science/article/pii/S0016508502838884"
"A639","AGA abstracts S989-S1336","","","","Gastroenterology","https://doi.org/10.1016/S0016-5085(02)83882-3","https://www.sciencedirect.com/science/article/pii/S0016508502838823"
"A640","Visualizing a high recall search strategy output for undergraduates in an exploration stage of researching a term paper","When accessing an information retrieval system, it has long been said that undergraduates who are in an exploratory stage of researching their essay topic should use a high recall search strategy; what prevents them from doing so is the information overload factor associated with showing the undergraduate a long list of citations. One method of overcoming information overload is summarizing and visualizing the citation list. This paper examines five summarization and visualization schemes for presenting information retrieval (IR) citation output, then discusses whether these schemes are appropriate for undergraduates and other domain novice users. We ask and answer four questions: (1) What is the message these schemes try to communicate and (2) is this message appropriate for domain novice users like undergraduates? (3) How do these schemes communicate their message and (4) is how they communicate the message appropriate for a domain novice? We conclude that (i) the most appropriate message for information space visualizations for domain novice users is associative thinking, and (ii) the message should be communicated with a standardized look that remains relatively constant over time so that the shape and form of the visualization can become familiar and thus useful to students as they navigate their way through the information space produced by a high recall search strategy.","Cartographic maps,Information retrieval,Information visualization,Information seeking,Information need","CharlesColea,BertieMandelblattb,JohnStevensonb","Information Processing & Management","https://doi.org/10.1016/S0306-4573(01)00029-2","https://www.sciencedirect.com/science/article/pii/S0306457301000292"
"A641","Brain aging and Alzheimer's disease; use it or lose it","","","D.F.Swaab1,E.J.G.Dubelaar1,M.A.Hofman1,E.J.A.Scherder2,E.J.W.van Someren1,R.W.H.Verwer1","Progress in Brain Research","https://doi.org/10.1016/S0079-6123(02)38086-5","https://www.sciencedirect.com/science/article/pii/S0079612302380865"
"A642","Text mining using database tomography and bibliometrics: A review","Database tomography (DT) is a textual database analysis system consisting of two major components: (1) algorithms for extracting multiword phrase frequencies and phrase proximities (physical closeness of the multiword technical phrases) from any type of large textual database, to augment (2) interpretative capabilities of the expert human analyst. DT has been used to derive technical intelligence from a variety of textual database sources, most recently the published technical literature as exemplified by the Science Citation Index (SCI) and the Engineering Compendex (EC). Phrase frequency analysis (the occurrence frequency of multiword technical phrases) provides the pervasive technical themes of the topical databases of interest, and phrase proximity analysis provides the relationships among the pervasive technical themes. In the structured published literature databases, bibliometric analysis of the database records supplements the DT results by identifying: the recent most prolific topical area authors; the journals that contain numerous topical area papers; the institutions that produce numerous topical area papers; the keywords specified most frequently by the topical area authors; the authors whose works are cited most frequently in the topical area papers; and the particular papers and journals cited most frequently in the topical area papers. This review paper summarizes: (1) the theory and background development of DT; (2) past published and unpublished literature study results; (3) present application activities; (4) potential expansion to new DT applications. In addition, application of DT to technology forecasting is addressed.","Database tomography,Text mining,Bibliometrics,Innovation,Information retrieval,Information extraction,Cluster,Taxonomies","Ronald NKostoffa,Darrell RayToothmanb,Henry JEberhartc,James AHumenikd","Technological Forecasting and Social Change","https://doi.org/10.1016/S0040-1625(01)00133-0","https://www.sciencedirect.com/science/article/pii/S0040162501001330"
"A643","Bibliometric cartography of information retrieval research by using co-word analysis","The aim of this study is to map the intellectual structure of the field of Information Retrieval (IR) during the period of 1987–1997. Co-word analysis was employed to reveal patterns and trends in the IR field by measuring the association strengths of terms representative of relevant publications or other texts produced in IR field. Data were collected from Science Citation Index (SCI) and Social Science Citation Index (SSCI) for the period of 1987–1997. In addition to the keywords added by the SCI and SSCI databases, other important keywords were extracted from titles and abstracts manually. These keywords were further standardized using vocabulary control tools. In order to trace the dynamic changes of the IR field, the whole 11-year period was further separated into two consecutive periods: 1987–1991 and 1992–1997. The results show that the IR field has some established research themes and it also changes rapidly to embrace new themes.","Co-word analysis,Information retrieval research,Research trends,Science citation index,Social science citation index","YingDing,Gobinda GChowdhury,SchubertFoo","Information Processing & Management","https://doi.org/10.1016/S0306-4573(00)00051-0","https://www.sciencedirect.com/science/article/pii/S0306457300000510"
"A644","To help pass the time","","","P.W.Hawkes","Ultramicroscopy","https://doi.org/10.1016/S0304-3991(00)00108-X","https://www.sciencedirect.com/science/article/pii/S030439910000108X"
"A645","Chapter 1.1: NeuroInformatics: The Issues","The neuroinformatics tool of interoperability ensures that tools and databases developed by different sub-communities communicate with each other despite their idiosyncrasies. Neuroinformatics is the integration of the use of databases, the World Wide Web, and visualization in the storage and analysis of neuroscience data with computational neuroscience, using computational techniques and metaphors to investigate relations between neural structure and function. In the studies of animals, the new methods of human brain imaging such as position emission tomography (PET) and functional magnetic resonance imaging (fMRI) are covered. The four important types of structures to be stored in the database are models, modules, simulations, and interfaces. The modeling work of the University of Southern California Brain Project (USCBP) focuses on computational techniques to model biological neural networks and attempts to understand the brain and its function in terms of structural and functional networks, whose units are at scales both coarser and finer than those of the neuron. This chapter reviews the various range of USCBP modeling such as basal ganglia, cerebellum, hippocampus, parietal-premotor interactions, and motivational systems.","","Michael A.Arbibab","Computing the Brain,Computing the Brain","https://doi.org/10.1016/B978-012059781-9/50002-X","https://www.sciencedirect.com/science/article/pii/B978012059781950002X"
"A646","Chapter 6.3: Knowledge Mechanics and the Neuroscholar Project: A New Approach to Neuroscientific Theory","Neuroscience literature has intrinsic complications because its subject matter is both broad and deep. It involves many different scientific subdisciplines ranging from animal behavior and psychology, through cellular anatomy and physiology, to studies of molecular biophysics and biochemistry. This chapter describes how knowledge mechanics will examine the philosophical basis of the concept of theory in neuroscience and how a knowledge mechanical approach may address key issues. It discusses the high-level software requirements and the fundamental design concepts of the neuroscholar system, neuroscholar, and the significance of knowledge mechanics in detail. The process of building a representation of user knowledge in neuroscholar is accomplished by placing a computational structure on the data that adequately captures the concepts of neuroscience theory. The retrieval of knowledge from the system may rely on the structured, interconnected nature of the ontology to give the user the capability to query data and information or knowledge in a combinatorial way. The strength of neuroanatomical connections is often used to prioritize how different connections influence the global organization of the system.","","Gully A.P.C.Burns","Computing the Brain,Computing the Brain","https://doi.org/10.1016/B978-012059781-9/50022-5","https://www.sciencedirect.com/science/article/pii/B9780120597819500225"
"A647","Chapter 5 Prominent chromatographers and their research seminal concepts in chromatography/separation sciences","This chapter presents several chromatography Awardees/scientists, including a biography of each of them. It discusses the unique activities of Awardees, their research experiences, and the description of their discovery(s) and contributions to chromatography. Daniel W. Armstrong has been recognized through a number of citations: Teaching Excellence Award from the Arts and Sciences Council of Texas Tech University, 1985; Faculty Excellence Award, 1988; Teaching Excellence Award, 1988–1989, 1992, and 1994; Curator's Distinguished Professorship, 1989, and others. The chapter describes the unconventional approaches of Daniel W. Armstrong for understanding and developing separations. He used both classic liquid chromatography (LC) and high performance liquid chromatography (HPLC) in an attempt to separate products from a micelle catalyzed reaction. The chapter outlines the theory and mechanism of pseudophase separations. Today, micelles and cyclodextrins are well-known, important elements in a variety of modern, high performance analytical procedures, including chromatography, capillary electrophoresis, and a variety of spectroscopic methods.","","Charles W.Gehrkea,Robert L.Wixomb,ErnstBayerc","Journal of Chromatography Library","https://doi.org/10.1016/S0301-4770(01)80011-7","https://www.sciencedirect.com/science/article/pii/S0301477001800117"
"A648","The Drosophila melanogaster malpighian tubule","This chapter reviews the morphology, function, and development of malpighian tubule of Drosophila melanogaster. Recent results have provided a reference point for tubule studies for insect physiologists and a unique resource for developmental and genetic analysis of fundamental questions of differentiated cell function. It is noted that the formation of the Drosophila melanogaster malpighian tubule is better understood than that of any other insect and it provides a model for epithelial development in general. In addition to the standard Drosophila techniques of close microscopic examination, genetic screens, enhancer trapping, and reporter gene expression, there are some specific tools that have made progress much easier.","","Julian A.TDow,Shireen ADavies","Advances in Insect Physiology","https://doi.org/10.1016/S0065-2806(01)28008-4","https://www.sciencedirect.com/science/article/pii/S0065280601280084"
"A649","Poster presentations","","","","Osteoarthritis and Cartilage","https://doi.org/10.1016/S1063-4584(00)80006-0","https://www.sciencedirect.com/science/article/pii/S1063458400800060"
"A650","Knowledge management","Knowledge management (KM) is the practice of transforming the intellectual assets of an organization into business value. This chapter takes a comprehensive look at KM, structured around five key questions that organizations face: what knowledge should be managed, where is it, how does it get where it is needed, what is the role of innovation, and what is the influence of organizational culture. Addressing these questions leads naturally to the consideration of intellectual capital, communities of practice, learning, knowledge sharing, knowledge packaging, and the life cycle of knowledge in organizations. The architecture and technology components of KM systems are described as they provide capabilities for publishing, profiling, content structuring, content delivery through push and pull mechanisms, collaboration, interface and portal design, and data mining. The discussion of KM systems includes references to representative tools and technologies such as case-based reasoning and XML. The strategic and tactical design of an organizational KM program is described, including program elements, success criteria, and the role of the Chief Knowledge Officer. Many examples and references are provided. Also discussed are issues surrounding KM and observations on its future.","","William W.Agresti","Advances in Computers","https://doi.org/10.1016/S0065-2458(00)80006-6","https://www.sciencedirect.com/science/article/pii/S0065245800800066"
"A651","Focused crawling: a new approach to topic-specific Web resource discovery","The rapid growth of the World-Wide Web poses unprecedented scaling challenges for general-purpose crawlers and search engines. In this paper we describe a new hypertext resource discovery system called a Focused Crawler. The goal of a focused crawler is to selectively seek out pages that are relevant to a pre-defined set of topics. The topics are specified not using keywords, but using exemplary documents. Rather than collecting and indexing all accessible Web documents to be able to answer all possible ad-hoc queries, a focused crawler analyzes its crawl boundary to find the links that are likely to be most relevant for the crawl, and avoids irrelevant regions of the Web. This leads to significant savings in hardware and network resources, and helps keep the crawl more up-to-date.To achieve such goal-directed crawling, we designed two hypertext mining programs that guide our crawler: a classifier that evaluates the relevance of a hypertext document with respect to the focus topics, and a distiller that identifies hypertext nodes that are great access points to many relevant pages within a few links. We report on extensive focused-crawling experiments using several topics at different levels of specificity. Focused crawling acquires relevant pages steadily while standard crawling quickly loses its way, even though they are started from the same root set. Focused crawling is robust against large perturbations in the starting set of URLs. It discovers largely overlapping sets of resources in spite of these perturbations. It is also capable of exploring out and discovering valuable resources that are dozens of links away from the start set, while carefully pruning the millions of pages that may lie within this same radius. Our anecdotes suggest that focused crawling is very effective for building high-quality collections of Web documents on specific topics, using modest desktop hardware.","Web resource discovery,Classification,Categorization,Topic distillation","SoumenChakrabartia1,Martinvan den Bergb2,ByronDomc","Computer Networks","https://doi.org/10.1016/S1389-1286(99)00052-3","https://www.sciencedirect.com/science/article/pii/S1389128699000523"
"A652","Visualising semantic spaces and author co-citation networks in digital libraries","This paper describes the development and application of visualisation techniques for users to access and explore information in a digital library effectively and intuitively. Salient semantic structures and citation patterns are extracted from several collections of documents, including the ACM SIGCHI Conference Proceedings (1995–1997) and ACM Hypertext Conference Proceedings (1987–1998), using Latent Semantic Indexing and Pathfinder Network Scaling. The unique spatial metaphor leads to a natural combination of search and navigation within the same semantic space in a 3-dimensional virtual world. Author co-citation patterns are visualised through a number of author co-citation maps in attempts to reveal the structure of the hypertext, including an overall co-citation map of 367 authors and three periodical maps. These maps highlight predominant research areas in the field. This approach provides a means for transcending the boundaries of collections of documents and visualising more profound patterns in terms of semantic structures and co-citation networks.","","ChaomeiChen","Information Processing & Management","https://doi.org/10.1016/S0306-4573(98)00068-5","https://www.sciencedirect.com/science/article/pii/S0306457398000685"
"A653","Abstract","","","","Biological Psychiatry","https://doi.org/10.1016/S0006-3223(99)80008-0","https://www.sciencedirect.com/science/article/pii/S0006322399800080"
"A654","Table Of Contents, Volumes 1-49","","","","Advances in Computers","https://doi.org/10.1016/S0065-2458(08)60057-1","https://www.sciencedirect.com/science/article/pii/S0065245808600571"
"A655","Italian participation to interplanetary exploration: The Cassini-Huygens mission","After the successfull launch of October 1997, the Cassini spacecraft, which carries the Probe Huygens, is on its way to reach the Saturn planetary system on July 2004. Purpose of the mission is to perform a very accurate investigation on Saturn and its moons, Titan in particular. The implementation of the program as seen the cooperation of the space agencies of USA, Europe anf Italy. After a general description of the Cassini/Huygens mission, this paper will provide an overview of the Italian participation in scientific, industrial and technology terms.","","E.Flamini1,RSomma2","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00049-1","https://www.sciencedirect.com/science/article/pii/S0094576599000491"
"A656","Exploring the Kuiper Belt: An extended Pluto mission","A robotic flyby mission to the planet Pluto is being planned for launch early in the next decade. The spacecraft will continue on out of the solar system in an almost radial direction traveling at about four AU per year and begin transiting the Kuiper Belt shortly after Pluto encounter. Recent discoveries and observations of Kuiper Belt objects have generated increased interest in the characteristics of these bodies. This paper examines the opportunities and requirements for extending the Pluto mission to include the search for, and encounters with, objects in the Kuiper Disk at 40+ AU. The trajectory and <U+0394>V requirements will be presented. An automated, on-board sky survey will be proposed to inventory the Kuiper objects in the vicinity of the flight path and to identify which objects are candidates for altering the trajectory for a close flyby. A possible Kuiper object encounter science scenario will be described.","","Paul KHenry(Science Payload Lead)1,Richard JTerrile(Project Scientist)2,Robert WMaddock(Mission Design Analyst)3,Harold RSobel(Instrument Performance Analyst)4","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00032-6","https://www.sciencedirect.com/science/article/pii/S0094576599000326"
"A657","The Aurora project: Estimation of the optical sail parameters","The thrust model for computing a sailcraft trajectory contains thermo-optical parameters that are averages over the spectrum of the incident photons, namely, with respect to energy, intensity and polarization. These parameters are not observables and could change considerably from a sail to sail for a number of practical reasons. The mission analysis for a sailcraft is a progressive task from a simple trajectory propagator to the orbit determination. Aurora sailcraft mission analysis has advanced another step forward by processing experimental data related to aluminium. Once appropriate fitting functions have been selected, differential specular and diffused reflectance and differential absorptance have been averaged over incident solar spectrum, assumed a Planckian here. The result has been to get incident-angle-dependent optical parameters more reliable than mere literature values. The procedure has entailed the computation of grids of complicated definite integrals. They are particularly important during the trajectory optimization of the Aurora solar flyby, a very sensitive profile that would allow the sailcraft to achieve cruise speeds ranging from 12 to 20 AU/yr.","","G.Vulpetti,S.Scaglione","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00038-7","https://www.sciencedirect.com/science/article/pii/S0094576599000387"
"A658","Soft computing technologies in nuclear engineering applications","The application of soft computing technologies, particularly neural networks, fuzzy logic, and genetic algorithms, to the surveillance, diagnostics and operation of nuclear power plants and their components is an area that has great potential for exploitation. Areas of potential application are to the surveillance and diagnostics of complete nuclear power plants and to specific systems such as check valves, instrumentation systems, and rotating machinery. Applications include sensor surveillance and calibration verification, diagnostics of both plant transients and specific faults, efficiency optimization, vibration analysis, loose parts monitoring, and adaptive and/or optimal control. The synergistic benefits of combining the use of neutral networks, fuzzy systems and genetic algorithms are illustrated in several application. Although some of the work cited (e.g. vibration systems) are not necessarily associated with nuclear power plants, the results are directly applicable. Indeed, the methodologies of soft computing technologies have many applications outside the nuclear power field, e.g., fossil-fired power plants, chemical process facilities, high performance aerospace systems, financial market issues, sociological systems, and others.","Neural networks,fuzzy logic,genetic algorithms,soft computing,nuclear power,diagnostics,system modeling","Robert E.Uhrig1,Lefteri H.Tsoukalas","Progress in Nuclear Energy","https://doi.org/10.1016/S0149-1970(97)00109-1","https://www.sciencedirect.com/science/article/pii/S0149197097001091"
"A659","Design issues for a mission to exploit the gravitational lensing effect at 550 AU","Reported herein are the first results of a NASA-sponsored study at the Jet Propulsion Laboratory (JPL), California Institute of Technology, exploring the scientific promise and technological viability of a mission to exploit the gravitational lensing effect of the Sun to obtain huge antenna gains for electromagnetic waves grazing the Sun's disk. With regard to scientific promise, these results, reported at about the halfway point of the study, substantiate the huge antenna gains offered by, as it will be called here, a Solar Gravitational Telescope (SGT) and point to the instrument's potential promise as a “discovery machine” but suggest considerable limitations to the telescope's usefulness as a general purpose astrophysical research tool. These limitations are seen to arise, primarily, from the geometry and scale of the “virtual” telescope which must be achieved and maintained to utilize the lensing effect and the turbulence effects of the Sun's plasma on the observed target's signal. With regard to technological viability, the preliminary results suggest a very aggressive use of unproven, as-yet-unflown new technology will be required to enable the desired science observations and mission durations approaching the short (3–10 year) NASA-targeted mission duration goal. Key needed new technologies are advanced propulsion, lightweight telescopes, membrane mirrors, inflatable/rigidizeable structures, and novel coronagraphic techniques.","","John L.West1","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00034-X","https://www.sciencedirect.com/science/article/pii/S009457659900034X"
"A660","Preface","","","GiovanniVulpetti(ISEC Chairman)","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00030-2","https://www.sciencedirect.com/science/article/pii/S0094576599000302"
"A661","On the strategy of space station injection in the point of Earth — Moon Libration / way of making the asteroid patrol/","One of the most important problem in the ecological area that stay for humanity is the problem of prevention Earth and asteroids collision. The danger of such collision isn't realized of the general public. But we know that on average twice in the every century the Earth comes into collision with the large celestial bodies (for example Tungussky or Arizonsky meteorites). The incidence of such meteorite in density population region of the Earth will simulate the ecumenical catastrophe. Much more seldom the Earth experiences collision with the particularly large celestial bodies. In accordance with one of the hypotheses namely the collision Earth with such body 65,000,000 years ago leads to the global change of Earth biosphere (in particular to the extinction of dinosaurs).Now we are able to stave off or at least to forewarn of this danger. One of the way for that is making the specific space station - asteroid patrol. Such the station will be able to track the approaching celestial bodies and perhaps (on second stage) to attempt altering its trajectory (for example with directional thermonuclear explosions)Some of the expedient points in the Space for the asteroid patrol's placing are the librations' points of the Earth - Moon system. In the report the preliminary results of analysis the problem of space station's taking into the libration's point are presented. For this taking it is suggested the electric jet propulsion to use.","","R.K.Tchuyan,V.V.Bagdasaryan,A.P.Belousov,L.A.Latusev","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00035-1","https://www.sciencedirect.com/science/article/pii/S0094576599000351"
"A662","Roadmap to a star","NASA is currently constructing an Interstellar Roadmap that will outline a progressive series of phased technology efforts over several decades that would enable new science beyond the solar system, leading to and culminating in robotics exploration of nearby stars. The Roadmap is structured around a decadal progression of science missions and enabling technologies in which each decadal cycle has an intrinsic value in itself. The Roadmap serves at least 5 functions: 1) it lays the foundation for the development of a broad new strategic thrust of space exploration and development; 2) it outlines a long term progressive program for which each phase has an intrinsic value and can be argued independently of a Star Mission itself; 3) it defines a phased approach that would culminate in a large- scale breakthrough beamed energy capability that would have broad planetary and terrestrial applicability; 4) it describes an endeavor that could provide the technological basis of a U.S. economic engine for the first half of the 21st century; and 5) it provides a focus and a structure around which new government/industry economic relationships may be established. This paper outlines the process for constructing the Roadmap which is due to be completed in Fall 1998. It also poses questions raised by a mission of such scale and suggests some of the strategic value of such a Roadmap.","","John L.Anderson(Advanced Concepts Executive)*","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00033-8","https://www.sciencedirect.com/science/article/pii/S0094576599000338"
"A663","The liquid annular reactor system (LARS) for deep space exploration","A new propulsion concept for high <U+0394> V space missions, termed LARS (Liquid Annular Reactor System), uses liquid nuclear fuel elements to heat hydrogen propellant to very high temperatures (-6000 K). The molten fuel is contained in a lower-temperature solid container which rotates to stabilize and hold in the liquid layer by centripetal force. Containment of ultra high temperature molten refractories, using this method, has been experimentally demonstrated by A.V. Grosse. The specific impulse of a rocket exhausting hydrogen at 6000 K is 2000 seconds, approximately double that of solid-core nuclear rockets. A LARS-powered space probe could accomplish extra-solar missions to 550 A.U. in approximately 35 years.","","GeorgeMaise(Principal)1,JohnPaniagua(Principal)2,James R.Powell(Principal)3,HansLudewig(Physicist)4,MichaelTodosow(Nuclear Engineer)5","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00044-2","https://www.sciencedirect.com/science/article/pii/S0094576599000442"
"A664","Revolutionary systems and technologies for missions to the outer planets","The Advanced Deep Space System Development Program is managed by the Jet Propulsion Laboratory for NASA and is also called X2000. X2000 is organized to create advanced flight and ground systems for the exploration of the outer planets and beyond; it has been created to develop the engineering elements of flight and ground systems. Payloads will be developed by another team. Each X2000 delivery gets its requirements from a set of planned missions, or “mission customers”.The X2000 First Delivery Project supports missions to the Sun (to 4 solar radii), Europa (looking for a liquid ocean), Mars (in support of several Mars missions including a sample return), a comet (including a sample return), and Pluto followed by a trip into the Kuiper belt. This set of missions leads to some outstanding requirements: 1.1. Long-life (10–12 years)2.2. Total Ionizing Dose of 4 Mrad (for a Europa Orbiter)3.3. Average power consumption less than or equal to 150 Watts4.4. Autonomous operations that result in an extreme reduction in operations costsThis paper describes the X2000 first delivery and its technologies following a brief overview of the program.","","David F.Woerner(Manager)1","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00047-8","https://www.sciencedirect.com/science/article/pii/S0094576599000478"
"A665","Introduction & layout of entries","","","Edward C.Conley","Ion Channel Factsbook,Ion Channel Factsbook","https://doi.org/10.1016/B978-012184453-0/50002-0","https://www.sciencedirect.com/science/article/pii/B9780121844530500020"
"A666","Java-based and secure learning agents for information retrieval in distributed systems","Intelligent agents represent a powerful tool to implement distributed functions in a network environment. This paper describes the current status of a research project whose target consists in using this new technology for automatic information retrieval, network management and security purposes within a distributed system. Specifically, we describe the software agents dedicated to information retrieval and to security aspects, focusing on architectural aspects and implementation issues. The system has been implemented using the Java language.","Information retrieval,Agent security,Learning agents,Distributed systems,Java","F.Bergadanoa,A.Puliafitob,S.Riccobenec,G.Ruffoa,L.Vitab","Information Sciences","https://doi.org/10.1016/S0020-0255(98)10041-5","https://www.sciencedirect.com/science/article/pii/S0020025598100415"
"A667","The Aurora project: A new sail layout","Aurora spacecraft is a scientific probe propelled by a “fast” solar sail whose first goal is to perform a technology assessment mission. The main characteristic of the sail is its low mass, which implies the absence of a plastic backing of the aluminum film and the lightness of the whole structure. In previous structural studies the limiting factor has been shown to be the elastic stability of a number of structural members subject to compressive loads. An alternative structural layout is here suggested: an inflatable beam, which is kept pressurized also after the deployment, relieves all compressive stresses, allowing a very simple configuration and a straightforward deployment procedure. However, as the mission profile requires a trajectory passing close to the Sun, a configuration different from the ‘parachute’ sail proposed in another paper, must be used.","","GiancarloGenta(Professor)1,EugenioBrusa(Researcher)2","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00040-5","https://www.sciencedirect.com/science/article/pii/S0094576599000405"
"A668","Radioisotope electric propulsion of sciencecraft to the outer solar system and near-interstellar space","Recent results are presented in the study of radioisotope electric propulsion as a near-term technology for sending small robotic sciencecraft to the outer Solar System and near- interstellar space. Radioisotope electric propulsion (REP) systems are low-thrust, ion propulsion units based on radioisotope electric generators and ion thrusters. Powerplant specific masses are expected to be in the range of 100 to 200 kg/kW of thrust power. Planetary rendezvous missions to Pluto, fast missions to the heliopause (100 AU) with the capability to decelerate an orbiter for an extended science program and prestellar missions to the first gravitational lens focus of the Sun (550 AU) are investigated.","","Robert J.Noble1","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00048-X","https://www.sciencedirect.com/science/article/pii/S009457659900048X"
"A669","Optical thomograph of the Universe","The concept of astrometric supervision of the Universe on the basis of using the extralong base for angular measurements realized by launching 3–4 spacecrafts in different directions from the Earth upto the distance of 500 AU is proposed. Under various variants of scientific and service payload of spacecrafts it will allow to execute direct measurement of distances upto stars at the distance of 1 ÷ 10 light-years. Within this distance ours and Domestic Group galaxies, including Andromeda Nebula are located. In perspective variants based on multiaperture optical systems the direct measurement at the distances upto boundary objects of the Universe, that is, quasars located on distance upto 10 billion light-years may be executed. The problems of sensor, and system of communication design also the concept of a spacecraft are considered.","","MichaelOvchinnikov(Professor, Dr.Sci., Chief of Division)ab1,IgorRodionov(Professor, Dr.Sci., Director General of the S&RC “Reagent”)ab2","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00051-X","https://www.sciencedirect.com/science/article/pii/S009457659900051X"
"A670","Imaging of extrasolar advanced terrestrial planets","The gravitational lens effect of the Sun would allow, by using a detector at one of its foci, to obtain a “telescope” with gigantic amplification and resolution powers opening extraordinary perspectives for the detailed study of extrasolar planets, particularly technologically advanced ones. But, astronautical challenges are raised by the necessity to align precisely and put in an efficient tracking and scanning mode the detector, necessarily modest in size compared to the dimensions of the planet images and ranges of orbital and rotational motions. In the frame of the FOCAL space mission submitted to ESA, we present the dynamical geometry of the images for two typical cases of observational wavelengths: 10 centimeters (radio) and 10 micrometers (infrared), for a solar-type stellar system 10 parsecs away. Plasma thrusters could provide interesting solutions for the control of the detector for tracking and scanning the focal images.","","JeanHeidmann(Astronomer)1","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00052-1","https://www.sciencedirect.com/science/article/pii/S0094576599000521"
"A671","Subject Index","","","","Advances in Computers","https://doi.org/10.1016/S0065-2458(08)60717-2","https://www.sciencedirect.com/science/article/pii/S0065245808607172"
"A672","The IAA Interstellar Space Exploration Committee (ISEC) its history & evolution","","","Leslie R.Shepherd(Past Chairman of ISEC 1983–1994)","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00031-4","https://www.sciencedirect.com/science/article/pii/S0094576599000314"
"A673","NASA breakthrough propulsion physics program","In 1996, NASA established the Breakthrough Propulsion Physics program to seek the ultimate breakthroughs in space transportation: propulsion that requires no propellant mass, propulsion that attains the maximum transit speeds physically possible, and breakthrough methods of energy production to power such devices. Topics of interest include experiments and theories regarding the coupling of gravity and electromagnetism, vacuum fluctuation energy, warp drives and wormholes, and superluminal quantum effects. Because these propulsion goals are presumably far from fruition, a special emphasis is to identify affordable, near-term, and credible research that could make measurable progress toward these propulsion goals. The methods of the program and the results of the 1997 workshop are presented. This Breakthrough Propulsion Physics program, managed by Lewis Research Center, is one part of a comprehensive, long range Advanced Space Transportation Plan managed by Marshall Space Flight Center.","","Marc G.Millis1","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00045-4","https://www.sciencedirect.com/science/article/pii/S0094576599000454"
"A674","The AURORA Project: Removal of plastic substrate to obtain an all-metal solar sail","The Orbital Angular Momentum Reversal (H-Reversal mode), is a new class of trajectories to get a cruise speed ranging from 12 to 20 AU/yr. To accomplish the H-reversal mode, a sailcraft needs of all metal solar sail. The solar sail envisaged by the “AURORA Project” is composed of two metallic layers (AI and Cr) deposited on plastic substrate. To obtain an all metal solar sail, required by the Project, the substrate must be removed in orbit. In order to accomplish that, two possible methods are described in this paper. The first one is based on the UV degradation of a buffer layer located between the substrate and the metallic layers. The UV degradation would be the starting mechanism that causes the interface weakness. The Diamond Like Carbon has been used as buffer layer and preliminary experimental results on its UV degradation are reported. The second method exploits the characteristic of most plastics to be etched (ashing process) by the atomic oxygen. The number density of atomic oxygen in Low Earth Orbit could be enough to remove a properly-selected plastic substrate in Short time.","","S.Scaglione,G.Vulpetti","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00041-7","https://www.sciencedirect.com/science/article/pii/S0094576599000417"
"A675","High performance nuclear thermal propulsion system for near term exploration missions to 100 A.U. and beyond","A new compact ultra light nuclear reactor engine design termed MITEE (MIniature Reac Tor EnginE) is described. MITEE heats hydrogen propellant to 3000 K, achieving a specific impulse of 1000 seconds and a thrust-to-weight of 10. Total engine mass is 200 kg, including reactor, pump, auxiliaries and a 30% contingency. MITEE enables many types of new and unique missions to the outer solar system not possible with chemical engines. Examples include missions to 100 A.U. in less than 10 years, flybys of Pluto in 5 years, sample return from Pluto and the moons of the outer planets, unlimited ramjet flight in planetary atmospheres, etc. Much of the necessary technology for MITEE already exists as a result of previous nuclear rocket development programs. With some additional development, initial MITEE missions could begin in only 6 years.","","James R.Powell(Principal)1,JohnPaniagua(Principal)2,GeorgeMaise(Principal)3,HansLudewig(Physicist)4,MichaelTodosow(Nuclear Engineer)5","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00043-0","https://www.sciencedirect.com/science/article/pii/S0094576599000430"
"A676","Applying international space station (ISS) and solar-sail technology to the exploration and diversion of small, dark near earth objects (NEO's)","Space-Station technology, micron-thick 100-m solar sails, and a near-Earth propulsion system allow exploration of small, dark Near-Earth-Objects (NEO's) of cometary origin. Early crewed missions to NEO's could analyze the objects' properties and evaluate resource-mining possibilities. Later missions to Earth-threatening 100-m radius NEO's could deploy NEO-centered, high-area, low-mass reflective structures. The solar gravitational parameter (GMsun) on a NEO is slightly reduced by increased radiation pressure. The central-force-field equations reveal that NEO eccentricity and average solar distance are thereby slightly increased. Given decades of warning and long-lived reflective canopies, such structures can convert Earth-impacts into near-misses. Although not suitable for NEO mining, such structures are superior to nuclear detonations because (as revealed by the 1994 Jupiter-comet interaction) NEO calving may be a consequence of explosions. NEO despinning is not required.","","G.L.Matloff(Professor)1","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00042-9","https://www.sciencedirect.com/science/article/pii/S0094576599000429"
"A677","11: EEG Biofeedback: An Emerging Model for Its Global Efficacy","This chapter discusses the electroencephalogram EEG Biofeedback, which is an emerging model for its global efficacy. EEG biofeedback has a favorable research history for both epilepsy and attention deficit hyperactivity disorder (ADHD). A model has been presented in the chapter in which ADHD and its comorbidities can be seen as a composite or spectrum disorder, grounded in the disregulation of basic neurophysiological mechanisms underlying attentional, cognitive, and effective function. This model has been extended so that much of psychopathology can be seen in neurophysiological terms such as “disorders of disregulation,” traceable to a relatively small number of characteristic failure modes of the brain acting as a control system. The EEG biofeedback training for a large variety of conditions has been accomplished to date with a parsimonious set of protocols. Such protocols had their origins in basic research, but have since been evolved and refined empirically. These protocols can be motivated by a straightforward partitioning of brain function in the spatial and frequency domains. Such remediation may result in the essentially complete amelioration of symptoms attendant to various disorders, many of which have been refractory to standard medical interventions. Clinical data indicate that broad generalization of these principles may be possible to the domain of psychopathology at large, including, among others, the dissociative disorders, addictions, eating disorders, and even personality disorders. Discovery and validation through research of the practical implications of brain regulation in the bioelectrical domain could potentially lead to a scientific revolution comparable to the development of pharmacotherapy in both the therapeutic and the scientific realm.","","SiegfriedOthmer,Susan F.Othmer,David A.Kaiser","Introduction to Quantitative EEG and Neurofeedback,Introduction to Quantitative EEG and Neurofeedback","https://doi.org/10.1016/B978-012243790-8/50012-2","https://www.sciencedirect.com/science/article/pii/B9780122437908500122"
"A678","Contributions from particle physics engineering developments","The origin of this contribution was an attempt to find a rational basis for linking particle physics understanding, especially engineering, to interstellar mission policy. The central theme is historical. Analysing these past attempts to kick-start space industry with particle physics (i.e. L 5 location of a superconducting supercollider) it is argued that such large scale activity rests with commercial access to space. There are, however, many concepts that should be included in future thinking and a first selection is presented.","","A.Hansson(Dr.)1","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00050-8","https://www.sciencedirect.com/science/article/pii/S0094576599000508"
"A679","The parachute sail with hydrostatic beam: A new concept for solar sailing","Solar sail spacecrafts are very large, lightly loaded structures which must be deployed in space. The limiting structural factor is usually the elastic stability of a number of elements subject to compressive loads. An alternative structural layout is here suggested: an inflatable beam, which is kept pressurized also after deployment, relieves all compressive stresses, allowing a very simple configuration and a straightforward deployment procedure. The layout here proposed can be used for many types of sail, from tiny demonstration vehicles to large planetary sailers, provided that their trajectory does not get too close to the Sun, and for other large space structures. Its simplicity and low cost could allow to experiment with this type of spacecraft in a near future.","","GiancarloGenta(Professor)1,EugenioBrusa(Researcher)2","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00039-9","https://www.sciencedirect.com/science/article/pii/S0094576599000399"
"A680","AIMStar: Antimatter initiated microfusion for pre-cursor interstellar missions","We address the challenge of delivering a scientific payload to 10,000 A.U. in 50 years. This mission may be viewed as a pre-cursor to later missions to Alpha Centauri and beyond. We consider a small, aneutronic nuclear fusion engine sparked by clouds of antiprotons, and describe the principle and operation of the engine and mission parameters.","","G.Gaidos(Student),R.A.Lewis(Senior Scientist),K.Meyer(Student),T.Schmidt(Student),G.A.Smith(Prof.)56","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00046-6","https://www.sciencedirect.com/science/article/pii/S0094576599000466"
"A681","Hyper-interspersed nano/MEMS-architecture design for new concepts in miniature robotics for space exploration","Launch weight and volume requirements are substantially decreased by reduction of probe size in exploration mission systems, as mass and volume both scale as the third power of system size. Accordingly, the already quite developed MEMS (Micro Electro Mechanical System) technology, that offers low cost, small, light weight, and increasingly reliable devices through durability and redundancy, is strongly attractive as a near-term technology for significantly reducing the cost to launch and operate space systems. It is shown that the final goal of MEMS technology, i.e. the merging through solid state microdcvices of the functions of sensing, computation, communication and actuation, can lead to a new, biomimetic kind of miniature robotics, particularly suitable for planetary exploration, through molecular mono- electronics/MEMS integration jointly with a hyper-interspersed architecture made up of autonomous units embodying sensors, information processors and actuators. The problem tackled here concerns the basic design of such miniature robots, from some µm to insect size, featuring finely structured intelligent autonomous parts as smart skins, sensory and manipulating members working on the analogue external reality and communicating with their inner molecular level nondiscrete pseudo-analogue information processing networks. The (mesoscopic network)/MEMS units are shown to embody a quantum mechanical/macroscopic world connection, in which the nondiscrete molecular devices allow the automaton parts to perform very complex, fast information processing operations as metaphores of bionic functions like learning, attention, and decision making under uncertain conditions, this last due to the stochasticity inherent in the quantum network. Flexible architectures instead of von Neumann type rigid architectures in addition to hyper-interspersion of autonomous units can be realized through such nano/MEMS devices, and the µm — cm size of the whole robots and their organs allow dynamic biochemical, possibly reaction - diffusion, spatially separated highly nonlinear systems to be exploited as additional primitive computing devices (e.g. chemical oscillators, dissipative biomolecular distributed systems, planar photoactivated enzyme biosensors). Each interspersed unit can be designed as a multilevel nondiscrete system according to the information processing “rank” to be obtained in simulating the biological nervous system activity.","","SalvatoreSantoli(Director)*","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00037-5","https://www.sciencedirect.com/science/article/pii/S0094576599000375"
"A682","Space missions for SETI","Radio Telescopes for SETI searches are less demanding than general purpose astronomical radio telescopes. This provides an opportunity to exploit economical approaches in designing SETI systems. Radio Telescopes in low Earth orbit offer no discernible advantages to SETI; indeed, they probably would perform more poorly than a telescope in any other location. Telescopes in geosynchronous orbits would be sufficiently far from Earth to mitigate greatly the deleterious effect of human radio transmissions. Telescopes on the far side of the moon would be superb both from a radio interference standpoint, and from a civil engineering standpoint. Single-reflector telescopes as large as 50 kilometers in diameter could be constructed with conventional materials. However, their costs appear prohibitive. The asteroid belt and the outer solar system are unpromising places to place a large radio telescope. Perhaps the ultimate radio telescope would utilize the sun as a gravitational lens, focusing radiation on free-flying 10-meter class or possibly larger radio telescopes located at distances of the order of 1000 A.U. from the sun. Such a combination has an energy collecting area at 10 centimeters wavelength equivalent to that of a radio telescope about 11 kilometers in diameter, or of the order of 3000 Arecibo radio telescopes. Such a system could detect transmitters with EIRP of the order of a gigawatt at a distance of the order of the distance to the galactic center.","","FrankDrake","Acta Astronautica","https://doi.org/10.1016/S0094-5765(99)00036-3","https://www.sciencedirect.com/science/article/pii/S0094576599000363"
"A683","Database tomography for technical intelligence: A roadmap of the near-earth space science and technology literature","Database Tomography (DT) is a system which includes algorithms for extracting multi-word phrase frequencies and performing phrase proximity analyses (relating physical closeness of the multi-word technical phrases to thematic relationships) on any type of large textual database. As an illustration of the DT process applied to the published literature, DT was used to derive technical intelligence from a near-earth space (NES) database derived from the Science Citation Index and the Engineering Compendex. Phrase frequency analysis (the occurrence frequency of multi-word technical phrases) provided the pervasive technical themes of the space database, and the phrase proximity analysis provided the relationships among the pervasive technical themes. Bibliometric analysis of the NES literature supplemented the DT results by identifying: the recent most prolific NES authors; the journals which contain numerous NES papers; the institutions which produce numerous NES papers; the keywords most frequently specified by the NES authors; the authors whose works are cited most frequently in the NES papers; and the particular papers and journals cited most frequently in the NES papers.","","Ronald N.Kostoff1,Henry J.Eberhart2,Darrell RayToothman3","Information Processing & Management","https://doi.org/10.1016/S0306-4573(97)00066-6","https://www.sciencedirect.com/science/article/pii/S0306457397000666"
"A684","Special issue: Reverse engineering of geometric models","","","TamásVárudy,Ralph RMartin,JordanCox","Computer-Aided Design","https://doi.org/10.1016/S0010-4485(96)00053-X","https://www.sciencedirect.com/science/article/pii/S001044859600053X"
"A685","Segmentation of a wrap-around model using an active contour","Segmentation in the past has been applied to single range maps, which are capable of modelling only the part of an object that is visible from the camera viewpoint. In the field of reverse engineering, there is a great need for the segmentation of complete wrap-around object models. In this paper, a new method is presented for segmenting a wrap-around wireframe model, which is created by interpolating and merging multiple range maps. A semi-automatic edge-based approach is used for the segmentation. Surface differential properties are estimated at each point in the model, and curvature extrema are identified as possible edge points. An energy-minimizing active contour is used interactively to link the edge points. The designer defines small closed contours within the regions to be segmented, and the contour is ‘inflated’ until it is trapped by the potentials at the edge points.","segmentation,active contour,snake,Darbonx frame,edge detection","MJMilroy,CBradley,GWVickers","Computer-Aided Design","https://doi.org/10.1016/S0010-4485(96)00058-9","https://www.sciencedirect.com/science/article/pii/S0010448596000589"
"A686","Static polyhedron simplification using error measurements","Polyhedral models of objects represent an efficient issue for reverse engineering applications and visualization purposes. Because digitizing devices can produce large amounts of points, the polyhedral representation of objects may require a treatment of simplification to preserve the efficiency of subsequent processes for machining or visualization. Here, a new approach is introduced to reduce the number of nodes of a polyhedral model in accordance to an error criterion which can be easily understood by the user. This criterion uses error zones assigned to each node of the initial polyhedron and guarantees that the simplified polyhedron intersects each of the error zones. This behaviour is equivalent to constraining the simplified polyhedron to be included into the geometric envelope defined by all the error zones attached to the initial polyhedron. The iterative treatments involved in the simplification process incorporate an inheritance mechanism to transfer the error zones from one iteration to the next one. Thus, an intuitive manner to monitor the simplification process is set up. A node selection criterion based on curvature approximation has been included to sort the nodes according to their probability of removal. A specific remeshing scheme has also been included to increase the robustness of the treatment when face arrangements around a node generate distorted polygon shapes. Examples highlight the predictable behaviour of the algorithm.","polyhedron simplification,conformity,node removal,error inheritance,Gaussian curvature approximation,meshing","PVéron,JCLéon","Computer-Aided Design","https://doi.org/10.1016/S0010-4485(96)00057-7","https://www.sciencedirect.com/science/article/pii/S0010448596000577"
"A687","High-level cad model acquisition from range images","Automatic extraction of caddescriptions which are ultimately intended for human manipulation requires the accurate inference of geometric and topological information. We present a system which applies segmentation techniques from computer vision to automatically extract cad models from range images of parts with curved surfaces.The segmentation process is an improvement upon Besl and Jain's variable-order surface fitting (IEEE PAMI, 1988, 10(2), 167–192), extracting general quadric surfaces and planes from the data, with a postprocessing stage to identify surface intersections and to extract a B-rep from the segmented image.We present results on a variety of machined objects, which illustrate the high-level nature of the acquired models, and discuss the numerical accuracy (feature sizes and separations) and the correctness of structural inferences of the system.","feature-based reverse engineering,range image segmentation,automatic model acquisition","Andrew WFitzgibbon,David WEggert,Robert BFisher","Computer-Aided Design","https://doi.org/10.1016/S0010-4485(96)00059-0","https://www.sciencedirect.com/science/article/pii/S0010448596000590"
"A688","Three-dimensional object reconstruction from two-dimensional images","In order to construct a 3D model from a collection of 2D images of an object, an energy function is defined between the object's images and corresponding images of an articulated mesh in three dimensions. Repeated adjustment of the mesh to minimize the energy function results in a mesh that produces images which closely approximate the input images, that is to say that under the appropriate conditions it realizes a preconceived object. It has implications for model building, reverse engineering and computer vision. Minimization of the energy function is a multivariate problem of large scale with many local minima. We give an approach for solving this problem. For certain restricted, but useful applications, intuitive solutions to the minimization are consistently obtained.","reverse engineering,simulated annealing,object reconstruction","Alyn PRockwoodb,JimWingetb*","Computer-Aided Design","https://doi.org/10.1016/S0010-4485(96)00056-5","https://www.sciencedirect.com/science/article/pii/S0010448596000565"
"A689","Calendar","","","","Computer-Aided Design","https://doi.org/10.1016/S0010-4485(97)90019-1","https://www.sciencedirect.com/science/article/pii/S0010448597900191"
"A690","Surface reconstruction: from points to splines","We describe a method for reconstructing an unknown surface X of arbitrary topology, possibly with boundaries, from a set of scattered points. Our method generates a parametric surface in two steps: first we use 3D a-shapes to construct a simplified surface M^ that captures the topological structure of X, and then we build a curvature-continuous surface M~ based on this structure. Starting from data points scanned on existing physical objects, the method can produce rather compact, accurate geometric models suitable for engineering design and analysis.","geometric modelling,parametric surface fitting,least squares minimization","BainingGuo","Computer-Aided Design","https://doi.org/10.1016/S0010-4485(96)00055-3","https://www.sciencedirect.com/science/article/pii/S0010448596000553"
"A691","Reverse engineering of geometric models—an introduction","In many areas of industry, it is desirable to create geometric models of existing objects for which no such model is available. This paper reviews the process of reverse engineering of shapes. After identifying the purpose of reverse engineering and the main application areas, the most important algorithmic steps are outlined and various reconstruction strategies are presented. Pros and cons of various data acquisition techniques are described with related problems of boundary representation model construction. Specific issues addressed include characterization of geometric models and related surface representations, segmentation and surface fitting for simple and free-form shapes, multiple view combination and creating consistent and accurate B-rep models. The limitations of currently known solutions are also described, and we point out areas in which further work is required before reverse engineering of shape becomes a practical, widely-available engineering tool.","cad,geometric modelling,reverse engineering,scanning,segmentation,surface fitting,boundary models","TamásVáradya,Ralph RMartin*,JordanCox†","Computer-Aided Design","https://doi.org/10.1016/S0010-4485(96)00054-1","https://www.sciencedirect.com/science/article/pii/S0010448596000541"
"A692","Induction of transplant tolerance by intrathymic inoculation of synthetic MHC class I allopeptides","","","N.C.Chowdhury,B.Murphy,M.H.Sayegh,M.A.Hardy,S.F.Oluwole","Transplantation Proceedings","https://doi.org/10.1016/S0041-1345(96)00469-1","https://www.sciencedirect.com/science/article/pii/S0041134596004691"
"A693","Syngeneic bone marrow cells expressing a single donor class I MHC molecule are more effective at inducing tolerance than donor bone marrow cells","","","W.Wong,P.J.Morris,K.J.Wood","Transplantation Proceedings","https://doi.org/10.1016/S0041-1345(96)00465-4","https://www.sciencedirect.com/science/article/pii/S0041134596004654"
"A694","Role of the thymus in donor specific hyporesponsiveness induced by retroviral transduction of bone marrow using an MHC class I gene","","","H.Hayashi,R.S.Mayfield,T.Sawada,S.Germana,M.Sykes,J.Iacomini,D.H.Sachs,C.LeGuern","Transplantation Proceedings","https://doi.org/10.1016/S0041-1345(96)00467-8","https://www.sciencedirect.com/science/article/pii/S0041134596004678"
"A695","The role of donor class I major histocompatibility complex peptides in the induction of allograft tolerance","","","H.Shirwan,A.Mhoyan,M.Learner,C.Wang,D.V.Cramer","Transplantation Proceedings","https://doi.org/10.1016/S0041-1345(96)00468-X","https://www.sciencedirect.com/science/article/pii/S004113459600468X"
"A696","Mechanism of tolerance following class II gene transduction of autologous swine bone marrow","","","A.Yasumoto,K.Yamada,T.Sablinski,C.LeGuern,M.Sykes,D.H.Sachs","Transplantation Proceedings","https://doi.org/10.1016/S0041-1345(96)00466-6","https://www.sciencedirect.com/science/article/pii/S0041134596004666"
"A697","Chapter 38: Hypertext and its Implications for the Internet","Hypertext is intended to overcome the artificiality of index-based systems of storage and retrieval by providing computer-supported links among related pieces of information. In hypertext, the information is divided over several pieces of text and the related pieces are connected by links. By doing so, hypertext permits non-sequential (or non-linear) associative mode of information access and provides a method of accessing information that is more direct and more immediate than possible in a conventional paper-based system of information storage. Hypermedia is essentially multimedia hypertext. That is, the nodes are not limited to textual information but can have graphics, sound, animation, and video. Hypertext and hypermedia are often distinguished, with hypertext referring to text-only systems and hypermedia referring to systems that support multiple media.","","Pawan R.Vora,Martin G.Helander","Handbook of Human-Computer Interaction,Handbook of Human-Computer Interaction (Second Edition)","https://doi.org/10.1016/B978-044481862-1.50104-7","https://www.sciencedirect.com/science/article/pii/B9780444818621501047"
"A698","A study of search intermediary working notes: Implications for IR system design","This paper reports findings from an exploratory study investigating working notes created during encoding and external storage (EES) processes, by human search intermediates using a Boolean information retrieval (IR) system. EES processes have been an important area of research in educational contexts where students create and use notes to facilitate learning. In the context of interactive IR, encoding can be conceptualized as the process of creating working notes to help in the understanding and translating a user's information problem into a search strategy suitable for use with an IR system. External storage is the process of using working notes to facilitate interaction with IR systems. Analysis of 221 sets of working notes created by human search intermediaries revealed extensive use of EES processes and the creation of working notes of textual, numerical and graphical entities. Nearly 70% of recorded working notes were textual/numerical entities, nearly 30% were graphical entities and 0.73% were indiscernible. Segmentation devices were also used in 48% of the working notes. The creation of working notes during EES processes was a fundamental element within the mediated, interactive IR process. Implications for the design of IR interfaces to support users' EES processes and further research is discussed.","","AmandaSpink,AbbyGoodrum","Information Processing & Management","https://doi.org/10.1016/S0306-4573(96)00031-3","https://www.sciencedirect.com/science/article/pii/S0306457396000313"
"A699","Database links are a foundation for interoperability","","","Peter D.Karp","Trends in Biotechnology","https://doi.org/10.1016/0167-7799(96)10044-5","https://www.sciencedirect.com/science/article/pii/0167779996100445"
"A700","Design and implementation of a tool for the automatic construction of hypertexts for information retrieval","The paper describes the design and implementation of TACHIR, a tool for the automatic construction of hypertexts for Information Retrieval. Through the use of an authoring methodology employing a set of well known Information Retrieval techniques, TACHIR automatically builds up a hypertext from a document collection. The structure of the hypertext reflects a three level conceptual model that has proved to be quite effective for Information Retrieval. Using this model it is possible to navigate among documents, index terms, and concepts using automatically determined links. The hypertext is implemented using the HTML hypertext mark up language, the mark up language of the World Wide Web project. It can be distributed on different sites and different machines over the Internet, and it can be navigated using any of the interfaces developed in the framework World Wide Web project, for example NetScape.","","MaristellaAgosti,FabioCrestani,MassimoMelucci","Information Processing & Management","https://doi.org/10.1016/0306-4573(95)00075-5","https://www.sciencedirect.com/science/article/pii/0306457395000755"
"A701","Entry 02: Introduction & layout of entries","","","Edward C.Conley","Ion Channel Factsbook,Ion Channel Factsbook","https://doi.org/10.1016/B978-012184450-9/50002-8","https://www.sciencedirect.com/science/article/pii/B9780121844509500028"
"A702","Surge-tectonic evolution of southeastern Asia: a geohydrodynamics approach","The repeated need for ad hoc modifications in plate-tectonic models to explain the evolution of southeastern Asia reveals their inability to fully explain the complex features and dynamics of this region. As one example, the hypothesis does not provide a mechanism to explain the 180° turns and twists along the strike of several foldbelts and island arcs in the region (e.g. Banda arc). Convection-cell configuration renders such 180° contortions and Rayleigh-Bénard-type convection impossible. However, during the last 10 years, new data bearing on the convection-cell problem have become available in the form of seismotomographic images of the earth's interior. These images show that (i) mantle diapirs as proposed by traditional plate-tectonic models do not exist; (ii) there is no discernible pattern of upper or lower mantle convection, and thus no longer an adequate mechanism to move plates; and (iii) the lithosphere above a depth of about 80 km is permeated by an interconnected network of low-velocity channels.Seismic-reflection studies of the low-velocity channels discovered on the seismotomographic images reveal that these channels have walls with a 7.1–7.8 km s-1 P-wave velocity. Commonly, the interiors of the channels are acoustically transparent, with much slower P-wave velocities, in places as low as 5.4 km s-1. The author and co-workers have interpreted the low velocities as evidence for the presence of partial melt in the channels, and they postulated that this melt moves preferentially eastward as a result of the earth's rotation. They named these channels “surge channels” and their new hypothesis for earth dynamics “surge tectonics”.Surge channels underlie every type of tectonic belt, which includes mid-ocean ridges, aseismic ridges, continental rifts, strike-slip fracture zones, and foldbelts. In southeastern Asia, surge channels—mainly foldbelts—lie between all platform and cratonic massifs. These massifs, platforms, and tectonics belts—the surge channels—form an anastomosing E-W pattern southern Asiatic Russia, Mongolia, western China, the Qinghai-Tibetan region, and northern India and Pakistan. Such an anastomosing pattern indicates that flow is an active process in the surge channels.Surface studies of phenomena that might be associated with the surge channels soon revealed that all active channels are characterized by higher-than-normal heat flow (> 55 mW m-2, thermal springs and elevated ground-water temperatures, volvanic phenomena, bands of microearthquakes, and linear belts of faults, fractures, and fissures. The latter are especially visible on satellite images. The bands of high heat flow, thermal springs, microearthquakes, and faults-fractures-fissures almost exactly coincide. The fault-fracture-fissure systems are interpreted to be streamlines caused by flow in the surge channels—a consequence of Stokes's Law (an expression of Newton's Second Law of Motion)-and show that Poiseuille flow must dominate in the channels. Hence, the mechanism producing the belts of linear faults-fractures-fissures is viscous drag, produced by fluid motions.The eastward flow of the magma in the channels is demonstrated clearly in the tectonic patterns of southeastern Asia. In the northern part of the region studied, the E-W striking anastomosing surge channels (tectonic belts) splay northeastward into the coastal regions of Russia. In the south, they splay southward and southeastward through the Malay Peninsula and Indonesia. The open horsetail structures thus created prove that flow is W-E. The presence of the two splay directions, NE and S-SE, indicates in addition that a barrier to eastward flow must lie directly east of Asia. In this author's opinion, this barrier is the existing Benioff zone, because the same NE and S-SE splay patterns are present on each of the paleotectonic maps that have been prepared for nine time intervals from the beginning of Sinian (latest Proterozoic) time to the present.The presence of the W-E flow patterns through 850 Ma of geological time, patterns that remain essentially unchanged, means simply that tectonic explanations of Asian geology need revision. The patterns that have been mapped indicate that W-E flow across Asia has persisted essentially unchanged for 850 Ma. Surge tectonics is the only hypothesis yet proposed that explains these patterns and their persistence.","","Arthur A.Meyerhoff","Journal of Southeast Asian Earth Sciences","https://doi.org/10.1016/0743-9547(95)00028-3","https://www.sciencedirect.com/science/article/pii/0743954795000283"
"A703","Chapter 9: Computational Techniques in Macromolecular Structural Analysis","This chapter discusses the data collected by the techniques used to determine the structure and properties of proteins and nucleic acids in conjunction with computational and visualization tools to create a graphical representation of the experimental structures, to generate hypothetical model structures based on sequence homology methods, and to predict new physical properties. The chapter focuses on practical aspects needed to use existing computational tools for determination of sequence homology, secondary structure predictions, hydropathy analysis, three-dimensional computer modeling, macromolecular docking, and calculation of binding free energy and catalytic properties. It compares the theoretical basis of selected tools and computational methods in terms of ease of use, computer resources required, and validity of resultant structures and properties. Basic understanding of function and homology can be determined from an analysis of primary structure, and such an analysis is an essential prerequisite to the procedures of secondary and tertiary structure analysis.","","MichaelB. Bolger","Introduction to Biophysical Methods for Protein and Nucleic Acid Research,Introduction to Biophysical Methods for Protein and Nucleic Acid Research","https://doi.org/10.1016/B978-012286230-4/50010-9","https://www.sciencedirect.com/science/article/pii/B9780122862304500109"
"A704","Chapter 5: A strategic perspective on managing change","","","ColinEgan","Creating Organizational Advantage,Creating Organizational Advantage","https://doi.org/10.1016/B978-0-7506-1937-0.50009-7","https://www.sciencedirect.com/science/article/pii/B9780750619370500097"
"A705","Organic catalysis over zeolites: A perspective on reaction paths within micropores","Since the early 1960s, the field of organic catalysis over zeolites and related microporous materials has shown enormous international expansion. Not only has a multiplicity of new reactions been explored over a continually increasing assemblage of zeolite structures, but also the depth of understanding of the catalytic chemistry and structure—reactivity relationships has shown dramatic growth. Further, the utilization of ZSM-5 and related medium-pore zeolites has truly enabled a revolution in shape-selective control of reaction selectivity. In the present review, we first conduct a broad classification and survey of organic chemistry over zeolites. This reflects, for the most part, a mechanistic rather than a process or applications frame of reference. We then examine selected examples of underlying physicochemical phenomena and structure—reactivity patterns that are peculiar to heterogeneous catalytic reactions within zeolite micropores. These include diffusion/adsorption effects, shape-selective principles, mechanistic disguises, catalyst deactivation pathways and related considerations.","Organic catalysis,Zeolite chemistry,Reaction mechanisms","Paul B.Venuto1","Microporous Materials","https://doi.org/10.1016/0927-6513(94)00002-6","https://www.sciencedirect.com/science/article/pii/0927651394000026"
"A706","Active Databases: Concepts and Design Support","This chapter describes the motivation of research in active databases, introducing several key concepts related to active databases and focusing on the problem of methodological support for this kind of database management system (DBMS) functionality. It gives an outline of active database concepts compared to traditional DBMS architectures and presents a discussion of technical questions, such as event definition languages and trigger execution models. A rationale for all the subsequent methodological considerations is given. The chapter discusses several design sub-phases in the context of information system development projects and aims at giving a justification of a specialized design formalism for the construction of active databases. It provides some background with respect to Statecharts and extended event-reaction (ER) diagrams, and introduces a new formalism—namely, entity-relationship Statechart (ERSC) monitors. An ERSC monitor resembles an event-driven device which is constructed following a predefined template, that is, an ERSC monitor type.","","Thomas A.Mueck","Advances in Computers","https://doi.org/10.1016/S0065-2458(08)60379-4","https://www.sciencedirect.com/science/article/pii/S0065245808603794"
"A707","A patent-based cartography of technology","We use bibliometric (in particular patent-based) methods and techniques to develop a cartography of technology. Two types of maps are presented: co-word maps and co-classification maps. Both types of maps have been constructed for the entire domain of technology (the macro-level), i.e. the ensemble of all fields of technology in their mutual relations. Time series clearly illustrates the changing relations between the major clusters of technology, and in particular the changing role of fields which act as a “bridge” between clusters, or as a (declining or emerging) centre of technological activities within a specific cluster. Maps visualize relations between fields of technology. In order to have measures of the relative strength of these relations, we develop the concept of affinity between fields. A special feature of our macro-maps concerns the role of Japan in technology.A second hierarchical level is the combination of several fields of technology (meso-level). As an example we constructed a co-word map for the emerging “crossroad” technology optomechatronics based on patents as well as on scientific publications. In this way, optomechatronics is mapped from a technological point of view, and from a research point of view.The third hierarchical level concerns one specific field of technology (micro-level). Co-word maps have been constructed for the technology fields coating and crystal growing, optical equipment, and building materials.An important aspect of the map is the possibility to identify centers of activity within a specifically defined field of technology. These centers of activity may indicate important innovative developments, or they may reflect important markets. Furthermore, we introduce the concept of “technological peripheries”: for a specific technology field one may identify the direct “surroundings”; i.e. the most strongly linked fields.Also, first attempts are made to map the “science and technology interface” by a specific combination of publication and patent data.Our general conclusion is that the mapping methods and techniques presented in this publication already offer a unique way to visualize developments in fields of technology, and within technology as a whole. We emphasize that our technology maps are intended as a support tool, and never as a replacement of experts.","","E.C.Engelsman,A.F.J.van Raan","Research Policy","https://doi.org/10.1016/0048-7333(94)90024-8","https://www.sciencedirect.com/science/article/pii/0048733394900248"
"A708","The toad, ugly and venomous, wears yet a precious jewel in his skin","","","Lawrence H.Lazarus,MarttiAttila†","Progress in Neurobiology","https://doi.org/10.1016/0301-0082(93)90027-P","https://www.sciencedirect.com/science/article/pii/030100829390027P"
"A709","Co-word-based science maps of chemical engineering. Part I: Representations by direct multidimensional scaling","In this paper we present the results of the first part of our study on science mapping. We discuss a new approach to co-word analysis in order to solve or to circumvent some of the problems mentioned in the earlier literature. The mapping technique is based on a “direct” application to the word co-occurrence data matrix of multidimensional scaling. The subject area of our co-word mapping approach is chemical engineering. We have chosen this field of scientific research because we found it tempting to bibliometrically map such a large, rather multidisciplinary and economically important field. Furthermore, it is important to assess bibliometric methods and techniques not only for basic research fields, but also for the more applied and engineering fields.We discuss maps based on three different datasets (top-journals, top-scientists, and a conference). Furthermore, we discuss the differences between maps based on title- and on abstract-words. Moreover, we experiment with different relational indices to obtain optimal contrasts between interesting and not-interesting features. We explore the possibilities to visualize changes over time in one display. An important part of the work is the evaluation of the maps by an extensive expert judgement.","","H.P.F.Peters,A.F.J.van Raan","Research Policy","https://doi.org/10.1016/0048-7333(93)90031-C","https://www.sciencedirect.com/science/article/pii/004873339390031C"
"A710","Giftedness and school: New issues and challenges","","","Arthur J.Cropley(Guest Editor)","International Journal of Educational Research","https://doi.org/10.1016/0883-0355(93)90018-F","https://www.sciencedirect.com/science/article/pii/088303559390018F"
"A711","Visualization of a document collection: The vibe system","The idea of using visualization for document retrieval is introduced through a new paradigm for query response handling. The paradigm is based on parallel queries or points of interest. Each point of interest is defined by a number of key terms and a display position. Documents, represented by icons, are positioned in the display based on the frequency count of word matches in the document to key terms in the points of interest. This visualization method has been implemented through a visualization system called VIBE.","","Kai A.Olsen1,Robert R.Korfhagea,Kenneth M.Sochatsa,Michael B.Springa,James G.Williamsa","Information Processing & Management","https://doi.org/10.1016/0306-4573(93)90024-8","https://www.sciencedirect.com/science/article/pii/0306457393900248"
"A712","Subject index","","","","Deep Sea Research Part B. Oceanographic Literature Review","https://doi.org/10.1016/S0198-0254(09)90023-1","https://www.sciencedirect.com/science/article/pii/S0198025409900231"
"A713","Stabilizing student knowledge in open structured CAI","This paper describes STAR, a system for stabilizing student knowledge in mixed initiative CAI application. The system characterizes knowledge as existing at three levels of stability: required, ambiguous or stable. The primary instructional objective of the system is to improve the stability level of student knowledge. The knowledge acquisition environment utilizes target domain knowledge and knowledge acquired from the student to generate a dynamic student model. The student model, in turn, guides the selection of appropriate instructional strategies. The operation of the system is demonstrated using an English vocabulary development activity.","","YoneoYano,AkihiroKashihara,WilliamMcMichael","International Journal of Man-Machine Studies","https://doi.org/10.1016/0020-7373(92)90025-G","https://www.sciencedirect.com/science/article/pii/002073739290025G"
"A714","Relations between sill intrusions and bedding-parallel extensional shear zones in the Mid-continent Rift System of the Lake Superior region","The Mid-continent Rift System is a continuous U-shaped feature extending from Kansas north through the Lake Superior region and then south through Michigan. The Logan Sills on the northwest side of the lake were intruded during the rifting stage (1109 Ma). Deformation features in the country rock adjacent to the Logan sills indicate two episodes of shear strain. The first consists of minor thrusts and mesoscopic shear bands, both suggesting top-to-the-south (southwest) movement parallel to the bedding. The second rotates the previously formed shear bands in the opposite sense, top-to-the-north (northeast) and is localized at the basal contact between the sills and the country rock. We attempt to explain the relations observed with a tectonic model in which sill intrusions take advantage of bedding-parallel shear zones that are the surface expression of a south-dipping detachment plane. The detachment plane steps up in the layered proterozoic sedimentary sequence and allows extension during rifting. In this scenario the first episode of shear strain might be related to bedding-parallel extension and the second to shear stress induced by the intrusion of magma along the detachment from the south. The polarity of both events is supported by small scale kinematic indicators such as veins, fiber growths and foliation.","","M.A.Antonellini,F.W.Cambray","Tectonophysics","https://doi.org/10.1016/0040-1951(92)90299-L","https://www.sciencedirect.com/science/article/pii/004019519290299L"
"A715","Seismicity of the Cameroon Volcanic Line, 1982–1990","This paper is dedicated to Soba Djallo, Director of IRGM, who died in 1991Results of seismic monitoring of the continental segment of the Cameroon Volcanic Line for the period 1982 to 1990 are reported. Mount Cameroon continues to be seismically the most active area with a well defined seismicity pattern characterized by single and swarm events with duration magnitudes between 2 and 3 occurring at depths down to 55 km. On average, the earthquakes here occur at the rate of about 2 events every 3 days. Further north, the seismicity is low except for isolated felt events located along the Foumban Shear Zone which probably controls the location of the earthquakes as well as the volcanic centres making up the volcanic line.During this eight-year period two fatal carbon dioxide gas emissions from crater lakes occurred in 1984 (L. Monoun) and 1986 (L. Nyos) causing 37 and 1700 deaths respectively. Seismic monitoring indicates that no seismic activity was associated with these lakes thus favouring an aseismic cause to the disasters.These gas emissions, the increased number of felt earthquakes and a recent natural explosion on Mount Cameroon suggest either a more active phase of the Cameroon Volcanic Line and/or a greater awareness by the local population of the phenomena associated with this volcanic province.","","C.TTaboda,J.DFairheada,G.WStuarta,BAtebab,NNtepeb","Tectonophysics","https://doi.org/10.1016/0040-1951(92)90297-J","https://www.sciencedirect.com/science/article/pii/004019519290297J"
"A716","A gravity model for the lithosphere in western Kenya and northeastern Tanzania","We present a new gravity model for the lithosphère beneath the Kenya Rift Valley, the Mozambique Belt, and the Tanzania Craton in western Kenya and northeastern Tanzania. The Kenya Rift lies within the eastern branch of the extensive Cenozoic East African Rift System and has developed almost entirely in the Pan-African Mozambique Belt about 50 to 150 km east of the exposed margin of the Archean Tanzania Craton. The gravity field over western Kenya and northeastern Tanzania is characterized by a long-wavelength Bouguer anomaly. We propose that this anomaly has two components: 1.(1) a “rift” signature, deriving from a shallow rift basin, a lower crustal intrusion and a low-density zone in the mantle lithosphere localized beneath the rift axis2.(2) a “suture” signature, arising from a crustal root along the boundary between the Mozambique Belt and Tanzania Craton and higher density crust in the mobile belt above part of the crustal root. Two lines of reasoning support our interpretation: 1.(1) Recent geological studies of the Mozambique Belt in Kenya and Tanzania suggest that it is a continent-continent collision zone, and continent-continent collision zones worldwide commonly exhibit a characteristic gravity anomaly.2.(2) The long-wavelength Bouguer anomaly has at least two minima, one over the craton-mobile belt boundary, and one or more over the rift valley. Corroborative evidence for our interpretation of the gravity field is provided by recent seismic investigations.","","Andrew A.Nyblade,Henry N.Pollack","Tectonophysics","https://doi.org/10.1016/0040-1951(92)90294-G","https://www.sciencedirect.com/science/article/pii/004019519290294G"
"A717","Seismic velocity structure of the crust beneath the Japan Islands","More than 13,000 arrival times of 562 local shallow earthquakes selected from the Japan University Network Earthquake Catalog are used to investigate the seismic velocity structure of the crust beneath the Japan Islands. We simultaneously determined the hypocenter parameters, P- and S-wave station corrections and depth distributions of the Conrad and Moho discontinuities beneath the whole of the Japan Islands by applying an inversion method. The P- and S-wave station corrections show similar distribution patterns. They are negative (relatively late arrivals of seismic waves) in Hokkaido and positive (relatively early arrivals of seismic waves) in western Japan. In eastern Honshu, they are positive along the coast of the Pacific Ocean and negative in the land area and along the coast of the Japan Sea. The Conrad discontinuity is located at a depth range from 12 to 22 km. In Hokkaido, the Conrad is shallow in the eastern pan and becomes deep toward the west. In NE Honshu the Conrad is deep beneath the land area, and becomes shallow toward the surrounding seas. In western Japan, the Conrad is shallow in the northern part and becomes deep toward the south. The Moho is located in a depth range from 25 to 40 km. In Hokkaido, the Moho has the shape of a circular cone with a maximum depth of 36 km. In most parts of the Japan Islands, the Moho is deep beneath the land area and becomes shallow toward the surrounding seas. The Moho is deepest, up to 40 km, beneath the central part of the Chubu District.","","DapengZhao,ShigekiHoriuchi,AkiraHasegawa","Tectonophysics","https://doi.org/10.1016/0040-1951(92)90296-I","https://www.sciencedirect.com/science/article/pii/004019519290296I"
"A718","The Ayia Varvara Formation of SW Cyprus: A product of complex collisional tectonics","The Ayia Varvara Formation is a wedge of amphibole schists and intercalated metasediments within the intensely deformed pre-upper Maastrichtian volcanosedimentary Mamonia Complex. All contacts are steep faults against Upper Triassic transitional to alkaline lavas with reefoidal limestones, subalkaline depleted Troodos-type lavas, and serpentinised harzburgite. Ophiolite-related metamorphics are believed to have been formed by dynamothermal processes, beneath young oceanic crust during emplacement.Characteristically, such rocks might be expected to show a decrease of metamorphic grade away from the contact. Mineral analyses from the Ayia Varvara metamorphics, however, show no systematic variations that would indicate a metamorphic gradient. Hornblende remains generally calcic and of tschermakitic hornblende composition with an almost complete substitution of Mg and Fe2+, suggesting disequilibrium. Plagioclase is essentially albitic and remains so for a distance of some 800 m from the harzburgite contact. Trace element analyses of the amphibolites and surrounding extrusives define four lava types. Types 1–3 are transitional to alkaline intraplate lavas believed to be remnants of intraoceanic islands and atolls. Type 4-lavas are extremely depleted in the HFS elements and are very similar to the Arakapas transform-fault lavas. The amphibolites have, in part, a trace-element geochemistry that is close to mid-ocean ridge basalts (MORB), a type that has not previously been recorded from Cyprus.The small area around Ayia Varvara records a long and complicated tectonic history that provides an insight into the evolution and emplacement of the Troodos ophiolite. The Mamonia Complex is interpreted as a passive margin sequence with intra-oceanic islands that was accreted onto a Late Cretaceous north-dipping subduction zone. Suprasubduction spreading produced the Troodos ophiolite and associated fracture zones. Spreading and subduction ceased in the late Maastrichtian when the newly-formed Troodos crust underwent a 90° anticlockwise rotation which juxtaposed Mamonia and Troodos (Arakapas) fracture zone rocks along arcuate, steep, strike-slip faults.At least some of the Ayia Varvara metamorphic rocks most likely represent Triassic oceanic crust and sediments metamorphosed during subduction by the overriding young Troodos crust.","","J.Malpasa,C.Xenophontosb,D.Williamsa","Tectonophysics","https://doi.org/10.1016/0040-1951(92)90291-D","https://www.sciencedirect.com/science/article/pii/004019519290291D"
"A719","Geology of the d'Entrecasteaux-New Hebrides arc collision zone: results from a deep submersible survey","During the SUBPSO1 cruise, seven submersible dives were conducted between water depths of 5350 and 900 m over the collision zone between the New Hebrides island arc and the d'Entrecasteaux Zone (DEZ). The DEZ, a topographic high on the Australian plate, encompasses the North d'Entrecasteaux Ridge (NDR) and the Bougainville guyot, both of which collide with the island-are slope. In this report we use diving observations and samples, as well as dredging results, to analyse the geology of the Bougainville guyot and the outer arc slope in the DEZ-arc collision zone, and to decipher the mechanisms of scamount subduction. These data indicate that the Bougainville guyot is a middle Eocene island arc volcano capped with reef limestones that appear to have been deposited during the Late Oligocene to Early Miocene and in Miocene-Pliocene times. This guyot possibly emerged during the Middle and Late Miocene, and started to sink in the New Hebrides trench after the Pliocene. The rocks of the New Hebrides arc slope, in the collision zone, consist primarily of Pliocene-Recent volcaniclastic rocks derived from the arc, and underlying fractured island-arc volcanic basement, possibly of Late Miocene age. However, highly sheared, Upper Oligocene to Lower Miocene nannofossil ooze and chalk are exposed at the toe of the arc slope against the northern flank of the NDR. Based on a comparison with cores collected at DSDP Site 286, the ooze and chalk can be interpreted as sediments accreted from the downgoing plate. East of the Bougainville guyot an antiform that developed in the arc slope as a consequence of the collision reveals a 500-m-thick wedge of strongly tectonized rocks, possibly accreted from the guyot or an already subducted seamount. The wedge that is overlain by less deformed volcaniclastic island-arc rocks and sediments includes imbricated layers of Late Oligocene to Early Miocene reef and micritic limestones. This wedge, which develops against the leading flank of the guyot, tends to smooth its high-drag shape. A comparison between the 500-m-thick wedge of limestones that outcrops southeast of the guyot and the absence of such a wedge over the flat top of the guyot, although the top is overthrust by island-arc rocks and sediments, can be interpreted to suggest that the wedge moves in the subduction zone with the guyot and facilitates its subduction by streamlining.","","J.-Y.Collota,S.Lallemandb,B.Pelletierc,J.-P.Bissenc,G.Glaçond,M.A.Fishere,H.G.Greenee,J.Boulinf,J.Danielc,M.Monzierc","Tectonophysics","https://doi.org/10.1016/0040-1951(92)90292-E","https://www.sciencedirect.com/science/article/pii/004019519290292E"
"A720","A gravity model of the crust beneath the Tertiary Piemonte basin (northwestern Italy)","A gravity model of a crustal section crossing the Tertiary Piemonte basin from north to south is presented. It was constructed by combining geological data and the results of the application of several geophysical methods, with particular reference to the seismic findings. A model is proposed for the morphology of the deep crust (crust/mantle transition) identified by the wide angle reflection seismic data from the European Geotraverse (EGT) project and its geological consequences are discussed. The existence of substantial displacements at the crust/mantle boundary is stressed. They do not appear to be directly related to superficial structures but underscore the wedging of the Ligurian mantle on the Insubrian crust.Compared with the observed Bouguer gravity field, gravity modelling of the section has supplied a calculated anomaly with a persistent short wavelength negative residual anomaly curve in the area of the Asti basin. It is suggested that this anomaly is due to a wedge of sedimentary rocks within the crust.The wedge consists of both Apennine and Padane units and is located along a major structural boundary where metamorphic crust and Tertiary sediments belonging to the Alpine domain overthrust Apennine and Padane units during the Tertiary","","M.Miletto,R.Polino","Tectonophysics","https://doi.org/10.1016/0040-1951(92)90293-F","https://www.sciencedirect.com/science/article/pii/004019519290293F"
"A721","Ice age as a trigger of active Quaternary volcanism and tectonism","The stress accumulation within the crust, caused by the surface mass redistribution associated with the glaciation-deglaciation cycle during the Quaternary, was numerically evaluated in order to examine the relationship between active Quaternary volcanism and tectonism in island-arc areas and ice age. The vertical gradient of horizontal stress difference in the lithosphere for a meltwater of 130 m in equivalent sea-level reaches a maximum value of 0.8 MPa/km, which is corresponding to the equivalent buoyancy of about 100 kg/m3 for magma-filled cracks, for an earth model with a lithospheric layer of 20–30 km thickness and with a viscosity greater than 1023 Pa s. The changes in stress difference during the stages of deglaciation of 10,000 years amount to 13 MPa for both the top and bottom of the thin lithosphere. Thus, the additional stress difference within the crust may be effective for island-arc areas with thin lithospheric thickness. We, therefore, speculate that the stress accumulation associated with ice age may be an important trigger and/or accelerator on the active Quaternary volcanism and tectonism for the areas along the circum-Pacific.","","MasaoNakada,HisayoshiYokose","Tectonophysics","https://doi.org/10.1016/0040-1951(92)90298-K","https://www.sciencedirect.com/science/article/pii/004019519290298K"
"A722","A crustal study off Lofoten, N. Norway, by use of 3-component Ocean Bottom Seismographs","Twenty-four 3-component Ocean Bottom Seismographs (Obs) were used in August 1988 in a combined seismic refraction and reflection study off Lofoten, N. Norway. The purpose of the experiment was to map the crustal structure from the continental shelf to the oceanic crust off Lofoten. The very high data quality is demonstrated by the strong P-wave and shear-wave reflections, as well as converted waves from the Moho observed on the continental shelf. These arrivals are observed continuously from near vertical to wide angle incidence. Very high seismic sea-floor velocities in this area (3.1 km/s to 5.1 km/s) indicates absence or very thin sequences of Mesozoic sediments. The 5.1 km/s refractor coincides with the base Cretaceous reflection interpreted from the multichannel reflection data. The crystalline continental crust is here divided in layers with velocities of 6.0 km/s, 6.4 km/s and 6.8 km/s, respectively. On the seaward side of the escarpment Tertiary sediments varying in thickness from 1.0–1.5 km are situated on top of a 1.5-2.0-km-thick layer of flood-basalt containing seaward-dipping reflectors. A layer with velocity of 6.7 km/s is observed above the lower crust, which in this area is found to have a velocity as high as 7.3 km/s. These high velocities indicate that the crust in this area is of oceanic origin or, alternatively, the high-velocity layer in the lower crust might represent a magmatic body underplating highly thinned and intruded continental crust. Seven obss were deployed in the area that was covered by landward-flowing basalt deposited during the early Eocene breakup between Norway and Greenland. The survey was partly performed to investigate whether this method can be used to map structures below the basalt, which is impenetrable with conventional seismic reflection techniques. The obs data contain considerable information about structures below the flood-basalt; pre-opening sediments up to 4.0 km thick are indicated below the 1.0–2.5-km-thick landward-flowing basalt. The velocities of the crystalline portion of the crust are found to be similar to those observed under the continental shelf (6.0–6.8 km/s), which implies that the crust east of the escarpment is of continental origin. The crystalline crust is strongly thinned in this area, showing a minimum thickness of about 6 km. The depth to the Moho increases from about 15 km in the western part of the area to about 26 km on the continental shelf. The success of the obs survey indicates that such measurements can become an important tool in investigations on passive volcanic margins, and, potentially, in other areas where highly reflective surfaces make the reflection technique inefficient.","","RMjeldea,M.ASellevolla,HShimamurab,TIwasakib,TKanazawac","Tectonophysics","https://doi.org/10.1016/0040-1951(92)90295-H","https://www.sciencedirect.com/science/article/pii/004019519290295H"
"A723","A quantitative assessment of interdisciplinary structures in science and technology: Co-classification analysis of energy research","The wide diversity in subject matter and volume of research publications of large multidisciplinary areas often presents an insurmountable barrier in obtaining a comprehensive overview of its internal (“intellectual”) structure. In this article it is shown that a systematic, quantitative examination of the contents of an area's research publications offers an empirical solution for this problem. This “co-classification analysis” is based on the network of interdisciplinary links between research fields contributing to such an area, as manifest in the co-occurrence of different subject-classification headings assigned to research publications. The analysis yields quantitative measures of: (1) the level of interdisciplinarity in contributing research fields; (2) the strength of interdisciplinary relations between these fields, as well as (3) graphical representations (“maps”) of the interdisciplinary structure in single fields, as well as the area as a whole.Capabilities and limitations of this methodology, as an aid in research policy studies, are discussed by way of a Dutch science-policy-driven application to the area of energy research. Results are presented concerning the worldwide interdisciplinary structure of energy research, and the structure in Dutch publications on research sources of renewable energy. Findings of a subsequent validation study amongst Dutch scientists, R&D managers, and S&T policy makers support our assertion that the method is useful for certain analytical and descriptive purposes, but also point out limits in its range of application.","","Robert J.W.Tijssen","Research Policy","https://doi.org/10.1016/0048-7333(92)90025-Y","https://www.sciencedirect.com/science/article/pii/004873339290025Y"
"A724","2: Aging and Human Performance","","","D.R.DAVIES,A.TAYLOR,L.DORN","State and Trait,State and Trait","https://doi.org/10.1016/B978-0-12-650353-1.50008-3","https://www.sciencedirect.com/science/article/pii/B9780126503531500083"
"A725","Expert critics: operationalizing the judgement/decisionmaking literature as a theory of “bugs” and repair strategies","Humans are well-known for being adept at using their intuition and expertise in many situations. However, in some settings even human experts are susceptible to errors in judgement, and a failure to recognize the limits of knowledge. This happens often especially in semi-structured situtations, where multi-disciplinary expertise is required, or when uncertainty is a factor. At these times our natural ability to recognize and correct errors fails us, since we have faith in our reasoning. One way to deal with such problems is to have a computerized “critic” to assist in the process. This article introduces the concept of automated critics that collaborate with human experts to help improve their problem solving performance. A critic is a narrowly focused program that uses a knowledge base to help it recognize (1) what types of human error have occurred, and (2) what kinds of criticism strategies could help the user prevent or eliminate those errors. In discussing the “errors” half of this knowledge base, there is a difference between the expert's knowledge and his or her judgement. The focus in this article is more on judgement than on knowledge but both are addressed.To build automated critics it is important to understand the use and behavior of human critics. For this reason critic theory, principles and rules for design are described in this article. These are presented by showing various types of criticism encountered across a variety of generic tasks, such as medical diagnosis, coaching forecasting and authoring among many others. Thus a model of expert cognition and rules for identifying cognitive biases are presented. This rule base exploits four decades of literature on the psychology of judgement and decisionmaking as a generative theory of “bugs” in expert intuition and as a deep knowledge from which rules about buggy behavior are drawn. For the commonly recurring expert errors, specific preventive and corrective strategies are also reviewed and considerations for criticism presentation and deployment are explained. Particular attention is given to rules about when and how criticism should be offered. By consulting and attempting to operationalize the judgement and decisionmaking literature within the critiquing approach, this establishes criticism-based problem solving as a novel way to bridge the gap between the traditional domain knowledge-rich approaches of AI and the domain-independent, theory-rich approaches of decision analysis. Attention is also devoted to the obstacles to, and opportunities for, further bridging this gap.","","Barry G.Silverman","Knowledge Acquisition","https://doi.org/10.1016/1042-8143(91)90004-7","https://www.sciencedirect.com/science/article/pii/1042814391900047"
"A726","Hypermedia—introduction and survey","Our paper begins with an introduction to hypermedia presented with the example of a hypothetical hypermedia system. This is followed by an overview of the main hypermedia components visible to the user—data structures, authoring tools, navigation tools, and user interface. In the next section, we present a brief history of hypermedia, list applications in which hypermedia systems have been used, and describe several important commercial products and research projects. The last two sections introduce the major issues facing hypermedia technology and attempt to predict what direction it might take in the near future.","","IvanTomek,SaleemKhan,TomaszMüldner,MostafaNassar,GeorgeNovak,PiotrProszynski","Journal of Microcomputer Applications","https://doi.org/10.1016/0745-7138(91)90002-9","https://www.sciencedirect.com/science/article/pii/0745713891900029"
"A727","Hypermedia bibliography","","","","Journal of Microcomputer Applications","https://doi.org/10.1016/0745-7138(91)90006-D","https://www.sciencedirect.com/science/article/pii/074571389190006D"
"A728","Carbon Dioxide and Global Change: Earth in Transition: Sherwood, B. Idso. IBR Press, 631 E. Laguna Dr. Tempe, AZ 85282, U.S.A. 1989. 292 pp. ISBN 0-9623489-1-0. $19.95 (paperback)","","","P.MickRichardson(Executive Editor)","Biochemical Systematics and Ecology","https://doi.org/10.1016/0305-1978(90)90059-O","https://www.sciencedirect.com/science/article/pii/030519789090059O"
"A729","Statistics for the Life Sciences: Myra L. Samuels. Dellen Publishing Co., San Francisco; Collier MacMillan Publishers, London 1989. 591 pp.; 14 chapters, numerous appendices and statistical tables, index. ISBN 0-02-405501-8","","","J.Lecomte","Biochemical Systematics and Ecology","https://doi.org/10.1016/0305-1978(90)90060-S","https://www.sciencedirect.com/science/article/pii/030519789090060S"
"A730","Intermediary Xenobiotic Metabolism in Animals: Methodology, Mechanisms and Significance: Edited by D. M. Hutson, J. Caldwell and G. D. Paulson. Taylor and Francis, London. 1989. 389 pp","","","J.Gielen","Biochemical Systematics and Ecology","https://doi.org/10.1016/0305-1978(90)90058-N","https://www.sciencedirect.com/science/article/pii/030519789090058N"
"A731","Subject index: Notes","","","","Deep Sea Research Part B. Oceanographic Literature Review","https://doi.org/10.1016/S0198-0254(06)80113-5","https://www.sciencedirect.com/science/article/pii/S0198025406801135"
"A732","Feminist forum","","","","Women's Studies International Forum","https://doi.org/10.1016/0277-5395(90)90118-H","https://www.sciencedirect.com/science/article/pii/027753959090118H"
"A733","CHAPTER 9: MAPPING OF SCIENCE: POSSIBILITIES AND LIMITATIONS","Possibilities to map scientific fields and developments in science have been developed by scientometrics, and are becoming increasingly important for science policy in a strategic age. Technical and conceptual issues in constructing and using maps are discussed, and the relation to policy goals and utilization is emphasized. A comparison with the development of environmental mapping and impact analysis allows some further critical reflection on the status and policy role of maps of science.","","A.Rip","Handbook of Quantitative Studies of Science and Technology,Handbook of Quantitative Studies of Science and Technology","https://doi.org/10.1016/B978-0-444-70537-2.50014-3","https://www.sciencedirect.com/science/article/pii/B9780444705372500143"
"A734","Educational evaluation: The state of the field","","","Richard M.Wolf(Guest Editor)","International Journal of Educational Research","https://doi.org/10.1016/0883-0355(87)90033-4","https://www.sciencedirect.com/science/article/pii/0883035587900334"
"A735","The aerobic/anaerobic transition of glucose metabolism in Trypanosoma brucei","The ratio of glycerol to pyruvate produced by T. brucei incubated with glucose at various oxygen tensions has been used as an index of the aerobic and anaerobic pathways of glucose metabolism. A minimal model is presented which fits the observed data. The value of the notional K of the aerobic/anaerobic transition from the model is close to that of the Km of trypanosomal glycerophosphate oxidase. The anaerobic pathway appears to be almost completely inoperative at oxygen tensions in the range of those found in venous and arterial blood.","Trypanosoma brucei,Glucose,Glycolysis,Oxygen,Glycerol,Pyruvate,Abbreviations,3GP, L-glycerol-3-phosphate,DHAP, dihydroxyactone phosphate,Po2, partial pressure of oxygen","RobertEisenthal,AlisonPanes","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81106-6","https://www.sciencedirect.com/science/article/pii/0014579385811066"
"A736","Salt-stable association of simian virus 40 capsid with simian virus 40 DNA","In 8 M CsCl, a fraction of the wild-type previrions and tsB228 nucleoprotein complexes lose their core histones but retain their capsid. These histone-depleted complexes apear in the electron microscope as a protein shell attached to supercoiled DNA. Consistent with this result, we find that in l M NaCl, the wildtype previrions dissociate into two populations of nucleoprotein complexes. One population sediments between 50 and 140 S and morphologically resembles the shell-DNA complexes isolated in CsCl gradients. The other population is comprised primarily of nucleoproteins which sediment at 40 S.","SV40 assembly,Protein-DNA interaction,Nucleoprotein complex,SV40 assembly mutant,SV40 VP1,Nonhistone protein","VeronicaBlasquez,MinouBina","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81114-5","https://www.sciencedirect.com/science/article/pii/0014579385811145"
"A737","Prostaglandin E2-like activity of 20:3n-9 platelet lipoxygenase end-product","5,8,11-Icosatrienoic acid (20:3n-9), a fatty acid associated with platelet hyperactivity, was oxygenated by platelet lipoxygenase. The end-product of this pathway was purified by high-performance liquid chromatography (HPLC) and characterized as 12-hydroxy-5,8,10-icosatrienoic acid [12-OH-20:3(5,8,10)] by capillary gas-liquid mass spectrometry. When tested upon platelet aggregation, 12-OH-20:3(5,8,10) exhibited a biphasic effect. At low concentrations (below 5 × 10-7 M) it potentiated aggregation but inhibited it at higher levels, a pattern similar to that obtained with prostaglandin E2. However, since the amounts of 12-OH-20:3(5,8,10) generated under thrombin stimulation are in the range of concentrations with potentiating effects, it seems that the 12-OH derivative is responsible for the hyperaggrebility of 20: 3n-9-rich platelets.","Human platelet,Lipoxygenase-5,8,11-icosatrienoic acid,Platelet aggregation,Abbreviations,PG, prostaglandin,20:3n-9, 5,8,11-icosatrienoic acid,U46619, 9-methano analogue of PGH2,HPLC, high-performance liquid chromatography,TLC, thin-layer chromatography,GC-MS, gas-liquid chromatography-mass spectrometry,TMS, trimethylsilyl,BSTFA, bis-silyl trifluoroacetamide","M.Lagardea,M.Burtina,M.Rigaudb,H.Sprecherc,M.Dechavannea,S.Renauda","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81112-1","https://www.sciencedirect.com/science/article/pii/0014579385811121"
"A738","A role for Ca2+ in the effect of very low frequency electromagnetic field on the blastogenesis of human lymphocytes","The DNA synthesis of lymphocytes triggered by phytohemagglutinin or phorbol-myristate-acetate is strongly reduced by the externally applied electromagnetic field (ELF). Ca2+ uptake by stimulated lymphocytes is also reduced by ELF. The effect appears to be synergistic with that of the well-known calcium blocker agent, verapamil.","Ca2+ flux,Electromagnetic field,Lymphocyte blastogenesis,Phytohemagglutinin,Phorbol-myristate-acetate,Verapamil,Abbreviations,ELF, very low frequency elec-tromagnetic field,PHA, phytohemagglutinin,PMA, phorbol-myristate-acetate,CRPMI, complete medium RPMI 1640","P.Conti*,G.E.Gigante,E.Alesse,M.G.Cifone,C.Fieschi,M.Reale*,P.U.Angeletti","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81107-8","https://www.sciencedirect.com/science/article/pii/0014579385811078"
"A739","Domain structure and evolution in a-crystallins and small heat-shock proteins","","a-Crystallin,Heat-shock protein,Domain structure","GraemeWistow","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81102-9","https://www.sciencedirect.com/science/article/pii/0014579385811029"
"A740","Association of the glucocorticoid hormone receptor with ribonucleic acid","The hypothesis that the glucocorticoid hormone receptor interacts with RNA has been tested in cultured rat hepatoma cells. The receptor was covalently labeled with radioactive dexamethasone mesylate, and putative RNA-receptor complexes were stabilized by either cell-free crosslinking using formaldehyde or irradiation of intact cells. After chemical cross-linking in vitro, the receptor displayed the buoyant density of a ribonucleoprotein in CsCl gradients. After photochemical crosslinking in cells labeled with radioactive uridine, the receptor analysed by polyacrylamide gel electrophoresis was carrying labeled ribonucleotides.","Glucocorticoid,Receptor,Affinity labeling,Ribonucleoprotein,Crosslinking,Abbreviations,dexamethasone, 9a--fluoro-16a-methyl-11ß,17,21 -trihydroxy-1,4-pregnadiene-3,20-dione,HTC, hepatoma tissue culture,Tricine, N-[2-hydroxy-1,1-bis-(hydroxymethyl)ethyl]glycine","Ioannis V.Economidis,Guy G.Rousseau","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81111-X","https://www.sciencedirect.com/science/article/pii/001457938581111X"
"A741","The increase of cGMP by atrial natriuretic factor correlates with the distribution of particulate guanylate cyclase","We have demonstrated previously that atrial natriuretic factor (ANF) augments urinary, plasma and kidney cGMP levels but has no significant effect upon cAMP. Using cGMP as a marker, we searched for specific target sites involved in the action of ANF in the dog kidney, and observed no changeof cGMP in the proximal tubules, a 2-fold increase over basal levels in the thick loop of Henle and a 3-fold elevation in the collecting duct. The most striking action on cGMP occurred in the glomeruli with a rise of up to 50-fold being evident at 1–2 min. after the addition of ANF. The results obtained in the absence or presence of a phosphodiesterase inhibitor support the notion that the effects of ANF were exerted at the level of guanylate cyclase stimulation rather than cGMP phosphodiesterase inhibition. The action of sodium nitroprusside (SNP), a direct stimulator of soluble guanylate cyclase, differed from that of ANF. The ability of the factor to enhance cGMP levels was correlated with the distribution of particulate guanylate cyclase. This study identifies the glomeruli and the distal part of the nephron as specific targets of ANF and implicates particulate guanylate cyclase as the enzyme targetted for the expression of its action.","Atrial natriuretic factor,Cyclic GMP,Particulate guanylate cyclase,Glomerulus,Tubule,Sodium nitroprusside,Abbreviations,MIX, 1-methyl-3-isobutylxanthine,TEA, triethanolamine","JohanneTremblaya,RupertGerzerb,PatrickVinayc,Stephen C.Panga,RichardBéliveaud,PavelHameta","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81105-4","https://www.sciencedirect.com/science/article/pii/0014579385811054"
"A742","Kinetic analysis of short-term effects of a-agonists on gluconeogenesis in isolated rat hepatocytes","Isolated hepatocytes from fasted rats were perifused with glycerol as gluconeogenic substrate. Stimulation of gluconeogenesis with phenylephrine (10-5M) as a-adrenergic agonist consisted of two distinct phases. The first phase was a transient stimulation of gluconeogenesis and was accompanied by transient changes in cytosolic and mitochondrial redox state; this phase was abolished by the transaminase inhibitor aminooxyacetate. The second phase was a stable stimulation of less magnitude, without change in redox state and insensitive to addition of aminooxyacetate. It is concluded that the first phase is due to a transient enhancement of flux through the malate/aspartate shuttle and that the stable phase is probably due to a stimulation of mitochondrial glycerol-3-phosphate dehydrogenase and glycerol kinase.","Gluconeogenesis,a-Agonist,Phenylephrine,Malate-aspartate shuttle,Hepatocyte,Catecholamine","X.M.Leverve,A.K.Groen,A.J.Verhoeven,J.M.Tager","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81110-8","https://www.sciencedirect.com/science/article/pii/0014579385811108"
"A743","An ammonium sulphate fraction from rabbit reticulocytes increases the release of proteins from rat liver mitochondria","Incubation of [35S]methionine labeled mitochondria from rat liver with rabbit reticulocyte lysate under the same conditions as those used in the import of mitochondrial protein precursors results in the release of mitochondrial proteins to the medium. Fractionation of the lysates with ammonium sulphate yields a fraction, essentially free of haemoglobin, which exhibits higher activity for the release of mitochondrial proteins than the starting lysate. The fraction has a molecular mass of > 10 kDa and is heat-sensitive. The release is insensitive to inhibitors of reticulocyte lipoxygenase.","Protein,Mitochondria,Rat liver,Reticulocyte Precursor,Abbreviations,FRL55,fraction obtained by saturation to 55% with ammonium sulphate of reticulocyte lysates followed by centrifugation","Vicente J.Miralles,SantiagoGrisolía","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81109-1","https://www.sciencedirect.com/science/article/pii/0014579385811091"
"A744","On the 6-phosphofructo-1-kinase phosphatase activity of protein phosphatase 2C and its dimeric nature","A recently described 6-phosphofructo-1-kinase phosphatase (PFK-phospatase [1]) shared several properties with protein phosphatase 2C [2,3], but exhibited differences with respect to molecular mass and substrate specificity. Chromatography on histone-Sepharose, gel filtration experiments on Sephacryl S-200 and Sephadex G-100 as well as sucrose density gradient centrifugation [4] show that both enzyme preparations behave identically under all experimental conditions used. The low activity of PFK-phosphatase phosphorylated histone H2B [1] had resulted from an inhibition of the enzyme by high concentrations of this substrate. The apparent molecular mass of protein phosphatase 2C as calculated from Sephacryl chromatography and sedimentation analysis is about 90 kDa, the molecular mass obtained by SDS gel electrophoresis about 45 kDa. The native enzyme therefore seems to be a dimer consisting probably of 2 identical subunits. Accordingly, the previously described PFK-phosphatase is protein phosphatase 2C.","Protein phosphatase,6-Phosphofructo-1-kinase,Dephosphorylation,Glycolytic enzyme","GottfriedMieskes,Hans-DieterSöling","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81103-0","https://www.sciencedirect.com/science/article/pii/0014579385811030"
"A745","Folding of single-stranded DNA on the histone octamer","A complex between the single-stranded DNA of the bacteriophage M13 and the histone octamer was analyzed by electron microscopy, low-angle X-ray diffraction and nuclease analysis. The morphology and the diffraction pattern of the complex strongly resemble those of the nucleosome. These results, as well as the finding of a protected DNA fragment about 100 nucleotides long following single-stranded DNA specific nuclease digestion, indicate that ‘a nucleosome-like’ complex can be formed between single-stranded DNA and the histone octamer. Competition experiments suggest that under physiological conditions the histone octamer is transferred from single- to double-stranded DNA.","Chromatin,Single-stranded DNA,Histone octamer,Electron microscopy,Low-angle X-ray diffraction,Nuclease analysis","E.Caffarelli,L.Leoni,M.Savino","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81115-7","https://www.sciencedirect.com/science/article/pii/0014579385811157"
"A746","Pre-replicative changes of the rat sinusoidal plasma membrane glycoproteins during hepatic regeneration","Cell-surface glycoproteins of rat liver sinusoidal plasma membranes from control and regenerating livers were studied. The glycoproteins were labeled using specific methods for sialic acid (NAIO4/NaB3H4) and galactosyl/N-acetyl galctosaminyl residues (galactose oxidase/NaB3H4 and neuraminidase-galactose oxidase (NaB3H4) and the solubilized proteins were analyzed by gel electrophoresis. The patterns obtained with regenerating livers were quantitatively different from controls. This shows that cell surface glycoproteins change during liver regeneration.","Sialic acid,Liver plasma membrane,Liver regeneration,Cell surface glycoprotein","CarlosEnricha,Carl G.Gahmbergb","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81104-2","https://www.sciencedirect.com/science/article/pii/0014579385811042"
"A747","ß2-Inhibin contains the active core of human seminal plasma ß-inhibin: synthesis and bioactivity","The complete synthesis of the C-terminal 28 residues segment 67–94 of human seminal plasma jS-Inhibin, called ß2-Inhibin, is reported. The Inhibin-like activity of the native 94 amino acids ß-Inhibin is compared to that of the synthetic replica of ß2-Inhibin. In all assays used both peptides effectively suppress the FSH release induced by LHRH but have little effect on the LH release. In the mouse both peptides are equipotent on a mole basis. In the rat the synthetic ß2-Inhibin is 3–10 times more potent than ß-Inhibin. Both peptides are active in rat anterior pituitary primary culture assays where maximum suppression of FSH release induced by LHRH occurs around 300 pmolml of ß2-Inhibin. In contrast, maximum suppression of FSH release in the mouse pituitary assay occurs at 10–15 pmolml of either Inhibin.","ß2-Inhibin,Chemical synthesis,Human seminal plasma,Pituitary FSH release","N.J.Arbattibd,N.G.Seidaha,J.Rochemonta,E.Escherc,A.R.Shethd,M.Chrétiena","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81113-3","https://www.sciencedirect.com/science/article/pii/0014579385811133"
"A748","Isolation and characterization of syncytiotrophoblast plasma membrane from human placenta","Human full-term syncytiotrophoblast plasma membranes isolated by mechanical procedures (sieving and ultrasonic disintegration), purified by phase centrifugation, form a single band of 1.052 ± 0.002 gml density in percoll gradient. The purity of the preparation was assessed by electron microscopy, enzyme analysis and ß2-microglobulin determination.","Plasma membrane isolation,Syncytiotrophoblast,Human placenta","B.Khalfouna,D.Degennea,B.Arbeille-Brassartb,N.Gutmanc,P.Bardosa","FEBS Letters","https://doi.org/10.1016/0014-5793(85)81108-X","https://www.sciencedirect.com/science/article/pii/001457938581108X"
"A749","Kinetics of the inhibition by naphtholsulfonate compounds of AMP deaminase from chicken erythrocytes","The effect of a variety of naphthalene sulfonate compounds on the chicken erythrocyte AMP deaminase (AMP aminohydrolase, EC 3.5.4.6) reaction was analyzed kinetically. Of the naphthalene sulfonate deritives tested, the compounds with hydroxyl, sulfonate and nitrogen groups such as amino, anilino or azo groups showed an inhibitory effect. The cooperative effect of AMP, analyzed in terms of Hill coefficient, was increased from about 2 to 4 and the maximal velocity was unchanged with the addition of these compounds, suggested the ligands as an allosteric inhibitor of the enzyme. The inhibition of AMP deaminase by naphtholsulfonate compounds can be qualitatively and quantitatively accounted for by the Monod-Wyman-Changeux model. Theoretical curves yield a satisfactory fit of all experimental saturation and inhibition curves, assuming four binding sites for AMP and the inhibitor, and various KT(I) values. The structure-activity analysis of the interaction of the naphtholsulfonate compounds with AMP deaminase has demonstrated that the affinity of the enzyme for naphtholsulfonates as the inhibitors is correlated with electronic properties of the nitrogen atoms attached to naphthalene moiety: the delocalization of lone electron pair on nitrogen through naphtholsulfonate group makes the compound less basic, resulting in more tight binding of the ligand to the enzyme. Introduction of hydrophobic group to naphtholsulfonate moiety increases the binding affinity for the enzyme, and of the inhibition. These results suggest the location of hydrophobic regions as the allosteric inhibitory sites of the enzyme for the binding of naphtholsulfonate compounds.","AMP deaminase,Naphtholsulfonate compound,Allosteric inhibition,(Chicken erythrocyte)","MasatakaYoshinoa,KeikoMurakamib,YasuhikoKawamurac","Biochimica et Biophysica Acta (BBA) - Protein Structure and Molecular Enzymology","https://doi.org/10.1016/0167-4838(84)90348-0","https://www.sciencedirect.com/science/article/pii/0167483884903480"
"A750","Author index","","","","Biochimica et Biophysica Acta (BBA) - Protein Structure and Molecular Enzymology","https://doi.org/10.1016/0167-4838(84)90353-4","https://www.sciencedirect.com/science/article/pii/0167483884903534"
"A751","Anomalous pH dependence of the heme-bound carbon monoxide spectroscopic properties in the glycera dibranchiata monomer hemoglobin fraction compared to vertebrate hemoglobins","The pH dependence of infrared and NMR spectroscopic parameters for carbon monoxide bound to human, equine, rabbit and Glycera dibranchiata monomer fraction hemoglobins has been examined. In all cases, the vetebrate hemoglobins exhibit CO vibrations and 13CO chemical shifts which are pH dependent, whereas the invertebrate hemoglobin does not. The Glycera dibranchiata monomer fraction exhibits the highest wavenumber CO vibration (1970 cm-1) and the most shielded chemical shift (206.2 ppm). The pH behavior of the vertebrate CO-hemoglobins is that the heme-coordinated carbon monoxide chemical shifts and principal infrared vibrations tend toward the values observed for the G. dibranchiata CO-hemoglobin fraction. These results are interpreted as originating in protonation of the distal histidine (E-7) in the vertebrate hemoglobins. The anomalous values for Glycera dibranchiata are concluded to be due to the absence of a distal histidine (E-7 His <U+2192> Leu) in the heme pocket and not to gross structural dissimilarities between the proteins of the different species examined. Primary sequence similarity matrices have been constructed to compare the functional classes of amino acids at homologous positions for the CD and E helices and for the primary heme contacts in human, equine, sperm whale myoglobin, and the Glycera dibranchiata monomer hemoglobin to illustrate this point. They reveal a high correspondence for all globins and do not correlate with the spectroscopic parameters of heme-coordinated CO.","Heme,Hemoglobin,Carbon monoxide,NMR,pH dependence,Abbreviations,Hbhemoglobin,Mbsperm whale myoglobin,Mes4-morpholineethanesulfonic acid","James D.Satterlee","Biochimica et Biophysica Acta (BBA) - Protein Structure and Molecular Enzymology","https://doi.org/10.1016/0167-4838(84)90351-0","https://www.sciencedirect.com/science/article/pii/0167483884903510"
"A752","The domain structure of the cholesterol side-chain cleavage cytochrome P-450 from bovine adrenocortical mitochondria: Localization of haem group and domains in the polypeptide chain","Cytochrome P-450scc consists of two domains linked with a short loop of the polypeptide chain; under hydrolysis by trypsin the domains retain their associated state due to rigid noncovalent interactions. A partial separation of the domains by gel-chromatography on Sephadex G-200 with retention of a haem group in domain I has been achieved after incubation of the trypsin-modified cytochrome P-450scc in 50 mM phosphate buffer (pH 7.2)/1 M NaCl/0.3% sodium cholate/0.3% Tween 80. The separation of domains I and II to individual fragments of the haemoprotein polypeptide chain has been achieved by chromatography under denaturation conditions on the activated thiopropyl-Sepharose via a selective covalent immobilization of domain II. Dissociation of a complex of domains I and II has been effectuated in the presence of 7 M guanidine. Structural characteristics of individual domains have been investigated. It is established that domain I containing a haem group is the N-terminal moiety, and domain II, the C-terminal moiety of the polypeptide chain of cytochrome P-450scc. The pathways of limited trypsinolysis of the native cytochrome P-450scc have been determined. The peptides containing cysteine residues localized on the surface of domain II and responsible for the interaction of haemoprotein with activated thiopropyl-Sepharose have been isolated in a homogeneous form and their amino-acid sequences have been assessed.","Cytochrome P-450,Domain structure,Trypsin digestion,(Bovine adrenal cortex),Abbreviations,P-450sccadrenal mitochondrial cytochrome P-450 which functions in the cholesterol side-chain cleavage reaction,P-450(I + II)trypsin-modified form of P-450scc","V.L.Chashchin,V.I.Vasilevsky,V.M.Shkumatov,V.N.Lapko,T.B.Adamovich,T.M.Berikbaeva,A.A.Akhrem","Biochimica et Biophysica Acta (BBA) - Protein Structure and Molecular Enzymology","https://doi.org/10.1016/0167-4838(84)90350-9","https://www.sciencedirect.com/science/article/pii/0167483884903509"
"A753","Cadmium binding to human a2-macroglobulin","a2-Macroglobulin (a2M) is one of the major cadmium-binding proteins of human plasma. As determined with equilibrium dialysis, a2M bound 4.6 (±0.7) mol Cd2+ per mol protein with an apparent dissociation constant of (9.6 (±5.0))·10-7M. Methylamine-modified a2M (a2M-Me) had a similar affinity for Cd2+ (Kd,app = 5.3·10-7M, but fewer binding sites. Cadmium produced a small increase in the amidolytic activity of trypsin in the presence of a2M and soybean trypsin inhibitor. Using the binding parameters determined from the equilibrium dialysis studies, the Cd2+ concentration which produced a half-maximal increase in amidolytic activity corresponded to saturation of all Cd2+-binding sites in one-half of the a2M molecules. From these results, a model is proposed in which one Cd2+-binding site is present in each of the four polypeptide chains which compose a2M.","a2-Macroglobulin,Equilibrium binding,Cd2+ binding,(Human),Abbreviations,a2Ma2-macroglobulin","Steven D.Carson","Biochimica et Biophysica Acta (BBA) - Protein Structure and Molecular Enzymology","https://doi.org/10.1016/0167-4838(84)90349-2","https://www.sciencedirect.com/science/article/pii/0167483884903492"
"A754","Erratum","","","","Biochimica et Biophysica Acta (BBA) - Protein Structure and Molecular Enzymology","https://doi.org/10.1016/0167-4838(84)90352-2","https://www.sciencedirect.com/science/article/pii/0167483884903522"
"A755","Role of water in urban ecology","","","H.Hengeveld,C.De Vocht","Urban Ecology","https://doi.org/10.1016/0304-4009(82)90022-5","https://www.sciencedirect.com/science/article/pii/0304400982900225"
"A756","Computers in the World of Chemistry","Chemistry is an experimental science, based on the laws of physics and using the language of mathematics augmented by graphics. It addresses to the properties of materials, including those important to the life process from an atomic and molecular perspective. This chapter describes a set of five complementary areas—namely, chemical education and computer, computer in the chemical laboratory, the modeling of matter from a molecular perspective, chemical information, and the chemistry establishment. Chemistry is international in scope. The common and accepted language of chemists provides an international communication network. Computers in the world of chemistry offer completely new possibilities for quantitatively handling molecules consisting of many nuclei and electrons, for modeling of complex reactions, and for banking and retrieving tremendous amounts of data and information of all kinds. The chemist, on entering the world of computing, not only becomes more potent as a chemist, but can also discover new channels of communication with people working in other disciplines.","","PeterLykos","Advances in Computers","https://doi.org/10.1016/S0065-2458(08)60571-9","https://www.sciencedirect.com/science/article/pii/S0065245808605719"
"A757","6: Principles of the Regulation of Enzyme Activity","","","Peter J.Roach","Cell Biology: A Comprehensive Treatise,Cell Biology: A Comprehensive Treatise","https://doi.org/10.1016/B978-0-12-289504-3.50012-7","https://www.sciencedirect.com/science/article/pii/B9780122895043500127"
"A758","PART III: THE IMPACT OF OFFICE AUTOMATION","This chapter discusses the strategies for successful implementation of office of the future, methods by which impacts are studied, impacts as they have been observed to date, and how these impacts relate to organizational productivity. The office and organization are complex communication systems. The chapter further discusses the importance of communication in the implementation of office automation systems and the realization of beneficial impacts. The communication system concept has enabled the understanding of far deeper changes than the scattered efficiencies obtained from data and word processing support. There is a need for mature office automation technologies and also for mature installations. Most implementations have been rather immature because the knowledge of how to implement a system of the needed size and capability has not been applied. The strategies have not been specified in detail, and there have not been systems advanced enough to warrant a staged evolution. The chapter presents a step-by-step strategy to manage the human use of computer-based office systems. Commitment to evolving a mature implementation requires well-developed methods of assessing impact. The complex communication system requires an elaborate structure because of many interdependencies and variable relationships. This structure includes lists of the variables by kind and type, some of the possible values of the variables, a framework for measuring the variables, and methods of measurement.","","Ronald P.UHLIG,David J.FARBER,James H.BAIR","The Office of the Future,The Office of the Future","https://doi.org/10.1016/B978-0-444-85336-3.50009-X","https://www.sciencedirect.com/science/article/pii/B978044485336350009X"
"A759","Neurobiology in Statu Nascendi","This chapter provides an introduction to neurobiology. Much less is known about the way the billions of neurons acquire those intrinsic characteristics that define their later functional idioms. Some seem to be preprogrammed at an early stage, others seem to gain specifications secondarily from their surroundings or contacts, and others remain consistently pluripotent. Conclusive evidence is that early preprogramming of neurons is a fact that is manifested by Mauthner cells of amphibian larvae, a pair of single neurons in the medulla, distinctive by their giant sizes and destined for some sensory function in aquatic life. Studies show that a small fragment of future medulla of an egg in neurulation, explanted into a neutral medium, will still give rise to a singular giant Mauthner cell amidst a mass of conventionally small-sized neurons. Aside from its gigantism, this peculiar cell also seems pre-endowed with the potential for its specific future reactivity. According to Weiss and Rossetti, the larva of Xenopus grows conspicuously for about a month and so do its two Mauthner cells. Thyroid secretion then supervenes and transforms the larva into the metamorphosed frog, which continues to grow. While the other brain cells likewise keep enlarging, the two Mauthner cells shrink down to indistinctiveness. No external intervention, such as amputating the tail, transecting the long Mauthner fibers, etc., has any effect.","","Paul A.Weiss","Progress in Brain Research","https://doi.org/10.1016/S0079-6123(08)60981-4","https://www.sciencedirect.com/science/article/pii/S0079612308609814"
"A760","Notice","","","","Toxicology and Applied Pharmacology","https://doi.org/10.1016/0041-008X(72)90301-8","https://www.sciencedirect.com/science/article/pii/0041008X72903018"
"A761","Case grammar: Its viability as an alternative grammatical model","","","PaulFletcher","Lingua","https://doi.org/10.1016/0024-3841(71)90059-3","https://www.sciencedirect.com/science/article/pii/0024384171900593"
"A762","COMMENTS ON THE EXPERIMENTAL AND THEORETICAL STUDY OF TRANSPORT PHENOMENA IN SIMPLE LIQUIDS","","","Stuart A.Rice*,Jean PierreBoon,H.Ted Davis","Simple Dense Fluids,Simple Dense Fluids","https://doi.org/10.1016/B978-0-12-395698-9.50015-7","https://www.sciencedirect.com/science/article/pii/B9780123956989500157"
"A763","Chapter 20: The Structure Proteins","","","SAMSEIFTER,PAUL M.GALLOP","The Proteins Composition, Structure, and Function,The Proteins Composition, Structure, and Function (Second Edition)","https://doi.org/10.1016/B978-0-12-395726-9.50013-9","https://www.sciencedirect.com/science/article/pii/B9780123957269500139"
"A764","1: The Social Use of Space","","","JOHN B.CALHOUN","Physiological Mammalogy,Physiological Mammalogy","https://doi.org/10.1016/B978-0-12-395673-6.50007-3","https://www.sciencedirect.com/science/article/pii/B9780123956736500073"
"A765","CHAPTER III: The Era of Radiation Physics: pts 15 to pts 9","","","MARTIN D.KAMEN","Primary Processes in Photosynthesis,Primary Processes in Photosynthesis","https://doi.org/10.1016/B978-1-4832-2959-1.50010-8","https://www.sciencedirect.com/science/article/pii/B9781483229591500108"
