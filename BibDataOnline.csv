"Title","Abstract","Keywords","Authors","Journal","DOI","URL"
"A1","Short-long term anomaly detection in wireless sensor networks based on machine learning and multi-parameterized edit distance","Heterogeneous wireless sensor networks are a source of large amount of different information representing environmental aspects such as light, temperature, and humidity. A very important research problem related to the analysis of the sensor data is the detection of relevant anomalies. In this work, we focus on the detection of unexpected sensor data resulting either from the sensor system itself or from the environment under scrutiny. We propose a novel approach for automatic anomaly detection in heterogeneous sensor networks based on coupling edge data analysis with cloud data analysis. The former exploits a fully unsupervised artificial neural network algorithm, whereas cloud data analysis exploits the multi-parameterized edit distance algorithm. The experimental evaluation of the proposed method is performed applying the edge and cloud analysis on real data that has been acquired in an indoor building environment and then distorted with a range of synthetic impairments. The obtained results show that the proposed method can self-adapt to the environment variations and correctly identify the anomalies. We show how the combination of edge and cloud computing can mitigate the drawbacks of purely edge-based analysis or purely cloud-based solutions.","Intelligent sensing,Sensor fusion,Anomaly detection,Cloud-assisted sensing,Internet of Things","FrancescoCauteruccioa,GiancarloFortinoab,AntonioGuerrierib,AntonioLiottac,Decebal ConstantinMocanud,CristianPerrae,GiorgioTerracinaa,MariaTorres Vegaf","Information Fusion","https://doi.org/10.1016/j.inffus.2018.11.010","https://www.sciencedirect.com/science/article/pii/S1566253518304305"
"A2","Genome-wide survey of efflux pump-coding genes associated with Cronobacter survival, osmotic adaptation, and persistence","","","FlaviaNegrete1,HyeinJang1,JayanthiGangiredla1,JungHaWoo1,YouYoungLee1,Isha RPatel1,Hannah RChase1,SamanthaFinkelstein1,Caroline ZWang1,ShabarinathSrikumar2,ScottNguyen2,AthmanyaEshwar3,RogerStephan3,AngelikaLehner3,SéamusFanning2,Ben DTall1,Gopal RGopinath1","Current Opinion in Food Science","https://doi.org/10.1016/j.cofs.2018.11.005","https://www.sciencedirect.com/science/article/pii/S221479931830033X"
"A3","Data fusion in cyber-physical-social systems: State-of-the-art and perspectives","Cyber-Physical-Social systems (CPSSs) are the extension of Cyber-Physical systems (CPS), which seamlessly integrate cyber space, physical space and social space. CPSSs promote the information resource from single space to tri-space, so as to lead a revolution in data science (DS). This paper aims to provide a comprehensive review of data fusion in CPSSs for readers. We firstly analyze data collection and representation in CPSS and propose to use tensors to represent CPSS data, then a general definition of CPSS data fusion is proposed to clarify the concept of information fusion in CPSS. After that, some representative data fusion methods related to CPSS are reviewed. Furthermore, we propose a series of tensor based data fusion methods for CPSS data. Also, we review the design of data fusion frameworks and propose a comprehensive data fusion framework for CPSS. Some challenges and future works are discussed as well.","CPSS,Data fusion,Data fusion framework design,Tensor","PumingWanga,Laurence T.Yangab,JintaoLia,JinjunChenc,ShangqingHud","Information Fusion","https://doi.org/10.1016/j.inffus.2018.11.002","https://www.sciencedirect.com/science/article/pii/S1566253518301507"
"A4","Machine learning for integrating data in biology and medicine: Principles, practice, and opportunities","New technologies have enabled the investigation of biology and human health at an unprecedented scale and in multiple dimensions. These dimensions include a myriad of properties describing genome, epigenome, transcriptome, microbiome, phenotype, and lifestyle. No single data type, however, can capture the complexity of all the factors relevant to understanding a phenomenon such as a disease. Integrative methods that combine data from multiple technologies have thus emerged as critical statistical and computational approaches. The key challenge in developing such approaches is the identification of effective models to provide a comprehensive and relevant systems view. An ideal method can answer a biological or medical question, identifying important features and predicting outcomes, by harnessing heterogeneous data across several dimensions of biological variation. In this Review, we describe the principles of data integration and discuss current methods and available implementations. We provide examples of successful data integration in biology and medicine. Finally, we discuss current challenges in biomedical integrative methods and our perspective on the future development of the field.","Computational biology,Personalized medicine,Systems biology,Heterogeneous data,Machine learning","MarinkaZitnika,FrancisNguyenbc,BoWangd,JureLeskovecae,AnnaGoldenbergfgh,Michael M.Hoffmanbcgh","Information Fusion","https://doi.org/10.1016/j.inffus.2018.09.012","https://www.sciencedirect.com/science/article/pii/S1566253518304482"
"A5","On the necessity of abstraction","","","GeorgeKonidaris","Current Opinion in Behavioral Sciences","https://doi.org/10.1016/j.cobeha.2018.11.005","https://www.sciencedirect.com/science/article/pii/S2352154618302080"
"A6","Evidence gathering for hypothesis resolution using judicial evidential reasoning","Realistic decision-making often occurs with insufficient time to gather all possible evidence before a decision must be rendered, requiring an efficient process for prioritizing between potential action sequences. This work aims to develop a rigorous framework for gathering evidence to resolve hypotheses notwithstanding ambiguous, incomplete, and uncertain evidence. Studies have shown that decision-makers demonstrate several biases in decisions involving probability judgment, so decision-makers must be confident that the evidence-based hypothesis resolution is strong and impartial before declaring a resolution. The proposed Judicial Evidential Reasoning framework encodes decision-maker questions as rigorously testable hypotheses to be interrogated through evidence-gathering actions. Dempster–Shafer theory is applied to model hypothesis knowledge and quantify ambiguity, and an equal-effort heuristic is proposed to balance time-efficiency and impartiality. Adversarial optimization techniques are used to make many-hypothesis resolution computationally tractable. This work includes derivation of the generalized formulation, computational tractability considerations for improved performance, several illustrative examples, and application to a space situational awareness sensor network tasking scenario. The results show strong hypothesis resolution and robustness to fixation due to poor prior evidence.","Dempster–Shafer theory,Hypothesis resolution,Confirmation bias,Ambiguity aversion,Decision support","A.D.Jaunzemisa,M.J.Holzingera,M.W.Chanb,P.P.Shenoyc","Information Fusion","https://doi.org/10.1016/j.inffus.2018.09.010","https://www.sciencedirect.com/science/article/pii/S1566253518302598"
"A7","Machine learning algorithms for wireless sensor networks: A survey","Wireless sensor network (WSN) is one of the most promising technologies for some real-time applications because of its size, cost-effective and easily deployable nature. Due to some external or internal factors, WSN may change dynamically and therefore it requires depreciating dispensable redesign of the network. The traditional WSN approaches have been explicitly programmed which make the networks hard to respond dynamically. To overcome such scenarios, machine learning (ML) techniques can be applied to react accordingly. ML is the process of self-learning from the experiences and acts without human intervention or re-program. The survey of the ML techniques for WSNs is presented in [1], covering period of 2002–2013. In this survey, we present various ML-based algorithms for WSNs with their advantages, drawbacks, and parameters effecting the network lifetime, covering the period from 2014–March 2018. In addition, we also discuss ML algorithms for synchronization, congestion control, mobile sink scheduling and energy harvesting. Finally, we present a statistical analysis of the survey, the reasons for selection of a particular ML techniques to address an issue in WSNs followed by some discussion on the open issues.","Wireless sensor networks,Machine learning,Energy efficiency,Network lifetime,Data aggregation","D.Praveen Kumar,TarachandAmgoth,Chandra Sekhara RaoAnnavarapu","Information Fusion","https://doi.org/10.1016/j.inffus.2018.09.013","https://www.sciencedirect.com/science/article/pii/S156625351830277X"
"A8","Deep learning with multi-scale feature fusion in remote sensing for automatic oceanic eddy detection","Oceanic eddies are ubiquitous in global oceans and play a major role in ocean energy transfer and nutrients distribution, thus being significant for understanding ocean current circulation and marine climate change. They are characterized by a combination of high-speed vertical rotations and horizontal movements, leading to irregular three-dimensional spiral structures. While the ability to detect eddies automatically and remotely is crucial to monitoring important spatial–temporal dynamics, existing methods are inaccurate because eddies are highly dynamic and the underlying physical processes are not well understood. Typically, remote sensing is used to detect eddies based on physical parameters, geometrics or other handcrafted features. In this paper, we show how Deep Learning may be used to reliably extract higher-level features and then fuse multi-scale features to identify eddies, regardless of their structures and scales. We learn eddy features using two principal component analysis convolutional layers, then perform a non-linear transformation of the features through a binary hashing layer and block-wise histograms. To handle the difficult problem of spatial variability across synthetic aperture radar (SAR) images, we introduce a spatial pyramid model to allow multi-scale features fusion. Finally, a linear support vector machine classifier recognizes the eddies. Our method, dubbed DeepEddy, is benchmarked against a dataset of 20,000 SAR image samples, achieving a 97.8<U+202F>±<U+202F>1% accuracy of detection.","Remote sensing,Feature fusion,SAR images,Eddy detection,Deep learning","DuYanlingab,SongWeia,HeQia,HuangDongmeia,LiottaAntonioc,SuChenb","Information Fusion","https://doi.org/10.1016/j.inffus.2018.09.006","https://www.sciencedirect.com/science/article/pii/S1566253518304214"
"A9","A survey on region based image fusion methods","Image fusion has been emerging as an important area of research. It has attracted many applications such as surveillance, photography, medical diagnosis, etc. Image fusion techniques are developed at three levels: pixel, feature and decision. Region based image fusion is one of the methods of feature level. It possesses certain advantages – less sensitive to noise, more robust and avoids misregistration. This paper presents a review of region based fusion approaches. A first hand classification of region based fusion methods is carried out. A comprehensive list of objective fusion evaluation metrics is highlighted to compare the existing methods. A detailed analysis is carried out and results are presented in tabular form. This may attract researchers to further explore the research in this direction.","Image fusion,Region based fusion,Segmentation","BikashMehera,SanjayAgrawala,RutuparnaPandaa,AjithAbrahamb","Information Fusion","https://doi.org/10.1016/j.inffus.2018.07.010","https://www.sciencedirect.com/science/article/pii/S1566253517307583"
"A10","Tourism slogans – Towards a conceptual framework","This paper perused extant literature to develop a conceptual framework for tourism slogan analysis. Brand image, leisure motivations, and cultural dimensions were identified to influence the creation and effects of brand slogans. Based on this framework, the author further explored the affect levels of 134 national tourism slogans through the application of ANEW (Affective Norms for English Words). Three clusters of tourism slogans were identified based on their valence and arousal scores listed in ANEW. Moreover, the cultural dimension of Uncertainty Avoidance was found to be negatively correlated to valence and arousal levels of tourism slogans. Theoretically, the contribution of this paper lies in its application of affect levels of words to make possible multivariate analysis and visualization of tourism slogans. Pragmatically, the application of ANEW in this paper offers a guideline on choosing desirable affective words in creating tourism slogans.","Tourism slogans,Affective image,Cultural dimensions,Brand personality","StevePan","Tourism Management","https://doi.org/10.1016/j.tourman.2018.11.023","https://www.sciencedirect.com/science/article/pii/S0261517718303042"
"A11","The global impact of science gateways, virtual research environments and virtual laboratories","Science gateways, virtual laboratories and virtual research environments are all terms used to refer to community-developed digital environments that are designed to meet a set of needs for a research community. Specifically, they refer to integrated access to research community resources including software, data, collaboration tools, workflows, instrumentation and high-performance computing, usually via Web and mobile applications. Science gateways, virtual laboratories and virtual research environments are enabling significant contributions to many research domains, facilitating more efficient, open, reproducible research in bold new ways. This paper explores the global impact achieved by the sum effects of these programs in increasing research impact, demonstrates their value in the broader digital landscape and discusses future opportunities. This is evidenced through examination of national and international programs in this field.","Science gateways,Virtual research environments,Virtual laboratories,Open science,e-infrastructure,Cyberinfrastructure","MichelleBarkera,Silvia DelgadoOlabarriagab,NancyWilkins-Diehrc,SandraGesingd,Daniel S.Katze,ShayanShahandf,ScottHenwoodg,TristanGlatardh,KeithJefferyi,BrianCorriejk,AndrewTreloarl,HelenGlavesm,LesleyWybornn,Neil P. ChueHongo,AlessandroCostap","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.12.026","https://www.sciencedirect.com/science/article/pii/S0167739X18314018"
"A12","Role of subjective and objective measures of cognitive processing during learning in explaining the spatial contiguity effect","The main objective of this study was to investigate the potential of combining subjective and objective measures of learning process to uncover the mechanisms underlying the spatial contiguity effect in multimedia learning. The subjective measures of learning process were self-reported cognitive load ratings and the objective measures were eye-tracking and EEG measures. Learning outcome was measured by scores on retention and transfer posttests. A sample of 78 university students participated in a between-subjects design in which a multimedia slideshow lesson on how lightning storms develop was presented either with printed text as a caption at the bottom of each illustration (separated presentation) or with printed text placed next to the corresponding part of each illustration (integrated presentation). Regarding spatial contiguity, the integrated group spent significantly more time looking at the text (d<U+202F>=<U+202F>0.64), but significantly less time looking at irrelevant illustrations (d<U+202F>=<U+202F>1.10), and reported a significantly lower level of extraneous load (d<U+202F>=<U+202F>0.57), compared to the separated group. As expected, they also scored significantly higher on the transfer test (d<U+202F>=<U+202F>0.49). Students who performed best on posttests reported a lower level of extraneous load (d<U+202F>=<U+202F>0.56). Furthermore, EEG based alpha band activity was predictive of intrinsic cognitive load but not predictive of extraneous cognitive load, and EEG based theta activity was not predictive of intrinsic or extraneous load. The results suggest that subjective and objective measures of cognitive load can provide different information to test the theoretical mechanisms involved in multimedia learning.","Spatial contiguity,EEG,Eye tracking,Cognitive load,Multimedia learning","GuidoMakranskya,Thomas S.Terkildsena,Richard E.Mayerb","Learning and Instruction","https://doi.org/10.1016/j.learninstruc.2018.12.001","https://www.sciencedirect.com/science/article/pii/S0959475218303797"
"A13","Human intention estimation based on hidden Markov model motion validation for safe flexible robotized warehouses","With the substantial growth of logistics businesses the need for larger warehouses and their automation arises, thus using robots as assistants to human workers is becoming a priority. In order to operate efficiently and safely, robot assistants or the supervising system should recognize human intentions in real-time. Theory of Mind (ToM) is an intuitive human conception of other humans’ mental state, i.e., beliefs and desires, and how they cause behavior. In this paper we propose a ToM based human intention estimation algorithm for flexible robotized warehouses. We observe human’s, i.e., worker’s motion and validate it with respect to the goal locations using generalized Voronoi diagram based path planning. These observations are then processed by the proposed hidden Markov model framework which estimates worker intentions in an online manner, capable of handling changing environments. To test the proposed intention estimation we ran experiments in a real-world laboratory warehouse with a worker wearing Microsoft Hololens augmented reality glasses. Furthermore, in order to demonstrate the scalability of the approach to larger warehouses, we propose to use virtual reality digital warehouse twins in order to realistically simulate worker behavior. We conducted intention estimation experiments in the larger warehouse digital twin with up to 24 running robots. We demonstrate that the proposed framework estimates warehouse worker intentions precisely and in the end we discuss the experimental results.","Human intention estimation,Hidden Markov model,Virtual reality,Theory of Mind","TomislavPetkovica,DavidPuljizb,IvanMarkovica,BjörnHeinb","Robotics and Computer-Integrated Manufacturing","https://doi.org/10.1016/j.rcim.2018.11.004","https://www.sciencedirect.com/science/article/pii/S0736584518302965"
"A14","Developing a government enterprise architecture framework to support the requirements of big and open linked data with the use of cloud computing","Governmental and local authorities are facing many new information and communication technologies challenges. The amount of data is rapidly increasing. The data sets are published in different formats. New services are based on linking and processing differently structured data from various sources. Users expect openness of public data, fast processing, and intuitive visualisation. The article addresses the challenges and proposes a new government enterprise architecture framework. The following partial architectures are included: big and open linked data storage, processing, and publishing using cloud computing. At first, the key concepts are defined. Next, the basic architectural roles and components are specified. The components result from the decomposition of related frameworks. The main part of the article deals with the detailed proposal of the architecture framework and partial views on architecture (sub-architectures). A methodology, including a proposal of appropriate steps, solutions and responsibilities for them, is described in the next step - after the verification and validation of the new framework with respect to the attributes of quality. The new framework responds to emerging ICT trends in order to evolve government enterprise architecture continually and represent current architectural components and their relationships.","Government enterprise architecture framework,Design science research,Big data,Open linked data,Cloud computing,Quality attributes,ATAM,Methodology","MartinLnenicka,JitkaKomarkova","International Journal of Information Management","https://doi.org/10.1016/j.ijinfomgt.2018.12.003","https://www.sciencedirect.com/science/article/pii/S0268401218305942"
"A15","The use of next generation sequencing for improving food safety: Translation into practice","Next Generation Sequencing (NGS) combined with powerful bioinformatic approaches are revolutionising food microbiology. Whole genome sequencing (WGS) of single isolates allows the most detailed comparison possible hitherto of individual strains. The two principle approaches for strain discrimination, single nucleotide polymorphism (SNP) analysis and genomic multi-locus sequence typing (MLST) are showing concordant results for phylogenetic clustering and are complementary to each other. Metabarcoding and metagenomics, applied to total DNA isolated from either food materials or the production environment, allows the identification of complete microbial populations. Metagenomics identifies the entire gene content and when coupled to transcriptomics or proteomics, allows the identification of functional capacity and biochemical activity of microbial populations.The focus of this review is on the recent use and future potential of NGS in food microbiology and on current challenges. Guidance is provided for new users, such as public health departments and the food industry, on the implementation of NGS and how to critically interpret results and place them in a broader context. The review aims to promote the broader application of NGS technologies within the food industry as well as highlight knowledge gaps and novel applications of NGS with the aim of driving future research and increasing food safety outputs from its wider use.","Next generation sequencing,Whole genome sequencing,Metabarcoding,Metagenomics,Food safety and quality,Microbiology,Implementation,Data sharing","BalamuruganJagadeesana,PeterGerner-Smidtb,Marc W.Allardc,SébastienLeuilletd,AnettWinklere,YinghuaXiaof,SamuelChaffrong,JosVan Der Vossenh,SilinTangi,MitsuruKatasej,PeterMcClurek,BonKimural,LayChing Chaim,JohnChapmann,KathieGranto","Food Microbiology","https://doi.org/10.1016/j.fm.2018.11.005","https://www.sciencedirect.com/science/article/pii/S0740002018305306"
"A16","Proactive management of SLA violations by capturing relevant external events in a Cloud of Things environment","The cloud of things (CoT) is an emerging paradigm that has merged and combined cloud computing and the Internet of Things (IoT). Such a paradigm has enabled service providers to provide on-demand computing resources from devices spread across different locations for service users to be dynamically connected to them. While this benefits the CoT service providers and users in many ways, it also brings a key challenge of ensuring that the service is delivered according to the promised quality. Failure to ensure this will result in the service provider experiencing penalties of different types and the service user experiencing disruptions. The literature addresses this problem by proactively managing for SLA violations. However, given the geographically dispersed region of a formed CoT service, in this paper we argue that for proactive SLA violation identification, we need specialized techniques that also consider events that are outside the usual control of service providers and users, but will impact the CoT environment and the quality of service. We propose a framework that identifies such external events of interest and ascertains their impact on achieving the service according to the promised quality. We explain the working of our proposed framework in detail and demonstrate its superiority in proactively determining SLA violations as compared to existing approaches.","Cloud of things,SLA violation,Proactive management,External events,Internal events","FalakNawaza,OmarHussaina,Farookh KhadeerHussainb,Naeem KhalidJanjuac,MortezaSaberia,ElizabethChanga","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.12.034","https://www.sciencedirect.com/science/article/pii/S0167739X18318065"
"A17","Graph-based ontology reasoning for formal verification of BREEAM rules","Globally, the need to check regulation compliance for sustainability has become central in the delivery of construction projects. This is partly due to policies by various governments requiring existing and new buildings to comply with certain standards or regulations. However, the verification of whether a building complies with any particular standard or regulation has proven challenging in practice. The purpose of formal verification is to prove that under a certain set of assumptions, a building will adhere to a certain set of requirements, for example the minimum performance standards of key environmental issues. Compliance checking requires different criteria often difficult to straightforwardly define and combine in an integrated fashion for providing holistic interpretation to facilitate easy decision-making. Such criteria, their various flows and combinations can easily be dealt with using conceptual graph theories and Semantic Web concepts which allow rules to be imbued to facilitate reasoning. The aim of this study is to tap on conceptual graphs and Semantic Web concepts to develop a system for checking Building Research Establishment Environmental Assessment Methodology (BREEAM) sustainability standard compliance in the French construction industry. A conceptual graph-based framework that formally describes BREEAM requirements and visually analyse compliance checking processes has been proposed. When implemented in a software that integrates conceptual graphs and Semantic Web knowledge, automatic reasoning allows both the logical specification and the visual interpretation to be displayed and further provides a semantic support for compliance checking information.","Data,Information,Knowledge,Reasoning,Building,Sustainability","B.Kamsu-Foguema,F.H.Abandab,M.B.Doumbouyaa,J.F.Tchouanguema","Cognitive Systems Research","https://doi.org/10.1016/j.cogsys.2018.12.011","https://www.sciencedirect.com/science/article/pii/S1389041718301608"
"A18","Heat-induced aggregation and gelation of proteins from edible honey bee brood (Apis mellifera) as a function of temperature and pH","Edible insects offer a huge potential as a new source of proteins for food and feed and as a promising functional agent. In this regard, our study aimed to evaluate the effect of pH and temperature on aggregation and gelation of honey bee brood (Apis mellifera). Aggregation of soluble proteins was dependent on temperature and pH value and the highest coagulation was reached at 85<U+202F>°C at pH 5 and 7 (73.7 and 68.4%, respectively). Changes in protein surface hydrophobicity, net charge and amount of available and buried sulfhydryl groups demonstrated the contribution of either covalent or non-covalent intermolecular interactions resulted in aggregation at various pH. The least gelation concentration of raw powder from honey bee brood varied from 5 to 11% on raw powder basis at pH 7 and 3, respectively. Moreover, the effect of pH on rheological and textural properties, as well as gel microstructure from honey bee brood is discussed. Therefore, freeze dried raw powder of honey bee brood has rich nutritional value and demonstrated gelation concentration comparable to conventional protein sources that reveal its potential as an ingredient for insect-based gel product.","Edible insects,Apis mellifera,Gel,Coagulation,Protein,Novel food","MaryiaMishynaab,Jean-Jacques ItzhakMartinezcd,JiansheChena,MayaDavidovich-Pinhase,OfirBenjaminb","Food Hydrocolloids","https://doi.org/10.1016/j.foodhyd.2019.01.017","https://www.sciencedirect.com/science/article/pii/S0268005X18319374"
"A19","Cloud-based manufacturing equipment and big data analytics to enable on-demand manufacturing services","Making manufacturing as on-demand cloud services is a transformative paradigm to achieve the required business flexibility in the context of Industry 4.0 via enabling rapid configuration of loosely-connected manufacturing devices to develop highly customized products. The research in this paper aimed to fill the gap that there is a lack of a feasible solution for cloud-based manufacturing equipment that can provide on-demand manufacturing services accessible via the Internet. The technical challenges in developing cloud-based manufacturing equipment and the enabling technologies are discussed. A generic system architecture for cloud-based manufacturing equipment based on cyber-physical production systems and big data analytics is proposed, allowing manufacturing equipment to be connected to the cloud and made available for the provision of on-demand manufacturing services. An industry implementation in a world-leading machinery solution provider confirms that the proposed system architecture for cloud-based manufacturing equipment can successfully enable on-demand manufacturing services provisioned via the Internet and can be extended to businesses that endeavor to transform legacy production systems into cloud-based cyber-physical production systems.","Cloud manufacturing,Cyber-physical production system,Big data analytics,Industry 4.0,Digital twin","YuqianLu1,XunXu2","Robotics and Computer-Integrated Manufacturing","https://doi.org/10.1016/j.rcim.2018.11.006","https://www.sciencedirect.com/science/article/pii/S0736584518302801"
"A20","Calibration of capacitance sensor for Andosol under field and laboratory conditions in the temperate monsoon climate","Capacitance sensors (CS) were developed to continuously measure soil water content using the dielectric properties of soils. Although CS are calibrated in soils of various types, the default calibrated functions may not work for all conditions as in the case of this soil that has high organic matter content, hence, soil-specific calibrations are sometimes required to achieve reasonable accuracy. This study (1) evaluated the suitability of the default calibrated functions of a Decagon 5<U+2009>T<U+2009>M CS for Andosol (Kuroboku), and (2) derived soil-specific calibration functions to Andosol. A field monitoring experiment was conducted at Sakaecho (western suburb of Tokyo) from August 2016 to July 2017, where volumetric soil water content (<U+03B8>v) was measured in bare field and repacked soils using both gravimetric method with oven drying and CS installed at 5<U+2009>cm depth. The values of <U+03B8>v monitored using soil cores sampled from the field under natural condition and CS revealed large errors under both field and laboratory conditions when the default factory supplied calibration function (FSC) was used. The deviations depicted significant (P<U+2009><<U+2009>0.001) underestimations of the observed <U+03B8>v measured in soil cores by 0.117 - 0.199 and -0.004 - 0.131<U+2009>cm3<U+2009>cm-3 for field and laboratory conditions, respectively. Accordingly, soil-specific calibration functions were developed by correlating the dielectric permittivity of the soil with <U+03B8>v measured from the soil core samples. The <U+03B8>v recalculated based on the site-specific calibration function under field condition best fitted to the observed <U+03B8>v. Calibration of CS improved the <U+03B8>v measurement error from 15% with FSC to = ±2%. Whereas the improvement with laboratory calibration was from ±15% with FSC to ±4% when the function was implemented to the field measured data, hence, it still underestimated the observed field <U+03B8>v. The deviation between the field and laboratory procedures was attributed to the deformation of the well-aggregated soil structure and its consequent changes in hydraulic properties due to crushing when a 2-mm sieve was used for sample preparation. Quasi-field calibration of the 5<U+2009>T<U+2009>M CS under natural condition is highly recommended for real-time monitoring of <U+03B8>v in Andosol. In cases when field calibration is impractical, laboratory calibration further verified with field data could also offer a reliable method for calibration of the 5<U+2009>T<U+2009>M CS for Andosols.","Calibration,Capacitance sensor,Andosol (Kuroboku),Soil water content","Kassu TadesseKassayeab,JulienBoulangec,HirotakaSaitoa,HirozumiWatanabea","Soil and Tillage Research","https://doi.org/10.1016/j.still.2018.12.020","https://www.sciencedirect.com/science/article/pii/S0167198718306226"
"A21","A systematic examination of knowledge loss in open source software projects","Context Open Source Software (OSS) development is a knowledge focused activity which relies heavily on contributors who can be volunteers or paid workers and are geographically distributed. While working on OSS projects contributors acquire project related individualistic knowledge and gain experience and skills, which often remains unshared with others and is usually lost once contributors leave a project. All software development organisations face the problem of knowledge loss as employees leave, but this situation is exasperated in OSS projects where most contributors are volunteers with largely unpredictable engagement durations. Contributor turnover is inevitable due to the transient nature of OSS project workforces causing knowledge loss, which threatens the overall sustainability of OSS projects and impacts negatively on software quality and contributor productivity.,ObjectiveThe objective of this work is to deeply and systematically investigate the phenomenon of knowledge loss due to contributor turnover in OSS projects as presented in the state-of-the-art literature and to synthesise the information presented on the topic. Furthermore, based on the learning arising from our investigation it is our intention to identify mechanisms to reduce the overall effects of knowledge loss in OSS projects.,MethodologyWe use the snowballing methodology to identify the relevant literature on knowledge loss due to contributor turnover in OSS projects. This robust methodology for a literature review includes research question, search strategy, inclusion, exclusion, quality criteria, and data synthesis. The search strategy, and inclusion, exclusions and quality criteria are applied as a part of snowballing procedure.Snowballing is considered an efficient and reliable way to conduct a systematic literature review, providing a robust alternative to mechanically searching individual databases for given topics.,ResultKnowledge sharing in OSS projects is abundant but there is no evidence of a formal strategy or practice to manage knowledge. Due to the dynamic and diverse nature of OSS projects, knowledge management is considered a challenging task and there is a need for a proactive mechanism to share knowledge in the OSS community for knowledge to be reused in the future by the OSS project contributors. From the collection of papers found using snowballing, we consolidated various themes on knowledge loss due to contributor turnover in OSS projects and identified 11 impacts due to knowledge loss in OSS projects, and 10 mitigations to manage with knowledge loss in OSS projects.,ConclusionIn this paper, we propose future research directions to investigate integration of proactive knowledge retention practices with the existing OSS practices to reduce the current knowledge loss problem. We suggest that there is insufficient attention paid to KM in general in OSS, in particular there would appear to an absence of proactive measures to reduce the potential impact of knowledge loss. We also propose the need for a KM evaluation metric in OSS projects, similar to the ones that evaluate health of online communities, which should help to inform potential consumers of the OSS of the KM status on a project, something that is not existent today.","Open Source Software,Knowledge loss,Contributor turnover,Knowledge retention,Knowledge loss impact,Knowledge Management","MehvishRashidab,Paul M.Clarkeab,Rory V.O’Connorab","International Journal of Information Management","https://doi.org/10.1016/j.ijinfomgt.2018.11.015","https://www.sciencedirect.com/science/article/pii/S0268401217310095"
"A22","Essence of digital transformation—Manifestations at large financial institutions from North America","There is focus among most leading academic institutions globally to understand digital transformation. While most operate on some common premise related with the construct of digital transformation there is no established definition yet. Existing descriptions cover a wide range of things from smart living, future of work, automation, industry convergence, and technology among others. These are sometimes fairly all encompassing, inconsistent and incomparable as a point of reference. Interestingly, major consulting firms, technology promoters, independent influencers, analysts promote transformation solutions, each with their own models, interpretation and descriptions.In the paper, we develop an understanding on what is the nature of demand for digital transformation. This is based on evidences of narratives from large financial institutions. We scoped our study on four large banks in North America to see — is there an essence of transformation when institutions adopt digital technology? The paper deals on key themes — drivers, benefits, perception of digital transformation, readiness of banks and deployment instances. Understanding how large financial institutions are adopting digital technologies is important for contemporary technology providers, institutions, researchers and analysts.The study conducted is qualitative along with associated quantitative techniques and visual analytics. This is achieved by theme-based narrative analysis of the public disclosures from four large North American Banks across five years (FY’13–FY’17). The research analyzes the relevant narratives from annual reports to code them into logical themes thereby providing a view of the key focus and associations. Analyzing the practices and manifestations of the institutions this research classifies standard and more advanced differentiating practices. This leads to an emergent structure for a Digital Transformation Maturity Model (DTMM). The authors believe these will serve as indicative maturity guidance for digital technology adoption by financial institutions, in similar context and will also be beneficial to technology providers.","","Himadri SikharPramanika,ManishKirtaniaa,Ashis K.Panib","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.12.003","https://www.sciencedirect.com/science/article/pii/S0167739X18308951"
"A23","Expansin assisted bio-affinity immobilization of endoxylanase from Bacillus subtilis onto corncob residue: Characterization and efficient production of xylooligosaccharides","A one-step method to immobilize xylanase onto cellulosic material by fusion of expansin from Bacillus subtilis to xylanase LC9 without the requirement of prior purification of enzyme has been developed. Fusion enzyme EXLX-R2-XYN was specifically adsorbed onto corncob residue with high loading capacity due to bio-affinity adsorption of expansin onto cellulose. The immobilization yield was close to 100%, with a recovered activity of 82.4%. The immobilized EXLX-R2-XYN retained 45.3% of its activity after incubation at 70<U+202F>°C for 3<U+202F>h, whereas only 16.3% of the activity was left in free form under the same conditions. The conversion yield of XOS by using immobilized EXLX-R2-XYN reached up to 515<U+202F>mg/g xylan from 2% corncob extracted xylan, which was higher than that of the free enzyme. The hydrolysis products were mainly xylobiose (57.5%) and xylotriose (38.4%), without undesirable xylose production. After five cycles of hydrolysis, more than 70% of conversion was obtained.","Endoxylanase,Expansin,Fusion enzyme,Bio-affinity immobilization,Corncob residue,Xylooligosaccharides","BinWua,QiYua,SiyuanChangb,Marcelo MonteiroPedrosoc,ZhenGaoa,BingfangHeb,GerhardSchenkc","Food Chemistry","https://doi.org/10.1016/j.foodchem.2019.01.004","https://www.sciencedirect.com/science/article/pii/S0308814619300251"
"A24","Testing the vertical and cyber-physical integration of cognitive robots in manufacturing","In recent years, cognitive robots have started to find their way into manufacturing halls. However, the full potential of these robots can only be exploited through (a) an integration of the robots with the Manufacturing Execution System (MES), (b) a new and simpler way of programming based on robot skills, automated task planning, and knowledge modeling, and (c) enabling the robots to function in a shared human/robot workspace with the ability to handle unexpected situations. The STAMINA project has built a robotic system that meets these objectives for an automotive kitting application, which has also been tested, validated, and demonstrated in a relevant environment (TRL6). This paper describes the STAMINA robot system and the evaluation of this system on a series of realistic kitting tasks. The structure of the system, evaluation methodology, and experimental results, are presented along with the insights and experiences gained from this work.","Autonomous robot,Robot skills,Kitting","VolkerKruegerab,FrancescoRovidab,BjarneGrossmannb,RonaldPetrickc,MatthewCrosbyc,ArnaudCharzouled,GermanMartin Garciae,SvenBehnkee,CesarToscanof,GermanoVeigaf","Robotics and Computer-Integrated Manufacturing","https://doi.org/10.1016/j.rcim.2018.11.011","https://www.sciencedirect.com/science/article/pii/S0736584517304465"
"A25","Web services-based knowledge sharing, reuse and integration in the design evaluation of mechanical systems","The process of design evaluation is a complicated task for designers due to the need to employ sufficient multi-disciplinary design knowledge. To aid this task, the sharing, reuse and integration of multi-disciplinary knowledge between workers, who play different roles and perform different operations in the design evaluation process, is of great importance. Web services provide an appropriate means to transfer design knowledge between individuals and teams in different disciplines, offering reductions in operation costs and enhanced efficiency, with a better, more streamlined service. This paper identifies and clarifies the knowledge needs required in the design evaluation process, models the knowledge flow among various organizations and the knowledge shared between them, and proposes a web services-based knowledge flow framework to enhance collaboration among various disciplinary experts. An illustrative case is presented to demonstrate how the proposed model may be used to represent design knowledge and integrate it into the design evaluation process. Results from this study contribute significantly to efforts in fulfilling the diverse knowledge needs of workers in the evaluation process. It also helps integrated designers to obtain a clear view of knowledge flow during design evaluation and facilitates knowledge sharing, exchange and reuse among various organizations via a web service-based method.","Web services,Design evaluation,Design knowledge reuse,Knowledge sharing,Knowledge integration,Collaborative design","JunLiu,ZhinanZhang,RichardEvans,YoubaiXie","Robotics and Computer-Integrated Manufacturing","https://doi.org/10.1016/j.rcim.2018.12.010","https://www.sciencedirect.com/science/article/pii/S073658451830187X"
"A26","Functionally graded graphene reinforced porous nanocomposite curved beams: Bending and elastic stability using a higher-order model with thickness stretch effect","Here, the investigation of thick functionally graded graphene platelets reinforced porous nanocomposite curved beams is carried out considering the static bending and elastic stability analyses based on a higher-order shear deformation theory accounting for through-thickness stretching effect. The formulation is general through which different theories can be realized for various structural applications of beam. The governing equations are developed using the Hamilton's principle and are solved by introducing the Navier's solutions. The formulation is firstly assessed considering problems for that results are available in the literature. The performance of various theories is compared here for the selected problems. The structural characteristics of curved beam, constituting of porous metal foam and graphene platelets as nanofillers for reinforcement, are evaluated considering different dispersion patterns for the graphene and porosity, shallowness of the curved beam, thickness ratio, and platelet geometry. The deflection and stress variations in the thickness direction of the beam are also examined.","Porous curved beams,Graphene reinforcement,Higher-order model,Navier's solutions,Bending and buckling","O.Polita,C.Anantb,B.Anirudhb,M.Ganapathib","Composites Part B: Engineering","https://doi.org/10.1016/j.compositesb.2018.11.074","https://www.sciencedirect.com/science/article/pii/S1359836818326969"
"A27","Knowledge model for emergency response based on contingency planning system of China","China is severely exposed to natural hazards. Currently, there are more than 5.5 million contingency plans for handling various incidents. Similar to those produced in other counties, the paper-based plans in China are limited in that emergency responders cannot easily extract helpful information for them. In this paper, a knowledge-based system will be proposed for providing different stakeholders with helpful information in the emergency response. The conceptual model is the core for the whole system, which can link plans in the physical world and the ontology in the cyber world.","Conceptual model,Ontology,Documentary analysis,Top-level ontology,N-ary relation","Zi-jianNia,LiliRonga,NingWanga,ShuoCaoab","International Journal of Information Management","https://doi.org/10.1016/j.ijinfomgt.2018.10.021","https://www.sciencedirect.com/science/article/pii/S0268401218305334"
"A28","Modeling of emotion elicitation conditions for a cognitive-emotive architecture","To cater to the need of embodying emotional behavior in an autonomous agent, there is a need for modeling computationally apt definitions of emotions. A number of emotion theories have been developed that provide an understanding of human psychology and their emotional behaviors, but it is difficult to directly decipher a theory into a computational model of emotion. Nevertheless, these theories together can serve as the theoretical foundation for designing a model for emotion-eliciting conditions. In this study, the salient features of OCC, Scherer, and Roseman theories of emotions are identified, which complement each other. The features are unified and standardized to bring consistency in deriving the computationally apt definition of five emotions viz. Happiness/Joy, Sadness, Fear, Anger, and Surprise. The objective of this hybridization is to set a ground framework for appraising the emotion-triggering cues (e.g., an event) for a simple, flexible and tolerant computational model of emotions. The underlying emotion-eliciting processes are designed using Fuzzy Logic. Fuzzy rules are framed to model the conditions behind emotion elicitation. Furthermore, the ISEAR data set and the real test-case scenarios are used to validate the accuracy of emotion prediction and rule fulfillment respectively.","Emotion theory,Cognitive-emotive architecture,Affective computing,Emotion model,Emotional agent,Emotion modeling,Computational model of emotion","ShikhaJain,KrishnaAsawa","Cognitive Systems Research","https://doi.org/10.1016/j.cogsys.2018.12.012","https://www.sciencedirect.com/science/article/pii/S1389041717301602"
"A29","Business intelligence and analytics for value creation: The role of absorptive capacity","Firms continuously report increased competitive value gains from the use of business intelligence and analytics (BI&A), however, little is known about how insights from BI&A are transformed to added value to date. We have conducted fourteen in-depth, semi-structured interviews with a sample of informants in CEO positions, IT managers, CIO, Heads of R&D, as well as Market Managers from nine medium or large-sized European firms. Applying the absorptive capacity’s theoretical lens, we have provided evidence that absorptive capacity’s capabilities are an underlying foundation in the process of transforming BI&A triggered insights into valuable knowledge. Moreover, this process is supported by technological, human, and relationship assets.","Business intelligence and analytics,Value,Insights,Absorptive capacity,Assets","KaterinaBožic,VladoDimovski","International Journal of Information Management","https://doi.org/10.1016/j.ijinfomgt.2018.11.020","https://www.sciencedirect.com/science/article/pii/S0268401218301701"
"A30","Parametric sizing optimization process of a casing for a Savonius Vertical Axis Wind Turbine","The aim of this work is to improve the performance of a Savonius Vertical Axis Wind Turbine (VAWT) by sizing a suitable rotor guide plates configuration, or what is called a turbine’s casing, using Computational Fluid Dynamics (CFD) technique. Starting from a proposed baseline casing design, a 2-D parametric optimization process was followed, where several design parameters pertaining to the casing’s geometry were assigned and optimized. Owing to the limitations of the 2-D numerical simulations, the optimized casing dimensions were extracted and used to carry out 3-D numerical investigations. The turbine with the optimized casing readily performed better than the caseless one, especially at lower Tip Speed Ratios (TSR). In addition, the obtained results showed that there exist no universal optimal values for the casing dimensions that maintain peak turbine performance at all TSRs. Thus, a clear trend relating all the optimized casing dimensions to the TSR was established.","Savonius wind turbine,Parametric optimization,CFD,Savonius casing","E.Antar,M.Elkhoury","Renewable Energy","https://doi.org/10.1016/j.renene.2018.12.092","https://www.sciencedirect.com/science/article/pii/S0960148118315398"
"A31","Astrocyte identity: evolutionary perspectives on astrocyte functions and heterogeneity","","","YongjieYang12,RobJackson12","Current Opinion in Neurobiology","https://doi.org/10.1016/j.conb.2018.11.006","https://www.sciencedirect.com/science/article/pii/S0959438818301971"
"A32","Layer-specific expression of extracellular matrix molecules in the mouse somatosensory and piriform cortices","In the developing central nervous system (CNS), extracellular matrix (ECM) molecules have regulating roles such as in brain development, neural-circuit maturation, and synaptic-function control. However, excluding the perineuronal net (PNN) area, the distribution, constituent elements, and expression level of granular ECM molecules (diffuse ECM) present in the mature CNS remain unclear. Diffuse ECM molecules in the CNS share the components of PNNs and are likely functional. As cortical functions are greatly region-dependent, we hypothesized that ECM molecules would differ in distribution, expression level, and components in a region- and layer-dependent manner. We examined the layer-specific expression of several chondroitin sulfate proteoglycans (aggrecan, neurocan, and brevican), tenascin-R, Wisteria floribunda agglutinin (WFA)-positive molecules, hyaluronic acid, and link protein in the somatosensory and piriform cortices of mature mice. Furthermore, we investigated expression changes in WFA-positive molecules due to aging. In the somatosensory cortex, PNN density was particularly high at layer 4 (L4), but not all diffuse ECM molecules were highly expressed at L4 compared to the other layers. There was almost no change in tenascin-R and hyaluronic acid in any somatosensory-cortex layer. Neurocan showed high expression in L1 of the somatosensory cortex. In the piriform cortex, many ECM molecules showed higher expression in L1 than in the other layers. However, hyaluronic acid showed high expression in deep layers. Here, we clarified that ECM molecules differ in constituent elements and expression in a region- and layer-dependent manner. Region-specific expression of ECM molecules is possibly related to functions such as region-specific plasticity and vulnerability.","a.u.arbitrary units,ChABCchondroitinase ABC,CNScentral nervous system,CSPGchondroitin sulfate proteoglycans,ECMextracellular cellular matrix,HABPhyaluronic acid binding protein,HAhyaluronic acid,Hapln1hyaluronan and proteoglycan link protein 1,PNNperineuronal ntes,WFAWisteria floribunda agglutinin,Keywords,Extracellular matrix,Perineuronal nets,Piriform cortex,Proteoglycans,Somatosensory cortex,Wisteria floribunda","HiroshiUenoa,ShunsukeSuemitsub,ShinjiMurakamib,NaoyaKitamurab,KentaWanib,YosukeMatsumotoc,MotoiOkamotod,TakeshiIshiharab","IBRO Reports","https://doi.org/10.1016/j.ibror.2018.11.006","https://www.sciencedirect.com/science/article/pii/S2451830118300773"
"A33","A transformation-free <U+03C8>-v formulation of the Navier–Stokes equations on compact nonuniform grids","In this work, we have developed a second order accurate compact finite difference scheme for the biharmonic form of the steady-state Navier–Stokes (N–S) equations on nonuniform Cartesian grids without transformation. Contrary to the schemes developed on rectangular Cartesian grids for N–S equations that could handle only rectangular boundaries, the proposed scheme can easily accommodate bluff bodies with curved boundary. The scheme is applied to one problem having analytical solution and three fluid flow problems having different complexities. While one of them, viz., the lid-driven cavity depict internal flows, the flow past a circular cylinder and a flat plate immersed in uniform flow represents external flows. The scheme is shown to handle both Dirichlet and Neumann boundary conditions with equal ease. The efficiency of the scheme is demonstrated not only by its ability to capture smaller scales up to post quaternary level of vortices for the flow in lid-driven cavity, but also its robustness in handling non-rectangular boundaries of immersed bodies. While the scheme has handled the boundary of an immersed body not necessarily aligned to the grid lines for one of the problems, for another, it has tackled a curved boundary on Cartesian grid without the need of roping in any immersed interface in the process. Its efficiency is further asserted by the proximity of the computed solutions to available experimental results.","<U+03C8>-v formulation,Navier–Stokes,Curved boundary,Post-quaternary vortex,Inclined flat plate,Circular cylinder","PankajKumara,Jiten C.Kalitab","Journal of Computational and Applied Mathematics","https://doi.org/10.1016/j.cam.2018.12.035","https://www.sciencedirect.com/science/article/pii/S0377042718307660"
"A34","Gelation and microstructural properties of protein hydrolysates from trypsin-treated male gonad of scallop (Patinopecten yessoensis) modified by <U+03BA>-Carrageenan/K+","This article reported the gelation and microstructural properties of scallop male gonads hydrolysates (SMGHs) in the presence of <U+03BA>-Carrageenan (<U+03BA>-C) and treated or untreated with potassium chloride (KCl). The presence of <U+03BA>-C significantly increased the elastic moduli (10.3–449.5<U+202F>Pa) and melting temperature (32.7–46.7<U+202F>°C) of SMGHs. The decrease in the relaxation time (T21, T23) signified the strong binding between SMGHs and <U+03BA>-C. The blue shift in the amide I and II peals coupled with a new band of 1159<U+202F>cm-1 in SMGHs/<U+03BA>-C further demonstrated the electrostatic interactions between SMGHs and <U+03BA>-C. <U+03BA>-C rose the percentage of ß-sheets from 28.10% to 35.93% but at the expense of a-helix and ß-turn fractions and highly ebbed the intrinsic fluorescence of SMGHs. Such scenarios resulted in a more compact network formation and flocculation of <U+03BA>-C chains. The salt-treatment to <U+03BA>-C promoted helical formation, however, presence of SMGHs created larger interstitial spaces in the <U+03BA>-C network due to aggregates of SMGHs and decreased the overall gel strength. The outcome promises novel opportunities in the design and development of functional hydrogels based on protein and polysaccharide complexes for food, pharmaceutical and biomedical applications.","Scallop,Male gonad hydrolysates,<U+03BA>-Carrageenan,Potassium chloride,Gelation,Abbreviations,SMGHsscallop male gonad hydrolysates,<U+03BA>-C<U+03BA>-Carrageenan,LF-NMRlow-field NMR,FTIRfourier transform infrared spectroscopy,CDcircular dichroism,cryo-SEMcryo-scanning electron microscopy,CLSMconfocal laser scanning microscopy,SMGsscallop male gonads,FITCfluorescein isothiocyanate,RITCrhodamine B isothiocyanate,LVRlinear viscoelastic region,T2transverse spin-spin","Jia-NanYana,Wen-HuiShanga,JunZhaob,Jia-RunHana,Wen-GangJinc,Hai-TaoWangab,Yi-NanDua,Hai-TaoWuab,SrinivasJanaswamyd,Youling L.Xionge,Bei-WeiZhuab","Food Hydrocolloids","https://doi.org/10.1016/j.foodhyd.2019.01.024","https://www.sciencedirect.com/science/article/pii/S0268005X18314966"
"A35","VR-PROUD: Vehicle Re-identification using PROgressive Unsupervised Deep architecture","Vehicle re-identification (Re-ID) is one of the primary components of an automated visual surveillance system. It aims to automatically identify/search vehicles in a multi-camera network usually having non-overlapping field-of-views. Majority of the approaches dealing with the re-ID problem tackle it in a supervised manner which have certain limitations that pose challenges of generalization e.g., large amount of annotated data is required for training and is often limited to the dynamic growth of the data. Unsupervised learning techniques can potentially cope with such issues by drawing inference directly from the unlabeled input data and have been effectively employed in the context of person re-ID. To this end, this paper presents an approach that essentially formulates the whole vehicle re-ID problem into an unsupervised learning paradigm using a progressive two step cascaded framework. It combines a CNN architecture for feature extraction and an unsupervised technique to enable self-paced progressive learning. It also incorporates the contextual information into the proposed progressive framework that significantly improves the convergence of the learned algorithm. Moreover, the approach is generic and has been the first attempt to tackle the vehicle re-ID problem in an unsupervised manner. The performance of the proposed algorithm has been thoroughly analyzed over two large publically available benchmark datasets VeRi and VehicleID for vehicle re-ID using image-to-image and cross-camera search strategies and achieved better performance in comparison to current state-of-the-art approaches using standard evaluation metrics.","Vehicle re-id,Deep learning,Unsupervised,Clustering,Visual surveillance,Progressive learning,Self pace","R.M.S.Bashira,M.Shahzadab,M.M.Frazabcd","Pattern Recognition","https://doi.org/10.1016/j.patcog.2019.01.008","https://www.sciencedirect.com/science/article/pii/S0031320319300147"
"A36","Optimization of the protein extraction method of goat meat using factorial design and response surface methodology","Protein extraction from goat meat was carried out based on the combination of response surface methodology and factorial design to optimize the variables: temperature (25–50<U+202F>°C), extraction time (8–20<U+202F>min), volume (3–10<U+202F>mL) and extractor concentration (0.05–0.1<U+202F>mol<U+202F>L-1). The proposed model did not present a lack of fit, explaining 96% of the total data variance (R2<U+202F>=<U+202F>0.96). The optimum extraction conditions were: 0.05<U+202F>mol<U+202F>L-1 for extractor concentration, extraction time of 10<U+202F>min, temperature of 44<U+202F>°C and extractor volume of 3.5<U+202F>mL. The protein content (19.3<U+202F>g/100<U+202F>g) obtained by the optimized method was higher than some results reported in the literature. HPLC-SEC-DAD analysis revealed that the extraction conditions used did not significantly modify the protein structure. The proposed method proves to be simple, fast, robust, cheap and adequate for native protein extraction, being a potential approach for proteomic research focusing in goat meat.","Goat’s meat,Proteins extraction,Factorial design,Response surface methodology,HPLC-SEC-DAD","Tiago Linus SilvaCoelhoa,Francislene Machado SilvaBragab,Naise Mary CaldasSilvaa,ClecioDantasc,Cícero AlvesLopes Júniorab,Samuel Anderson Alvesde Sousaab,Edivan CarvalhoVieiraa","Food Chemistry","https://doi.org/10.1016/j.foodchem.2018.12.055","https://www.sciencedirect.com/science/article/pii/S0308814618321599"
"A37","Recent advances in the theory and practice of Logical Analysis of Data","Logical Analysis of Data (LAD) is a data analysis methodology introduced by Peter L. Hammer in 1986. LAD distinguishes itself from other classification and machine learning methods by the fact that it analyzes a significant subset of combinations of variables to describe the positive or negative nature of an observation and uses combinatorial techniques to extract models defined in terms of patterns. In recent years, the methodology has tremendously advanced through numerous theoretical developments and practical applications. In the present paper, we review the methodology and its recent advances, describe novel applications in engineering, finance, health care, and algorithmic techniques for some stochastic optimization problems, and provide a comparative description of LAD with well-known classification methods.","Logical analysis of data,Boolean mathematics,Pattern,Data mining,Combinatorial optimization","MiguelLejeunea,VadimLozinb,IrinaLozinab,AhmedRagabcd,SoumayaYacoutc","European Journal of Operational Research","https://doi.org/10.1016/j.ejor.2018.06.011","https://www.sciencedirect.com/science/article/pii/S0377221718305344"
"A38","Excitation-emission fluorescence-kinetic third-order/four-way data: Determination of bisphenol A and nonylphenol in food-contact plastics","The endocrine disrupting chemicals bisphenol A (BPA) and 4-nonylphenol (NP) were simultaneously quantified through third-order/four-way calibration. Excitation-emission fluorescence matrix-kinetic (EEFM-K) third-order data were generated by measuring the EEFMs of these priority xenoestrogens as a function of reaction time during their Fenton degradation. Third-order/four-way calibration notably improves the sensitivity of the method and provides the required selectivity for quantifying analytes with critically overlapped fluorescence signals. In fact, collinearity between BPA and NP emission spectra prevented their quantification using EEFM second-order data and three-way PARAFAC (parallel factor analysis); however, the addition of a third instrumental mode allowed the correct chemometric modeling with four-way PARAFAC. In this way, the compliance of Kruskal's theorem extended to higher-order data was verified. The method was applied for the determination of the analytes in samples of different plastic materials, which are in contact with food and/or beverages. In these cases, where unmodelled constituents are present, good results for BPA were achieved with four-way PARAFAC, but the predictions for NP using this model were deficient. A better predictive capability for NP in real samples was achieved when either U-PLS/RTL (unfolded partial least-squares combined with residual trilinearization) or MCR-ALS (multivariate curve resolution with alternating least-squares) was applied for data processing, demonstrating the power of these latter models for the resolution of more complex systems.","Multi-way calibration,Excitation-emission fluorescence matrix-kinetic data,Bisphenol A,4-Nonylphenol","Maira D.Carabajal,Juan A.Arancibia,Graciela M.Escandar","Talanta","https://doi.org/10.1016/j.talanta.2019.01.045","https://www.sciencedirect.com/science/article/pii/S0039914019300451"
"A39","Deep understanding in industrial processes by complementing human expertise with interpretable patterns of machine learning","Experts in industrial processes rely on domain knowledge (DK) repositories to identify the causes of abnormal situations in order to make appropriate decisions that mitigate the negative effects of such events. These DK repositories need to be enriched and updated continuously as different unexpected events occur. A common causality analysis method in DK repositories is the fault tree analysis (FTA). The major limitation of updating a fault tree is that it requires in-depth system knowledge, which involves a high level of human experience. Data exploitation based on machine learning (ML) can address this limitation by deeply analyzing process historical data to discover hidden phenomena that are difficult for human experts to identify and to analyze. This paper proposes an innovative methodology that combines domain knowledge, in the form of FTA, with additional knowledge extracted by a descriptive ML method called logical analysis of data (LAD). More specifically, LAD is a classification method, which provides as a by-product a set of interpretable rules (patterns) explaining the classification results. The patterns extracted from historical data represent an important and complementary source of knowledge that provides experts with insights and allows them to better understand the process operations. The objective of using these patterns in the proposed methodology is to provide automatic enrichment and updating of existing fault trees in order to achieve accurate fault detection and diagnosis (FDD) in industrial processes. The proposed methodology is demonstrated using fault trees constructed for two different systems in the process industry. The fault tree for each system was updated successfully with minimal effort from process experts.","Fault detection and diagnosis (FDD),Logical analysis of data (LAD),Fault tree analysis (FTA),Machine learning and pattern recognition,Causality analysis","AhmedRagababc,MohamedEl Koujokb,HakimGhezzazb,MouloudAmazouzb,Mohamed-SalahOualia,SoumayaYacouta","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2019.01.011","https://www.sciencedirect.com/science/article/pii/S0957417419300107"
"A40","Design of a noise reduction passive control system based on viscoelastic multilayered plate using PDSO","The sound transmission and insulation of aeronautical panels represents one of the major problem of the aircraft comfort. In the present work, a plate finite element with advanced higher-order kinematic field is proposed for the analysis of noise reduction passive control system in laminated structures. A novel Decline Population Swarm Optimization (PDSO) procedure is introduced and used to select the optimal parameters for the sound control. The present sound insulation passive control is based on Finite Elements obtained by applying the Principle of Virtual Displacements, taking into account the frequency dependence of the viscoelastic material, making use of higher-order Layer-Wise theories, and employing the Mixed Interpolated Tensorial Components (MITC) method to contrast the shear locking effect. The PDSO procedure is based on a decline demographic model and is characterized by high global search capabilities with reduced computational costs. The acoustic insulation of the panels is evaluated by computing its sound transmission factor using Rayleigh integral method. Several numerical investigations are carried out to validate and demonstrate the accuracy and efficiency of the acoustic optimization procedure for the design of viscoelastic plates.","Plate elements,PDSO,Noise reduction,Viscoelastic","S.Valvano,C.Orlando,A.Alaimo","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2019.01.011","https://www.sciencedirect.com/science/article/pii/S0888327019300111"
"A41","Iron-based photocatalytic and photoelectrocatalytic nano-structures: Facts, perspectives, and expectations","The increasing demand for clean renewable energy needed for sustainable industrial progress and population growth is the driving force for the scientific community to achieve a continuous development in the field of photocatalysis and photoelectrochemistry. Nanostructures and nanomaterials have contributed significantly to the field of renewable energy due to their new physicochemical properties. Iron-based nanostructures have considerable advantages like small band gaps, allowing to harvest photons in the visible region of the solar spectrum, abundance, and important physical properties like magnetism and ferroelectricity. But they also have many shortcomings and drawbacks related to stability in the different photocatalytic media, low surface area, conductivity, and fast charge carrier recombination. In this review, the focus is placed on important members of the iron-based photocatalyst family such as, hematite, iron oxy-hydroxide, iron-based perovskites, and spinel ferrites. Also, iron doped titanium dioxide as visible light photocatalysts is covered. Various strategies employed for enhancing the photocatalytic and photoelectrocatalytic performance are discussed. Doping, oxygen vacancies, induced defects and formation of solid solutions seem to be a working strategy to address some of the challenges in photocatalysis and photoelectrocatalysis. Finally, photocatalytic and photoelectrocatalytic applications employing iron-based semiconductors are presented.","Photocatalysis,Photoelectrocatalysis,Iron-based,Nanostructures,Perovskites,Ferrites","YamenAlSalkaab,Luis I.Granoneab,WegdanRamadanabc,AmerHakkid,RalfDillertab,Detlef W.Bahnemannabe","Applied Catalysis B: Environmental","https://doi.org/10.1016/j.apcatb.2018.12.014","https://www.sciencedirect.com/science/article/pii/S0926337318311676"
"A42","Encoding decisions and expertise in the operator's eyes: Using eye-tracking as input for system adaptation","We investigated the possibility of developing a decision support system (DSS) that integrates eye-fixation measurements to better adapt its suggestions. Indeed, eye fixation give insight into human decision-making: Individuals tend to pay more attention to key information in line with their upcoming selection. Thus, eye-fixation measures can help the DSS to better capture the context that determines user decisions. Twenty-two participants performed a simplified Air Traffic Control (ATC) simulation in which they had to decide to accept or to modify route suggestions according to specific parameter values displayed on the screen. Decisions and fixation times on each parameter were recorded. The user fixation times were used by an algorithm to estimate the utility of each parameter for its decision. Immediately after this training phase, the algorithm generated new route suggestions under two conditions: 1) Taking into account the participant's decisions, 2) Taking into account the participant's decisions plus their visual behavior using the measurements of dwell times on displayed parameters. Results showed that system suggestions were more accurate than the base system when taking into account the participant's decisions, and even more accurate using their dwell times. Capturing the crucial information for the decision using the eye tracker accelerated the DSS learning phase, and thus helped to further enhance the accuracy of consecutive suggestions. Moreover, exploratory eye-tracking analysis reflected two different stages of the decision-making process, with longer dwell times on relevant parameters (i.e. involved in a rule) during the entire decision time course, and frequency of fixations on these relevant parameters that increased, especially during the last fixations prior to the decision. Consequently, future DSS integrating eye-tracking data should pay specific care to the final fixations prior to the decision. In general, our results emphasize the potential interest of eye-tracking to enhance and accelerate system adaptation to user preference, knowledge, and expertise.","Eye-tracking,Human factors,Decision-making,Air Traffic Control,Adaptive system,Machine learning,Case-Based Reasoning","MickaëlCaussea,FrançoisLancelotab,JordanMaillanta,JuliaBehrendc,MathieuCousyd,NicolasSchneiderb","International Journal of Human-Computer Studies","https://doi.org/10.1016/j.ijhcs.2018.12.010","https://www.sciencedirect.com/science/article/pii/S1071581918306888"
"A43","A new methodology for automated Petri Net generation: Method application","","Risk and reliability,Automatic Petri Net generation,UML Activity Diagram,Model transformation,MySQL database","ChristinaLatsou,Sarah J.Dunnett,Lisa M.Jackson","Reliability Engineering & System Safety","https://doi.org/10.1016/j.ress.2018.12.017","https://www.sciencedirect.com/science/article/pii/S0951832017312073"
"A44","Innovative screening approach for the identification of triacylglycerol accumulating oleaginous strains","Currently, triacylglycerides (TAG) accumulation in the form of lipid droplets (LDs) in oleaginous microorganisms is of immense importance due to their ability to get transesterified into value-added products in the form of biodiesel. Hence, in order to search for oleaginous microorganisms having high lipid content among a wide range of samples from different niches, there is a compulsive need to develop simple, reliable and rapid methods for screening of TAG accumulating strains. Conventional methods require multistep processes for the isolation, cultivation, extraction and estimation of lipids to identify oleagenic strains. To overcome these challenges, we are proposing an easy, live cell imaging technique for the estimation of lipids via visualization of TAG accumulation in probable strains at the single cell level that gives real-time monitoring of intracellular lipid accumulation in yeasts. In this screening technique, only 100<U+202F>µl of specific neutral lipid accumulating medium was used to grow the isolated culture in the microtiter plate. The harvested cells were stained with LipidTOX™ Green and visualized by a LED based digital inverted fluorescence microscope. Among 446 yeast colonies screened, maximum lipid producing yeast strains Rhodosporidium kratochvilovae HIMPA1 and Rhodotorula minuta, having supersized lipid body of 5.05<U+202F>±<U+202F>0.87<U+202F>µm and 4.46<U+202F>±<U+202F>0.61<U+202F>µm, respectively, were identified as potential candidates for biodiesel production. To the best of our knowledge, this is the first report of using LipidTOX™ Green for the staining of lipid droplets present in yeast cells as per the literature.","Oleaginous microorganisms,Live fluorescence microscopy,Triacylglycerides (TAG),Lipid droplets (LDs),LipidTOX™ green,Biodiesel","AlokPatelab,VikasPruthiac,Parul A.Pruthia","Renewable Energy","https://doi.org/10.1016/j.renene.2018.12.078","https://www.sciencedirect.com/science/article/pii/S0960148118315258"
"A45","Adaptive event-triggered anomaly detection in compressed vibration data","Anomaly detection is a crucial task in Prognostics and Condition Monitoring (PCM) of machinery. In modern remote PCM systems, data compression techniques are regularly used to reduce the need for bandwidth and storage. In these systems the challenge arises of how the compressed (distorted) vibration data affects the condition monitoring algorithms. This paper introduces a novel algorithm that can adaptively establish normal bounds of operation from continuous noisy vibration profiles working with compressed vibration data. The proposed technique is based on four modules, including feature extraction, feature fusion, extreme value vibration modeling and adaptive thresholding for anomaly detection. The proposed method has been validated with experiments using three time-series datasets. The experimental results indicate that the proposed algorithm is able to perform detection of malfunctions in rotating machines effectively without faulty reference data. Moreover, the proposed method is able to produce accurate early warning and alarm indications from both the raw and compressed (distorted) datasets with equal veracity.","Machine faulty detection,Health status modeling,Adaptive learning,Signal compression","YangZhangab,PaulHutchinsonc,Nicholas A.J.Lievena,JoseNunez-Yanezb","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.12.039","https://www.sciencedirect.com/science/article/pii/S0888327018308161"
"A46","Assessment of the properties of chitin deacetylases showing different enzymatic action patterns","Chitin deacetylases are a group of enzymes catalysing the conversion of chitin to chitosan. Obtaining chitosan with established deacetylation degree and pattern is important for biomedical and biotechnological applications. Understandings of the structural properties of chitin deacetylases and the specificity of their interactions with chitin may conduct to the control of the pattern of deacetylation of chitosan. Our study is focused on the characterization and comparison of the structural and physicochemical properties of chitin deacetylases from fungi and marine bacteria. Despite the low sequences identity for the investigated chitin deacetylases, there are amino acids belonging to their active sites that are strongly conserved. Moreover, they reveal an increased structural similarity of their catalytic domains, reflecting the common biological function of these enzymes. The studied enzymes present dissimilar local physicochemical properties of their catalytic cavities that could be responsible of their distinct deacetylation patterns. Molecular docking studies reflect that deacetylation efficiency is also distinct for the chitin and partially deacetylated chitin oligomers and that N-acetylglucosamine units and some partially deacetylated chitin oligomers could have inhibitory effect against chitin deacetylases belonging to fungi and marine bacteria.","Chitin deacetylases,Deacetylation pattern,Structure comparison,Physiochemical properties,Molecular docking,Catalytic cavities","Diana LarisaRomana,MarinRomana,HavardSlettab,VasileOstafea,AdrianaIsvorana","Journal of Molecular Graphics and Modelling","https://doi.org/10.1016/j.jmgm.2019.01.002","https://www.sciencedirect.com/science/article/pii/S1093326318307988"
"A47","Risk analysis for consumer-level utility gas and liquefied petroleum gas incidents using probabilistic network modeling: A case study of gas incidents in Japan","Utility gas and liquefied petroleum gas (LPG) are commonly used in Japan for their convenience as fuels for household and commercial needs. Although several efforts have been made to promote the safe use of gas, more gas accidents occur at the consumer level than in gas production facilities or in the supply chain. Incident investigations can acquire facts about the causes and effects of these accidents. In this paper, we propose a probabilistic network modeling approach in which the inherent characteristics of risk factors for consumer-level gas incidents are considered. In the approach, cause–effect chains are formulated for gas incidents, and network diagrams with probabilistic estimations are constructed to indicate the structure behind the occurrence of such incidents. The investigation shows that most gas incidents are caused by more than one risk factor, and one risk factor tends to cascade into others. These risk factors can be clustered according to their nature and can also be classified as originating causes or intermediate risk factors by analyzing their interdependencies in network diagrams. By identifying significant intermediate effects together with their causes, these risk factors can be reduced, which may reduce the occurrence of serious gas incidents at the consumer level.","Safety analysis,Incident investigation,Complex network theory,Gas incidents,Case study in Japan","C.Y.LAMa,A.M.CRUZb","Reliability Engineering & System Safety","https://doi.org/10.1016/j.ress.2018.12.008","https://www.sciencedirect.com/science/article/pii/S0951832018307026"
"A48","Coupling privileged kernel method for multi-view learning","Multi-view learning concentrates on fully using the data collected from diverse domains or obtained from various feature extractors to learn effectively. The consensus and complementarity principles provide significant guidance in multi-view modeling. Many support vector machine (SVM)-based multi-view learning models have been proposed, which mainly follow the consensus principle through exploiting the label correlation with regularization terms. In this paper, we propose a simple yet effective coupling privileged kernel method for multi-view learning, termed as MCPK. The coupling term included in the primal objective allows the combination of the errors from all views to be minimized, which guarantees the consensus principle. Similar to our previous work PSVM-2V, MCPK realizes the complementarity principle by applying the learning using privileged information (LUPI) paradigm. The proposed model not only fully integrates the information from all views in the learning process, but also maintains the characteristic of different views to some extent. We employ the standard quadratic programming solver to solve MCPK. Further more, we theoretically analyze the performance of MCPK from the viewpoints of the generalization capability and the PSVM-2V and SVM-2K models. Experimental results demonstrate that MCPK compares more favorably than other state-of-the-art multi-view algorithms in terms of classification accuracy and efficiency.","Multi-view learning,Coupling term,Privileged information,Support vector machine,Consensus and complementarity principles","JingjingTanga,YingjieTianbcd,DalianLiue,GangKoua","Information Sciences","https://doi.org/10.1016/j.ins.2018.12.058","https://www.sciencedirect.com/science/article/pii/S0020025518310090"
"A49","Flow-based network traffic generation using Generative Adversarial Networks","Flow-based data sets are necessary for evaluating network-based intrusion detection systems (NIDS). In this work, we propose a novel methodology for generating realistic flow-based network traffic. Our approach is based on Generative Adversarial Networks (GANs) which achieve good results for image generation. A major challenge lies in the fact that GANs can only process continuous attributes. However, flow-based data inevitably contain categorical attributes such as IP addresses or port numbers. Therefore, we propose three different preprocessing approaches for flow-based data in order to transform them into continuous values. Further, we present a new method for evaluating the generated flow-based network traffic which uses domain knowledge to define quality tests. We use the three approaches for generating flow-based network traffic based on the CIDDS-001 data set. Experiments indicate that two of the three approaches are able to generate high quality data.","GANs,TTUR WGAN-GP,NetFlow,Generation,IDS","MarkusRinga,DanielSchlörb,DieterLandesa,AndreasHothob","Computers & Security","https://doi.org/10.1016/j.cose.2018.12.012","https://www.sciencedirect.com/science/article/pii/S0167404818308393"
"A50","Neutrosophic rule-based prediction system for toxicity effects assessment of biotransformed hepatic drugs","Measuring toxicity is an important step in drug development. However, the current experimental methods which are used to estimate the drug toxicity are expensive and need high computational efforts. Therefore, these methods are not suitable for large-scale evaluation of drug toxicity. As a consequence, there is a high demand to implement computational models that can predict drug toxicity risks. In this paper, we used a dataset that consists of 553 drugs that biotransformed in the liver. In this data, there are four toxic effects, namely, mutagenic, tumorigenic, irritant and reproductive effects. Each drug is represented by 31 chemical descriptors. This paper proposes two models for predicting drug toxicity risks. The proposed models consist of three phases. In the first phase, the most discriminative features are selected using rough set-based methods to reduce the classification time and improve the classification performance. In the second phase, three different sampling algorithms, namely, Random Under-Sampling, Random Over-Sampling, and Synthetic Minority Oversampling Technique (SMOTE) are used to obtain balanced data. In the third phase, the first proposed model employs the Neutrosophic Rule-based Classification System (NRCS), and the second model uses Genetic NRCS (GNRCS) to classify an unknown drug into toxic or non-toxic. The experimental results proved that the proposed models obtained high sensitivity (89–93%), specificity (91–97%), and GM (90–94%) for all toxic effects. Overall, the results of the proposed models indicate that it could be utilized for the prediction of drug toxicity in the early stages of drug development.","Toxic effects,Drugs design,Neutrosophic theory,Rule-based classification,Prediction model","Sameh H.Bashaa,AlaaTharwat1bd,AreegAbdallaa,Aboul EllaHassaniencd","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.12.014","https://www.sciencedirect.com/science/article/pii/S0957417418307760"
"A51","Transformation from IT-based knowledge management into BIM-supported knowledge management: A literature review","Construction is a knowledge-intensive industry, in which organizations are known for the delivery of products and services, relying on different types of knowledge. To manage knowledge effectively, various information technology (IT) models and systems have been developed for knowledge management (KM) in the construction industry over the years. As the next generation of IT application in construction, building information modeling (BIM) is increasingly used today to aid KM. Compared to generic IT tools, BIM has some distinctive features, such as parametric modeling, virtual visualization and centralized platform. However, how to apply these features of BIM to better serve KM has not yet been well summarized and analyzed. In this research, 115 papers on IT-based KM and 73 papers on BIM-supported KM are reviewed, based on which an integrated framework is developed to describe the current status and future directions for KM in IT-generic and BIM-specific contexts. It is followed by a conceptual model of BIM-supported KM which shows the possible KM factors and their relationships in the BIM environment. This research highlights the transformation from IT-based KM into BIM-supported KM. It contributes to the identification of remaining challenges to BIM-supported KM and the elaboration of BIM-supported KM in construction research and practice.","Construction industry,Building information modeling,Knowledge management","HaoWang,XianhaiMeng","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.12.017","https://www.sciencedirect.com/science/article/pii/S0957417418307796"
"A52","Cost-based temporal reasoning","Reasoning about the behavior of real-world systems and processes faces problems such as repeating events or subprocesses, evolving component behaviors, and indefinite time horizons. To date, existing representations of time and uncertainty have been unable to fully address such requirements. They often tradeoff assumptions of available knowledge against richness of representing time and semantics for uncertainty. This has made representations either overly simplistic or cumbersome to model with, or both. In this paper, we present a new theoretical representation for reasoning about time and uncertainty extending our ability to better address real-world systems. Called cost-based temporal reasoning, we believe it is simple to understand, is rigorously defined, and allows for strong semantics of time and uncertainty. This paper formally details the definitions and proofs about the capabilities of cost-based temporal reasoning.","Uncertainty reasoning,Temporal reasoning,Cost-based reasoning,Probabilistic semantics,Representation,Modeling","EugeneSantosJr.","Information Sciences","https://doi.org/10.1016/j.ins.2019.01.037","https://www.sciencedirect.com/science/article/pii/S0020025519300453"
"A53","Workflow-based automatic processing for Internet of Floating Things crowdsourced data","Data from sensors incorporated into mobile devices, such as networked navigational sensors, can be used to capture detailed environmental information. We describe here a workflow and framework for using sensors on boats to construct unique new datasets of underwater topography (bathymetry). Starting with a large number of measurements of position, depth, etc., obtained from such an Internet of Floating Things, we illustrate how, with a specialized protocol, data can be communicated to cloud resources, even when using delayed, intermittent, or disconnected networks. We then propose a method for automatic sensor calibration based on a novel reputation approach. Sampled depth data are interpolated efficiently on a cloud computing platform in order to provide a continuously updated bathymetric database. Our prototype implementation uses the FACE-IT Galaxy workflow engine to manage network communication and exploits the computational power of GPGPUs in a virtualized cloud environment, working with a CUDA-parallel algorithm, for efficient data processing. We report on an initial evaluation involving data from a sailing vessel in Italian coastal waters.","Workflows,Data crowd sourcing,Mobile computing,Cloud computing,GPGPU virtualization,Internet of Things,Bathymetry interpolation","RaffaeleMontellaab,DianaDi Luccioab,LiviaMarcellinoa,ArdelioGallettia,SokolKostad,GiulioGiuntaa,IanFosterbce","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.11.025","https://www.sciencedirect.com/science/article/pii/S0167739X18307672"
"A54","Loss of inhibitory synapses causes locomotor network dysfunction of the rat spinal cord during prolonged maintenance in vitro","The isolated spinal cord of the neonatal rat is widely employed to clarify the basic mechanisms of network development or the early phase of degeneration after injury. Nevertheless, this preparation survives in Krebs solution up to 24<U+202F>h only, making it desirable to explore approaches to extend its survival for longitudinal studies. The present report shows that culturing the spinal cord in oxygenated enriched Basal Medium Eagle (BME) provided excellent preservation of neurons (including motoneurons), glia and primary afferents (including dorsal root ganglia) for up to 72<U+202F>h. Using DMEM medium was unsuccessful. Novel characteristics of spinal networks emerged with strong spontaneous activity, and deficit in fictive locomotion patterns with stereotypically slow cycles. Staining with markers for synaptic proteins synapsin 1 and synaptophysin showed thoroughly weaker signal after 3<U+202F>days in vitro. Immunohistochemical staining of markers for glutamatergic and glycinergic neurons indicated significant reduction of the latter. Likewise, there was lower expression of the GABA-synthesizing enzyme GAD65. Thus, malfunction of locomotor networks appeared related to loss of inhibitory synapses. This phenomenon did not occur in analogous opossum preparations of the spinal cord kept in vitro. In conclusion, despite histological data suggesting that cultured spinal cords were undamaged (except for inhibitory biomarkers), electrophysiological data revealed important functional impairment. Thus, the downregulation of inhibitory synapses may account for the progressive hyperexcitability of rat spinal networks despite apparently normal histological appearance. Our observations may help to understand the basis of certain delayed effects of spinal injury like chronic pain and spasticity.","AUArbitrary Units,BMEBasal Medium Eagle,CPGCentral Pattern Generator,CVCoefficient of Variation,DCDays in culture,DAPI4, 6-Diamidino-2-Phenylindole,DRDorsal Root,DRGsDorsal Root Ganglions,FLFictive Locomotion,FFFreshly Fixed,GABAGamma-Aminobutyric Acid,GAD65Glutamic Acid Decarboxylase,vGLUT2Anti-Vesicular Glutamate Transporter 2,GLYT2Glycine Transporter 2,NMDAN-Methyl-D-Aspartate P, Postnatal Day,ROIRegion of Interest,5-HTSerotonin,SCISpinal Cord Injury,S.DStandard Deviation,TThreshold,VRsVentral Roots,Keywords,Spinal cord preparation in vitro,Locomotor networks,Fictive locomotion,Motoneurons,Network plasticity,Loss of inhibitory synapses","AntonelaPetrovicab4,PriyadharishiniVeeraraghavana14,DarioOlivieria3,AndreaNistria,NinaJurcica2,MirandaMladinicab","Brain Research","https://doi.org/10.1016/j.brainres.2018.12.029","https://www.sciencedirect.com/science/article/pii/S0006899318306474"
"A55","A new model for textured surface lubrication based on a modified Reynolds equation including inertia effects","For textured surface lubrication problems, a small texture aspect ratio and a large Reynolds number can lead to strong recirculation in the textures and significant convective inertia effects. When these effects cannot be neglected, the Stokes system and the Reynolds equation are unsuitable and the Navier-Stokes equations should be considered instead. Particularly compared with the Reynolds equation, solving the Navier-Stokes system is computationally much more demanding due to its higher spatial dimension and nonlinearity. In this work, a new model is presented based on a modified Reynolds equation taking into account convective inertia and recirculation effects while so far neglecting cavitation. The model provides an accurate and considerably less expensive alternative to Navier-Stokes, demonstrated for two- and three-dimensional numerical configurations.","Hydrodynamic lubrication,Surface texture,Simulation,Journal bearing","MichaelRom,SiegfriedMüller","Tribology International","https://doi.org/10.1016/j.triboint.2018.12.030","https://www.sciencedirect.com/science/article/pii/S0301679X18306091"
"A56","Application of CSA-VMD and optimal scale morphological slice bispectrum in enhancing outer race fault detection of rolling element bearings","The bearing vibration signal with strong non-stationary properties is normally composed of multiple components (e.g. periodic impulses, background noise and other external signal), where periodic impulses relevant to bearing fault are easily contaminated by background noise and other external signal, making it difficult to excavate the inherent fault features. Variational mode decomposition (VMD) is a recently introduced approach for analyzing multi-component signal and is formulated based on the classic Wiener filter. However, some challenges remain when VMD is employed to process the real non-stationary signal. The most significant aspect of difficulties is that the inside parameters of VMD demand to be set manually in advance. To overcome this weakness, a modified method known as cuckoo search algorithm-based variational mode decomposition (CSA-VMD) is proposed in this paper, which can decompose adaptively a multi-component signal into a superposition of sub-signals termed as intrinsic mode function (IMF) by means of parameter optimization. In addition, a spectrum analysis technique called optimal scale morphological slice bispectrum (OSMSB) is presented for extracting fault symptoms from the susceptive mode components, which can restrain the Gaussian noise to a great extent and enhance the fault characteristics. Finally, a new fault diagnosis scheme consisting of CSA-VMD and OSMSB are compared with the existing methods (e.g. CEEMD-FWEO and fast kurtogram) by the application of simulation signal and experimental data, and the comparative results verify the effectiveness and superiority of the proposed method in extracting bearing outer race fault symptoms. The studies provide a novel perspective for the improvement of bearing outer race fault detection.","Variational mode decomposition,Cuckoo search algorithm,Optimal scale morphological slice bispectrum,Rolling bearing,Fault detection","XiaoanYan,MinpingJia","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.12.022","https://www.sciencedirect.com/science/article/pii/S088832701830801X"
"A57","High-throughput foodomics strategy for screening flavor components in dairy products using multiple mass spectrometry","A reliable Fisher discriminant model was established which was able to analyze the aroma component in milk, dairy products, flavors and fragrance, and applied on its variety identification. Foodomics was applied on screening of flavor components in 1093 dairy products and flavor samples in this study. Stepwise discrimination was used to screen the components of the dairy products and flavor samples that had a significant effect on the classification results, and discriminant function analysis. Then nine principal components were used for established the Fisher discriminant model. The three-dimensional coordinate distance of the sample was calculated and as the gist. The result showed that samples and flavors were distributed in eight different sites. The separation and clustering effects are better. The objective of the present study was to effectively determine whether or not flavors were added to dairy products.","Dairy products,Flavors,HS-SPME-GC/MS,Q-Orbitrap,Authentication,Fisher discriminant analysis","WeiJiaab,HanWanga,LinShia,FengZhangb,ChengFanc,XuefengChena,JamesChangd,XiaogangChuab","Food Chemistry","https://doi.org/10.1016/j.foodchem.2018.12.005","https://www.sciencedirect.com/science/article/pii/S030881461832096X"
"A58","A stacking model using URL and HTML features for phishing webpage detection","In this paper, we present a stacking model to detect phishing webpages using URL and HTML features. In terms of features, we design lightweight URL and HTML features and introduce HTML string embedding without using the third-party services, making it possible to develop real-time detection applications. Furthermore, we devise a stacking model by combining GBDT, XGBoost and LightGBM in multiple layers, which enables different models to be complementary, thus improving the performance on phishing webpage detection. In particular, we collect two real-world datasets for evaluations, named as 50K-PD and 50K-IPD, respectively. 50K-PD contains 49,947 webpages with URLs and HTML codes. 50K-IPD contains 53,103 webpages with screenshots in addition to URLs and HTML codes. The proposed approach outperforms quite a few machine learning models on multiple metrics, achieving 97.30% on accuracy, 4.46% on missing alarm rate, and 1.61% on false alarm rate on 50K-PD dataset. On 50K-IPD dataset, the proposed approach achieves 98.60% on accuracy, 1.28% on missing alarm rate, and 1.54% on false alarm rate.","Anti-phishing,HTML string embedding,Machine learning,Stacking model","YukunLia,ZhenguoYangbc,XuChena,HuapingYuanb,WenyinLiub","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.11.004","https://www.sciencedirect.com/science/article/pii/S0167739X1830503X"
"A59","Packet-data anomaly detection in PMU-based state estimator using convolutional neural network","With more phasor measurement units (PMU) being deployed by utilities for reliable monitoring of power systems, there grows an increasing risk of vulnerability to various cyber-attacks. This paper is concerned with a class of false data injection attacks (FDIA) which aim to modify PMU measurements resulting in incorrect state estimation solutions. We extract multi-variate time-series signals from PMU data packets aggregated in phasor data concentrators (PDC) corresponding to different events such as line faults and trips, generation and load fluctuations, shunt disconnections and FDIA prior to every cycle of state estimation (SE). A Convolutional Neural Network (CNN) data filter with Nesterov Adam gradient descent and categorical cross entropy loss is proposed to validate the PMU data. This filter extracts inter time-series relationships to classify different power system events by comparing the temporal structure of PMU packet data. The performance of the filter is then compared with (a) deep learning algorithms such as Recurrent Neural Networks (RNN) and Long Short Term Memory (LSTM) and (b) traditional classifiers such as SVM and ensemble methods. It is seen that the proposed CNN-based filter results in higher classification accuracies among all classifiers. This makes the CNN classifier suitable to serve as an independent data filter to identify falsified data streams targeted to alter SE. In order to verify the accuracy of the proposed filter, a hybrid state estimator (HSE) has been used in this study which obtains measurements from both PMU and traditional meters. All simulations are carried out on IEEE-30 bus and IEEE-118 bus systems.","Convolutional neural network,False data injection,Hybrid state estimation,Multi-variate time series,Nesterov Adam","SagnikBasumallik,RuiMa,SaraEftekharnejad","International Journal of Electrical Power & Energy Systems","https://doi.org/10.1016/j.ijepes.2018.11.013","https://www.sciencedirect.com/science/article/pii/S0142061518319884"
"A60","A relational exploratory study of business incubation and smart cities - Findings from Europe","This is a pioneering research linking two areas of knowledge which attract great attention from academia, industry, and governments: business incubation and smart cities. It is a quantitative exploratory study, whose purpose is to investigate the relationship between incubation mechanisms and local urban development according to the concept of Smart City. Methodologically, canonical correlation analysis was applied between two sets of elements: variables associated to business incubation and variables related to smart city characteristics. The research was concentrated on 157 medium- and large-sized cities from 25 European countries. Based on the findings, clusters analysis was also performed. The article presents, among the main results: (1) evidence of correlation between business incubation and smart urban development, and (2) visual classification of these cities into four clusters, according to their urban development and incubation activity.","Business incubation,Smart cities,Canonical correlation,Cluster analysis","MeryBlanck,José Luis DuarteRibeiro,Michel J.Anzanello","Cities","https://doi.org/10.1016/j.cities.2018.12.032","https://www.sciencedirect.com/science/article/pii/S0264275118305948"
"A61","Comparative evaluation of magnetic hyperthermia performance and biocompatibility of magnetite and novel Fe-doped hardystonite nanoparticles for potential bone cancer therapy","Hyperthermia—increasing temperature of cancerous tissue for a short period of time—is considered as an effective treatment for various cancer types such as malignant bone tumors. Superparamagnetic and ferromagnetic particles have been studied for their hyperthermic properties in treating various types of cancers. The activation of magnetic nanoparticles by an alternating magnetic field is currently being explored as a technique for targeted therapeutic heating of different tumors and is being studied as an adjuvant to conventional chemotherapy and radiation therapy. In the case of bone cancers, to increase the efficiency of treatment in the hyperthermia therapy, employed materials should support bone regeneration as well. Magnetite is one of the most attractive magnetic nanoceramics used in hyperthermia application. However, biocompatibility and bioactivity of this material have raised questions. There is a high demand for extremely efficient hyperthermia materials which are equally biocompatible to non-tumor cells and tissues. We report the development of a biocompatible and bioactive material with desirable magnetic properties that show excellent hyperthermia properties and can be used for destruction of the cancerous tissue in addition to supporting tissue regeneration for treatment of bone tumors. In the current study, iron (Fe3+)-containing HT nanostructured material was prepared, and its biocompatibility, bioactivity, and hyperthermia abilities were studied. The developed materials showed effective hyperthermic properties with increased biocompatibility as compared to magnetite.","Biocompatibility,Hyperthermia,Hardystonite,Magnetite","AliFarzinabcd,ShabirHassancd,RahmatollahEmadie,S. AlirezaEtesamif,JafarAib","Materials Science and Engineering: C","https://doi.org/10.1016/j.msec.2019.01.038","https://www.sciencedirect.com/science/article/pii/S0928493118324512"
"A62","A minimal hyperbolic system for unstable shock waves","We present a computational analysis of a 2×2 hyperbolic system of balance laws whose solutions exhibit complex nonlinear behavior. Traveling-wave solutions of the system are shown to undergo a series of bifurcations as a parameter in the model is varied. Linear and nonlinear stability properties of the traveling waves are computed numerically using accurate shock-fitting methods. The model may be considered as a minimal hyperbolic system with chaotic solutions and can also serve as a stringent numerical test problem for systems of hyperbolic balance laws.","Hyperbolic systems,Shock waves,Stability,Bifurcations,Chaos,Detonation","Dmitry I.Kabanova,Aslan R.Kasimovbcd","Communications in Nonlinear Science and Numerical Simulation","https://doi.org/10.1016/j.cnsns.2018.10.022","https://www.sciencedirect.com/science/article/pii/S1007570418303381"
"A63","Operational risk assessment model for marine vessels","This paper presents a practical approach to quantify the risk associated with different systems in a marine vessel using the existing operational database. A structured bow-tie methodology is proposed to assess risk. The first step was the development of probable failure scenarios for four different events, namely, fire and explosion, propulsion engine failure, power failure, and maneuverability failure. The second step includes the formulation of corresponding bow-tie models representing these scenarios using vessel configuration and process information. Using the failure data for different elements obtained from the vessel's maintenance logbook and incident records, the frequency of events and failure rates of the safety barriers are estimated to quantify risk. Operational data from the vessel, a single engine ice-breaker bulk career navigating mainly in the Canadian sub-arctic region, validated the proposed model. The methodology is verified by comparing the model's observations with an alternative dataset (actual failure scenario from the ship). The proposed methodology is expected to serve as a useful tool for marine vessel's safety and risk management.","Marine operations,Process hazards,Marine vessel reliability,Operational risk,Fault tree,Event tree","AbdulAziza,SalimAhmeda,FaisalKhana,ChrisStackb,AnnesLindb","Reliability Engineering & System Safety","https://doi.org/10.1016/j.ress.2019.01.002","https://www.sciencedirect.com/science/article/pii/S0951832018301741"
"A64","Application of deep transfer learning for automated brain abnormality classification using MR images","Magnetic resonance imaging (MRI) is the most common imaging technique used to detect abnormal brain tumors. Traditionally, MRI images are analyzed manually by radiologists to detect the abnormal conditions in the brain. Manual interpretation of huge volume of images is time consuming and difficult. Hence, computer-based detection helps in accurate and fast diagnosis. In this study, we proposed an approach that uses deep transfer learning to automatically classify normal and abnormal brain MR images. Convolutional neural network (CNN) based ResNet34 model is used as a deep learning model. We have used current deep learning techniques such as data augmentation, optimal learning rate finder and fine-tuning to train the model. The proposed model achieved 5-fold classification accuracy of 100% on 613 MR images. Our developed system is ready to test on huge database and can assist the radiologists in their daily screening of MR images.","MRI classification,Abnormal brain images,Deep transfer learning,CNN","MuhammedTaloa,Ulas BaranBaloglua,ÖzalYildirima,URajendra Acharyabcd","Cognitive Systems Research","https://doi.org/10.1016/j.cogsys.2018.12.007","https://www.sciencedirect.com/science/article/pii/S1389041718310933"
"A65","Co-PoeTryMe: Interactive poetry generation","PoeTryMe is a poetry generation system that autonomously produces poems from a set of initial parameters. After using it, creative writers and other users of this system expressed the desire to partake in the creative process by directly interacting with PoeTryMe. This paper is motivated by the previous impressions. It illustrates some of the challenges of automatic poetry generation, highlights limitations of PoeTryMe, and reports on recent efforts to address user feedback and provide alternative ways of using this system. First, making some functionalities available via a web API enabled their exploitation by other systems. Those include the generation of single lines as well as retrieval of related words, allowing for additional constraints on the number of syllables, sentiment and rhyme. On top of this API, a co-creative interface, Co-PoeTryMe, has been developed. Co-PoeTryMe allows users to either start from scratch or from a generated draft. Extensive editing functionality has been incorporated, in particular, allowing lines and words to be switched or replaced by newly generated alternatives. Co-PoeTryMe, its interface and the co-creative process for producing poetry are described, along with a user study that provided useful feedback. Users pointed out the strengths of this new system, including its capacities in providing inspiration, and giving the user the ability to customize an existing draft and visualize the changes, but also pointed out weaknesses, primarily by identifying potential improvements in the user interface.","Computational creativity,Poetry generation,Creative web services,Creativity API,Co-creativity,Interactive poetry generation","HugoGonçalo Oliveiraa,TiagoMendesa,AnaBoavidaa,AiNakamurab,MargaretaAckermanc","Cognitive Systems Research","https://doi.org/10.1016/j.cogsys.2018.11.012","https://www.sciencedirect.com/science/article/pii/S138904171730311X"
"A66","All talk and no action? An analysis of environmental concern, income and greenhouse gas emissions in Switzerland","Private households play a significant part in reducing greenhouse gas emissions. Therefore, it is important to know which factors are related to emissions. However, most studies so far have focused on income, household size and other structural factors while neglecting the potential relevance of attitudinal variables such as environmental concern. Those studies that did examine environmental attitudes were mostly based on \"intent-oriented\" measures of pro-environmental behavior instead of actual environmental impacts. The present study brings these lines of research together by analyzing the relationship between emissions, income and environmental attitudes within a framework of multivariate analysis. Furthermore, three specific emissions domains – mobility, housing and food – are analyzed separately and the results are compared to those based on a scale of pro-environmental behavior. All analyses are based on data from a large representative general population survey, the Swiss Environmental Survey 2007 (n = 3369), and a subsequent life cycle analysis. The results clearly indicate that next to income, environmental concern is an important predictor of emissions, even when controlling for the effects of income.","Greenhouse gas emissions,Pro-environmental behavior,Income,Environmental concern","HeidiBruderer Enzlera,AndreasDiekmannab","Energy Research & Social Science","https://doi.org/10.1016/j.erss.2019.01.001","https://www.sciencedirect.com/science/article/pii/S2214629618304195"
"A67","Semi-supervised feature learning for improving writer identification","Data augmentation is typically used by supervised feature learning approaches for offline writer identification, but such approaches require a mass of additional training data and potentially lead to overfitting errors. In this study, a semi-supervised feature learning pipeline is proposed to improve the performance of writer identification by training with extra unlabeled data and the original labeled data simultaneously. Specifically, we propose a weighted label smoothing regularization (WLSR) method for data augmentation, which assigns a weighted uniform label distribution to the extra unlabeled data. The WLSR method regularizes the convolutional neural network (CNN) baseline to allow more discriminative features to be learned to represent the properties of different writing styles. The experimental results on well-known benchmark datasets (ICDAR2013 and CVL) showed that our proposed semi-supervised feature learning approach significantly improves the baseline measurement and perform competitively with existing writer identification approaches. Our findings provide new insights into offline writer identification.","Semi-supervised feature learning,Feature extraction,Regularization,CNN,Writer identification.","ShimingChena,YisongWangab,Chin-TengLind,WeipingDingc,ZehongCaode","Information Sciences","https://doi.org/10.1016/j.ins.2019.01.024","https://www.sciencedirect.com/science/article/pii/S0020025519300283"
"A68","Persuasion: How phishing emails can influence users and bypass security measures","Phishing is a very dangerous form of social engineering with the aim to deceive people into disclosing private/confidential information. Despite widespread warnings and means to educate users to identify phishing messages, these are still a prevalent practice and a lucrative business. The authors believe that persuasion, as a style of human communication designed to influence others, has a central role in successful digital scams. Research on persuasion applied to phishing emails is scarce and tends to build on Cialdini's work alone. Only a single study has proposed a list of merged principles from three different perspectives but it has methodological limitations regarding the analysis’ performance by a single researcher and the testing of principles in a small, not validated sample of phishing emails. This paper aims to fill those gaps by building on Cialdini's, Gragg's and Stajano & Wilson's works to derive a unique list of Principles of Persuasion in Social Engineering (PPSE), resulting from the application of the relational method by two independent researchers. The PPSE are identified, by two independent researchers (Kappa<U+202F>><U+202F>0.789) on a sample of phishing email subject lines (N<U+202F>=<U+202F>194), dated from 2008 to 2017 and randomly selected from a reliable phishing archive (millersmiles.co.uk). A thematic content analysis, together with the sample characterization in terms of visual elements and targeted content, revealed that the most prominent principles of persuasion in phishing emails were ‘Authority’, ‘Strong Affect’, ‘Integrity’ and ‘Reciprocation’. The larger percentage of references with the presence of visual elements was found for the ‘Strong Affect’ principle. The use of the pronouns ‘you' and ‘your’ was more evident for the categories ‘Strong Affect’ and ‘Authority’, while the employment of the pronouns ‘we, us, our’ was more frequent in the ‘Reciprocation’ principle. This paper constitutes a step further in understanding the use of principles of persuasion in phishing emails with future applications on how their recognition can be automated.","Principles of persuasion,Social engineering,Phishing emails,Human computer interaction,Computer security and human behaviour","AnaFerreiraa,SoraiaTelesab","International Journal of Human-Computer Studies","https://doi.org/10.1016/j.ijhcs.2018.12.004","https://www.sciencedirect.com/science/article/pii/S1071581918306827"
"A69","Kalman filter and a fuzzy logic processor for series arcing fault detection in a home electrical network","This paper presents a method for detecting series arcing faults in AC home electrical networks. The proposed algorithm is based on both a Kalman filter, used for identifying fault symptoms and a decision block, which confirms the presence of a series arc fault to activate a tripping signal. The current measured at one end of the power line is estimated using a model of two steady-state variables (X1 and X2). Firstly, residuals and the third order difference of state X2 are used as input parameters of a Fuzzy logic processor for detecting fault symptoms. Secondly, the fault symptoms are processed by a detection logic block, which confirms the presence of an electrical arcing fault.The algorithm is tested on a variety of loads in single or masking load configurations chosen accordingly to the requirements of the UL 1699 and IEC 62606 standards. The algorithm is also tested in the steady state or at load start (transient state). This method’s performance is studied and discussed in the final part. Experimental results show that the method we propose can detect arcing faults efficiently, avoiding false tripping, whilst taking into account a high degree of diagnosis accuracy and average detection time.","AC series arcing fault,Fuzzy logic processor,Kalman filter,Adaptive threshold","EdwinCalderon-Mendoza,PatrickSchweitzer,SergeWeber","International Journal of Electrical Power & Energy Systems","https://doi.org/10.1016/j.ijepes.2018.11.002","https://www.sciencedirect.com/science/article/pii/S0142061518319094"
"A70","An intelligent fault diagnosis approach based on transfer learning from laboratory bearings to locomotive bearings","Intelligent fault diagnosis of rolling element bearings has made some achievements based on the availability of massive labeled data. However, the available data from bearings used in real-case machines (BRMs) are insufficient to train a reliable intelligent diagnosis model. Fortunately, we can easily simulate various faults of bearings in a laboratory, and the data from bearings used in laboratory machines (BLMs) contain diagnosis knowledge related to the data from BRMs. Therefore, inspired by the idea of transfer learning, we propose a feature-based transfer neural network (FTNN) to identify the health states of BRMs with the help of the diagnosis knowledge from BLMs. In the proposed method, a convolutional neural network (CNN) is employed to extract transferable features of raw vibration data from BLMs and BRMs. Then, the regularization terms of multi-layer domain adaptation and pseudo label learning are developed to impose constraints on the parameters of CNN so as to reduce the distribution discrepancy and the among-class distance of the learned transferable features. The proposed method is verified by two fault diagnosis cases of bearings, in which the health states of locomotive bearings in real cases are identified by using the data respectively collected from motor bearings and gearbox bearings in laboratories. The results show that the proposed method is able to effectively learn transferable features to bridge the discrepancy between the data from BLMs and BRMs. Consequently, it presents higher diagnosis accuracy for BRMs than existing methods.","Intelligent fault diagnosis,Rolling element bearings,Transfer learning,Convolutional neural network,Domain adaptation","BinYang,YaguoLei,FengJia,SaiboXing","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.12.051","https://www.sciencedirect.com/science/article/pii/S0888327018308367"
"A71","Nonlocal nonlinear chaotic and homoclinic analysis of double layered forced viscoelastic nanoplates","The homoclinic phenomena and chaotic motions of the forced double layered nanoplates (DLNP) are investigated. By the nonlocal theory, the nonlinear equations of motion of DLNP subjected to transverse harmonic excitation are established. The buckled DLNP considered herein means that the parameter regime of the first mode are always unstable. It should be emphasized that the homoclinic Melnikov function is related to the nonlinear term which is affected by the boundary conditions. Hence two different boundary conditions, i.e. simply supported with movable and immovable edges are compared herein. The extended Melnikov method is employed to discuss the homoclinic phenomena and chaotic motions of the DLNP system. The criteria for the homoclinic motions of the four buckling cases are established. Then the results by the above global perturbation analyses are verified by the numerical integration evidences including Lyapunov exponential spectrums, Fourier spectrums and Poincaré sections. The influences of the structural parameters such as small scale effect and boundary conditions on the homoclinic behaviors are mainly discussed. From the results, the most remarkable fact can be seen that the rotary inertia term could break the symplectic symmetry of the unperturbed vibration system. The parametric regime where the chaotic motion may appear shrink with the increase of the nonlinear term r1, which means chaotic motion more likely appear for immovable edges than those with movable edges. Parametric regime where the transverse homoclinic phenomenon appears will decrease with the increase of the small scale parameter. And the homoclinic phenomena more likely appear in higher mode vibration.","Nonlocal theory,Chaotic vibration,Extended Melnikov method,Nanostructures,Homoclinic phenomena","YuWanga,FengmingLia,HaishengShub","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.12.041","https://www.sciencedirect.com/science/article/pii/S0888327018308240"
"A72","Disentangled Variational Auto-Encoder for semi-supervised learning","Semi-supervised learning is attracting increasing attention due to the fact that datasets of many domains lack enough labeled data. Variational Auto-Encoder (VAE), in particular, has demonstrated the benefits of semi-supervised learning. The majority of existing semi-supervised VAEs utilize a classifier to exploit label information, where the parameters of the classifier are introduced to the VAE. Given the limited labeled data, learning the parameters for the classifiers may not be an optimal solution for exploiting label information. Therefore, in this paper, we develop a novel approach for semi-supervised VAE without classifier. Specifically, we propose a new model called Semi-supervised Disentangled VAE (SDVAE), which encodes the input data into disentangled representation and non-interpretable representation, then the category information is directly utilized to regularize the disentangled representation via the equality constraint. To further enhance the feature learning ability of the proposed VAE, we incorporate reinforcement learning to relieve the lack of data. The dynamic framework is capable of dealing with both image and text data with its corresponding encoder and decoder networks. Extensive experiments on image and text datasets demonstrate the effectiveness of the proposed framework.","Semi-supervised learning,Variational Auto-encoder,Disentangled representation,Neural networks","YangLia,QuanPana,SuhangWangc,HaiyunPengb,TaoYanga,ErikCambriab","Information Sciences","https://doi.org/10.1016/j.ins.2018.12.057","https://www.sciencedirect.com/science/article/pii/S0020025518310077"
"A73","Neural embedding-based indices for semantic search","Traditional information retrieval techniques that primarily rely on keyword-based linking of the query and document spaces face challenges such as the vocabulary mismatch problem where relevant documents to a given query might not be retrieved simply due to the use of different terminology for describing the same concepts. As such, semantic search techniques aim to address such limitations of keyword-based retrieval models by incorporating semantic information from standard knowledge bases such as Freebase and DBpedia. The literature has already shown that while the sole consideration of semantic information might not lead to improved retrieval performance over keyword-based search, their consideration enables the retrieval of a set of relevant documents that cannot be retrieved by keyword-based methods. As such, building indices that store and provide access to semantic information during the retrieval process is important. While the process for building and querying keyword-based indices is quite well understood, the incorporation of semantic information within search indices is still an open challenge. Existing work have proposed to build one unified index encompassing both textual and semantic information or to build separate yet integrated indices for each information type but they face limitations such as increased query process time. In this paper, we propose to use neural embeddings-based representations of term, semantic entity, semantic type and documents within the same embedding space to facilitate the development of a unified search index that would consist of these four information types. We perform experiments on standard and widely used document collections including Clueweb09-B and Robust04 to evaluate our proposed indexing strategy from both effectiveness and efficiency perspectives. Based on our experiments, we find that when neural embeddings are used to build inverted indices; hence relaxing the requirement to explicitly observe the posting list key in the indexed document: (a) retrieval efficiency will increase compared to a standard inverted index, hence reduces the index size and query processing time, and (b) while retrieval efficiency, which is the main objective of an efficient indexing mechanism improves using our proposed method, retrieval effectiveness also retains competitive performance compared to the baseline in terms of retrieving a reasonable number of relevant documents from the indexed corpus.","Semantic search,Information retrieval,Inverted index,Neural embeddings","FatemehLashkaria,EbrahimBagherib,Ali A.Ghorbania","Information Processing & Management","https://doi.org/10.1016/j.ipm.2018.10.015","https://www.sciencedirect.com/science/article/pii/S0306457318302413"
"A74","Graph matching approach and generalized median graph for automatic labeling of cortical sulci with parallel and distributed algorithms","The human brain cortex is very complex structure containing folds (gyri) and fissures (sulci) that were the subject of our study in this paper. The sulcus is one of the most important features in order to know the different functions areas of the brain. The exact identification of sulci on human brain using MRI images is helpful in many studies and applications related to brain diseases and human behavior. Automatic labeling of cortical sulci with all this complexity and inter-subject variability, this is considered non-trivial task. In this paper, we have proposed a new graph based approach of automatic labeling of cortical sulci with parallel and distributed algorithms using graph matching and generalized median graph. The graph matching is very important in many studies and applications such as pattern recognition and classification. The generalized median graph of a set of graphs is a way to represent a set of graphs by a comprehensive graph that minimizes the sum of the distances to all graphs. We have used the characteristics of shape, orientation and location to describe the sulci. The results that we have obtained prove that our approach is accurate and acceptable in this field which uses the graph matching for automatic labeling of cortical sulci.","Sulcus recognition,Median graph,Generalized median graph,Graph matching,MRI,Parallel matching","HichemFelouat,SalihaOukid-Khouas","Cognitive Systems Research","https://doi.org/10.1016/j.cogsys.2018.08.008","https://www.sciencedirect.com/science/article/pii/S1389041718301402"
"A75","Estimating VR Sickness and user experience using different HMD technologies: An evaluation study","This paper presents results of a user study of the effects of virtual reality technology on VR Sickness and User Experience. In our study the participants watched two different panoramic (360) videos, one with relaxing content (beach clip) and second one with action content (roller coaster video clip). Videos were watched on four different head mounted displays (HMDs) and on the 2D television as a reference display. To assess VR Sickness discomfort levels, we have used the Simulator Sickness Questionnaire (SSQ), and for user experience the User Experience Questionnaire (UEQ) was used. For quick assessments of VR Sickness discomfort levels, we have also used Subjective Units of Distress Scale (SUDS). We have found a strong correlation between SUDS and total SSQ score and between total SSQ score and SSQ-D score. Shown negative correlation between VR Sickness discomfort levels (assessed by SSQ and UEQ Questionnaire), and user experience (assessed by UEQ Questionnaire), indicates that presence of VR Sickness symptoms affects the user experience.","Virtual reality,VR sickness,Cybersickness,User experience,User study","AndrejSomraka,IztokHumara,M. ShamimHossainb,Mohammed F.Alhamidb,M. AnwarHossainb,JožeGunaa","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.11.041","https://www.sciencedirect.com/science/article/pii/S0167739X18325044"
"A76","A recurrence plot-based approach for Parkinson’s disease identification","Parkinson’s disease (PD) is a neurodegenerative disease that affects millions of people worldwide, causing mental and mainly motor dysfunctions. The negative impact on the patient’s daily routine has moved the science in search of new techniques that can reduce its negative effects and also identify the disease in individuals. One of the main motor characteristics of PD is the hand tremor faced by patients, which turns out to be a crucial information to be used towards a computer-aided diagnosis. In this context, we make use of handwriting dynamics data acquired from individuals when submitted to some tasks that measure abilities related to writing skills. This work proposes the application of recurrence plots to map the signals onto the image domain, which are further used to feed a Convolutional Neural Network for learning proper information that can help the automatic identification of PD. The proposed approach was assessed in a public dataset under several scenarios that comprise different combinations of deep-based architectures, image resolutions, and training set sizes. Experimental results showed significant accuracy improvement compared to our previous work with an average accuracy of over 87%. Moreover, it was observed an improvement in accuracy concerning the classification of patients (i.e., mean recognition rates above to 90%). The promising results showed the potential of the proposed approach towards the automatic identification of Parkinson’s disease.","Parkinson’s disease,Recurrence plot,Convolutional neural networks,Optimum-path forest","Luis C.S.Afonsoa,Gustavo H.Rosab,Clayton R.Pereirab,Silke A.T.Weberc,ChristianHookd,Victor Hugo C.Albuquerquee,João P.Papab","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.11.054","https://www.sciencedirect.com/science/article/pii/S0167739X18322507"
"A77","An optical multiple-image authentication based on transport of intensity equation","An optical multiple-image authentication approach based on transport of intensity equation technique has been proposed. Initially, a phase-encoded plaintext is synthesized with significant blocks chosen from the multiple plain images by evaluating their spatial frequency coefficients, which is bonded with a random intensity mask generated with logistic map to constitute the complex amplitude. Then, the complex amplitude is encrypted to a real-valued ciphertext with noise-like distribution by using Fresnel diffraction. In the process of authentication, the phase information is firstly reconstructed by solving transport of intensity equation. The existence of a plain image can be identified by calculating the nonlinear correlation between it and its partial data only containing the extracted significant blocks from the phase information by aid of the corresponding binary mask. To our best knowledge, it is the first time to apply the transport of intensity equation technique to implement the optical multiple-image authentication. A set of numerical simulations are carried out to demonstrate the feasibility of the proposed approach.","Transport of intensity equation,Multiple-image authentication,Spatial frequency coefficient","LianshengSuiab,XiaoyuZhaoa,ChongtianHuangd,AilingTianc,AsundiAnandd","Optics and Lasers in Engineering","https://doi.org/10.1016/j.optlaseng.2019.01.006","https://www.sciencedirect.com/science/article/pii/S0143816618316841"
"A78","Science gateways: Sustainability via on-campus teams","The challenges for creators of specific science gateways are manifold, and the expertise needed for well-designed science gateways is very diverse. The sustainability of science gateways is crucial to serve communities effectively, efficiently and reliably. One measure to achieve greater sustainability of science gateways is establishing on-campus teams. Researchers are served more efficiently since the support by experienced developers reduces individual project investments, and a team can bring the diversity of required expertise for a well-designed science gateway. This paper goes into detail about the challenges and the benefits of on-campus groups and of sharing resources across a campus. We provide four successful cases, describe the services of the Science Gateways Community Institute (SGCI) to support the process in building such groups, and recommend strategies for using free campus resources.","Science gateways,Science gateways community institute,Sustainability,On-campus groups","SandraGesinga,KatherineLawrenceb,MaytalDahanc,Marlon E.Pierced,NancyWilkins-Diehre,MichaelZentnerf","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.09.067","https://www.sciencedirect.com/science/article/pii/S0167739X18315395"
"A79","A mitigation strategy for the prevention of cascading trust failures in social networks","In the past decade, we have seen a massive growth in social networks and a day to day increase in their users. Loose constraints and almost no limitation in the propagation of information in these networks have resulted in a lot of false information, spam and inappropriate messages being exchanged among users. This has caused the creation of a trust crisis in which trust relationships turn into distrust. But, the real threat to the general integrity of social networks occurs when the removed trust edges in the social network result in more and more connections to turn into distrust and thus be removed from the corresponding trust network. This phenomenon is called cascading trust failure.The primary purpose of this research is to build upon the dynamic modeling of cascading failures due to the occurrence of a trust crisis within a unidirectional or bidirectional social network. After the model is created, the next step would be on the detection of neighboring edges that can be influenced by the trust crisis and may be removed because of it. The second purpose of the research is to propose a mitigation strategy for the prevention of cascading failures in trust relationships. This will be beneficial for the honest and free expression of opinions and experiences without their privacy getting compromised or the trust relationships being affected. The proposed model has four steps: (1) trust calculation and evaluation, (2) propagation, (3) updating and (4) the filtration process. In the model, important parameters such as changes in topology, cascading times and failure as well as the connectivity ratio are considered. The impact of these parameters is also investigated in the Facebook’s sparse network and Twitter’s ripple network. The performed evaluations show that the strength of trust relationships not only depend on profile similarity measures but also on the subjective, propagative, dynamic, event sensitive and the asymmetrical characteristics of trust. Also, it is shown that the sensitivity of users toward the change in their network topology is also a considerable factor in the occurrence and subsequent prevention of cascading trust failures. Based on the performed evaluations, the proposed mitigation strategy is capable of maintaining 95% and 92% of the trust relations when a trust crisis targets the highest trust values in the Facebook and Twitter’s networks respectively. This is a considerable increase from the 52% and 2% remaining edges in the occurrence of trust crisis in the previously proposed approaches. Also, the proposed approach has an average of 50% increase in reducing the number of cascading failures as well as their impact on the network.","Social networks,Cascading failures,Trust crisis,Mitigation strategy,Trust calculation,Trust propagation,Filtration process","NasrinHamzelou,MehrdadAshtiani","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.12.013","https://www.sciencedirect.com/science/article/pii/S0167739X18305065"
"A80","A multi-stage stochastic optimization model of a pastoral dairy farm","Pastoral dairy farmers make sequential decisions in the face of long-term environmental uncertainty and price volatility. Decisions made early in the season, such as the number of cows to stock per hectare, can have significant effects later in the season if the farmer is forced to import additional feed to meet the cows’ energy demands during a drought. In this paper, we present POWDer: the milk Production Optimizer incorporating Weather Dynamics. POWDer is a novel multi-stage stochastic program that divides the dairy farming season into weeks and links these weeks by a system of linear dynamics. By applying POWDer to a case farm in New Zealand, we demonstrate POWDer’s promise as a tool that can help participants in the New Zealand dairy industry understand and plan for the challenge of farming in a stochastic world.","OR in agriculture,Stochastic dual dynamic program,Multi-stage,Stochastic programming,Dairy","OscarDowson,AndyPhilpott,AndrewMason,AnthonyDownward","European Journal of Operational Research","https://doi.org/10.1016/j.ejor.2018.10.033","https://www.sciencedirect.com/science/article/pii/S0377221718308865"
"A81","Approximate critical curves in exponentially damped nonviscous systems","In this paper a new approximate numerical method to obtain critical curves in exponentially damped nonviscous systems is proposed. The assumed viscoelastic forces depend on the past history of the velocity response via convolution integrals over exponential kernel functions. Critical surfaces are manifolds in the multidimensional domain defined by the damping parameters, depicting thresholds between the induced oscillatory and non-oscillatory motion. If these surfaces are formed by two parameters, then they are named critical curves. The available method in the literature to construct these curves involves the analytical manipulation of the transcendental matrix determinant, something that can become highly inefficient for large systems. In this paper, it is proved that approximate critical curves can be constructed eliminating the Laplace parameter from two eigenvalue problems: the original one controlled by the dynamical stiffness matrix and another one defined by its derivative respect to the Laplace parameter. The theoretical background of the approach is derived with help of the implicit function theorem. It turns out that the so-found approximate overdamped regions are enclosed by a set of critical curves, which can be derived in parametric form. The proposed method is validated through two numerical examples involving multiple degrees of freedom.","Nonviscous damping,Critical damping,Exponential damping,Overdamped region,Critical curves,Approximate method","MarioLázaro","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.12.044","https://www.sciencedirect.com/science/article/pii/S0888327018308276"
"A82","Simultaneous functional and structural imaging for photovoltaic devices","The functionality of photovoltaic devices (such as, solar cells) is converting photons to electricity. Characterization of photovoltaic devices is essential at production level and during use. Here we put forward a new concept of functional imaging for photovoltaic devices. Based on the concept, we also propose an optical technique that can simultaneously acquire functionality and structure images of a single or multiple photovoltaic devices. The technique is simple, low-cost, effective, and efficient. It requires no mechanic motion and instead structured illumination is adopted for image acquisition. The complementary information provided by the functionality and structure images acquired allows one to better identify any existing and developing faults of photovoltaic devices. What's more, the technique is able to give reliable results with much fewer measurements than image pixels by exploiting the sparsity of functionality and structure images in the Fourier domain. The technique allows not only users to monitor the ‘health condition’ of the utilized devices, but also manufacturers to improve their fabrication conditions. The proposed technique may be applicable for rapid characterization for other semiconductor-based devices.","Photovoltaic devices characterization,Current response mapping,Solar cells,Functional imaging,Structural imaging","ZibangZhangab1,ManhongYaoa1,XiangLia,QiwenDenga,QingyuPengc,JingangZhongab","Solar Energy Materials and Solar Cells","https://doi.org/10.1016/j.solmat.2019.01.013","https://www.sciencedirect.com/science/article/pii/S0927024819300133"
"A83","Mining direct acyclic graphs to find frequent substructures — An experimental analysis on educational data","The number of undergraduate students joining universities in Brazil has largely grown in the recent years. However, the number of students who actually graduate remains low. Some studies show that this is due to a phenomenon called retention, consisting of a student taking more time to graduate than the minimum required by the program, which may lead to late graduation. Hence, identifying retention patterns in an undergraduate program may assist the universities in anticipating the entrance of qualified professionals in the job market, while lessening the students’ dropout rate. Undergraduate programs and grade reports can be represented by DAGs, in which each course (as a task to be accomplished by each student) is represented as a vertex, and relations between courses are represented as edges. This article proposes methods for mining DAGs using statistical analysis and Apriori-based concepts, to identify retention patterns in undergraduate programs. This work also presents an experimental analysis using real data from Fluminense Federal University, a Brazilian public higher education institution, for evaluating the methods.","Graph mining,Educational mining,Undergraduate program","Jefferson de J.Costabc,FlaviaBernardinia,DaniloArtigasb,JoséViterboa","Information Sciences","https://doi.org/10.1016/j.ins.2019.01.032","https://www.sciencedirect.com/science/article/pii/S0020025519300398"
"A84","Influence of mitral valve elasticity on flow development in the left ventricle","The Mitral valve of the human heart has a great relevance for numerous cardiac pathologies; however, the knowledge of relationships between valvular properties and cardiac function is still limited. On one side, this is partly due to the limited resolution of clinical imaging technologies that do not allow routinely visualization of the valve during its motion. On the other, its modeling presents serious challenges either due to the strong flow–tissueinteraction or because the mechanical properties of its constitutive elements are complex and not measurable in vivo. This work introduces a parametric model of the Mitral valve where the interaction with the blood flow obeys global balances and the overall elastic properties are summarized into a single functional parameter. This is integrated into a numerical model of left ventricular fluid dynamics with the aim to study the effect of varying the valvular stiffness. Results show that the elasticity of the valve influences the amplitude of the mitral opening, while the timings of opening/closure are driven by the transmitral blood flow due to the ventricular dynamics. In addition, the increase of stiffness increases the transvalvular pressure gradients required to ensure the same flow. These results are discussed in relation to parameters for monitoring valvular stiffness that are accessible through clinical imaging.","Left ventricle,Mitral valve,Immersed boundary method,flow–tissue interaction","ChiaraCelotto,LuiginoZovatto,DarioCollia,GianniPedrizzetti","European Journal of Mechanics - B/Fluids","https://doi.org/10.1016/j.euromechflu.2018.11.018","https://www.sciencedirect.com/science/article/pii/S0997754618303649"
"A85","Attention allocation to 2D and 3D emotion-inducing scenes: A neurophysiological study","Past research on emotions was mostly supported on emotion inducing slides, but studies in the field are moving towards more ecological stimuli, including 3D stimuli and virtual reality scenes. The present study aims to compare the effects of two-dimensional (2D) and three-dimensional (3D) emotion-inducing scenes in the modulation of attention, as indexed by the amplitude of the P3 event-related component in a dual-task paradigm. We recorded the EEG signal of 31 healthy male participants performing an active auditory oddball task, while simultaneously observing pleasant, unpleasant and neutral scenes in 2D or 3D. We analyzed the effects of emotional valence and visualization mode in the mean amplitude of the P3 component at Pz. The results revealed than revealed that 2D scenarios were as effective as 3D stimuli in capturing attention resources and this effect was consistently observed in all emotional scenes.","Attention,Emotion,Two-dimensional (2D),Three-dimensional (3D),Dual-task,Oddball,P3","FernandoBarbosaa,RitaPasiona,JorgeSilvérioc,Carlos M.Coelhod,JoãoMarques-Teixeiraa,Luís C.Monteiroab","Neuroscience Letters","https://doi.org/10.1016/j.neulet.2019.01.011","https://www.sciencedirect.com/science/article/pii/S0304394019300175"
"A86","Abnormal auditory mismatch fields in adults with autism spectrum disorder","The auditory mismatch field (MMF) is a pre-attentive processing component, reflecting neural discrimination and inhibitory processing. Abnormal MMFs have been reported in children with autism spectrum disorder (ASD) along with an association with abnormal language comprehension; however, relatively little is known about MMF abnormalities to contrasting vowel stimuli in adults with ASD. To better understand the neurophysiological mechanisms underlying auditory language discrimination of vowel stimuli in individuals with ASD, magnetoencephalography was used to measure MMFs during an auditory oddball paradigm with vowel stimuli (/a/ and /u/) in adults with ASD. MMFs arising from left and right superior temporal gyrus are reported from nine high-functioning right handed males with ASD (22.22<U+2009>±<U+2009>5.74yrs) and sixteen typically developing (TD) right handed males (27.25<U+2009>±<U+2009>6.63yrs). The MMF was delayed in adults with ASD (188.90<U+2009>±<U+2009>5.8<U+2009>ms) as compared to the TD participants (173.08<U+2009>±<U+2009>4.31<U+202F>ms, p<U+2009><<U+2009>0.05). Replicating previous findings in children, the earlier M100 component to single stimulus tokens was also delayed in adults with ASD (108.59<U+2009>±<U+2009>4.1<U+2009>ms) compared to the TD participants (94.60<U+2009>±<U+2009>3.0<U+202F>ms, p<U+2009><<U+2009>0.05). However, there was no correlation between delayed M100 latency and MMF latency. Furthermore, whereas TD participants showed a leftward lateralization of MMF amplitude, participants with ASD showed an opposite (rightward) lateralization. Findings suggest that adults with ASD have hemispherically- and temporally- abnormal auditory discrimination processing in addition to and distinct from abnormal neurophysiological mechanisms in earlier cortical responses.","Autism spectrum disorder,Magnetoencephalography,Adults,Vowel mismatch fields,Auditory language discrimination process and laterality","JunkoMatsuzakia,MatthewKua,Jeffrey I.Bermana,LisaBlaskeya,LukeBloya,Yu-hanChena,JohnDella,J. ChristopherEdgara,Emily S.Kuschnera,SongLiua,JoniSabya,Edward S.Brodkinb,Timothy P.L.Robertsa","Neuroscience Letters","https://doi.org/10.1016/j.neulet.2018.12.043","https://www.sciencedirect.com/science/article/pii/S0304394018309005"
"A87","The human factor in supply chain forecasting: A systematic review","Demand forecasts are the lifeblood of supply chains. Academic literature and common industry practices indicate that demand forecasts are often subject to human interventions. Judgmental forecasting or judgmental forecast adjustments can cause both positive and negative repercussions to the rest of the supply chain. This paper provides the first systematic literature review of judgmental forecasting and adjustments focusing on key features that impact various decisions in supply chains. A carefully assembled and shortlisted literature pool is analyzed for systematic mapping of the published works using bibliometric tools. The primary sub streams of research within the broader scope of the field are synthesized from a rigorous keyword cluster analysis and a thorough discussion is presented. Our review concludes by encapsulating the key learnings from four decades of academic research in judgmental forecasting and suggests future research avenues to expand our understanding of the role of humans in demand forecasting and supply chain decision-making.","Supply chain management,Demand forecasting,Judgment,Behavioral operations,Literature review","H. NilesPerera†,JasonHurley†,BehnamFahimnia,MohsenReisi","European Journal of Operational Research","https://doi.org/10.1016/j.ejor.2018.10.028","https://www.sciencedirect.com/science/article/pii/S0377221718308816"
"A88","Epicyclic gearbox fault detection by Instantaneous Circular Pitch Cycle Map","The paper introduces the concept of Instantaneous Circular Pitch Cycle Map (ICPCM) as a tool for analysis and diagnosis of modulation signatures in vibrations generated by Epicyclic Gearbox (EGs). The method is based on the representation of a vibration signal as a 3-D map illustrating selected signal properties. Within the method, a novel concept of a Resampling Relative Order (RRO) is introduced. The paper illustrates how the ICPCM might serve as an auxiliary tool for proper interpretation of spectra, envelope spectra, and time-synchronous averaged representations. The idea of the method is presented on a simulated signal, while its practical performance is illustrated on a real signal from a multi-stage EG.","Vibration signal,Hunting tooth,Cyclic signal analysis,Planetary gearbox diagnostics,Epicyclic gearbox","KajetanDziedziech,AdamJablonski,ZiemowitDworakowski","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.11.053","https://www.sciencedirect.com/science/article/pii/S0888327018307726"
"A89","Deep feature learning for soft tissue sarcoma classification in MR images via transfer learning","Medical image analysis is motivated by deep learning emergence and computation power increase. Meanwhile, relevant deep features can significantly enhance learnable expert and intelligent systems performance and reduce diagnosis time and arduousness. This paper presents a deep learning-based radiomics framework for aided diagnosis of soft tissue sarcomas of the extremities. MR Images with histologically confirmed Liposarcoma (LPS) and Leiomyosarcomas (LMS) have been retrieved from the Cancer Imaging Archives database and pre-processed to recuperate ROIs from MR scans with delineated tumors. This study investigates the significance and impact of medical image fusion on deep feature learning based on transfer learning from the natural domain to the medical domain. Towards this end, we propose to fuse T1 with T2FS or STIR modalities using type-2 fuzzy sets in the non-subsampled shearlet domain. Being decomposed, low-frequency sub-images were selected using local energy and type-2 fuzzy entropy, while high frequencies were selected according to the maximum of the absolute value. Experimental results indicated that the proposed fusion framework outperformed the state-of-the-art fuzzy logic-based fusion techniques in terms of entropy and mutual information. Accordingly, we fine-tuned the pre-trained AlexNet deep convolutional neural network (CNN) with stochastic gradient descent (SGD). First, with the pre-processed dataset, and second with the fused images. As a result, the average classification accuracy using the augmented training data by image rotation and flipping was 97.17% with the raw data and 98.28% with the fused images, which highlighted the usefulness of complementary information for deep feature learning. One crucial concern was to investigate the depth of knowledge transferability. We incrementally fine-tuned the pre-trained CNN to assess the required level that achieves performance improvements in STS classification. Through layer-wise fine-tuning, our study further confirms the potential of middle and deep layers in performance improvement. Moreover, the transferability was concluded better than random weights. With the encouragement of classification results, our aided diagnosis framework may be in the pipeline to assist radiologists in classifying LPS and LMS.","Convolutional Neural Networks,Soft tissue sarcoma,Multi-modal medical image fusion and classification,Type-2 fuzzy logic,Transfer learning","HaithemHermessi,OlfaMourali,EzzeddineZagrouba","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.11.025","https://www.sciencedirect.com/science/article/pii/S0957417418307450"
"A90","Characterizing the properties of anticancer silibinin and silybin B complexes with UV–Vis, FT-IR, and Raman spectroscopies: A combined experimental and theoretical study","We present a combined experimental and theoretical study dedicated to analyze the structure, optical properties, and vibrational behavior of the anticancer silibinin complex and one of its molecular constituents, namely; silybin B. A comparison of the UV–Vis and FT-IR characterization of these samples reveals the presence of almost identical features. In both cases, the existence of four absorption maxima located at 204, 230, 287, and 330<U+202F>nm are observed, as well as vibrational bands that show a complex distribution in the 300–1700<U+202F>cm-1 frequency domain together with three infrared excitations placed at ~3180, 3450, and 3600<U+202F>cm-1 typically associated with different CH and OH bond vibrations. For the first time, we present the Raman spectra of these samples. Interestingly, the Raman response reveals more notable differences between the two molecular complexes, mainly in the 300–900<U+202F>cm-1 frequency range. Furthermore, we obtain that the wavelength of the excitation laser plays a fundamental role in revealing precise features of the spectra. Based on density functional theory (DFT) calculations we also simulate the UV–Vis, circular dichroism, infrared, and Raman spectra of model silybin A and silybin B (C25H22O10) molecules in both isolated and aggregated forms. An excellent agreement is found when contrasting experimental and theoretical data. Based on this comparison, we identify the main infrared- and Raman-active vibrational modes of silybin B, and infer those frequencies that seems to be unique to silybin A. Wavelength dependent calculations of the Raman spectra also reveal the crucial role played by the energy of the incident laser in determining the intensities of the Raman active modes, allowing for a better comparison between theory and experiment. Finally, simulations of the circular dichroism spectra for isolated silybin A and B species reveal clear differences between the two molecules, being thus an appropriate tool to distinguish the presence of specific isomers in a sample.","Silybin,UV–Vis,Infrared spectroscopy,Raman spectroscopy,Density functional theory,Circular dichroism","A.Solís-Gómeza,R.Y.Sato-Berrúa,M.E.Mata-Zamoraa,J.M.Sanigera,R.A.Guirado-Lópezb","Journal of Molecular Structure","https://doi.org/10.1016/j.molstruc.2019.01.042","https://www.sciencedirect.com/science/article/pii/S0022286019300523"
"A91","Copy number variation of PR-39 cathelicidin, and identification of PR-35, a natural variant of PR-39 with reduced mammalian cytotoxicity","Proline-arginine-rich (PR)-39 is neutrophil antimicrobial peptide that has potent antimicrobial activity against a broad spectrum of microorganisms, including bacteria, fungi, and some enveloped viruses as a part of the innate immune system. We analyzed the nucleotide sequence variations of PR-39 exon 4, which is the mature peptide region responsible for antimicrobial activity, from 48 pigs of six breeds using sequence-based typing. The analysis identified four alleles including allele PR-35 with a 12-bp deletion near the N-terminus. Interestingly, 16.7% of individuals showed the presence of three alleles per individual, but only in the Berkshire and Duroc breeds. We further analyzed the genetic diversity of PR-39 for the entire genomic region of the gene from PR-39 exon 1 to the 3' untranslated region for different alleles by PCR amplification and cloning. The antimicrobial activity of chemically synthesized PR-35 was similar to that of PR-39, but the level of mammalian cell cytotoxicity was lower than the wild type. Better knowledge of the genetic diversity of PR-39 among different individuals and breeds may contribute to improved immune defense of pigs. PR-35, as a natural antimicrobial peptide variant, could be an interesting candidate for the development of peptide antibiotics.","AMPsantimicrobial peptides,CLSIClinical and Laboratory Standards Institute,CNVCopy Number Variations,HEK293THuman Embryonic Kidney cells,HPLChigh performance liquid chromatography,MICMininal Inhibitory Concentration,NCBINational Center for Biotechnology Information,PRProline-Rich,SNPSingle Nucleotide Polymorphism,SRASequence Read Archive database,Keywords,Antimicrobial peptide,Cathelicidin,Sus scrofa,Antimicrobial activity,Cytotoxicity","HyoimJeon1,Minh ThongLe1,ByeongyongAhn,Hye-sunCho,Van Chanh QuyLe,JooriYum,KwonhoHong,Jin-HoiKim,HyukSong,ChankyuPark","Gene","https://doi.org/10.1016/j.gene.2018.12.065","https://www.sciencedirect.com/science/article/pii/S037811191930023X"
"A92","Two-photon direct laser writing of beam expansion tapers on single-mode optical fibers","Small misalignments between two standard telecom single-mode fibers in a physical contact connection can lead to large optical losses. It is known that by expanding the mode field diameter of the fiber, the misalignment tolerances can be relaxed. One of the approaches to obtain this beam expansion is to use tapers. We propose an air-clad taper structure to transmit the fundamental mode of a single-mode fiber adiabatically to a 3 times larger mode field area in physical contact expanded beam connectors. This results in a 241.4<U+202F>µm long linear taper. The taper itself is fabricated on top of a cleaved fiber facet by means of the two-photon polymerization direct laser writing technique. Experimental results for lateral misalignment show excellent agreement with simulated values and give an increase in lateral misalignment tolerance of 1<U+202F>µm (-1<U+202F>dB) and 1.8<U+202F>µm (-3<U+202F>dB). Total insertion losses down to 0.76<U+202F>dB are measured, showing the trade-off between achievable insertion loss and misalignment tolerance relaxation. Finally, we show that the use of additive manufacturing techniques in fiber beam expansion applications make it possible to fabricate taper structures with full 3D design freedom and to upscale the process to multi-fiber components.","3D direct laser writing,Adiabatic beam expansion,Fiber connector,Fiber taper,Misalignment tolerances,Two-photon polymerization,2010 MSC,00-01,99-00","KoenVanmola,SalvatoreTucciob,VivekPanapakkamb,HugoThienponta,JanWattéb,JürgenVan Erpsa","Optics & Laser Technology","https://doi.org/10.1016/j.optlastec.2018.11.028","https://www.sciencedirect.com/science/article/pii/S0030399218312623"
"A93","Using semi-independent variables to enhance optimization search","In this study, the concept of a semi-independent variable (SIV) problem representation is investigated that embodies a set of expected or desired relationships among the original variables, with the goal of increasing search effectiveness and efficiency. The proposed approach intends to eliminate the generation of infeasible solutions associated with the known relationships among the variables and cutting the search space, thereby potentially improving a search algorithm's convergence rate and narrowing down the search space. However, this advantage does not come for free. The issue is the multiplicity of SIV formulations and their varying degree of complexity, especially with respect to variable interaction. In this paper, we propose the use of automatic variable interaction analysis methods to compare and contrast different SIV formulations. The performance of the proposed approach is demonstrated by implementing it within a number of classical and evolutionary optimization algorithms (namely, interior-point algorithm, simulated annealing, particle swarm optimization, genetic algorithm and differential evolution) in the application to several practical engineering problems. The case study results clearly show that the population-based algorithms can significantly benefit from the proposed SIV formulation resulting in better solutions with fewer function evaluations than in the original approach. The results also indicate that an automatic variable interaction analysis is capable of estimating the difficulty of the resultant SIV formulations prior to any optimization attempt.","Semi-independent variable,Heuristics,Evolutionary computation,Swarm intelligence","Amir HGandomia1,KalyanmoyDebb,Ronald CAverillc,ShahryarRahnamayand,Mohammad NabiOmidvare","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.11.031","https://www.sciencedirect.com/science/article/pii/S0957417418307516"
"A94","A reduced basis approach for PDEs on parametrized geometries based on the shifted boundary finite element method and application to a Stokes flow","We propose a model order reduction technique integrating the Shifted Boundary Method (SBM) with a POD-Galerkin strategy. This approach allows to deal with complex parametrized domains in an efficient and straightforward way. The impact of the proposed approach is threefold.First, problems involving parametrizations of complex geometrical shapes and/or large domain deformations can be efficiently solved at full-order by means of the SBM. This unfitted boundary method permits to avoid remeshing and the tedious handling of cut cells by introducing an approximate surrogate boundary.Second, the computational effort is reduced by the development of a Reduced Order Model (ROM) technique based on a POD-Galerkin approach.Third, the SBM provides a smooth mapping from the true to the surrogate domain, and for this reason, the stability and performance of the reduced order basis are enhanced. This feature is the net result of the combination of the proposed ROM approach and the SBM. Similarly, the combination of the SBM with a projection-based ROM gives the great advantage of an easy and fast to implement algorithm considering geometrical parametrization with large deformations. The transformation of each geometry to a reference geometry (morphing) is in fact not required.These combined advantages will allow the solution of PDE problems more efficiently. We illustrate the performance of this approach on a number of two-dimensional Stokes flow problems.","Immersed,Embedded,FEM,Reduced basis,SBM","Efthymios N.Karatzasa,GiovanniStabilea,LeoNouveaub,GuglielmoScovazzib,GianluigiRozzaa","Computer Methods in Applied Mechanics and Engineering","https://doi.org/10.1016/j.cma.2018.12.040","https://www.sciencedirect.com/science/article/pii/S0045782518306479"
"A95","Assessment of electronic system for e-patent application and economic growth prediction","Information system development is a complex endeavor, one which is fraught with peril if one do not follow a proven method. The Rational Unified Process (RUP) is one such method which could help to organize the development process of any information system. The RUP takes an evolutionary approach to development which has been shown to be far more effective than the traditional approach which is based on simple procedure. Unified Modeling Language (UML) is a RUP graphical language for visualizing, specifying, constructing, and documenting the artifacts of a information system. UML offers a standard way to write a system’s blueprints which is crucial for any information system development. The main goal of the study is to develop electronic patent (e-patent) system by RUP approach and UML standard tools. Afterwards artificial neural networks are applied to predict potential economic growth (GDP) based on science factors including patents. Extreme learning machine (ELM) is used for training process of the networks. Extreme learning machine (ELM) is a class of single-hidden layer feedforward neural network (SLFN). In theory, ELM algorithm tends to provide good generalization performance at extremely fast learning speed. Experimental results show that ELM has very high correlation with current economic dispatch.","e-patent,Economic growth,ELM,RUP,UML","SrdjanJovica,AleksandarCukarica,AndjelijaRaicevica,PanchoTomovb","Physica A: Statistical Mechanics and its Applications","https://doi.org/10.1016/j.physa.2019.01.009","https://www.sciencedirect.com/science/article/pii/S0378437119300123"
"A96","Multivariate dependent interval finite element analysis via convex hull pair constructions and the Extended Transformation Method","Classical (independent) interval analysis considers a hyper-cubic input space consisting of independent intervals. This stems from the inability of intervals to model dependence and results in a serious over-conservatism when no physical guarantee of independence of these parameters exists. In a spatial context, dependence of one model parameter over the model domain is usually modelled using a series expansion over a set of basis functions that interpolate a set of globally defined intervals to local (coupled) uncertainty. However, the application of basis functions is not always appropriate to model dependence, especially when such dependence does not have a spatial nature but is rather scalar. This paper therefore presents a flexible approach for the modelling of dependent intervals that is also applicable to multivariate problems. Specifically, it is proposed to construct the dependence structure in a similar approach to copula pair constructions, yielding a limited set of 2-dimensional dependence functions. Furthermore, the well-known Transformation Method is extended to the case of dependent interval analysis. The applied case studies indicate the flexibility and performance of the method.","Interval analysis,Dependent intervals,Copula pair constructions,Non-probabilistic analysis,Transformation method,Imprecise probability","MatthiasFaes,DavidMoens","Computer Methods in Applied Mechanics and Engineering","https://doi.org/10.1016/j.cma.2018.12.021","https://www.sciencedirect.com/science/article/pii/S0045782518306200"
"A97","Local structural investigation of refractory oxide thin films near laser damage threshold","Study of laser induced damage mechanism and effort to increase the damage threshold of oxide thin films is of immense technological importance because as improved laser-damage resistant optical materials and better fabrication technologies are developed, laser designers can increase the system operating energies and powers to the limits of these new materials. Although, many efforts have been made to investigate how stoichiometry or long range order structure plays a role in describing the laser damage process, to the best of our knowledge, efforts to understand the local structural changes in the materials due to laser irradiation around the damage threshold has not been made so far. In this communication, a set of RF sputter deposited dielectric refractory oxide thin film samples have been subjected to laser irradiation across their damage threshold. In case of TiO2, Ta2O5, and HfO2 thin films, the samples were irradiated with optimized laser fluence and different locations on the samples were irradiated with varying number of pulse shots, while in case of Gd2O3 films, different locations of the samples were irradiated with fixed number of pulse shots and with varying laser fluence. The irradiated samples have subsequently been subjected to X-ray absorption spectroscopy (XAS) studies to find out change in the local structure of the samples under laser irradiation. Apart from XAS measurements, various other characterization techniques such as optical microscopic imaging, grazing incidence X-ray reflectivity and grazing incidence X-ray diffraction have also been employed to study the laser irradiated zones. The results indicate interesting local structural evolution in oxide thin films with the onset of laser induced damage which gives novel insight about the laser damage mechanism.","Pulse laser,Laser damage threshold,XANES,EXAFS,Refractory oxide material,Thin film","S. MaidulHaqueab,RajnarayanDea,S.Tripathia,C.Mukherjeebc,S.N.Jhad,D.Bhattacharyyad","Optics & Laser Technology","https://doi.org/10.1016/j.optlastec.2018.11.030","https://www.sciencedirect.com/science/article/pii/S0030399218313884"
"A98","A new way for harmonic probing of hysteretic systems through nonlinear smooth operators","This paper proposes a new way to approach hysteresis with the rate-independent property through an analytical response for the non-smooth hysteresis loop using frequency response approximations. The method consists of rewriting the loading and unloading loop using smooth operators and after applying a harmonic probing in the equivalent system to obtain the higher-order frequency response functions computed by Volterra series. The novelty of this paper lies on predicting analytically, through closed-form equations of the Volterra kernels, the output and the hysteresis loop from a non-smooth system. To illustrate the applicability of the proposed approach, a challenging benchmark with hysteretic damping, described by the Bouc-Wen model, is simulated through a numerical integration scheme. The hysteresis loops, as well as the outputs, are compared to the analytical approach proposed here. The results show that the Volterra model is able to predict the hysteretic outputs when the excitation amplitude is weak and the hysteresis draws a single loop in the restoring force × displacement plane. The higher-order FRFs are given as a function of the model parameters. This framework could turn into an alternative tool to perform nonlinear modal analysis on a hysteretic system.","Hysteretic systems,Higher-order frequency response function,Harmonic probing,Volterra series","Rafael de O.Teloli,Samuelda Silva","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.11.044","https://www.sciencedirect.com/science/article/pii/S0888327018307659"
"A99","Lagged correlation-based deep learning for directional trend change prediction in financial time series","Trend change prediction in complex systems with a large number of noisy time series is a problem with many applications for real-world phenomena, with stock markets as a notoriously difficult to predict example of such systems. We approach predictions of directional trend changes via complex lagged correlations between them, excluding any information about the target series from the respective inputs to achieve predictions purely based on such correlations with other series. We propose the use of deep neural networks that employ step-wise linear regressions with exponential smoothing in the preparatory feature engineering for this task, with regression slopes as trend strength indicators for a given time interval. We apply this method to historical stock market data from 2011 to 2016 as a use case example of lagged correlations between large numbers of time series that are heavily influenced by externally arising new information as a random factor. The results demonstrate the viability of the proposed approach, with state-of-the-art accuracies and accounting for the statistical significance of the results for additional validation, as well as important implications for modern financial economics.","Lagged correlation,Deep learning,Trend analysis,Stock market,MSC,68T05,62P20","BenMoewsa,J. MichaelHerrmannb,GbengaIbikunlec","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.11.027","https://www.sciencedirect.com/science/article/pii/S0957417418307474"
"A100","Revisiting fish toxicity of active pharmaceutical ingredients: Mechanistic insights from integrated ligand-/structure-based assessments on acetylcholinesterase","The release of active pharmaceutical ingredients (APIs) into the environment is of great concern for aquatic ecosystem as many of these chemicals are designed to exert biological activity. Hence, their impact on non-target organisms like fish would not be surprising. In this respect, we revisited fish toxicity data of pharmaceuticals to generate linear and non-linear quantitative structure-toxicity relationships (QSTRs). We predicted fish lethality data from the validated QSTR models for 120 APIs with no experimental fish toxicity data. Toxicity of APIs on aquatic organisms is not fully characterized. Therefore, to provide a mechanistic insight for the assessment of API's toxicity to fish, the outcome of the derived QSTR models was integrated with structure-based toxicophore and molecular docking studies, utilizing the biomarker enzyme acetylcholinesterase originating from fish Torpedo californica (TcAChE). Toxicophore virtual screening of 60 chemicals with pT<U+202F>><U+202F>0 identified 23 hits as potential TcAChE binders with binding free energies ranging from -6.5 to -12.9<U+202F>kcal/mol. The TcAChE-ligand interaction analysis revealed a good nesting of all 23 hits within TcAChE binding site through establishing strong lipophilic and hydrogen bonding interactions with the surrounding key amino acid residues. Among the chemicals passing the criteria of our integrated approach, majority of APIs belong noticeably to the Central Nervous System class. The screened chemicals displayed not only comprehensive toxicophore coverage, but also strong binding affinities according to the docking calculations, mainly due to interactions with TcAChE's key amino acid residues Tyr121, Tyr130, Tyr334, Trp84, Phe290, Phe330, Phe331, Ser122, and Ser200. Moreover, we propose here that binding of pharmaceuticals to AChE might have a potential in triggering molecular initiating events for adverse outcome pathways (AOPs), which in turn can play an important role for future screening of APIs lacking fish lethality data.","Active pharmaceutical ingredients,Fish toxicity,AChE (Torpedo californica),QSTR,Structure-based toxicophores,Molecular docking","NikolaMinovskia,Melek TürkerSaçanb1,Elif MerveEminogluc,Safiye SagErdemc,MarjanaNovica","Ecotoxicology and Environmental Safety","https://doi.org/10.1016/j.ecoenv.2018.11.099","https://www.sciencedirect.com/science/article/pii/S0147651318312442"
"A101","Predicting soil organic carbon content in croplands using crop rotation and Fourier transform decomposed variables","Previous studies on soil organic carbon content or stock mapping mostly use natural environmental covariates and do not consider the soil management practice factor. However, human activities have become an important influencing factor for soil organic carbon, especially for agricultural soils. Crop species/crop rotations and management practices significantly affect the amount and spatial variation of soil organic carbon in croplands, but have not been considered for mapping soil organic carbon. In this study, we used direct crop rotation information and variables generated using Fourier transform on HJ-1A/1B NDVI time series data to capture the periodic effect of crop rotation, and explored the effectiveness of incorporating such information in predicting topsoil organic carbon content in cropland. A case study applied such method in a largely agricultural area in Anhui province, China. Crop rotation information was obtained through field investigation. Various combinations of predictive environmental variables were experimented for mapping soil organic carbon. The results were validated using field samples. Results showed that the combination of natural environment variables with both crop rotation type and variables derived through Fourier transform yielded the highest accuracy. In addition, only using the Fourier decomposed variables and crop rotation information were able to achieve a similar accuracy with using only soil formative natural environmental variables. This indicates that crop rotation information has comparable predictive power of soil organic carbon as natural environment variables. This study demonstrates the effectiveness of including agricultural practice information in digital soil mapping in agricultural landscapes with differences in crop rotation.","Digital soil mapping,Soil organic carbon content,Human activity factor,Crop rotation,Fourier transform","LinYangab,MinSongb,A-XingZhubcdef,ChengzhiQinbce,ChenghuZhoubc,FengQig,XinmingLibc,ZiyueChenh,BinboGaoi","Geoderma","https://doi.org/10.1016/j.geoderma.2019.01.015","https://www.sciencedirect.com/science/article/pii/S0016706118316173"
"A102","Developing a data analytics platform to support decision making in emergency and security management","The Emergency and Security Coordinating Centre is the public service responsible for managing all the incidents registered in the Canary Islands. More than 7 million records have been collected in the last decade with more than twenty observed variables for each incident, which comprise more than 140 million data. All these data emanate from different islands and municipalities but with very marked differences. The study in this paper presents complete and novel research about geographical and temporal incident distribution, which may be of interest to emergency services managers and people responsible for designing public policies concerning security and health matters. We have developed an analytical web platform that features several dashboards with statistically significant results, by island, municipality, etc., and incorporating certain external data sources regarding social and economic issues which allow us to study the relationship between these factors and incident distribution at different geographical levels. Certain specific results are presented and illustrated in order to show all dimensions of data analytics that not only significantly improve companies’ and organizations’ processes, but also demonstrate how data analytics competency relates to decision making performance. Several statistical models that forecast and classify the incidents are proposed to illustrate the potential of statistical modelling in the study. The application has become into a crucial strategic tool for the organization because it helps in decision making processes. The information provided is highly modular and allows for the future inclusion of new features in order to provide larger and improved data analyses.","Data analytics,Decision-making support,Dashboard and visualization tool,Forecasting and classification models","Carlos J.Pérez-Gonzáleza,MarcosColebrookb,José L.Roda-Garcíab,Carlos B.Rosa-Remediosc","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.11.023","https://www.sciencedirect.com/science/article/pii/S0957417418307449"
"A103","Global disparity in public awareness of the biological control potential of invertebrates","Invertebrates make up over 95% of animal biodiversity on Earth and contribute to multiple ecosystem services (ES) in natural and human-dominated systems. One such service, biological control (BC) of herbivorous pests, is a core component of sustainable intensification of agriculture, yet its importance is routinely overlooked. Here we report a macro-scale, cross-cultural assessment of the public visibility (or ‘salience’) of BC invertebrates, using high-throughput analysis of large bodies of digitized text (i.e., ‘culturomics’). Using binomial scientific name frequency as proxy for visibility, we compared the extent to which a given species featured in webpages within either scientific media or the entire worldwide web, and in total search volume at varying spatial scale. For a set of 339<U+202F>BC invertebrate species, scientific and internet coverage averaged 1020 and 1735 webpages, respectively. Substantial variability was recorded among BC taxa with Coleoptera, Hemiptera and Nematoda having comparatively high visibility. Online visibility exhibited large geographical variability ranging from France covering BC invertebrates on average in 1050 webpages versus Thailand or Indonesia on just 31–38. This work represents the first extensive use of culturomics to assess public visibility of insect-mediated ES. As BC uptake is dictated by stakeholders' access to (agro-ecological) information, our work identifies geographically-delineated areas that are differentially attuned to the concept of invertebrate BC, pinpoints opportunities for focusing education campaigns and awareness-raising, enables real-time tracking of BC public appeal, and informs public policy.","Agro-ecology,Ecological intensification,Functional biodiversity,Ecosystem services,Pest management,Computational science,Public perception,Big data","K.A.G.Wyckhuysabcd,G.Pozsgaia,G.L.Loveiae,L.Vasseuraf,S.D.Wrattenag,G.M.Gurrah,O.L.Reynoldsahi,M.Goettelaj","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2019.01.077","https://www.sciencedirect.com/science/article/pii/S0048969719300841"
"A104","Dual network extraction algorithm to investigate multiple transport processes in porous materials: Image-based modeling of pore and grain scale processes","Image processing of 3D tomographic images to extract structural information of porous materials has become extremely important in porous media research with the commoditization of x-ray tomography equipment to the lab scale. Extracted pore networks from images using image analysis techniques enable transport properties calculation for bigger domains at a low computational cost, allowing pore-scale investigation of porous media over meaningful macroscopic length scales. The present study reports a pore network extraction algorithm to simultaneously extract void and solid networks from tomographic images of porous materials using simple image analysis techniques. Crucially, it includes connectivity and geometrical information of both void and solid phases as well as the interlinking of these phases with each other. Validation was obtained on networks extracted from simple cubic and random sphere packings over a range of porosities. The effective diffusivity in the void phase and thermal conductivity in the solid phase was then calculated and found to agree well with direct numerical simulation results on the images, as well as a range of experimental data. One important outcome of this work was a novel and accurate means of calculating interfacial areas between grains and voids directly from digital images, which is critical to many phenomena where phase interactions occur. The efficient ‘dual network’ algorithm is written in PYTHON using open source tools and provides a new way to study critical processes that depend on transport in both void and solid phase such as catalytic reactors and electrochemical systems.","Porous media,Transport phenomena,Heterogeneous catalysis,Tomography,Pore network modeling","Zohaib AtiqKhanac,TomTrantera,MehrezAgnaoua,AliElkamelab,JeffGosticka","Computers & Chemical Engineering","https://doi.org/10.1016/j.compchemeng.2018.12.025","https://www.sciencedirect.com/science/article/pii/S0098135418309402"
"A105","The apple yang cycle’s gene MdDEP1 enhances salt and drought tolerance, as well as triggers early-flowering in Arabidopsis","DEHYDRATASE-ENOLASE-PHOSPHATASE-COMPLEX1 (DEP1), a trifunctional enzyme with dehydratase, enolase, and phosphatase activities, initially characterizes with its enzymatic function in the recycling of the ethylene precursor methionine (Met). Here, we identified an apple MdDEP1 gene, which encodes a protein highly homologous to Arabidopsis Yang’s cycle gene AtDEP1. GUS staining of 35S::pMdDEP1-GUS transgenic Arabidopsis showed that MdDEP1 is widely expressed in Arabidopsis tissues especially in vascular systems. Additionally, ectopic expression of MdDEP1 alters salt and drought tolerance, and triggers early flowering in Arabidopsis on the medium. The increase of salt tolerance in MdDEP1-expressing plants was realized through upregulation of the typical salt overly sensitive (SOS) pathway-related genes, including AtSOS1, AtSOS2, and AtSOS3; and that MdDEP1 controlled flowering time mainly by influencing the expression of flowering-associated genes. Collectively, these findings provide new functions of the DEP1 protein and its underlying mechanisms, in which MdDEP1 confers salt and drought-tolerance, and early flowering phenotypes.","MdDEP1,Yang’s cycle,Salt tolerance,Drought tolerance,Early-flowering","Jia-HuiWanga,Kai-DiGua,XiDuanb,Chu-KunWanga,Quan-YanZhanga,Da-GangHua1,Yu-JinHaoa1","Scientia Horticulturae","https://doi.org/10.1016/j.scienta.2018.12.012","https://www.sciencedirect.com/science/article/pii/S0304423818308847"
"A106","Tissue-specific transcriptional biomarkers in medicinal plants: Application of large-scale meta-analysis and computational systems biology","Biosynthesis of secondary metabolites in plant is a complex process, regulated by many genes and influenced by several factors. In recent years, the next-generation sequencing (NGS) technology and advanced statistical analysis such as meta-analysis and computational systems biology have provided novel opportunities to overcome biological complexity. Here, we performed a meta-analysis on publicly available transcriptome datasets of twelve economically significant medicinal plants to identify differentially expressed genes (DEGs) between shoot and root tissues and to find the key molecular features which may be effective in the biosynthesis of secondary metabolites. Meta-analysis identified a total of 880 genes with differential expression between two tissues. Functional enrichment and KEGG pathway analysis indicated that the functions of those DEGs are highly associated with the developmental process, starch metabolic process, response to stimulus, porphyrin and chlorophyll metabolism, biosynthesis of secondary metabolites and phenylalanine metabolism. In addition, systems biology analysis of the DEGs was applied to find protein–protein interaction network and discovery of significant modules. The detected modules were associated with hormone signal transduction, transcription repressor activity, response to light stimulus and epigenetic processes. Finally, analysis was extended to search for putative miRNAs that are associated with DEGs. A total of 31 miRNAs were detected which belonged to 16 conserved families. The present study provides a comprehensive view to better understand the tissue-specific expression of genes and mechanisms involved in secondary metabolites synthesis and may provide candidate genes for future researches to improve yield of secondary metabolites.","ROMratio of means,FCfold change,GOgene ontology,DEGdifferentially expressed gene,qPCRquantitative real-time RT-PCR,PPIprotein–protein interaction,CHSchalcone synthase,C3'Hcytochrome p450 reductase,CYPcytochrome P450,PALphenylalanine ammonia-lyase,HMGR3-hydroxy-3-methylglutaryl-coenzyme A reductase,SK1shikimate kinase 1,Keywords,Medicinal plant,Shoot and root tissues,Secondary metabolites,Transcriptome data,Meta-analysis","AhmadTahmasebia,EsmaeilEbrahimiebcde,HassanPakniyata,MansourEbrahimifg,ManijehMohammadi-Dehcheshmehcg","Gene","https://doi.org/10.1016/j.gene.2018.12.056","https://www.sciencedirect.com/science/article/pii/S0378111919300046"
"A107","Alignment-free approaches for predicting novel Nuclear Mitochondrial Segments (NUMTs) in the human genome","The nuclear human genome harbors sequences of mitochondrial origin, indicating an ancestral transfer of DNA from the mitogenome. Several Nuclear Mitochondrial Segments (NUMTs) have been detected by alignment-based sequence similarity search, as implemented in the Basic Local Alignment Search Tool (BLAST). Identifying NUMTs is important for the comprehensive annotation and understanding of the human genome. Here we explore the possibility of detecting NUMTs in the human genome by alignment-free sequence similarity search, such as k-mers (k-tuples, k-grams, oligos of length k) distributions. We find that when k=6 or larger, the k-mer approach and BLAST search produce almost identical results, e.g., detect the same set of NUMTs longer than 3<U+202F>kb. However, when k=5 or k=4, certain signals are only detected by the alignment-free approach, and these may indicate yet unrecognized, and potentially more ancestral NUMTs. We introduce a “Manhattan plot” style representation of NUMT predictions across the genome, which are calculated based on the reciprocal of the Jensen-Shannon divergence between the nuclear and mitochondrial k-mer frequencies. The further inspection of the k-mer-based NUMT predictions however shows that most of them contain long-terminal-repeat (LTR) annotations, whereas BLAST-based NUMT predictions do not. Thus, similarity of the mitogenome to LTR sequences is recognized, which we validate by finding the mitochondrial k-mer distribution closer to those for transposable sequences and specifically, close to some types of LTR.","Alignment-free,k-mer,Mitochondria,NUMT,Jensen-Shannon divergence,Manhattan plot,abbreviations,BLASTbasic local alignment search tool,ERVendogenous retrovirus,JSJensen-Shannon (divergence),kbkilo (1000) bases,KLKullback-Leibler (divergence),LTRlong terminal repeats,Mbmillion (1,000,000) bases,MDSmulti-dimensional scaling,MTmitochondrial,NUMTnuclear mitochondrial DNA segments/sequences,tSNEt-distributed stochastic neighbor embedding","WentianLia,JeromeFreudenberga,JanFreudenbergb","Gene","https://doi.org/10.1016/j.gene.2018.12.040","https://www.sciencedirect.com/science/article/pii/S0378111918312976"
"A108","Multi-spectroscopic approaches and molecular simulation research of the intermolecular interaction between the angiotensin-converting enzyme inhibitor (ACE inhibitor) benazepril and bovine serum albumin (BSA)","Benazepril, a common ACE inhibitor, widely used in the treatment of arterial hypertension and congestive heart failure. In this study, We evaluated the characteristics of the interaction between benazepril and BSA under the simulated physiological condition (pH<U+202F>7.4) through various spectroscopic and molecular docking methods. Fluorescence and absorption spectroscopy results showed benazepril quenched the intrinsic fluorescence of BSA through a combined dynamic and static quenching mechanism. The number of binding sites (n) and the binding constant (Kb) of benazepril–BSA complex were circa 1 and 6.81<U+202F>×<U+202F>103<U+202F>M-1 at 298<U+202F>K, respectively, indicating that the binding affinity between benazepril and BSA was moderate. The displacement experiments confirmed that benazepril binding to the site I of BSA, which was quite in accordance with molecular docking. The values of the Gibbs free energy (<U+0394>G0), enthalpic change (<U+0394>H0) and entropic change (<U+0394>S0) were negative, verifying that van der Waals force and hydrogen bonding interaction played a predominant roles in the process of spontaneous bonding. Furthermore, a slight change of the conformation in BSA upon benazepril interaction was proved through SF, 3-DF and FTIR spectroscopy results.","ACEangiotensin-converting enzyme,BSABovine serum albumin,FTIRfourier transform infrared,CDcircular dichroism,FRETForster resonance energy transfer,<U+03BB>exexcitation wavelength,<U+03BB>ememission wavelength,IFEinner-filter effect,LGALamarckian Genetic Algorithm,KSVfluorescence quenching constant,kqquenching rate constant,ANS-NH48-Anilino-1-naphthalenesulfonate-NH4,Trptryptophane,Tyrtyrosine,Keywords,Benazepril,Bovine serum albumin,Interaction,Multi-spectroscopy,Molecular simulation","Bao-LiWang,Dong-QiPan,Kai-LiZhou,Yan-YueLou,Jie-HuaShi","Spectrochimica Acta Part A: Molecular and Biomolecular Spectroscopy","https://doi.org/10.1016/j.saa.2018.12.040","https://www.sciencedirect.com/science/article/pii/S1386142518311107"
"A109","A multiscale method for model order reduction in PDE parameter estimation","Estimating parameters of Partial Differential Equations (PDEs) is of interest in a number of applications such as geophysical and medical imaging. Parameter estimation is commonly phrased as a PDE-constrained optimization problem that can be solved iteratively using gradient-based optimization. A computational bottleneck in such approaches is that the underlying PDEs need to be solved numerous times before the model is reconstructed with sufficient accuracy. One way to reduce this computational burden is by using Model Order Reduction (MOR) techniques such as the Multiscale Finite Volume Method (MSFV).In this paper, we apply MSFV for solving high-dimensional parameter estimation problems. Given a finite volume discretization of the PDE on a fine mesh, the MSFV method reduces the problem size by computing a parameter-dependent projection onto a nested coarse mesh. A novelty in our work is the integration of MSFV into a PDE-constrained optimization framework, which updates the reduced space in each iteration. We present a computationally tractable way of explicitly differentiating the MOR solution that acknowledges the change of basis. As we demonstrate in our numerical experiments, our method leads to computational savings for large-scale parameter estimation problems where iterative PDE solvers are necessary and offers potential for additional speed-ups through parallel implementation.","Model order reduction,Parameter estimation,PDE constrained optimization,Optimal control,Geophysical imaging","Samy WuFung,LarsRuthotto","Journal of Computational and Applied Mathematics","https://doi.org/10.1016/j.cam.2018.09.043","https://www.sciencedirect.com/science/article/pii/S0377042718305946"
"A110","Is evaluation obsolete in a post-truth world?","The contemporary post-truth phenomenon is characterised by denial of facts and tolerance of politicians’ lies. It has enhanced the appeal of authoritarian and nationalist leaders as a populist reaction to policy failures. While emerging market countries hugely benefited from globalization, the hourly wages of working people in high-income countries have stagnated while inequality has surged, and environmental stresses have escalated. Post-truth dispositions are distorting decision making in the public sphere and they have increased public distrust of knowledge professionals. This is likely to aggravate the very problems that gave rise to the post-truth phenomenon. Evaluation can help reverse the trends that underlie voters’ anxieties, amplification of tribal prejudices and appeals to national pride through sound advice, transparency and public education. This will require new evaluation policy directions. Evaluation internationalization, diversification, democratization and professionalization will have to take place simultaneously.","Alternative facts,Democracy,Evaluation,Methods,Policy,Post-truth,Psychology,Internationalization","RobertPicciotto","Evaluation and Program Planning","https://doi.org/10.1016/j.evalprogplan.2018.12.006","https://www.sciencedirect.com/science/article/pii/S014971891830329X"
"A111","The development of a deep neural network and its application to evaluating the interior sound quality of pure electric vehicles","Interior noise substantially influences the physiological and psychological sensations of passengers in pure electric vehicles (EVs). Numerous studies have examined the development of acoustic prediction models and acoustic metrics to evaluate EV interior sound quality. However, the existing studies have the following four deficiencies: (1) the interior noise of EVs was studied only on general roads, and few EV samples were tested; (2) the physical acoustical metrics and psychoacoustic metrics did not comprehensively reflect all the characteristics of the interior noise of EVs; (3) features added to the acoustic prediction models were manually extracted and selected and were highly dependent on prior knowledge of acoustic theory and experience; and (4) the most common acoustic prediction models used to evaluate interior noise have shallow architectures. To overcome these deficiencies, we introduce a novel intelligent acoustic model based on deep neural networks (DNNs) called the Laplacian score-deep belief network (LS-DBN). We used the LS-DBN to evaluate the sound quality of EV interior noise. To verify the effectiveness of the proposed method, the interior noises of ten EVs were recorded on eight different road surfaces and corresponding subjective evaluations were conducted. In addition, noise features were extracted adaptively using the LS-DBN, and adaptively extracted features and manually extracted features were compared. The performance of the LS-DBN was validated against a conventional DBN and a back-propagation neural network (BPNN). The results show that the proposed LS-DBN model is superior to the conventional DBN and BPNN in terms of accuracy and stability, and it is highly efficient. Thus, the LS-DBN can achieve good prediction results when evaluating the interior sound quality of EVs.","Electric vehicle,Sound quality,Interior noise,Laplacian score,Deep neural networks","Hai B.Huangab,Jiu H.Wua,Xiao R.Huangbd,Ming L.Yangb,Wei P.Dingbc","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.09.035","https://www.sciencedirect.com/science/article/pii/S0888327018306538"
"A112","Support driven wavelet frame-based image deblurring","Wavelet frames have been widely applied in the field of image processing, due to their good capability for sparsely representing the piece-wise smooth functions which are suitable for describing natural images. In this paper, we propose a novel and efficient wavelet frame based sparse recovery model denoted as Support Driven Sparse Regularization (SDSR) for image deblurring. The partial support information of the wavelet frame coefficients is first attained via a self-learning strategy applied on a reference image, and this support prior is then exploited via a proposed truncated l0 regularization term. Moreover, existing off-the-shelf deblurring methods can be easily incorporated into the open interface of our flexible algorithmic framework, by providing the initial reference image for support detection. In the experiments, we compare our method with several state-of-the-art deblurring approaches. The results demonstrate the effectiveness of the proposed method in terms of PSNR and SSIM values.","Wavelet frame,Image deblurring,Support estimation,Truncated l0 regularization","LiangtianHeab,YilunWangbcd,ZhaoyinXiangb","Information Sciences","https://doi.org/10.1016/j.ins.2018.12.005","https://www.sciencedirect.com/science/article/pii/S0020025516320229"
"A113","Impact of data breach locality and error management on attitude and engagement","Given the growing number of credit card transactions, data breaches have become an increasingly serious concern for hotel businesses. Even when a rival hotel experiences a data breach, customers of the focal hotel may feel vulnerable as well. Nevertheless, firms have little insight into the potential impacts of a data breach on customers and the corresponding recovery strategies. For this study, the joint effect of data breach locality (i.e., focal hotel vs. rival hotel) and error management (i.e., no vs. low vs. high EM) on customers’ attitudes toward the focal hotel and engagement behaviors (i.e., intentions to spread positive WOM and negative WOM) was examined. A 2<U+2009>×<U+2009>3 scenario-based experiment was conducted. The results of the MANCOVA analysis suggest that when a rival hotel is breached, low error management is more effective. Interestingly, when the focal hotel is breached, high error management and low error management are equally effective.","Data breach,Locality,Error management,Attitude,Consumer engagement behaviors","LuZhanga,WeiWeib,NanHuab","International Journal of Hospitality Management","https://doi.org/10.1016/j.ijhm.2018.12.001","https://www.sciencedirect.com/science/article/pii/S0278431918302147"
"A114","Webthetics: Quantifying webpage aesthetics with deep learning","As web has become the most popular media to attract users and customers worldwide, webpage aesthetics plays an increasingly important role for engaging users online and impacting their user experience. We present a novel method using deep learning to automatically compute and quantify webpage aesthetics. Our deep neural network, named as Webthetics, which is trained from the collected user rating data, can extract representative features from raw webpages and quantify their aesthetics. To improve the model performance, we propose to transfer the knowledge from image style recognition task into our network. We have validated that our method significantly outperforms previous method using hand-crafted features such as colorfulness and complexity. These promising results indicate that our method can serve as an effective and efficient means for providing objective aesthetics evaluation during the design process.","Webpage aesthetics,Deep learning,Web visual design,User experience","QiDoub,Xianjun SamZhenga,TongfangSunc,Pheng-AnnHengb","International Journal of Human-Computer Studies","https://doi.org/10.1016/j.ijhcs.2018.11.006","https://www.sciencedirect.com/science/article/pii/S1071581918306682"
"A115","A comparative biophysical and in-silico studies on the interactions of ticlopidine hydrochloride with two serum albumins","The current study is undertaken to explore the interaction between ticlopidine hydrochloride (Tic) and the serum transport proteins, human serum albumin (HSA) and bovine serum albumin (BSA) by multi-spectroscopic, calorimetric, and molecular modeling techniques. The fluorescence results indicate that quenching of HSA and BSA is initiated by Tic through static manner. The binding constant (Kb) was found to be in the order of 104, reflecting high affinity of Tic for serum albumins. The binding site of Tic on HSA and BSA is determined by site specific displacement studies. The thermodynamic profile, obtained from isothermal titration calorimetry (ITC), suggested that all reactions are exothermic and hydrogen bonding and/or van der Waals are predominant forces in stabilizing the HSA-Tic and BSA-Tic complexes. The UV–vis, synchronous and 3D fluorescence spectroscopic results confirm conformational alteration in HSA and BSA by Tic which is further proved by CD spectroscopy. In addition, molecular docking on HSA-Tic and BSA-Tic systems were performed to confirm the binding site, amino acids residues involved in the binding process and their mode of interaction with Tic molecule. This study is expected to provide greater pharmacological understanding of Tic and highlights its pharmacokinetic properties.","Human serum albumin,Bovine serum albumin,Ticlopidine hydrochloride,Spectroscopy,Isothermal titration calorimetry,Molecular docking","SamimaKhatuna,Riyazuddeena,GulamRabbanib","The Journal of Chemical Thermodynamics","https://doi.org/10.1016/j.jct.2018.10.017","https://www.sciencedirect.com/science/article/pii/S0021961418307985"
"A116","Fused-ring acceptor with a spiro-bridged ladder-type core for organic solar cells","Side-chain engineering could tune the crystallinity, solubility and aggregation styles of fused-ring electron acceptors (FREAs), and thus could influence the morphology and charge carrier mobility of blend films as well as the final device performances. Herein, we developed a novel FREA called spiro-IDT-O-IC, which is composed of a spiro-bridged IDT core and two 1,1-dicyanomethylene-3-indanone (IC) terminal units. Similar acceptor molecule IDT-O-IC with four 4-octyloxyphenyl side chains is also prepared for the control experiment. The absorptions, energy levels, molecular configurations, and electronic wave functions of these two acceptor molecules have been comparatively studied. Polymer solar cells (PSCs) fabricated with PBDB-T:spiro-IDT-O-IC as the active layer demonstrated a PCE of 6.23% with a Jsc of 11.76<U+202F>mA/cm2, a Voc of 0.84<U+202F>V and an FF of 0.63. To the best of our knowledge, this is the first report that a spiro-bridged ladder type core was used for the fabrication of fused ring acceptors.","","ShouliMinga,YahuiLiua,ShiyuFenga,PengchengJianga,Cai'eZhanga,MiaoLia,JinshengSongb,ZhishanBoa","Dyes and Pigments","https://doi.org/10.1016/j.dyepig.2018.11.040","https://www.sciencedirect.com/science/article/pii/S0143720818321454"
"A117","The worldwide research trends on water ecosystem services","In recent decades, the scarcity of water resources, the deterioration of aquatic ecosystems and associated repercussions for other ecosystems have become major global challenges. In this context, research on water ecosystem services has become increasingly important. The objective of this work is to analyse the evolution of this line of research worldwide for the period 1998–2017. A bibliometric analysis showed that this line of research has been gaining relevance within the ecosystem services field. Exponential growth has been observed in such research, and more than 65% of the studies have been performed in the last five years. Economic analyses have little relevance and gradually have lost relative importance. Results show that the most used keywords during the studied period are Ecosystem, Biodiversity, Water Quality, Ecology and Climate Change. The highest contributing countries on this topic are USA, China, UK, Germany and Australia. The leading institutions in this research field are the Chinese Academy of Sciences, the Research Center for Eco-Environmental Sciences and the Wageningen University and Research Centre. A high level of international collaboration is observed between the different agents involved in ecosystem services research and extensive cooperation networks. Three differentiated clusters have been detected around which this type of work is grouped: aquatic ecosystems, forest ecosystems and agricultural ecosystems. The interactions between different types of ecosystems must be investigated with respect to water, and holistic frameworks should be developed that integrate the different disciplines to achieve a more complete analysis of the set of services that contribute to the sustainable management of the different types of ecosystems.","Scientific research,Ecosystem services,Water,Bibliometric analysis,Scopus","José A.Aznar-Sáncheza,Juan F.Velasco-Muñoza,Luis J.Belmonte-Ureñaa,FranciscoManzano-Agugliarob","Ecological Indicators","https://doi.org/10.1016/j.ecolind.2018.12.045","https://www.sciencedirect.com/science/article/pii/S1470160X18309786"
"A118","One-shot generation of near-optimal topology through theory-driven machine learning","We introduce a theory-driven mechanism for learning a neural network model that performs generative topology design in one shot given a problem setting, circumventing the conventional iterative process that computational design tasks usually entail. The proposed mechanism can lead to machines that quickly respond to new design requirements based on its knowledge accumulated through past experiences of design generation. Achieving such a mechanism through supervised learning would require an impractically large amount of problem–solution pairs for training, due to the known limitation of deep neural networks in knowledge generalization. To this end, we introduce an interaction between a student (the neural network) and a teacher (the optimality conditions underlying topology optimization): The student learns from existing data and is tested on unseen problems. Deviation of the student’s solutions from the optimality conditions is quantified, and used for choosing new data points to learn from. We call this learning mechanism “theory-driven”, as it explicitly uses domain-specific theories to guide the learning, thus distinguishing itself from purely data-driven supervised learning. We show through a compliance minimization problem that the proposed learning mechanism leads to topology generation with near-optimal structural compliance, much improved from standard supervised learning under the same computational budget.","Topology optimization,Meta-learning,Active learning","RuijinCang,HopeYao,YiRen","Computer-Aided Design","https://doi.org/10.1016/j.cad.2018.12.008","https://www.sciencedirect.com/science/article/pii/S0010448518303828"
"A119","Stability of dual circular tunnels in a rock mass subjected to surcharge loading","This paper investigates the stability of dual circular tunnels in a rock mass subjected to surcharge loading using adaptive finite element limit analysis (AFELA). The tunnels are modelled under plain-strain conditions, and the rock mass is assumed to be a homogeneous and isotropic material obeying the Hoek-Brown failure criterion. For the studied problem, numerical kinematic and static approaches are employed to calculate the rigorous upper and lower bounds of the stability number N, which has been bracketed within<U+202F>±5% from above and below. The calculated results are presented in the form of dimensionless stability charts, and the typical failure mechanisms are discussed through parametric studies of the problem variables using the visualized results of AFELA.","Dual tunnels,Stability,Rock mass,Hoek-Brown failure criterion,Finite element limit analysis","RuiZhanga,YaoXiaob,MinghuaZhaob,HengZhaob","Computers and Geotechnics","https://doi.org/10.1016/j.compgeo.2019.01.004","https://www.sciencedirect.com/science/article/pii/S0266352X19300047"
"A120","Challenges in diffusion MRI tractography – Lessons learned from international benchmark competitions","Diffusion MRI (dMRI) fiber tractography has become a pillar of the neuroimaging community due to its ability to noninvasively map the structural connectivity of the brain. Despite widespread use in clinical and research domains, these methods suffer from several potential drawbacks or limitations. Thus, validating the accuracy and reproducibility of techniques is critical for sound scientific conclusions and effective clinical outcomes. Towards this end, a number of international benchmark competitions, or “challenges”, has been organized by the diffusion MRI community in order to investigate the reliability of the tractography process by providing a platform to compare algorithms and results in a fair manner, and evaluate common and emerging algorithms in an effort to advance the state of the field. In this paper, we summarize the lessons from a decade of challenges in tractography, and give perspective on the past, present, and future “challenges” that the field of diffusion tractography faces.","Diffusion MRI,Challenges,Tractography,Validation,Algorithms,Accuracy","Kurt G.Schillinga,AlessandroDaduccib,KlausMaier-Heinc,CyrilPoupond,Jean-ChristopheHoudee,VishweshNathf,Adam W.Andersonag,Bennett A.Landmanagh,MaximeDescoteauxe","Magnetic Resonance Imaging","https://doi.org/10.1016/j.mri.2018.11.014","https://www.sciencedirect.com/science/article/pii/S0730725X18305162"
"A121","A distinct cortical network for mathematical knowledge in the human brain","How does the brain represent and manipulate abstract mathematical concepts? Recent evidence suggests that mathematical processing relies on specific brain areas and dissociates from language. Here, we investigate this dissociation in two fMRI experiments in which professional mathematicians had to judge the truth value of mathematical and nonmathematical spoken statements. Sentences with mathematical content systematically activated bilateral intraparietal sulci and inferior temporal regions, regardless of math domain, problem difficulty, and strategy for judging truth value (memory retrieval, calculation or mental imagery). Second, classical language areas were only involved in the parsing of both nonmathematical and mathematical statements, and their activation correlated with syntactic complexity, not mathematical content. Third, the mere presence, within a sentence, of elementary logical operators such as quantifiers or negation did not suffice to activate math-responsive areas. Instead, quantifiers and negation impacted on activity in right angular gyrus and left inferior frontal gyrus, respectively. Overall, these results support the existence of a distinct, non-linguistic cortical network for mathematical knowledge in the human brain.","fMRI,Mathematical cognition,Semantic processing","MarieAmalricabc,StanislasDehaeneac","NeuroImage","https://doi.org/10.1016/j.neuroimage.2019.01.001","https://www.sciencedirect.com/science/article/pii/S1053811919300011"
"A122","Pore-scale simulation of melting process of paraffin with volume change in high porosity open-cell metal foam","In this paper, a pore-scale model for melting phase change of paraffin with volume change in high porosity open-cell metal foam is first developed by comprehensively adopting the enthalpy-porosity method, the volume-of-fluid (VOF) method and the Weaire-Phelan foam structure. This model is validated with the pore-scale experimental result from literature, which can more reasonably consider the effects of paraffin volume variation and foam structure when compared with previously reported models. Then the validated model is utilized to directly simulate the paraffin melting in foam pore region and obtain the detailed phase change information including the phase, temperature, heat flux and flow fields, which helps exploring the phase change transport physics in metal foam/paraffin composite (MFPC). The numerical results show that during the melting process, the solid-liquid phase change interface evolves from a multiply-connected domain to many isolated curved surfaces and is remarkably extended due to the prominent volume expansion of paraffin and high specific surface area of metal foam, which is beneficial to reducing the characteristic length for phase change. Local thermal non-equilibrium between metal foam and paraffin is prominent during most of the phase change process. The metal foam can effectively weaken the heavily thermal insulating effect of the phase change interface and avoid the seriously thermal stratification phenomenon existing in the pure paraffin unit. Besides, the paraffin flow driven by the volume expansion pressure difference is strengthened (which has not been revealed before) while the natural convection flow is depressed by the metal foam. As compared to the pure paraffin, the MFPC has much higher phase change rate, volume expansion rate, temperature uniformity and heat storage rate. This work can contribute to new viewpoints for better understanding the phase change transport process in MFPC as compared to previous macroscopic-scale and pore-scale investigations.","Melting,Pore-scale model,Metal foam,Paraffin,Volume change","YuanpengYao,HuiyingWu","International Journal of Thermal Sciences","https://doi.org/10.1016/j.ijthermalsci.2018.12.052","https://www.sciencedirect.com/science/article/pii/S1290072918311037"
"A123","DNA methylation variability in Alzheimer's disease","DNA methylation plays a critical role in brain aging and Alzheimer's disease (AD). While prior studies have largely focused on testing mean DNA methylation, DNA methylation instability (quantified by DNA methylation variability) may also affect disease susceptibility. Using DNA methylation data collected by the Religious Orders Study and the Rush Memory and Aging Project, we identified 249 and 115 variably methylated probes (VMPs) associated with amyloid-ß and neurofibrillary tangles, respectively. These VMPs clustered into 133 and 14 regions, respectively. Notably, we found that most of these VMPs did not overlap with differentially methylated probes, indicating that VMPs and differentially methylated probes may capture different sets of genes associated with AD pathology. Overall, our results demonstrated that DNA methylation instability affects AD neuropathology and highlights the importance of testing methylation variability in epigenetic research.","DNA methylation variability,Alzheimer's disease,Amyloid-ß plaques,PHF-tau tangles,Postmortem brain,PFC,ROSMAP","ZhiguangHuoa,YunZhub,LeiYuc,JingyunYangc,PhilipDe Jagerd,David A.Bennettc,JinyingZhaob","Neurobiology of Aging","https://doi.org/10.1016/j.neurobiolaging.2018.12.003","https://www.sciencedirect.com/science/article/pii/S0197458018304391"
"A124","N-(6-Aminohexyl)-5-chloro-1-naphthalenesulfonamide, a centrin antagonist, inhibits Tb3+/peptides-binding properties","N-(6-Aminohexyl)-5-chloro-1-naphthalenesulfonamide (W-7), a kind of adjuvant chemotherapy, can bind to calmodulin and inhibit Ca2+/calmodulin-regulated enzyme activities and cell proliferation. Similar to calmodulin, euplotes octocarinatus centrin (EoCen) belongs to EF-hand superfamily of calcium-binding proteins. It is associated with nucleotide excision repair (NER), cell division cycle and ciliogenesis. In the present study, the comparative interaction of W-7 with EoCen was first examined by using various spectroscopic, calorimetric methods and molecular docking. The obtain results recommend that only one W-7 molecule is identified binding to the C-terminal hydrophobic pocket of centrin that normally plays a role in anchoring targets. Methyl groups of Ala126, Met141, Ile161 and M162 of C-terminal may react with W-7 chloronaphthalene ring, other aliphatic or aromatic side-chains in a deep hydrophobic pocket of protein. Circular dichroism (CD) and fluorescence lifetime experiments reveal that W-7 triggers a conformational change of centrin. As a result, W-7 is identified to be an antagonist of centrin. It appears to inhibit the centrin-mediated activation of target proteins by blocking the hydrophobic pocket. Moreover, the complex formation leads to affinity decrease of Tb3+ binding to C-terminal of protein and self-assembly affected. Our present study provides the first view of centrin recognizing a naphthalene-sulfonamide derivative. It is proposed that W-7 and its analogues can serve as a useful tool for research on the participation of centrin in biological processes and cell biology-related studies.","Centrin,W-7,Inhibit,Antagonist","MinLiab1,WenlongZhanga1,BinshengYanga","Journal of Inorganic Biochemistry","https://doi.org/10.1016/j.jinorgbio.2019.01.002","https://www.sciencedirect.com/science/article/pii/S0162013418304975"
"A125","Aggregating minutia-centred deep convolutional features for fingerprint indexing","Most current fingerprint indexing systems are based on minutiae-only local structures and index local features directly. For minutiae local structure, missing and spurious neighboring minutiae significantly degrade the retrieval accuracy. To overcome this issue, we employs deep convolutional neural network to learn a minutia descriptor representing the local ridge structures. Instead of indexing local features, we aggregate various number of learned Minutia-centred Deep Convolutional (MDC) features of one fingerprint into a fixed-length feature vector to improve retrieval efficiency. In this paper, a novel aggregating method is proposed, which employs 1-D convolutional neural network to learn a discriminative and compact representation of fingerprint. In order to understand the MDC feature, a steerable fingerprint generation method is proposed to verify that it describes the attributes of minutiae and ridges. Comprehensive experimental results on five benchmark databases show that the proposed method achieves better performance on accuracy and efficiency than other prominent approaches.","Fingerprint indexing,Deep convolutional neural network,Aggregating local features,Representation learning,Minutia descriptor","DehuaSong,YaoTang,JufuFeng","Pattern Recognition","https://doi.org/10.1016/j.patcog.2018.11.018","https://www.sciencedirect.com/science/article/pii/S0031320318304072"
"A126","Challenges in working towards an internal threshold of toxicological concern (iTTC) for use in the safety assessment of cosmetics: Discussions from the Cosmetics Europe iTTC Working Group workshop","The Threshold of Toxicological Concern (TTC) is an important risk assessment tool which establishes acceptable low-level exposure values to be applied to chemicals with limited toxicological data. One of the logical next steps in the continued evolution of TTC is to develop this concept further so that it is representative of internal exposures (TTC based on plasma concentration). An internal TTC (iTTC) would provide threshold values that could be utilized in exposure-based safety assessments. As part of a Cosmetics Europe (CosEu) research program, CosEu has initiated a project that is working towards the development of iTTCs that can be used for the human safety assessment. Knowing that the development of an iTTC is an ambitious and broad-spanning topic, CosEu organized a Working Group comprised a balance of multiple stakeholders (cosmetics and chemical industries, the EPA and JRC and academia) with relevant experience and expertise and workshop to critically evaluate the requirements to establish an iTTC. Outcomes from the workshop included an evaluation on the current state of the science for iTTC, the overall iTTC strategy, selection of chemical databases, capture and curation of chemical information, ADME and repeat dose data, expected challenges, as well as next steps and ongoing work.","Thresholds of toxicological concern,TTC,Physiologically based pharmacokinetic model,PBPK,Cosmetics europe,Risk assessment,Cosmetics","Corie A.Ellisona,Karen L.Blackburna,Paul L.Carmichaelb,Harvey J.ClewellIIIc1,Mark T.D.Cronind,BertrandDespreze,Sylvia E.Escherf,Steve S.Fergusong,SébastienGrégoireh,Nicola J.Hewitte,Heli M.Hollnageli,MartinaKlarice,AtishPatelj2,SabrinaSalhik,AndreasSchepkyl,Barbara G.Schmittm,John F.Wambaughn,AndrewWortho","Regulatory Toxicology and Pharmacology","https://doi.org/10.1016/j.yrtph.2019.01.016","https://www.sciencedirect.com/science/article/pii/S0273230019300169"
"A127","Personalized recommendation by matrix co-factorization with tags and time information","Personalized recommendation systems have solved the information overload problem caused by large volumes of Web data effectively. However, most existing recommendation algorithms are weak in handling the problem of rating data sparsity that characterizes most recommender systems and results in deteriorated recommendation accuracy. The results in the KDDCUP and Netflix competition have proven that the matrix factorization algorithm achieves better performance than other recommendation algorithms when the rating data is scarce. However, the highly sparse rating matrix will cause the overfitting problem in matrix factorization. Although regularization can relieve the issue of overfitting to some extent, it is still a significant challenge to train an effective model for recommender systems when the data is highly sparse. Therefore, this paper proposes a co-SVD model to enrich the single data source and mitigate the overfitting problem in matrix factorization. The user preferences are enriched not only by rating data but also the tag data; subsequently, the relevance between tags and item features are explored. Furthermore, according to the assumption that user preferences will change with time, we optimize the preference and relevance by adding the temporal influence. Based on the MovieLens benchmark datasets, the experimental results indicate that the proposed co-SVD method is more effective than other baselines. Matrix co-factorization provides an effective method to the solve data sparsity problem with additional information. The method can be used to address this problem in various expert and intelligent systems such as recommendation advertisements, e-commerce sites, and social media platforms, all of which require a relatively large amount of input data from users.","Personalized recommendation,Matrix factorization,Data sparsity,Tags,Temporal factor","LingLuoa,HaoranXieb,YanghuiRaoa,Fu LeeWangc","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.11.003","https://www.sciencedirect.com/science/article/pii/S0957417418307231"
"A128","Sigon: A multi-context system framework for intelligent agents","The usage of agents has become one of the most effective ways to deal with complex systems. The agent’s approach allows for the parallel execution of actions and eases the conception of the system. In this paper, we introduce a language, called Sigon, that allows the definition of agents as multi-context systems. Multi-context systems, in turn, allow for a modular description of the agent, and the implementation of bridge rules contributes to the system flexibility. We propose a generic framework to conceive agents, in which the system’s developer defines their internals in terms of contexts and bridge rules. In order to show the way in which the programmer can aggregate other logical contexts, we first present the configurations of a BDI-like agent in our framework. Subsequently, the programmer can add more contexts, such as emotional or negotiating ones, and develop other agent architectures. Thus, our approach can be characterized as a form of generic and extensible architecture. In order to validate our proposal, we introduce some examples that delineate some strengths of the proposal, and also we present an analysis of bridge rules execution to demonstrate the processing overhead.","Agent,Multi-context systems,Belief-Desire-Intention","Thiago ÂngeloGelaim1ab,Valdir LuizHoferb,JerusaMarchiab,Ricardo AzambujaSilveiraab","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.042","https://www.sciencedirect.com/science/article/pii/S0957417418307000"
"A129","DeepComNet: Performance evaluation of network topologies using graph-based deep learning","Modeling the performance of network protocols and communication networks generally relies on expert knowledge and understanding of the different elements of a network, their configuration, and the overall architecture and topology. Machine learning is often proposed as a tool to help modeling such complex systems. One drawback of this method is that high-level features are generally used – which require full understanding of the network protocols to be chosen, correctly engineered, and measured – and the approaches are generally limited to a given network topology. In this article, we present DeepComNet, an approach to address the challenges of working with machine learning by using lower-level features, namely only a description of the network architecture. Our main contribution is a method for applying deep learning on network topologies via the use of Graph Gated Neural Networks, a specialized recurrent neural network for graphs. Our approach enables us to make performance predictions based only on a graph-based representation of network topologies. To evaluate the potential of DeepComNet, we apply our approach to the tasks of predicting the throughput of TCP flows and the end-to-end latencies of UDP flows. In both cases, the same base model is used. Numerical results show that our approach is able to learn and predict performance properties of TCP and UDP flows with a median absolute relative error smaller than 1%, outperforming related methods from the literature by one order of magnitude.","Network performance evaluation,Graph neural network,Deep learning","FabienGeyer","Performance Evaluation","https://doi.org/10.1016/j.peva.2018.12.003","https://www.sciencedirect.com/science/article/pii/S0166531618300944"
"A130","Multi-Layer domain adaptation method for rolling bearing fault diagnosis","In the past years, data-driven approaches such as deep learning have been widely applied on machinery signal processing to develop intelligent fault diagnosis systems. In real-world applications, domain shift problem usually occurs where the distribution of the labeled training data, denoted as source domain, is different from that of the unlabeled testing data, known as target domain. That results in serious diagnosis performance degradation. This paper proposes a novel domain adaptation method for rolling bearing fault diagnosis based on deep learning techniques. A deep convolutional neural network is used as the main architecture. The multi-kernel maximum mean discrepancies (MMD) between the two domains in multiple layers are minimized to adapt the learned representations from supervised learning in the source domain to be applied in the target domain. The domain-invariant features can be efficiently extracted in this way, and the cross-domain testing performance can be significantly improved. Experiments on two rolling bearing datasets are carried out to validate the effectiveness of the domain adaptation approach. Comparisons with other approaches and related works demonstrate the superiority of the proposed method. The experimental results of this study suggest the proposed domain adaptation method offers a new and promising tool for intelligent fault diagnosis.","Fault diagnosis,Domain adaptation,Deep learning,Maximum mean discrepancy,Rolling bearing","XiangLiab,WeiZhangc,QianDingd,Jian-QiaoSune","Signal Processing","https://doi.org/10.1016/j.sigpro.2018.12.005","https://www.sciencedirect.com/science/article/pii/S0165168418303967"
"A131","Exploring the behavior space of agent-based simulation models using random forest metamodels and sequential sampling","Agent-based modeling is an effective way of understanding and analyzing complex adaptive phenomena. In this respect, discovering the relationship between inputs and outputs of agent-based models is the ultimate way of providing insights into understanding the dynamics of the system being modeled. Therefore, there are many approaches in the literature to clarify these relationships including sampling and metamodeling. Emphasizing the weaknesses and disadvantages of current methods, we present a metamodel-guided sequential sampling technique which combines random forests and uncertainty sampling. Experimental results on two well-known agent-based models show that the presented technique yields metamodels of higher accuracy compared to metamodels trained with randomly selected input–output data. Contrary to the previous studies emphasizing only the improvement in the metamodel accuracy, we also focus on input parameter combinations selected by the sequential sampling technique, and we observe that sequential sampling is able to capture the boundaries of tipping point behaviors as well as the points exhibiting counter-intuitive behavior, thus, potentially aiding verification, validation, and understanding of agent-based models. Additionally, we propose a novel two-step method for the categorization of the agent-based model outputs prior to metamodel training, which helps the analyst to decide on whether preserving numerical model outputs or continuing the metamodel training procedure with qualitative categorical agent-based model outputs.","Agent-based modeling,Metamodeling,Random forest,Sequential sampling,Active learning,Output categorization","MertEdaliab,GönençYücela","Simulation Modelling Practice and Theory","https://doi.org/10.1016/j.simpat.2018.12.006","https://www.sciencedirect.com/science/article/pii/S1569190X18301941"
"A132","Deep convolutional neural network-based in-process tool condition monitoring in abrasive belt grinding","Abrasive belt grinding has attracted attention in recent years in both industry and academia due to the rapid development of abrasive belts. In-process tool condition monitoring in abrasive belt grinding is difficult due to the large and unknown number of abrasive grains with variable and stochastic cutting geometries especially when the monitoring utilizes complicated sound signal for functionality. To monitor the wear of an abrasive belt, a new method using the deep convolutional neural network(DCNN) is proposed to identify the wear state of an abrasive belt based on sound signals. To comprehensively evaluate the recognition result of the belt wear state, one-level accuracy and precision are proposed, and the accuracy, one-level accuracy and precision of the method proposed in this paper are 82.2%, 97.6%, and 0.863, respectively. Compared with traditional methods, the results of this study infer that this method based on the DCNN can automatically and simultaneously search for the features of grinding sounds that are sensitive to belt wear in two dimensions, the time-domain and frequency-domain. The above characteristics of the DCNN are very suitable for extracting the features of the nonstationary sound signals that are produced by the alternate cutting process of multiple abrasive grains.","Abrasive belt grinding,Tool condition monitoring,DCNN,Sound","CanChenga,JianyongLiab,YuemingLiuab,MengNieab,WenxiWanga","Computers in Industry","https://doi.org/10.1016/j.compind.2018.12.002","https://www.sciencedirect.com/science/article/pii/S0166361518304032"
"A133","Convergence study and uncertainty quantification of average and statistical PIV measurements in a matched refractive index 5×5 rod bundle with mixing vane spacer grid","A new combination of materials with matched indices of refraction was used in average and statistical PIV analysis of a 5×5 rod bundle with prototypical pressurized water reactor (PWR) mixing vane spacer grids. The new combination of materials shows improved matching of refractive index which enabled detailed PIV measurement of subchannel flow, even when viewed through a relatively large number of material interfaces. Convergence of average full field PIV measurements at ~27,000 Reynolds number was demonstrated as independent of measurement plane depth relative to camera view window. A method for average vector post-processing elimination is proposed using validation statistics from PIV. The proposed method shows potential for eliminating vectors in areas of poor-convergence for planes with little interfering geometry. A full uncertainty quantification was performed on the full field of each PIV measurement planes. Similar to convergence rates, uncertainty demonstrated independence from measurement plane depth. Additional material interface between camera and measurement plane does not appear to have affected instantaneous velocity measurements’ contribution to average vector fields. Symmetric measurement planes were compared between 2 rod pitch intervals of the spacer grid. Velocity and statistically derived quantities show good coherence between symmetric planes. Measurements near and even below the tips of the mixing vanes were collected and analyzed.","5<U+202F>×<U+202F>5,Spacer grid,Mixing vane,Pressurized water reactor,PWR,Matched index of refraction,MIR,Particle image velocimetry,PIV","André AugustoCampagnole dos Santosab1,MasonChildsa1,Thien DuyNguyena,YassinHassana","Experimental Thermal and Fluid Science","https://doi.org/10.1016/j.expthermflusci.2018.11.009","https://www.sciencedirect.com/science/article/pii/S0894177718309634"
"A134","Rho-kinase inhibition has antidepressant-like efficacy and expedites dendritic spine pruning in adolescent mice","Adolescence represents a critical period of neurodevelopment, defined by structural and synaptic pruning within the prefrontal cortex. While characteristic of typical development, this structural instability may open a window of vulnerability to developing neuropsychiatric disorders, including depression. Thus, therapeutic interventions that support or expedite neural remodeling in adolescence may be advantageous. Here, we inhibited the neuronally-expressed cytoskeletal regulatory factor Rho-kinase (ROCK), focusing primarily on the clinically-viable ROCK inhibitor fasudil. ROCK inhibition had rapid antidepressant-like effects in adolescent mice, and its efficacy was comparable to ketamine and fluoxetine. It also modified levels of the antidepressant-related signaling factors, tropomyosin/tyrosine receptor kinase B and Akt, as well as the postsynaptic marker PSD-95, in the ventromedial prefrontal cortex (vmPFC). Meanwhile, adolescent-typical dendritic spine pruning on excitatory pyramidal neurons in the vmPFC was expedited. Further, vmPFC-specific shRNA-mediated reduction of ROCK2, the dominant ROCK isoform in the brain, had antidepressant-like consequences. We cautiously suggest that ROCK inhibitors may have therapeutic potential for adolescent-onset depression.","Forced swim,Novelty suppressed feeding,Protein kinase B,HA-1077,ROCKII,Slx-2119,Rho-associated coiled-coil containing kinase","Lauren P.Shapiroabc,Henry W.Kietzmanbcd,JidongGuoce,Donald G.Rainniece,Shannon L.Gourleyabcde","Neurobiology of Disease","https://doi.org/10.1016/j.nbd.2018.12.015","https://www.sciencedirect.com/science/article/pii/S0969996118303851"
"A135","Immune responses of fish to Ichthyophthirius multifiliis (Ich): A model for understanding immunity against protozoan parasites","The parasitic ciliate Ichthyophthirius multifiliis (Ich), which infects almost all freshwater fish species, provides an optimal model for the study of immunity against extracellular protozoa. Ich invades the epithelia of mucosal tissues, forms white spots covering the whole body, and induces high mortality, while survivor fish develop both innate and adaptive immunity against Ich attack in systemic and mucosal tissues. Besides the protective roles of the Toll-like receptor (TLR)-mediated innate immune response, the critical immune functions of novel IgT in the skin, gut, gill, and olfactory organ of teleosts have been demonstrated in recent years, and all this information contributes to the ontogeny of the mucosal immune response in vertebrates. Especially in rainbow trout, Ich-infected fish exhibited higher IgT concentrations and titers in the mucosa and increased IgT+ B-lymphocyte proliferation in mucosal tissues. IgM mainly functions in the adaptive immune response in the systemic tissues of rainbow trout, accompanied with increased IgM+ B-lymphocyte proliferation in the head kidney of Ich-infected trout. However, little is known about the interaction between these mucosal tissues and systemic immune organs and the interaction between the inductive immune organs and functional immune organs. Immobilization antigens (Iags), located on the parasite cell and ciliary membranes, have been characterized to be targeted by specific antibodies produced in the host. The crosslinking of antigens mediated by antibodies triggers either an escape response or the immobilization of Ich. With more knowledge about the Iags of Ich and the immunity of teleosts, a more targeted vaccine, even a DNA vaccine, can be developed for the immune control strategy of Ich. Due to the high frequency of clinical fish ichthyophthiriasis, the study of fish immune responses to Ich provides an optimal experimental model for understanding immunity against extracellular protozoa.","Ichthyophthirius multifiliis,Fish,Immobilization antigens,Mucosal immunity,Vaccine","QingchaoWang1,YongyaoYu1,XiaotingZhang1,ZhenXu","Developmental & Comparative Immunology","https://doi.org/10.1016/j.dci.2019.01.002","https://www.sciencedirect.com/science/article/pii/S0145305X18304944"
"A136","Articulating societal benefits in grant proposals: Move analysis of Broader Impacts","Being ‘scholarly’ includes the pursuit of grants, which requires understanding and satisfying the review criteria of specific funding organizations. An important merit review criterion against which the National Science Foundation (NSF) evaluates grant proposals is Broader Impacts (BI). The two-fold purpose of this study was to 1) identify the rhetorical conventions of stand-alone BI sections, which are expected to demonstrate the potential of a proposed project to benefit society, and 2) compare the use of rhetorical conventions in the BI sections of funded and non-funded proposals. In the tradition of genre theory, the study employed a top-down move analysis of a corpus of 91 BI texts from proposals in different disciplines submitted to the NSF. The analysis yielded a descriptive model of 3 moves and 9 steps, named Contextualize-Demonstrate-Predict, which was applied to the annotation of the entire corpus. Descriptive and statistical analyses of the annotated data provided a rich description of the composition of BI discourse in terms of primary and secondary rhetorical functions, also revealing similarities and differences in move and step distribution, functional prominence, and language use in the BIs of funded and non-funded proposals. The results of this study lend themselves to practical implications for grant writer education in rhetorical competence.","Move analysis,Grant proposals,Part-genre,Broader Impacts,Corpora","ElenaCotos1","English for Specific Purposes","https://doi.org/10.1016/j.esp.2018.11.002","https://www.sciencedirect.com/science/article/pii/S0889490617303484"
"A137","Calpain activation and neuronal death during early epileptogenesis","Epilepsy is a brain disorder characterized by a predisposition to suffer epileptic seizures. Acquired epilepsy might be the result of brain insults like head trauma, stroke, brain infection, or status epilepticus (SE) when one of these triggering injuries starts a transformative process known as epileptogenesis. There is some data to suggest that, during epileptogenesis, seizures themselves damage the brain but there is no conclusive evidence to demonstrate that spontaneous recurrent seizures themselves injure the brain. Our recent evidence indicates that calpain overactivation might be relevant for epileptogenesis. Here, we investigated if spontaneous recurrent seizures that occur during an early period of epileptogenesis show any correlation with the levels of calpain activation and/or expression. In addition, we also investigated a possible association between the occurrence of spontaneous seizures and increased levels of cell death, gliosis and inflammation (typical markers associated with epileptogenesis). We found that the number of spontaneous seizures detected prior to sample collection was correlated with altered calpain activity and expression. Moreover, the levels of hippocampal neurodegeneration were also correlated with seizure occurrence. Our findings suggest that, at least during early epileptogenesis, there is a correlation between seizure occurrence, calpain activity and neurodegeneration. Thus, this study opens the possibility that aberrant calpain reactivation by spontaneous seizures might contribute to the manifestation of future spontaneous seizures.","CA1Cornus Ammonis 1,DGDentate Gyrus,SEstatus epilepticus,SRSspontaneous recurrent seizures,Keywords,Spontaneous seizures,Calpain,Cell death,Gliosis,Inflammation,Epileptogenesis","Philip M.Lam,Marco I.González","Neurobiology of Disease","https://doi.org/10.1016/j.nbd.2018.11.005","https://www.sciencedirect.com/science/article/pii/S0969996118307423"
"A138","Foodstagramming in the travel encounter","This research investigates a new phenomenon – foodstagramming, in which tourists embark on capturing and sharing food photos – using a mixed-methods approach in three studies. Study 1 assesses how foodstagramming experiences are phenomenologically constructed in a field inquiry. Studies 2 and 3 undergo a rigorous scale development process by setting forth a foodstagramming benefit scale, which measures tourist perceived value in capturing and sharing of food photos in social media. These two studies further test its nomological network via a relationship leading from impression management to travel satisfaction through foodstagramming benefits. Results address the conundrum in the literature, which conjectures why self-expression, enrichment of dining experience, social connection, virtual community engagement, and special occasion memory underpin the foodstragramming phenomenon and how they could reap favorable travel outcomes. This research further contributes to the hospitality and tourism industry with insights on technology mediated dining and travel experiences.","Food selfie,Foodstagramming,Scale development,Travel satisfaction,Impression","IpKin AnthonyWongab,DanqingLiuc,NaoLid,ShushanWue,LanfengLuf,RobLawg","Tourism Management","https://doi.org/10.1016/j.tourman.2018.08.020","https://www.sciencedirect.com/science/article/pii/S0261517718301985"
"A139","The thermal hydraulic phenomenon in tight lattice bundles: A review","The analysis of thermal hydraulic phenomenon in tight lattice sub-channels is of importance in pursuing high conversion ratio of Light Water Reactors (LWR). Tight lattice is also a potential choice for reducing the volume of small modular reactor core, which is benefit for improving economy. In this work, an extensive overview of the experimental and numerical analysis for the thermal hydraulic phenomenon in tight lattice sub-channels was conducted, in order to summarize valuable conclusions and results for future work. The critical heat flux (CHF) and turbulent mixing experiments and theoretical models in tight lattice were overviewed systematically. The large scale flow pulsation in sub-channels and simulating methods were analyzed. Finally, the recommendations for future work were discussed.","Turbulent flow,Heat transfer,Vortex structure,Tight lattice","B.H.Yan","Annals of Nuclear Energy","https://doi.org/10.1016/j.anucene.2018.11.037","https://www.sciencedirect.com/science/article/pii/S0306454918306352"
"A140","The rise of motivational information systems: A review of gamification research","Today, our reality and lives are increasingly game-like, not only because games have become a pervasive part of our lives, but also because activities, systems and services are increasingly gamified. Gamification refers to designing information systems to afford similar experiences and motivations as games do, and consequently, attempting to affect user behavior. In recent years, popularity of gamification has skyrocketed and manifested in growing numbers of gamified applications, as well as a rapidly increasing amount of research. However, this vein of research has mainly advanced without an agenda, theoretical guidance or a clear picture of the field.To make the picture more coherent, we provide a comprehensive review of the gamification research (N<U+2009>=<U+2009>819 studies) and analyze the research models and results in empirical studies on gamification. While the results in general lean towards positive findings about the effectiveness of gamification, the amount of mixed results is remarkable. Furthermore, education, health and crowdsourcing as well as points, badges and leaderboards persist as the most common contexts and ways of implementing gamification. Concurrently, gamification research still lacks coherence in research models, and a consistency in the variables and theoretical foundations. As a final contribution of the review, we provide a comprehensive discussion, consisting of 15 future research trajectories, on future agenda for the growing vein of literature on gamification and gameful systems within the information system science field.","Gamification,Games,Motivational information system,Affordance,Literature review","JonnaKoivistoa,JuhoHamariab","International Journal of Information Management","https://doi.org/10.1016/j.ijinfomgt.2018.10.013","https://www.sciencedirect.com/science/article/pii/S0268401217305169"
"A141","Effect of magnetic field on natural convection inside a partially-heated vertical duct: Experimental study","We experimentally study the effect of the magnetic force from one or more block magnets on natural convection of paramagnetic liquid inside a partially-heated duct. The permanent magnet(s) is/are placed partially/fully behind the heated wall. For a single magnet, the local heat transfer coefficient is suppressed near the bottom edge of the magnet and enhanced near the top edge if the magnet edge is behind the heated wall. This effect depends on the elevation of the magnet relative to the heated wall. Using two block magnets with alternating magnetic poles enhances the force and corresponding effect at their junction because of an increase in magnetic flux density.","Magnetic force,Heat transfer enhancement,Natural convection,Paramagnetic liquid,Magnetic field","MasayukiKaneda,KensukeNazato,HiroakiFujiwara,KengoWada,KazuhikoSuga","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.12.056","https://www.sciencedirect.com/science/article/pii/S0017931018348385"
"A142","Learning peer recommendation using attention-driven CNN with interaction tripartite graph","Learning peer recommendation (LPR) is one of the effective solutions to overcome the information load of learners. This paper presents a multi-objective LPR framework for online learning. Using a dynamic interaction tripartite graph (DITG), we characterize and model the complex relationships among learners, learning content, and interaction behaviours, followed by capturing the dynamic interactions among learners with an attention-driven convolution neural network (CNN). The proposed attention-driven CNN is leveraged to tune the weights of interaction behaviours according to the features of the learning content. A multi-objective function composed of three conflicting metrics, interaction intensity, diversity and novelty, is optimized to achieve simultaneous multiple recommendations for a group of learners. Compared to the state-of-the-art approaches, the proposed LPR framework and algorithms perform favourably.","Interaction behaviours,Dynamic interaction tripartite graph,Attention-driven CNN,Multi-objective learning peer recommendation","QintaiHuab,ZhongmeiHanab,XiaofanLinab,QionghaoHuanga,XiaomeiZhanga","Information Sciences","https://doi.org/10.1016/j.ins.2018.12.003","https://www.sciencedirect.com/science/article/pii/S0020025518309472"
"A143","Gradient-enhanced damage modeling in Kirchhoff–Love shells: Application to isogeometric analysis of composite laminates","We extend a recently-developed framework for isogeometric analysis of composite laminates to drive material damage evolution with a smoothed strain field. This builds on ideas from gradient-enhanced continuum damage modeling, and is intended to limit the dependence of damage predictions on the choice of discrete mesh. The resulting enhanced framework models each lamina of a composite shell structure as a Kirchhoff–Love thin shell. To account for the anisotropic damage modes of laminae, we smooth a tensor-valued strain by solving an elliptic partial differential equation (PDE) system on each lamina. This strain-smoothing PDE system is formulated to be independent of the choice of coordinates and is applicable to general manifold shell geometries. Numerical examples illustrate the enhanced damage model’s validity, mesh-independence, and applicability to complex industrial geometries.","Nonlocal damage,Continuum damage,Gradient-enhanced model,Multilayer Kirchhoff–Love shell,Isogeometric analysis,NURBS","M.S.Pigazzinia,D.Kamenskyc,D.A.P.van Ierselb,M.D.Alaydinc,J.J.C.Remmersb,Y.Bazilevsc","Computer Methods in Applied Mechanics and Engineering","https://doi.org/10.1016/j.cma.2018.10.042","https://www.sciencedirect.com/science/article/pii/S0045782518305462"
"A144","Acoustic beamforming for noise source localization – Reviews, methodology and applications","This paper is a review on acoustic beamforming for noise source localization and its applications. The main concepts of beamforming, starting from the very basics and progressing on to more advanced concepts and techniques, are presented, in order to give the reader the possibility to identify concepts and references which might be useful for her/his work. Practical examples referring to application of this technique in different scenarios are also provided. The aim is to make the reader comfortable with the topic and aware of the wide stimuli a technique like acoustic beamforming can offer researchers.","Acoustic beamforming,Acoustic imaging techniques,Noise source localization,Microphone arrays,Acoustic measurements","PaoloChiariottia,MilenaMartarellib,PaoloCastellinia","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.09.019","https://www.sciencedirect.com/science/article/pii/S088832701830637X"
"A145","A method for numerical and experimental nonlinear modal analysis of nonsmooth systems","The development of nonlinear modal analysis so far has focused on structures with smooth nonlinearities. However, nonsmooth nonlinearities, which are, for instance, caused by contact interactions are highly relevant in practical applications. This paper proposes a novel numerical approach along with a method for the measurement of nonlinear modes of structures with nonsmooth contact nonlinearities.The proposed numerical method combines the shooting method and the harmonic balance method, yielding a mixed time-frequency domain representation of the system, allowing for an efficient treatment of the nonsmooth contact law within the numerical approach. Moreover, the mass of the system is redistributed such that the contact nodes are massless. Thereby, the dynamic contact problem can be reduced to a quasi-static contact problem. A salient feature of this numerical approach is that the contact problems are solved without the need for any contact parameters, such as penalty or restitution coefficients. Furthermore, the conservative nature of the contact law incorporated in this formulation allows for the calculation of nonlinear modes as periodic solutions of conservative systems.The experimental method relies on a nonlinear phase resonance approach. Hitherto, phase resonance methods have exclusively been applied to systems with smooth nonlinearities. In this study, an automated nonlinear phase resonance approach with phase-controlled excitation is used, providing a robust experimental procedure, which facilitates the treatment of strong nonsmooth nonlinearities, e.g., caused by unilateral constraints inducing impacts.The numerical and experimental methods are demonstrated by an application to a benchmark structure consisting of a beam with one-sided support leading to impacts. It is shown that the numerical method can be applied without the need for any nonlinear system identification effort and the results agree well with the measured nonlinear modes.","Nonlinear modes,Nonsmooth systems,Nonlinear modal analysis,Mixed Shooting-Harmonic Balance Method,Nonlinear phase resonance testing","SimonPeter,FredericSchreyer,Remco I.Leine","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.11.009","https://www.sciencedirect.com/science/article/pii/S0888327018307295"
"A146","Use of fluorescent CTP1L endolysin cell wall-binding domain to study the evolution of Clostridium tyrobutyricum during cheese ripening","Clostridium tyrobutyricum is a bacteria of concern in the cheese industry, capable of surviving the manufacturing process and causing butyric acid fermentation and late blowing defect of cheese. In this work, we implement a method based on the cell wall-binding domain (CBD) of endolysin CTP1L, which detects C. tyrobutyricum, to monitor its evolution in cheeses challenged with clostridial spores and in the presence or absence of reuterin, an anti-clostridial agent. For this purpose, total bacteria were extracted from cheese samples and C. tyrobutyricum cells were specifically labelled with the CBD of CTP1L attached to green fluorescent protein (GFP), and detected by fluorescence microscopy. By using this GFP-CBD, germinated spores were visualized on day 1 in all cheeses inoculated with clostridial spores. Vegetative cells of C. tyrobutyricum, responsible for butyric acid fermentation, were detected in cheeses without reuterin from 30<U+202F>d onwards, when LBD symptoms also became evident. The number of fluorescent Clostridium cells increased during ripening in the blowing cheeses. However, vegetative cells of C. tyrobutyricum were not detected in cheese containing the antimicrobial reuterin, which also did not show LBD throughout ripening. This simple and fast method provides a helpful tool to study the evolution of C. tyrobutyricum during cheese ripening.","Clostridium tyrobutyricum,Late blowing defect,Cheese,Detection,Endolysin","NataliaGómez-Torresa,MartaÁvilaa,ArjanNarbadb,Melinda J.Mayerb,SoniaGardea","Food Microbiology","https://doi.org/10.1016/j.fm.2018.09.018","https://www.sciencedirect.com/science/article/pii/S0740002017311814"
"A147","Crowdsourcing geo-information on landscape perceptions and preferences: A review","This paper offers a summary of different crowdsourcing modes to collect geo-information on landscape perception & preferences and cultural ecosystem services. Crowdsourcing modes range from harvesting information passively transmitted by large groups on the web to actively engaging the crowd to generate data by using dedicated mobile apps and web-platforms. The latter, active crowdsourcing projects, were described in more detail by analysing the organizational variables of the twelve projects that were identified. Crowdsourcing has great potential to advance the field of landscape perception & preference research as it enables the in-situ collection of real-time, location-based data. One of the main limitations of reviewed active and passive crowdsourcing modes, lies in the fact that sample selection bias easily occurs and sample representativeness of any target population has been proven hard to achieve. Often crowdsourcing projects are implemented with a strong focus on technical aspects and content, but with insufficient attention for participant engagement. Projects would benefit from more inter- and transdisciplinary approaches and professionalizing campaigns, and thereby bringing participant engagement to the heart of the project. We recommend more attention to be placed towards awareness raising, diversification of formats and activities to reach a larger diversity of participants, structured tracking of performance indicators and learning from participants’ feedback. Such strategies aim at enhancing participation and reducing bias in participant selection, which constrains the usefulness of the results for research, planning and policy.","Crowdsourcing,Volunteered geographic information,Landscape preferences,Landscape perception,Cultural ecosystem services","MartinaBubaloa,Boris T.van Zantena,Peter H.Verburgab","Landscape and Urban Planning","https://doi.org/10.1016/j.landurbplan.2019.01.001","https://www.sciencedirect.com/science/article/pii/S0169204619300143"
"A148","Identification of diseases in newborns using advanced acoustic features of cry signals","Our challenge in the current study is to extend research on the cries of newborns for the early diagnosis of different pathologies. This paper proposes a recognition system for healthy and pathological cries using a probabilistic neural network classifier. Two different kinds of features have been used to characterize newborn cry signals: 1) acoustic features such as fundamental frequency glide (F0glide) and resonance frequencies dysregulation (RFsdys); 2) conventional features such as mel-frequency cestrum coefficients.This paper describes the automatic estimation of the proposed characteristics and the performance evaluation of these features in identifying pathological cries. The adopted methods for F0glides and RFsdys estimation are based on the derived function of the F0 contour and the jump \"J\" of the RFs between two subsequent tunings, respectively. The database used contains 3250 cry samples of full-term and preterm newborns, and includes healthy and pathologic cries.The obtained results indicate the important association between the quantified features and some studied pathologies, and also an improvement in the identification of pathologic cries. The best result obtained is 88.71% for the correct identification of health status of preterm newborns, and 82% for the correct identification of full-term infants with a specific disease. We conclude that using the proposed characteristics improves the diagnosis of pathologies in newborns. Moreover, the method applied in the estimation of these characteristics allows us to extend this study to other uninvestigated pathologies.","Pathologic cry,Classification,Probabilistic neural network,Mel-frequency cestrum coefficients,RF dysregulations,F0 glides","YasminaKheddachea,ChakibTadjb","Biomedical Signal Processing and Control","https://doi.org/10.1016/j.bspc.2019.01.010","https://www.sciencedirect.com/science/article/pii/S1746809419300102"
"A149","Portability, compatibility and reuse of MAC protocols across different IoT radio platforms","To cope with the diversity of Internet of Things (IoT) requirements, a large number of Medium Access Control (MAC) protocols have been proposed in scientific literature, many of which are designed for specific application domains. However, for most of these MAC protocols, no multi-platform software implementation is available. In fact, the path from conceptual MAC protocol proposed in theoretical papers, towards an actual working implementation is rife with pitfalls. (i) A first problem is the timing bugs, frequently encountered in MAC implementations. (ii) Furthermore, once implemented, many MAC protocols are strongly optimized for specific hardware, thereby limiting the potential of software reuse or modifications. (iii) Finally, in real-life conditions, the performance of the MAC protocol varies strongly depending on the actual underlying radio chip. As a result, the same MAC protocol implementation acts differently per platform, resulting in unpredictable/asymmetrical behavior when multiple platforms are combined in the same network. This paper describes in detail the challenges related to multi-platform MAC development, and experimentally quantifies how the above issues impact the MAC protocol performance when running MAC protocols on multiple radio chips. Finally, an overall methodology is proposed to avoid the previously mentioned cross-platform compatibility issues.","MAC design architectures,Portability,Compatibility,Cross-platform design,Contikimac,TSCH","JanBauwens,BartJooris,SpiliosGiannoulis,IrfanJabandžic,IngridMoerman,EliDe Poorter","Ad Hoc Networks","https://doi.org/10.1016/j.adhoc.2018.11.013","https://www.sciencedirect.com/science/article/pii/S1570870518304980"
"A150","Reducing the randomness of latent variables using the evaluative space grid: Implementation in a hybrid choice model","The study of latent variables, and in particular of attitudes, contributes to a better understanding of individual preferences and behavior and it is now common practice within transportation literature. However, the procedure of attitude measurement is still not optimal. Two major issues are the misspecification of the attitude itself and the number of suitable items used for defining the psychological factor. The incorrect measurement entails a poor representation of individuals on the latent continuum and a less precise definition of the latent variable itself.These issues become even more relevant when a Likert scale is used. Indeed, the neutral point of this scale is selected by both individuals having an ambivalent and an indifferent attitude, and the poor representation makes impossible to distinguish these categories. Nevertheless, such a distinction can be very profitable for policy reasons. To overcome this issue and to suggest more effective policies, we propose using the Evaluative Space Grid (ESG), which is a single-item measure of positivity and negativity, to collect attitudinal variables. This tool can distinguish between individuals with indifferent and ambivalent attitudes, as well as those with positive and negative inclinations.This paper models the ESG using a pair of ordered logit regressions and suggests a procedure to include this approach in the framework of hybrid choice models. Furthermore, it endeavors to shed light on the preferences of individuals having indifferent and ambivalent inclinations in a transportation context, showing the hypothesis that their preferences are different for commuting trips.","Attitude measurement,Hybrid choice model,Evaluative space grid,Ambivalence,Indifference","AntonioBorrielloa,StefanoScagnolarib,John M.Rosea","Transportation Research Part F: Traffic Psychology and Behaviour","https://doi.org/10.1016/j.trf.2018.12.018","https://www.sciencedirect.com/science/article/pii/S1369847818300196"
"A151","A team-formation algorithm for faultline minimization","In recent years, the proliferation of online resumes and the need to evaluate large populations of candidates for on-site and virtual teams have led to a growing interest in automated team-formation. Given a large pool of candidates, the general problem requires the selection of a team of experts to complete a given task. Surprisingly, while ongoing research has studied numerous variations with different constraints, it has overlooked a factor with a well-documented impact on team cohesion and performance: team faultlines. Addressing this gap is challenging, as the available measures for faultlines in existing teams cannot be efficiently applied to faultline optimization. In this work, we meet this challenge with a new measure that can be efficiently used for both faultline measurement and minimization. We then use the measure to solve the problem of automatically partitioning a large population into low-faultline teams. By introducing faultlines to the team-formation literature, our work creates exciting opportunities for algorithmic work on faultline optimization, as well as on work that combines and studies the connection of faultlines with other influential team characteristics.","Teams,Team faultlines,Team formation","SanazBahargama,BehzadGolshana,TheodorosLappasb,EvimariaTerzia","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.046","https://www.sciencedirect.com/science/article/pii/S0957417418307048"
"A152","To sense or not to sense—new insights from GPCR-based and arrestin-based biosensors","","","Raphael SilvanusHaider1,AmodGodbole1,CarstenHoffmann","Current Opinion in Cell Biology","https://doi.org/10.1016/j.ceb.2018.10.005","https://www.sciencedirect.com/science/article/pii/S0955067418300784"
"A153","An approach to identify user preferences based on social network analysis","This paper introduces an approach for identifying user preferences using social network analysis (SNA). Main idea was to reduce complexity and enable effective and affordable social network analysis harnessing particular tools and techniques. As a proof of concept, we performed the research that included two sources: (1) the control data source — analytical data collected from mobile application FilterApp for cultural events and (2) the experimental data source — data based on survey for users of the mobile application. The results revealed three clusters of cultural events based on user preferences towards certain types of cultural events, the frequency of visits to cultural events and the size of groups when visiting these events. The obtained conclusions were used to develop system of recommendations and for customization of offer and marketing strategies according to the identified users’ preferences. The main value of this paper is reflected in the clearly defined research process with all the phases from data collection to validation of results.","Social computing,Social network analysis,User preferences,Mobile application event","StevanMilovanovic,ZoricaBogdanovic,AleksandraLabus,DušanBarac,MarijanaDespotovic-Zrakic","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.10.028","https://www.sciencedirect.com/science/article/pii/S0167739X18311208"
"A154","Machine learning methods for wind turbine condition monitoring: A review","This paper reviews the recent literature on machine learning (ML) models that have been used for condition monitoring in wind turbines (e.g. blade fault detection or generator temperature monitoring). We classify these models by typical ML steps, including data sources, feature selection and extraction, model selection (classification, regression), validation and decision-making. Our findings show that most models use SCADA or simulated data, with almost two-thirds of methods using classification and the rest relying on regression. Neural networks, support vector machines and decision trees are most commonly used. We conclude with a discussion of the main areas for future work in this domain.","Renewable energy,Wind farms,Condition monitoring,Machine learning,Prognostic maintenance","AdrianStetcoa,FatemeDinmohammadib,XingyuZhaob,ValentinRobub,DavidFlynnb,MikeBarnesc,JohnKeanea,GoranNenadica","Renewable Energy","https://doi.org/10.1016/j.renene.2018.10.047","https://www.sciencedirect.com/science/article/pii/S096014811831231X"
"A155","The role of clusters on heat transfer in sedimenting gas-solid flows","In this study, Eulerian-Lagrangian simulations of unbounded sedimenting gas-solid flows are conducted to quantify the effect of two-phase flow interactions on thermal transport. Cold particles are initially randomly distributed in a hot gas and settle under gravity for a wide range of volume fractions and Prandtl numbers. Two-way coupling spontaneously generates clusters of particles with a characteristic length scale much larger than the particle diameter, where fluctuations in particle concentration generate and sustain the carrier-phase turbulence. Simulations reveal that the gas phase is cooled relatively fast in the vicinity of clusters while hot spots persist in regions void of particles. This non-homogeneity was found to delay the overall heat transfer by as much as a factor of four compared to systems with a homogeneous particle distribution. To identify the mechanisms responsible for these variations, the spatially-averaged temperature equation is derived for statistically homogeneous (zero-dimensional) time-dependent particle-laden flows. It is found that the local fluid volume fraction-temperature covariance, referred to here as the fluid temperature seen by the particles, is the key term that accounts for the effect of clusters on heat transfer. Next, a framework for studying thermally fully-developed flows is presented, and statistics at steady state are reported. Consistent with previous work, local variations in the interphase heat transfer coefficient are found to vary by several orders of magnitude. Finally, a statistical modeling approach based on the concept of presumed-shape probability distribution functions is proposed.","Heat transfer,Particle,Cluster,Convection,Multiphase","LeiGuo,JesseCapecelatro","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.12.065","https://www.sciencedirect.com/science/article/pii/S0017931018336342"
"A156","Non-modal analysis of spectral element methods: Towards accurate and robust large-eddy simulations","High-order spectral element methods (SEM) for large-eddy simulation (LES) are still very limited in industry. One of the main reasons behind this is the lack of robustness of SEM for under-resolved simulations, which can lead to the failure of the computation or to inaccurate results, aspects that are critical in an industrial setting. To help address this issue, we introduce a non-modal analysis technique that characterizes the numerical diffusion properties of spectral element methods for linear convection–diffusion problems, including the scales affected by numerical diffusion and the relationship between the amount of numerical diffusion and the level of under-resolution in the simulation. This framework differs from traditional eigenanalysis techniques in that all eigenmodes are taken into account with no need to differentiate them as physical or unphysical. While strictly speaking only valid for linear problems, the non-modal analysis is devised so that it can give critical insights for under-resolved nonlinear problems. For example, why do SEM sometimes suffer from numerical stability issues in LES? And, why do they at other times be robust and successfully predict under-resolved turbulent flows even without a subgrid-scale model? The answer to these questions in turn provides crucial guidelines to construct more robust and accurate schemes for LES.For illustration purposes, the non-modal analysis is applied to the hybridized discontinuous Galerkin methods as representatives of SEM. The effects of the polynomial order, the upwinding parameter and the Péclet number on the so-called short-term diffusion of the scheme are investigated. From a non-modal analysis point of view, and for the particular case of hybridized discontinuous Galerkin methods, polynomial orders between 2 and 4 with standard upwinding are found to be well suited for under-resolved turbulence simulations. For lower polynomial orders, diffusion is introduced in scales that are much larger than the grid resolution. For higher polynomial orders, as well as for strong under/over-upwinding, robustness issues can be expected due to low and non-monotonic numerical diffusion. The non-modal analysis results are tested against under-resolved turbulence simulations of the Burgers, Euler and Navier–Stokes equations. While devised in the linear setting, non-modal analysis successfully predicts the behavior of the scheme in the nonlinear problems considered. Although the focus of this paper is on LES, the non-modal analysis can be applied to other simulation fields characterized by under-resolved scales.","65M60,65M70,76F99,Keywords,Hybridized discontinuous Galerkin,High-fidelity simulation,Large-eddy simulation,Numerical stability,Spectral element methods,Under-resolved simulations","PabloFernandeza,Rodrigo C.Mourab,GianmarcoMengaldoc,JaimePerairea","Computer Methods in Applied Mechanics and Engineering","https://doi.org/10.1016/j.cma.2018.11.027","https://www.sciencedirect.com/science/article/pii/S0045782518305863"
"A157","The entrepreneurship research in hospitality and tourism","The purpose of this study is to review entrepreneurship research in hospitality and tourism (H&T), draw a map of the evolving domain, and propose a framework for future research. The entrepreneurship literature is categorized by identifying the antecedents and consequences in the context of H&T. The study findings suggest that entrepreneurship research subjects in H&T are extended from developed countries to emerging economies. The research level begins at the meso level (firms) and gradually develops to the micro level (individual entrepreneurs) and macro level (environment). Entrepreneurship in H&T is currently rich in practice but poor in theoretical development. This study is one of the few to critically review entrepreneurship research in H&T. This paper identifies a range of research issues in H&T entrepreneurship.","Entrepreneurship research,Research domain,Hospitality,Tourism,Review","HuiFua,FevziOkumusb,KeWua,Mehmet AliKöseogluc","International Journal of Hospitality Management","https://doi.org/10.1016/j.ijhm.2018.10.005","https://www.sciencedirect.com/science/article/pii/S0278431918304432"
"A158","Interlayer coupling-driven magnetic ordering and magnetization processes in ultrathin Au/Co/Mo/Co/Au film","Interlayer magnetic coupling in an Au/Co/Mo/Co/Au system fabricated by molecular beam epitaxy was studied as a function of the thicknesses of the cobalt and molybdenum spacer layers (denoted as dCo and dMo, respectively). Magnetization processes and magnetic domain structures were investigated using magneto-optical techniques. In the investigated thickness ranges, various magnetization configurations of the Co layers were observed: (A) both perpendicular, (B) perpendicular and in-plane, and (C) both in-plane. The interlayer exchange coupling field HIEC was determined as a function of dMo. With increasing dMo, this coupling changed from antiferromagnetic with a huge coupling field of ˜0.27<U+202F>T to ferromagnetic and again to antiferromagnetic. A coupling oscillation period of around 1.4<U+202F>nm was deduced by comparing the experimental data with the Ruderman–Kittel–Kasuya–Yosida model. For configurations (B) and (C), oscillations of the saturation magnetic field HSAT(dMo) perpendicular to the sample plane were found. Simplified and precise analytical expressions for HSAT were proposed by considering HIEC as well as the uniaxial magnetic anisotropy of one and both magnetic layers, respectively. Magnetic ordering was numerically modeled taking into account the dependences of layer anisotropy and exchange coupling on dCo and dMo, respectively. This modeling well described the remanent magnetization map (dCo, dMo) determined using the polar Kerr effect. It is also shown that HIEC(dMo) induced magnetization reorientation from in-plane to out-of-plane or from out-of-plane to in-plane magnetization configurations and canted magnetization of the Co layers.","","Z.Kuranta,M.Tekielaka,I.Svekloa,A.Wawrob,A.Maziewskia","Journal of Magnetism and Magnetic Materials","https://doi.org/10.1016/j.jmmm.2018.12.015","https://www.sciencedirect.com/science/article/pii/S0304885318335984"
"A159","Integrating Building Information Modeling and Prefabrication Housing Production","The decision-making system in Prefabrication Housing Production (PHP) lacks efficiency and collaboration because relevant information is stored and managed in heterogeneous systems of various stakeholders, who are commonly geographically isolated. Building Information Modeling (BIM) has advantages of combining its object-oriented attributes and the production-oriented characteristics of PHP to support decision-making and collaborative working for raising working efficiency. Given the emerging recognition of BIM and PHP, an integrated conceptual framework based on existing studies is needed in order to facilitate their recognition and guide future research. Based on a critical review of 65 papers published in the peer-reviewed journals from 2005 to 2017, a conceptual framework is proposed for the integration of BIM and PHP. The framework involves three pillars, including smart BIM platform (SBP), smart work packages (SWPs), and smart PHP objects (SPOs). A gateway with interoperability function is created between the three pillars to facilitate the communication and interaction with the central database. The results can help develop the system architecture of BIM and PHP, which can then be used to benefit various stakeholders to facilitate the integration.","Building Information Modeling (BIM),Prefabrication Housing Production (PHP),Conceptual framework,Smart work packages (SWPs)","XiaoLia,Geoffrey QipingShenb,PengWuc,TengYued","Automation in Construction","https://doi.org/10.1016/j.autcon.2018.12.024","https://www.sciencedirect.com/science/article/pii/S0926580518300414"
"A160","Intelligent fault diagnosis method of planetary gearboxes based on convolution neural network and discrete wavelet transform","Considering the planetary gearbox vibration signals show highly non-stationary and non-linear behavior because of wind turbines (WTs) often working under time-varying running conditions, we propose an effective and reliable method based on convolution neural network (CNN) and discrete wavelet transformation (DWT) to identify the fault conditions of planetary gearboxes. Firstly, the discrete wavelet transformation is used with the goal of presenting more salient and comprehensive time-frequency distributed representation. Secondly, the deep hierarchical structure of CNN constructed by the alternating convolution layers and subsample layers is trained using a forward transmitting rule of greedy training layer by layer and translates the low-level features of input to the high-level features in order to identify the internal characteristic. Finally, a top classifier Softmax is added at uppermost layer of CNN and the backpropagation process is conducted to fine-tune the parameters of CNN, establishing the mapping relation among the feature space and the fault space. Thus, feature extraction process and fault recognition are incorporated into a general-purpose learning procedure. The experimental results of the fault diagnosis for the planetary gearbox demonstrated the effectiveness and feasibility of the proposed method.","Convolution neural network,Discrete wavelet transformation,Feature extraction,Fault diagnosis,Planetary gearboxes","RenxiangChenab,XinHuanga,LixiaYangc,XiangyangXua,XiaZhanga,YongZhanga","Computers in Industry","https://doi.org/10.1016/j.compind.2018.11.003","https://www.sciencedirect.com/science/article/pii/S0166361518305244"
"A161","Automatic detection of neurons in NeuN-stained histological images of human brain","In this paper we propose a new method for automatic detection of neurons in histological sections of the human brain cortex, based on anisotropic diffusion. The anisotropic diffusion is modeled using a partial differential equation (PDE) and is applied to high resolution microscopy images of the brain in order to detect neurons. We also present a novel approach for PDE-model parameter optimization. Due to the issue of inter-observer variability, three human experts have manually annotated neurons in the image dataset on which the proposed method was trained. The average correlation in neuron detection between the human experts was 86.88%, while the average correlation between the proposed method and the human experts is 88.79%, which shows that the proposed method’s performance is equal to that of human experts. Moreover, the proposed automatic method provides consistent and reproducible results on all sections and is much faster than human raters or other automatic methods. Additionally, the proposed method’s output was verified by a human expert and has correctly distinguished 95.41% of neurons in the test images.","Neuron detection,Partial differential equations,Brain histology,NeuN","AndrijaŠtajduharabcde,DomagojDžajaab,MilošJudašab,SvenLoncariccd","Physica A: Statistical Mechanics and its Applications","https://doi.org/10.1016/j.physa.2018.12.027","https://www.sciencedirect.com/science/article/pii/S0378437118315395"
"A162","Automatic screening using word embeddings achieved high sensitivity and workload reduction for updating living network meta-analyses","ObjectivesWe aimed to develop and evaluate an algorithm for automatically screening citations when updating living network meta-analysis (NMA).,Study Design and SettingOur algorithm learns from the initial screening of citations conducted when creating an NMA to automatically identify eligible citations (i.e., needing full-text consideration) when updating the NMA. We evaluated our algorithm on four NMAs from different medical domains. For each NMA we constructed sets of initially screened citations and citations to screen during an update that took place 2 years after the conduct of the NMA. We encoded free text of citations (title and abstract) using word embeddings. On top of this vectorized representation, we fitted a logistic regression model to the set of initially screened citations to predict the eligibility of citations screened during an update.,ResultsOur algorithm achieved 100% sensitivity on two NMAs (100% [95% confidence interval 93–100] and 100% [40–100] sensitivity), and 94% (81–99) and 97% (86–100) on the remaining two others. For all NMAs, our algorithm would have spared to manually screen 1,345 of 2,530 citations, decreasing the workload by 53% (51–55), while missing 3 of 124 eligible citations (2% [1–7]), none of which were finally included in the NMAs after full-text consideration.,ConclusionFor updating an NMA after 2 years, our algorithm considerably diminished the workload required for screening, and the number of missed eligible citations remained low.","Automatic screening,Network meta-analysis,Live cumulative network meta-analysis,Machine learning,Natural language processing,Word embeddings","IvanLernerabc,PerrineCréquitabcd,PhilippeRavaudabcde,IgnacioAtalabc","Journal of Clinical Epidemiology","https://doi.org/10.1016/j.jclinepi.2018.12.001","https://www.sciencedirect.com/science/article/pii/S0895435618305985"
"A163","Towards evaluation of cloud ontologies","Many enterprises consider that cloud computing will continue to play a key role due to its ability to deliver various types of on-demand IT services, and according to customer needs. Although cloud technology has characteristics that distinguish it from other technologies, unfortunately, services in this technology suffer from the heterogeneity issue. As a result, cloud services have many challenges, such as service description, interoperability, and service discovery. Many studies have contributed dealing with such challenges using ontology, as it can participate as a mapping layer to present such services in a unified description. Cloud ontologies included in these studies can be classified into three types of ontologies; ontologies that focus on representing functional features of cloud services, ontologies that focus on non-functional features, and ontologies that focus on both function and non-function features. These ontologies are not unified in representing such features, where they agree in some features and differ in others. By using techniques developed to evaluate ontologies related to the other technologies, it is difficult to decide which cloud ontology captures cloud services in the right way. We have noticed that there is not a framework or a benchmark to evaluate the cloud ontologies. In this survey, the current cloud ontologies are analyzed to identify a set of observations that represent their strengths and weaknesses. According to these observations, a set of suggested rules are introduced and verified to be considered during the construction or the evaluation of cloud ontologies. The work in this paper can be considered as the fundamental step for developing a formal framework to automatically evaluate cloud ontologies.","Cloud ontology,Cloud computing,Heterogeneity,Evaluation","Mustafa M.Al-Sayeda,Hesham A.Hassanb,Fatma A.Omarab","Journal of Parallel and Distributed Computing","https://doi.org/10.1016/j.jpdc.2018.12.005","https://www.sciencedirect.com/science/article/pii/S0743731518306105"
"A164","High-speed three-dimensional shape measurement using geometry-constraint-based number-theoretical phase unwrapping","In this paper, we propose a high-speed three-dimensional (3-D) shape measurement technique for dynamic scenes using geometry-constraint-based number-theoretical phase unwrapping. As a classical algorithm for temporal phase unwrapping (TPU), the number-theoretical approach is suitable for the binary defocusing fringe projection system since it can retrieve an absolute phase without using low-frequency fringe patterns. However, the conventional number-theoretical TPU approach cannot provide sufficient stability to unwrap a high-frequency phase since it requires the two fringe frequencies to be coprime within the global range of the projector coordinate. In contrast, using low-frequency fringe patterns tends to make phase unwrapping more reliable, but at the expense of the measurement precision. By introducing depth constraint into the traditional number-theoretical TPU, we only need to eliminate the phase ambiguity of each pixel within a small period range defined by the depth range, which means that our method just requires the two fringe frequencies to be coprime within the local period range instead of the conventional global range. Due to the reduction of fringe order candidates and the unambiguous phase range, the reliability of phase unwrapping can be significantly improved compared with the traditional number-theoretical TPU approach even when high-frequency fringe patterns are used. The proposed method has been successfully implemented on a high-frame-rate fringe projection system, achieving high-precision, robust, and absolute 3-D shape measurement at 3333 frames per second.","High-speed 3D,Phase unwrapping,Number-theoretical approach,Depth constraint","WeiYinabc,ChaoZuoabc,ShijieFengabc,TianyangTaoabc,YanHuabc,LeiHuangd,JiaweiMaa,QianChenab","Optics and Lasers in Engineering","https://doi.org/10.1016/j.optlaseng.2018.11.006","https://www.sciencedirect.com/science/article/pii/S0143816618311266"
"A165","Dual steady flow solutions of heat and pollutant removal from a slot ventilated welding enclosure containing a bottom heating source","Air conditioning and ventilation in buildings are major sources of energy consumption, particularly in large industrial buildings with significant pollutant and heat sources. Unfortunately, air flow motions in these slot-ventilated large building spaces are currently poorly understood, particularly concerning their special flow behaviours – multiple steady flows, i.e., identical boundary conditions but different initial conditions or load perturbations may lead to two or more flow solutions. Multiple steady enclosure flow behaviours essentially complicate the convective transport of air, heat and species, which has been vividly analyzed by streamlines, heatlines and masslines. In the present study, the flow mechanisms and transitions driven by combined natural and forced convections in an industrial building space for a welding process will be investigated through the numerical methodology of computational fluid dynamics. The research has taken into consideration the effects of ambient air temperature, indoor heating loads, and welding shifting position on multiple flow motions. The parameters governing the problem are the Reynolds number (103<U+202F>=<U+202F>Re<U+202F>=<U+202F>107) and the Grashof number (107<U+202F>=<U+202F>Gr<U+202F>=<U+202F>1013) and it is observed that the multiple-steady-regions can be maintained for a range of values of Gr/Re2, 150<U+202F><<U+202F>Gr/Re2<U+202F><<U+202F>1000, 6500<U+202F><<U+202F>Gr/Re2<U+202F><<U+202F>12,500 and Gr/Re2 ~ +8 with proper conditions.","Enclosure air flow,Slot ventilated jet,Thermal source,Multiple steady solutions,Heat transport function,Species transport function","Dong-DongZhangabc,YangCaiabc,DiLiud,Fu-YunZhaoabc,YuguoLie","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.11.121","https://www.sciencedirect.com/science/article/pii/S0017931018338808"
"A166","Unveiling the intellectual structure and evolution of external resource management research: Insights from a bibliometric study","In the current hyper-competitive economy, it is increasingly important to understand how firms can and should access and leverage external resources, such as customer knowledge or supply-chain partners' capabilities. In this paper, we report the results of bibliometric analyses on external resource management (ERM) research in nine representative journals, and elaborate the underlying patterns and dynamics in this relatively young research area. A total of 1290 articles ranging from year 2000 to 2015 were analyzed with text-mining and visualization methods. We found that the annual number of ERM publications is steadily increasing, and identified and described four distinct research clusters focusing on integration & operational effectiveness, innovation & value creation, inter-organizational relationships, and knowledge transfer & learning. The identification of research clusters and key works and authors in this multidisciplinary research field can assist future research in better positioning their studies and finding the key references across disciplinary silos.","Bibliometric analysis,Cross-disciplinary research,External resource management,Intellectual structure,Text-mining,Visualization","JohannaBraggea,KatriKauppia,TuomasAholab,AnnaAminoffc,RiikkaKaipiad,KariTanskanene","Journal of Business Research","https://doi.org/10.1016/j.jbusres.2018.12.050","https://www.sciencedirect.com/science/article/pii/S0148296318306696"
"A167","Automatic and high-quality surface mesh generation for CAD models","In this paper, we present a fully automatic framework that tessellates industrial computer-aided design (CAD) models into high-quality triangular meshes. In contrast to previous approaches that are purely parametric or performed directly in 3D space, our method is based on a remeshing algorithm that can achieve accuracy and high-quality simultaneously. Given an input standard CAD model, which is represented by B-rep format,we first rebuild the parametric domain for each surface patch according to an initial triangulation, and then the boundaries of the parametric domain are retriangulated by exploiting the Constrained Delaunay Triangulation (CDT). In the second stage, the 2D triangulation is projected back to the 3D space, and a modified global isotropic remeshing process is applied, which further improves the regularity and angle quality of the tessellated meshes. Experiments demonstrate the validity of the proposed approach and its ability to generate high-quality meshes. Moreover, we evaluate our technique and compare it with state-of-the-art CAD model tessellation approaches.","CAD tessellation,High-quality mesh,Remeshing","JianweiGuoa,FanDinga,XiaohongJiabc,Dong-MingYana","Computer-Aided Design","https://doi.org/10.1016/j.cad.2018.12.005","https://www.sciencedirect.com/science/article/pii/S0010448518302690"
"A168","An open-source multi-robot construction system","We describe a completely open source system for performing experiments in multi-robot construction in laboratory settings. The system consists of robots that are capable of assembling cubic blocks into structures, which can be up to three blocks in height. The building material contains microcontrollers and multi-color light-emitting diodes (LEDs) that can be programmed by the robots using a near-field communication (NFC) interface. This mechanism is implemented to facilitate experiments where the intelligence that coordinates the construction can be embedded not only in the robots but also in the building material.","Robotics,Construction,Open-source hardware,Multi-robot system","MichaelAllwright,WeixuZhu,MarcoDorigo","HardwareX","https://doi.org/10.1016/j.ohx.2018.e00050","https://www.sciencedirect.com/science/article/pii/S2468067218300786"
"A169","Business model innovation for circular economy and sustainability: A review of approaches","As circular economy and sustainability gain greater attention of governments, industry and academia, business model innovation for circularity and/or sustainability is becoming fundamental to sustain companies' competitive advantage. A variety of business model innovation approaches have been proposed to suit circular economy or sustainability principles. Although they largely have been addressed independently as two separate knowledge areas, there is an opportunity to seize synergies from the intersection of both streams. This paper provides a review of approaches for business model innovation for circular economy and/or sustainability, based on a systematic review of academic literature and practitioner-based methodologies. The systematic literature review identified 94 publications and 92 approaches (including conceptual models, methods or tools). The different approaches were categorized according to the business model innovation process, following a three stage dynamic capability view. Subsequently they were compared based on five characteristics (nature of data, boundaries of analysis, level of abstraction, time-based view, and representation style), to allow for a better understanding of how to use the approaches in research and practice. Based on the review, key findings outlining trends and a reflection about the interface of the scopes of circular economy-oriented and sustainability-oriented business model innovation are presented. Moreover, a number of gaps are identified and a framework that maps a future research agenda to simultaneously advance both streams is outlined.","Business model innovation,Circular economy,Circularity,Sustainability","Marina P.P.Pieroni,Tim C.McAloone,Daniela C.A.Pigosso","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2019.01.036","https://www.sciencedirect.com/science/article/pii/S0959652619300423"
"A170","An in depth economic restructuring framework by using particle swarm optimization","The aim of this paper is the development of an integrated framework, based on environmental input-output analysis, for optimizing the economic structure of an economy. The restructuring process is approached as a constraint optimization problem where the optimized variables are the elements of the matrix of domestic technical coefficients. A method for determining the optimal level of the productive linkages of an economy in order to maximize its output with the minimal greenhouse gas emissions the possible is suggested. The proposed methodology is able to join both environmental and economic policy targets, in the form of predefined constraints. The objective function, which is going to be minimized, expresses the greenhouse gas emissions (GHG) intensity or GHG emissions per unit of output. A particle swarm algorithm is employed for the solution of the optimization problem. An illustrative application to the Greek economy was carried out. The experimental results revealed that if the Greek economy will apply policies for boosting the sectors of high and medium-high R&D intensity, then the greenhouse gas emission per unit of gross domestic product of Greece would be reduced. Furthermore, the promotion of high and medium-high R&D intensity sectors is connected with an important improvement of the production linkages to a wide range of sectors, highlighting the important spillover effect of the suggested restructuring process.","Economic structure optimization,Input-output analysis,Particle swarm optimization","SteliosPapadakis,MariaMarkaki","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2019.01.041","https://www.sciencedirect.com/science/article/pii/S0959652619300484"
"A171","Modeling and evaluation on WSN-enabled and knowledge-based HACCP quality control for frozen shellfish cold chain","Shellfish have limited shelf life due to quality fluctuation caused by biochemical, microbiological or physical changes under real cold chain conditions. The objective of this study was to integrate Wireless Sensors Network (WSN) monitoring system and knowledge engineering to monitor the dynamic indicators that affect quality characteristics and establish knowledge-based HACCP quality control plan to improve the safety of frozen shellfish in the real cold chain. The obtained dynamic data by WSN including temperature, humidity, O2, CO2 indicators, and an Arrhenius equation based kinetic model were simulated with field cold chain scenarios to determine the shelf life and quality loss probability. The key quality control points were identified based on the HACCP plan and unified representation and reasoning rule were established for enhancing the HACCP knowledge sharing and reuse. The system was tested and evaluated in cold chain logistics from Rushan to Fuzhou, China. The results show WSN-based monitoring can achieve the dynamic indicators continuous monitoring and contribute to the CCPs dynamic adjustment. The application of WSN-enabled and knowledge-based HACCP modeling as effective approach can help to increase cold chain management (CCM) transparency and improve the quality control for the frozen shellfish during their commercial life.","Frozen shellfish,WSN,Knowledge-based HACCP plan,Shelf life,Quality control","HuanhuanFengab,JingChenc,WeiZhoud,VilaiRungsardthonge,XiaoshuanZhangab","Food Control","https://doi.org/10.1016/j.foodcont.2018.11.050","https://www.sciencedirect.com/science/article/pii/S0956713518305954"
"A172","Accuracy of lateral cephalogram for diagnosis of adenoid hypertrophy and posterior upper airway obstruction: A meta-analysis","IntroductionAccurate diagnosis of adenoid hypertrophy and posterior upper airway obstruction using a lateral cephalogram is challenging. No universal guidelines for assessing adenoidal enlargement and upper airway obstruction have been established. We performed a meta-analysis to assess the diagnostic accuracy of a lateral cephalogram for adenoid hypertrophy.,MethodsAfter searching a wide range of electronic databases and screening titles and abstracts, we evaluated full papers describing potentially eligible studies according to predefined inclusion criteria. Quality assessment was conducted by adapting the Quality Assessment of Diagnostic Accuracy Studies-2 checklist, and a 2<U+202F>×<U+202F>2 contingency table was constructed based on these results. Two authors independently judged the studies and extracted the data. The diagnostic accuracy of a lateral cephalogram for adenoid hypertrophy and posterior upper airway obstruction was calculated using a bivariate meta-analysis model. The Q-test and I2 index were used to test the heterogeneity.,ResultsNine studies were included in the meta-analysis. The pooled sensitivity, specificity, diagnostic odds ratio, positive likelihood ratio, and negative likelihood ratio were 0.86 [95% confidence interval (CI): 0.76–0.92], 0.59 (95% CI: 0.42–0.73), 9.00 (95% CI: 5–17), 2.1 (95% CI: 1.5–3.0), and 0.24 (95% CI: 0.15–0.37), respectively. The area under the summary receiver operator characteristic curve was 0.83 (95% CI: 0.80–0.86). Meta-regression analysis revealed that the sample size and study design significantly contributed to the heterogeneity of sensitivity.,ConclusionsOur findings suggest that the lateral cephalogram exhibits very good diagnostic accuracy (area under the curve: 0.86) for the diagnosis of adenoid hypertrophy and posterior upper airway obstruction. Nevertheless, the rate of false-positive diagnoses should be further considered.","Adenoids,Radiography,Cephalogram,Nasopharynx,Meta-analysis","HanzhongDuanab,LiXiab,WangfangHeb,YongdongLinb,ZhihuiLub,QingLana","International Journal of Pediatric Otorhinolaryngology","https://doi.org/10.1016/j.ijporl.2019.01.011","https://www.sciencedirect.com/science/article/pii/S0165587619300175"
"A173","Grab recruitment by Rab27A-Rabphilin3a triggers Rab3A activation in human sperm exocytosis","Sperm must undergo the regulated exocytosis of its dense core granule (the acrosome reaction, AR) to fertilize the egg. We have previously described that Rabs3 and 27 are organized in a RabGEF cascade within the signaling pathway elicited by exocytosis stimuli in human sperm. Here, we report the identity and the role of two molecules that link these secretory Rabs in the RabGEF cascade: Rabphilin3a and GRAB. Like Rab3 and Rab27, GRAB and Rabphilin3a are present, localize to the acrosomal region and are required for calcium-triggered exocytosis in human sperm. Sequestration of either protein with specific antibodies introduced into streptolysin O-permeabilized sperm impairs the activation of Rab3 in the acrosomal region elicited by calcium, but not that of Rab27. Biochemical and functional assays indicate that Rabphilin3a behaves as a Rab27 effector during the AR and that GRAB exhibits GEF activity toward Rab3A. Recombinant, active Rab27A pulls down Rabphilin3a and GRAB from human sperm extracts. Conversely, immobilized Rabphilin3a recruits Rab27 and GRAB; the latter promotes Rab3A activation. The enzymatic activity of GRAB toward Rab3A was also suggested by in silico and in vitro assays with purified proteins. In summary, we describe here a signaling module where Rab27A-GTP interacts with Rabphilin3a, which in turn recruits a guanine nucleotide-exchange activity toward Rab3A. This is the first description of the interaction of Rabphilin3a with a GEF. Because the machinery that drives exocytosis is highly conserved, it is tempting to hypothesize that the RabGEF cascade unveiled here might be part of the molecular mechanisms that drive exocytosis in other secretory systems.","2-APB2-aminoethoxydiphenylborate,ARacrosome reaction,GEFguanine nucleotide exchange factor,GSTglutathione-S-transferase,GRABguanine nucleotide exchange factor for Rab3A (also known as Rab3A interacting protein (rabin3)-like 1 or Rab3IL1),IPTGisopropyl-ß-d-thio-galactoside,NP-EGTA-AMO-nitrophenyl EGTA-acetoxymethyl ester,PBSphosphate buffer saline,RBDRab binding domain,RIMRab interacting molecule,SDS-PAGEsodium dodecyl sulfate-polyacrylamide gel electrophoresis,Slac2-bsynaptotagmin-like protein homology domain,SLOstreptolysin O,Keywords,Exocytosis,GRAB,RabGEF cascade,Rabphilin3a,Sperm","María FlorenciaQuevedoa,Matías AlbertoBustosa1,DiegoMasoneab,Carlos MarceloRoggeroc,Diego MartínBustosad,Claudia NoraTomesade","Biochimica et Biophysica Acta (BBA) - Molecular Cell Research","https://doi.org/10.1016/j.bbamcr.2018.12.005","https://www.sciencedirect.com/science/article/pii/S0167488918301836"
"A174","SparseMaps: Convolutional networks with sparse feature maps for tiny image classification","Deep convolutional models have been able to get extraordinary results in visual, speech and textual processing domains. Nevertheless, the complexity of manifold of images in data space necessitates the deep networks to have a large number of parameters and subsequently these deep models prone to redundancy and overfitting. One of the most effective methods to tackle this problem is devising special regularization methods in the context of convolutional models. In this paper, after presenting and discussing the most important models in the field, sparse feature maps are proposed and employed as a penalty term in the cost function. This conducts the learning process to construct kernels so that the feature maps at every point are sparse along the depth. A sparse representation is able to adapt to the varying level of information of natural images and can help to extract more independent and informative representations. Also, the DropMaps concept is proposed and employed in the last convolutional layer of the model. This technique applies dropout on the feature maps that causes coincidence of feature maps to be avoided. As is shown in this paper, sparse feature maps and DropMaps can handle the problem of overfitting in large models for tiny images. We have studied the effect of the sparsity rate on the accuracy of the model, and it is observed the accuracy of the test dataset reaches its maximum at a sparsity rate of 0.05. Moreover, by designing appropriate learning rate curves, we were able to obtain ensemble machines with much less cost for training. It is noticeable that the test accuracy is higher than the validation accuracy of the ensemble, indicating that the model has not overfitted. In the input of the model, a random online preprocessing layer is employed for the training phase that helps regularization of the model. Comparing input space and feature space of the model we found that the proposed network is able to successfully separate images of different classes. Finally, testing the proposed model with MNIST dataset has shown that the test set can be classified with accuracy 99.75. The same test with CIFAR 10 dataset attained an accuracy of 94.05.","Deep convolutional networks,Sparse feature map,DropMaps,Tiny image classification,Learning rate curve,Deep ensembles","RezaMoradi,RezaBerangi,BehrouzMinaei","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.012","https://www.sciencedirect.com/science/article/pii/S0957417418306547"
"A175","Real-time record sensitive background classifier (RSBC)","In computer vision, one of the ways to identify moving objects or foregrounds from a complex video scene is background subtraction. Two problems that usually arise in background subtraction are that of dynamic background and ghost effect. In this article, an efficient, adaptive, real-time, novel background subtraction method is proposed to handle these two problems by utilizing the classification history of previous frames to detect changes in a video scene. The proposed method, coined as Record Sensitive Background Classifier (RSBC) is an amalgamation of two models, the Adaptive Background Model (ABM) and the Neighbourhood Background Model (NBM), which make use of the foreground and background classification information of the previous frames. The novel design of the ABM considers the temporal history of transitions between foreground and background of a given pixel, while the novelty in NBM lies in considering the binary classification results of the local neighbourhood in the preceding frame. Several state-of-the-art methods are compared with the proposed RSBC method, over which the proposed method shows significant improvement. Because of its good performance at fast processing speeds the proposed method can also be used as a preliminary prioritization step for slower but high accuracy methods in an object tracking system.","Background subtraction,Computer vision,Mini-batch,Binary classification,Switch information,Neighbourhood search,Real-time analysis","Sujoy MadhabRoy,AshishGhosh","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.025","https://www.sciencedirect.com/science/article/pii/S0957417418306754"
"A176","Marketing analytics: Methods, practice, implementation, and links to other fields","Marketing analytics is a diverse field, with both academic researchers and practitioners coming from a range of backgrounds including marketing, expert systems, statistics, and operations research. This paper provides an integrative review at the boundary of these areas. The aim is to give researchers in the intelligent and expert systems community the opportunity to gain a broad view of the marketing analytics area and provide a starting point for future interdisciplinary collaboration. The topics of visualization, segmentation, and class prediction are featured. Links between the disciplines are emphasized. For each of these topics, a historical overview is given, starting with initial work in the 1960s and carrying through to the present day. Recent innovations for modern, large, and complex “big data” sets are described. Practical implementation advice is given, along with a directory of open source R routines for implementing marketing analytics techniques.","Analytics,Prediction,Marketing,Visualization,Segmentation,Data mining","Stephen L.Francea,SanjoyGhoseb","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.11.002","https://www.sciencedirect.com/science/article/pii/S095741741830722X"
"A177","MedGA: A novel evolutionary method for image enhancement in medical imaging systems","Medical imaging systems often require the application of image enhancement techniques to help physicians in anomaly/abnormality detection and diagnosis, as well as to improve the quality of images that undergo automated image processing. In this work we introduce MedGA, a novel image enhancement method based on Genetic Algorithms that is able to improve the appearance and the visual quality of images characterized by a bimodal gray level intensity histogram, by strengthening their two underlying sub-distributions. MedGA can be exploited as a pre-processing step for the enhancement of images with a nearly bimodal histogram distribution, to improve the results achieved by downstream image processing techniques. As a case study, we use MedGA as a clinical expert system for contrast-enhanced Magnetic Resonance image analysis, considering Magnetic Resonance guided Focused Ultrasound Surgery for uterine fibroids. The performances of MedGA are quantitatively evaluated by means of various image enhancement metrics, and compared against the conventional state-of-the-art image enhancement techniques, namely, histogram equalization, bi-histogram equalization, encoding and decoding Gamma transformations, and sigmoid transformations. We show that MedGA considerably outperforms the other approaches in terms of signal and perceived image quality, while preserving the input mean brightness. MedGA may have a significant impact in real healthcare environments, representing an intelligent solution for Clinical Decision Support Systems in radiology practice for image enhancement, to visually assist physicians during their interactive decision-making tasks, as well as for the improvement of downstream automated processing pipelines in clinically useful measurements.","Medical imaging systems,Image enhancement,Genetic Algorithms,Magnetic resonance imaging,Bimodal image histogram,Uterine fibroids","LeonardoRundo1ab,AndreaTangherloni1a,Marco S.Nobileac,CarmeloMilitellob,DanielaBesozzia,GiancarloMauriac,PaoloCazzanigadc","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.11.013","https://www.sciencedirect.com/science/article/pii/S0957417418307310"
"A178","Recent advances in failure diagnosis techniques based on performance data analysis for grid-connected photovoltaic systems","Over the last decade, research into photovoltaic (PV) technology has shifted from a race for the highest efficiency to the increase of the performance reliability in the field. A major part of current research activities focuses on the reliability of the installations and the guaranteed lifetime output through constant, solid and traceable PV plant monitoring. In this domain, several PV monitoring strategies for the early diagnosis of failures in grid-connected PV systems have been proposed in the literature and this study seeks to provide an overview of all the data analytic methods used by the research community and industry for the detection and classification of failures from acquired performance data of grid-connected PV systems. Insight into the performance monitoring requirements (parameters and resolution) for the detection of failures in monitored PV systems, as well as the various techniques used for their classification is also provided. Finally, this overview covers the data analytic methods based on electrical signature, numerical and statistical analysis and are summarised according to the type of failure, input requirements and validation procedure.","Failure detection,Classification of failures,Data analytic,Grid-connected systems,Photovoltaics","AndreasLivera,MariosTheristis,GeorgeMakrides,George E.Georghiou","Renewable Energy","https://doi.org/10.1016/j.renene.2018.09.101","https://www.sciencedirect.com/science/article/pii/S0960148118311753"
"A179","Compromised user credentials detection in a digital enterprise using behavioral analytics","In today’s digital age, the digital transformation is necessary for almost every competitive enterprise in terms of having access to the best resources and ensuring customer satisfaction. However, due to such rewards, these enterprises are facing key concerns around the risk of next-generation data security or cybercrime which is continually increasing issue due to the digital transformation four essential pillars—cloud computing, big data analytics, social and mobile computing. Data transformation-driven enterprises should ready to handle this next-generation data security problem, in particular, the compromised user credential (CUC). When an intruder or cybercriminal develops trust relationships as a legitimate account holder and then gain privileged access to the system for misuse. Many state-of-the-art risk mitigation tools are being developed, such as encrypted and secure password policy, authentication, and authorization mechanism. However, the CUC has become more complex and increasingly critical to the digital transformation process of the enterprise’s database by a cybercriminal, we propose a novel technique that effectively detects CUC at the enterprise-level. The proposed technique is learning from the user’s behavior and builds a knowledge base system (KBS) which observe changes in the user’s operational behavior. For that reason, a series of experiments were carried out on the dataset that collected from a sensitive database. All empirical results are validated through well-known evaluation measures, such as (i) accuracy, (ii) sensitivity, (iii) specificity, (iv) prudence accuracy, (v) precision, (vi) f-measure, and (vii) error rate. The experiments show that the proposed approach obtained weighted accuracy up to 99% and overall error of about 1%. The results clearly demonstrate that the proposed model efficiently can detect CUC which may keep an organization safe from major damage in data through cyber-attacks.","Compromised user detection,Compromised activities detection,Knowledge-base system,Prudence analysis,Cluster-level pattern","SalehShaha,BabarShahb,AdnanAmina,FerasAl-Obeidatb,FrancisChowc,Fernando Joaquim LopesMoreirad,SajidAnwara","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.09.064","https://www.sciencedirect.com/science/article/pii/S0167739X18312524"
"A180","Snapshot interferometric multispectral imaging using deconvolution and colorimetric fit","Multispectral imaging techniques provide spatial and spectral information about a scene. Among them, the spatial Fourier transform interferometric approach is popular, because it does not use moving parts and has the signal advantage. But the inherent antagonism between the recording of spectral and spatial frequencies in such techniques is truly bypassed only in remote sensing by using the relative motion between the scene and the imager as a substitute for the scanning device. Snapshot techniques, which do not use any sort of scanning, were also developed, but at the price of sacrificing the overall spatial-spectral resolution. They use mapping, multiplexing, and filtering to spread the spatial and the spectral information over a large sensor array. Here, a snapshot interferometric multispectral imaging technique is presented, that does not sacrifice resolution. The whole spectral and spatial information is obtained from a small quantity of input data; this was made possible by the use of deconvolution in the Fourier spatial spectrum and colorimetric fit, which puts our technique in the vicinity of the compressive sensing approach. A severe limitation is that the technique can be applied only to scenes that can be divided into subscenes in which the dependencies of the light intensity on the spectral and the spatial variables respectively are separable, i.e. the input data has high sparsity. This shifts the burden of creating complex hardware capable of performing snapshot spectral analysis to finding algorithms for dividing the scene in spectrally uniform subscenes. Another difficulty is the fact that the subscenes need to be smooth enough so that the Fourier spectrum due to interference does not overlap the Fourier spectrum of the non-interfered subscene. However, solutions to these problems exist or they are in development. For instance, we propose a test of high probability for separability. The use of deconvolution and colorimetric fit eliminates the need for calibrated dispersive elements in the spectral analysis and may be separated from other considerations and construed as a contribution to spectral analysis.","Multispectral imaging,Fourier transform,Deconvolution,Colorimetry","Petre CatalinLogofatu,VictorDamian","Optics & Laser Technology","https://doi.org/10.1016/j.optlastec.2018.09.008","https://www.sciencedirect.com/science/article/pii/S0030399217318194"
"A181","Subevents detection through topic modeling in social media posts","Event detection has been a significant topic for a long time, since the onset development of pervasive systems. The ability to gather data from various sensors, in a diverse number of formats, is a challenge due to the continuous growth of data volume. Users of social media act as human sensors, providing data and information in real time about entities and events. Most of the research about event detection – using human or non-human sensors – concentrates only on identifying events. These models assume an event to be a single entity and ignoring that it can be composed of other new events over time. The detection of subevents enriches the understanding of the main event, contextualizing it and creating a powerful knowledge about the scenario. To capture the parts of an event and the information changing over time, we created a scalable and modular topic modeling based algorithm. It identifies subevents and creates labels to represent them more accurately. We evaluate the proposed sub-event detection approach using two large-scale Twitter corpus. The first one is related to Brazil’s political protests scenario. The second analyzes the Zika Virus epidemic in the world. Our approach detected several subevents, most of them are related to real subevents. Due to the nature of social networks, with a minimum delay between an event occurrence and its dissemination, these results can open an opportunity for temporal tracking of emergence and outbreak scenarios.","Topic labeling,Topic modeling,Subevent detection,Social networks,Unsupervised learning","DiogoNolascoa,JoniceOliveirab","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.09.008","https://www.sciencedirect.com/science/article/pii/S0167739X18307611"
"A182","Interference graphs to monitor and control schedules in low-power WPAN","With billions of connected devices in the near future, the major challenge is to develop networks to build an Industrial Internet of Things which is scalable, energy-efficient, reliable and affordable. To this end, low-power wireless personal area networks (LP-WPAN) provide a solution at minimum costs. However, to ensure continuous performance verification, LP-WPAN requires a centrally monitored and controlled service. This work proposes such an edge service, i.e. network monitoring and optimal reconfiguration of scheduled LP-WPANs. The approach is based on a transformation of the schedule into a new model, interference graphs. The interference graphs allow to design evaluation and rescheduling recommender methods to monitor and reconfigure the schedule. An experimental setup was developed to test and validate the approach. The results show that the model and methods provide an accurate representation of the behavior of the network, and that the new rescheduling recommender greatly improves the network’s performance, compared to random rescheduling.","Internet of Things,Wireless sensor network,Interference graph,Disconnection probability,Network management,Network scheduling","Timvan der Leea,AntonioLiottab,GeorgiosExarchakosa","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.10.014","https://www.sciencedirect.com/science/article/pii/S0167739X17329862"
"A183","Sensitivity of test items to teaching quality","Instructional sensitivity is the psychometric capacity of tests or single items of capturing effects of classroom instruction. Yet, current item sensitivity measures’ relationship to (a) actual instruction and (b) overall test sensitivity is rather unclear. The present study aims at closing these gaps by investigating test and item sensitivity to teaching quality, reanalyzing data from a quasi-experimental intervention study in primary school science education (1026 students, 53 classes, Mage<U+202F>=<U+202F>8.79 years, SDage<U+202F>=<U+202F>0.49, 50% female). We examine (a) the correlation of item sensitivity measures and the potential for cognitive activation in class and (b) consequences for test score interpretation when assembling tests from items varying in their degree of sensitivity to cognitive activation. Our study (a) provides validity evidence that item sensitivity measures may be related to actual classroom instruction and (b) points out that inferences on teaching drawn from test scores may vary due to test composition.","Teaching quality,Instructional sensitivity,Educational effectiveness,Validity,Classroom assessment","AlexanderNaumannad,SvenjaRieserb,StephanieMusowcd,JanHochwebercd,JohannesHartigad","Learning and Instruction","https://doi.org/10.1016/j.learninstruc.2018.11.002","https://www.sciencedirect.com/science/article/pii/S0959475217307065"
"A184","Pa-syn* mitotoxicity is linked to MAPK activation and involves tau phosphorylation and aggregation at the mitochondria","We recently identified a truncated and phosphorylated form of a-synuclein, pa-syn*, as a key neurotoxic a-synuclein species found in cultured neurons, as well as in mouse and Parkinson's disease patients' brains. Small pa-syn* aggregates localize to mitochondria and induce mitochondrial damage and fragmentation. Herein, we investigated the molecular basis of pa-syn*-induced toxicity. By immunofluorescence, we found phosphorylated MKK4, JNK, ERK5 and p38 MAPKs in pa-syn* inclusions. pJNK colocalized with pa-syn* at mitochondria and mitochondria-associated ER membranes where it was associated with BiP and pACC1, markers for the ER and energy deprivation, respectively. We also found that pa-syn* aggregates are tightly associated with small ptau aggregates of similar size. Pa-syn*/ptau inclusions localized to areas of mitochondrial damage and to mitophagic vesicles, showing their role in mitochondrial toxicity, mitophagy induction and their removal along with damaged mitochondrial fragments. Several MAPKs may act cooperatively to phosphorylate tau, notably JNK, p38 and GSK3ß, a non-MAPK that was also found phosphorylated in the vicinity of pa-syn*/ptau aggregates. These results add insight into the mechanisms by which pa-syn* exerts its toxic effects that include the phosphorylation of several kinases of the MAPK pathway, as well as the formation of ptau at the mitochondrial membrane, likely contributing to mitotoxicity. Thus pa-syn* appears to be the trigger of a series of kinase mediated pathogenic events and a link between a-syn pathology and tau, another protein known to aggregate in Parkinson's disease and other synucleinopathies.","Alpha-synuclein,Tau,Parkinson's disease,Primary neurons,Kinases,Neurotoxicity,Mitochondria,Mitophagy","DiegoGrassiab,NataliaDiaz-Perezc,Laura A.Volpicelli-Daleyd,Corinne IdaLasmézasab","Neurobiology of Disease","https://doi.org/10.1016/j.nbd.2018.11.015","https://www.sciencedirect.com/science/article/pii/S0969996118307034"
"A185","On the overlap area of a disk and a piecewise circular domain","We provide an approach to solve the problem of locating a disk so that its overlap area with a piecewise circular domain is near-optimal when considering partial converage. To this purpose, we introduce the concept of overlap area map. Both, overlap area maps and near-optimal locations, provide useful tools for solving problems related to the placement, for example, of emergency warning sirens, cellular towers or radio receiving stations, that are commonly encountered in the location science field. We present parallel algorithms on graphics processing units (GPUs) for computing an overlap area map and obtaining a set of near-optimal locations from the overlap area map. These algorithms have as a key element the overlap area computation process to which we pay special attention. In addition, we describe a way of visualizing the obtained solutions. Integration of computation and visualization facilitates decision makers, with an iterative what-if-analysis process, to gain more information in order to facilitate the selection of an appropriate location. Finally, we also provide and discuss experimental results showing the efficiency and scalability of our approach.","Decision support systems,Facility placement,Service coverage,Continuous space,Graphics processing unit (GPU)","NarcisColla,MartaFortab,J. AntoniSellarésa","Computers & Operations Research","https://doi.org/10.1016/j.cor.2018.11.007","https://www.sciencedirect.com/science/article/pii/S0305054818302922"
"A186","Characteristic expressions of the natriuretic peptide family in the telencephalon of juvenile chick","Elucidation of the genes regulating the critical (sensitive) period of imprinting behavior may shed light on the mechanism underlying neural plasticity in early childhood learning. We focused on the family of natriuretic peptides (NPs) as candidates involved in the regulation of the critical period. In avians, several structurally related molecules comprised the NP family, including renal NP (RNP), B-type NP (BNP) and C-type NP (CNP1, CNP3 and CNPP). To understand the functional roles of NPs in neural plastic changes, we aimed to characterize NPs and their receptors in chick brain. We found that CNP3 mRNA was expressed in several regions in the telencephalon, including the visual Wulst (VW, considered as mammalian visual cortex) and amygdala. CNP1 mRNA was expressed throughout the telencephalon. Using real-time PCR, the gene expression levels of NPs and their receptors (NPR1 and NPR2) were studied during and after the critical period of imprinting (post-hatching day [P]1 and P7). CNP3 mRNA was found to show higher expression in the VW of P1 chicks than in VW of P7 chicks. Moreover, the ability of these peptides to stimulate chicken NPR1 or NPR2 was tested in HEK293 cells expressing either of the receptors. The activation of NPR1 was stronger with CNP3 than with other subtypes of CNP. In the VW, CNP3-expressing cells were negative for NPR1, but they resided in the vicinity of NPR1-expressing cells. These results suggest that CNP3 and its receptor NPR1 in the VW may have functional roles in the early learning.","AMarcopallium mediale,ANPatrial NP,BNPB-type NP,chBNPchicken BNP,chCNPchicken CNP,cGMPcyclic guanosine monophosphate,chNPRchicken NPR,chRNPchicken RNP,CNPC-type NP,DIGdigoxigenin,GCguanylyl cyclase,HAhyperpallium apicale,HDhyperpallium densocellulare,HDCocore region of the HD,HIhyperpallium intercalatum,Hiphippocampus,IHAinterstitial nucleus of the hyperpallium apicale,IMMintermediate medial mesopallium,Mmesopallium,Nnidopallium,NPnatriuretic peptide,NPRNP receptor,Ppost hatching days,PBphosphate buffer,PBSphosphate buffered saline,PoAbbasal division of the nucleus posterioris amygdalopalli,RNPrenal NP,SSubpallium,VWvisual Wulst,Keywords,Natriuretic peptide,Visual imprinting,Critical period,Juvenile learning","TomoharuNakamoria,YurinoChibaa,KazukoFujitanib,AmiMakitaa,TsugumiOkuboa,KasumiHiraia,NobuhikoTakamatsuc,HirokoOhki-Hamazakia","Brain Research","https://doi.org/10.1016/j.brainres.2018.12.007","https://www.sciencedirect.com/science/article/pii/S0006899318306140"
"A187","Following others through an information maze: The impact of social navigation on information seeking behavior","“Social Navigation” for the Web has been created in response to the problem of disorientation in an information space. It helps users tackle the information overload challenge by visualizing the traces of behavior of other users and adding social affordances to the information space. Despite the popularity of the concept of social navigation, very few studies of information systems with social navigation can be found in the research literature. In this paper, we report on our study of the impact of social navigation support in the context of task-centered information access. We explore the design of our information access interface which is designed to offer integrated social navigation support, as well as our experiment to systematically assess how social navigation support influenced participants’ information seeking behavior. This experiment will identify situations in which social navigation support is most useful and to investigate the effect of interpersonal trust as an individual factor on the likelihood of following social navigation cues. The results of the study show that social navigation support can successfully guide participants to relevant documents, enabling them to achieve higher search performance. The study also revealed that the effect of social navigation cues on participants’ information seeking behaviors varies under different circumstances, especially under time constraints and for those with high levels of interpersonal trust.","Social navigation support,Information seeking,Time constraint,Interpersonal trust,Experiment,Interface","RostaFarzan,PeterBrusilovsky","International Journal of Human-Computer Studies","https://doi.org/10.1016/j.ijhcs.2018.11.001","https://www.sciencedirect.com/science/article/pii/S1071581918306438"
"A188","The Politecnico di Torino rolling bearing test rig: Description and analysis of open access data","Nowadays, machines-diagnostics via vibration monitoring is rising an always growing interest thanks to the huge and accurate amount of health information which could be extracted by the raw data coming from accelerometers. Damage severity, type and location of a fault are the kind of information which are buried in the time records.The scope of this paper is double: first, to present the huge amount of data which have been acquired on the rolling bearing test rig of the Dynamic and Identification Research Group (DIRG), in the Department of Mechanical and Aerospace Engineering at Politecnico di Torino and to share them with the scientific community; secondly, to present a statistical approach analysis and its performances as example of a simple technique to be fruitfully adopted for comparison. To this goal, a detailed presentation of the test rig is given, which comprehends different working conditions up to 30,000<U+202F>rpm, damage types and levels, various sensors positions and directions as well as an endurance test. The related time records can be downloaded from ftp://ftp.polito.it/people/DIRG_BearingData/.Afterword, tried-and-tested statistical tools are exploited to learn the information about bearing damages from this massive amounts of data. This “data mining” will be performed using inferential statistical techniques as analysis of variance (ANOVA), applied on usual statistical features, which characterize of the signal. A linear discriminant analysis (LDA) in the configuration proposed by Fisher will be also used to see if the data were classifiable in a multidimensional space with this basic algorithm. Finally, an Outlier Analysis based on Mahalanobis distance will be formulated, so as to distinguish a damage condition from the healthy state (training data), compensating when possible for environmental (temperature) and operational (speed and load) variations.","Bearing test rig,Open access data,Damage detection,Damage evolution,Big data dimensionality,Statistical analysis,ANOVA,Fisher’s LDA,PCA,Mahalanobis distance,Outliers analysis","Alessandro PaoloDaga,AlessandroFasana,StefanoMarchesiello,LuigiGaribaldi","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.10.010","https://www.sciencedirect.com/science/article/pii/S0888327018306800"
"A189","Critical influences of particle size and adhesion on the powder layer uniformity in metal additive manufacturing","The quality of powder layers, specifically their packing density and surface uniformity, is a critical factor influencing the quality of components produced by powder bed metal additive manufacturing (AM) processes, including selective laser melting, electron beam melting and binder jetting. The present work employs a computational model to study the critical influence of powder cohesiveness on the powder recoating process in AM. The model is based on the discrete element method (DEM) with particle-to-particle and particle-to-wall interactions involving frictional contact, rolling resistance and cohesive forces. Quantitative metrics, namely the spatial mean values and standard deviations of the packing fraction and surface profile field, are defined in order to evaluate powder layer quality. Based on these metrics, the size-dependent behavior of exemplary plasma-atomized Ti–6Al–4V powders during the recoating process is studied. It is found that decreased particle size (increased cohesiveness) leads to considerably decreased powder layer quality in terms of low, strongly varying packing fractions and highly non-uniform surface profiles. For relatively fine-grained powders (median particle diameter 17<U+202F>µm), it is shown that cohesive forces dominate gravity forces by two orders of magnitude leading to low quality powder layers not suitable for subsequent laser melting without additional layer/surface finishing steps. Besides particle-to-particle adhesion, this contribution quantifies the influence of mechanical powder material properties, nominal layer thickness, blade velocity, as well as particle-to-wall adhesion. Finally, the implications of the resulting powder layer characteristics on the subsequent melting process are discussed and practical recommendations are given for the choice of powder recoating process parameters. While the present study focuses on a rigid blade recoating mechanism, the proposed simulation framework can be applied to systems using alternative recoating tools such as soft blades, rakes or rotating rollers.","Adhesion,Metal powders,Additive manufacturing,Recoating process simulation,Layer uniformity","ChristophMeierab,ReimarWeissbachab,JohannesWeinbergac,Wolfgang A.Wallb,A. JohnHarta","Journal of Materials Processing Technology","https://doi.org/10.1016/j.jmatprotec.2018.10.037","https://www.sciencedirect.com/science/article/pii/S0924013618304801"
"A190","Ensemble feature selection using election methods and ranker clustering","Feature selection (FS) has become a significant part of the data processing pipeline. Recently, ensemble FS has emerged as a new methodology that promises to improve FS robustness and performance. In this paper, we propose several ensemble FS methods built on voting aggregation schemes such as plurality vote, single transferable vote, Borda count, and novel weighted Borda count. Additionally, we present the new concept of clustering FS methods prior to building ensembles using a mean-shift clustering algorithm. The proposed methods are examined using three accuracy measures: the ability to correctly identify relevant features, FS stability, and influence on classification. The ensembles and clustered ensembles based on a weighted Borda count show very balanced performance, achieving quality results in all investigated measures and outperforming the other methods examined.","Feature selection,Ensemble,Voting,Mean shift clustering,Borda count","PeterDrotára,MatejGazdab,LiberiosVokorokosa","Information Sciences","https://doi.org/10.1016/j.ins.2018.12.033","https://www.sciencedirect.com/science/article/pii/S0020025518309812"
"A191","Robust multivariate and functional archetypal analysis with application to financial time series analysis","Archetypal analysis approximates data by means of mixtures of actual extreme cases (archetypoids) or archetypes, which are a convex combination of cases in the data set. Archetypes lie on the boundary of the convex hull. This makes the analysis very sensitive to outliers. A robust methodology by means of M-estimators for classical multivariate and functional data is proposed. This unsupervised methodology allows complex data to be understood even by non-experts. The performance of the new procedure is assessed in a simulation study, where a comparison with a previous methodology for the multivariate case is also carried out, and our proposal obtains favorable results. Finally, robust bivariate functional archetypoid analysis is applied to a set of companies in the S&P 500 described by two time series of stock quotes. A new graphic representation is also proposed to visualize the results. The analysis shows how the information can be easily interpreted and how even non-experts can gain a qualitative understanding of the data.","Multivariate functional data,Archetype analysis,Stock,M-estimators,Multivariate time series","JesúsMolinera,IreneEpifanioab","Physica A: Statistical Mechanics and its Applications","https://doi.org/10.1016/j.physa.2018.12.036","https://www.sciencedirect.com/science/article/pii/S0378437118315498"
"A192","Combining translation-invariant wavelet frames and convolutional neural network for intelligent tool wear state identification","On-machine monitoring of tool wear in machining processes has found its importance to reduce equipment downtime and reduce tooling costs. As the tool wears out gradually, the contact state of the cutting edge and the workpiece changes, which has a significant influence on the vibration state of the spindle. The performance of traditional intelligent fault diagnosis methods depend on feature extraction of dynamic signals, which requires expert knowledge and human labor. Recently, deep learning algorithms have been applied widely in machine health monitoring. In this paper, we present a novel intelligent technique for tool wear state recognition using machine spindle vibration signals. The proposed technique combines derived wavelet frames (DWFs) and convolutional neural network (CNN). Constructed based on dual tree wavelets, DWF are equipped with merits of centralized multiresolution and nearly translation-invariance. In this method, DWFs are employed to decompose the original signal into frequency bands of different bandwidths and different center frequencies, which are more pronounced as the tool wears. Further, the reconstructed sub-signals are stacked into a 2-D signal matrix to match the structure of 2-D CNN while retaining more dynamic information. The 2-D convolutional neural network is utilized to automatically recognize features from the multiscale 2-D signal matrix. End-milling experiments were performed on a S45C steel workpiece at different machining parameters. The experiment results of the recognition for tool wear state show the feasibility and effectiveness of the proposed method.","Tool wear state monitoring,Spindle vibration,End milling,Wavelet frame,Convolutional neural network (CNN)","Xin-ChengCaoa,Bin-QiangChena,BinYaoa,Wang-PengHeb","Computers in Industry","https://doi.org/10.1016/j.compind.2018.12.018","https://www.sciencedirect.com/science/article/pii/S0166361518304883"
"A193","Biofunctional gelatin-based films incorporated with food grade phycocyanin extracted from the Saharian cyanobacterium Arthrospira sp.","Biofunctional films based on bovine gelatin (G) incorporated with a food grade phycocyanin (PC) extract at various concentrations (1.25%, 2.5%, 6.25% and 12.5%; w/w) were developed. PC incorporation maintained the original solubility of gelatin (control) film, while, when added at 6.25% and 12.5% (w/w), PC decreased the L* and increased b*, <U+0394>E and the opacity values of the films, which enhances their light-barrier feature. Further, the tensile strength (TS) and elongation at break (EAB) were reduced with the increase of PC content in G-based films, and were inversely correlated to films thickness with respective R2 values of 0.94 and 0.97. Regarding microstructure, PC eliminated cracks present in the control film matrix resulting in a more smooth structure. Moreover, PC addition contributed to the thermal stabilization of the gelatin chain, delaying the glass transition temperature by 20 °C and conferring a thermal stability up to 250 °C. Regarding the antioxidant activity, the incorporation of 12.5% of PC significantly increased by 4.09, 3.2, 13.6 and 1.47-folds the chelating, reducing, ß-carotene bleaching inhibition and DPPH radical scavenging capacities, respectively. Likewise, G-PC films displayed antibacterial activity against several Gram (-) and Gram (+) bacteria. The present study suggested that G-PC films incorporated with 6.25% and 12.5% of PC extracted from Arthrospira sp. could be used as a promising colored external or inner (secondary) functional packaging for dehydrated food products as well as for hard or soft-shelled capsules containing powdered or oily active ingredients, although further analysis should be carried out.","Gelatin-based films,Phycocyanin,Solubility,Bioactivity,Light-barrier properties","ImeneChentirab,HelaKchaoub,MarwaHamdib,MouradJridib,SumingLic,AmelDoumandjia,MoncefNasrib","Food Hydrocolloids","https://doi.org/10.1016/j.foodhyd.2018.11.034","https://www.sciencedirect.com/science/article/pii/S0268005X18313511"
"A194","Swapping the roles of bacteriocins and bacteriophages in food biotechnology","","","BeatrizMartínez,PilarGarcía,AnaRodríguez","Current Opinion in Biotechnology","https://doi.org/10.1016/j.copbio.2018.07.007","https://www.sciencedirect.com/science/article/pii/S0958166918300715"
"A195","Lactoferrin adsorption onto silver nanoparticle interface: Implications of corona on protein conformation, nanoparticle cytotoxicity and the formulation adjuvanticity","Nanoparticle, in biological milieu, tends to bind a variety of biomolecules, especially protein, forming an interfacial corona that provides biological identity to nanoparticle. Understanding the protein corona is likely to provide insight in nanoparticle bio-distribution, nanoparticle-mediated cytotoxicity and potential nanoparticle-mediated applications. Thus, the bovine lactoferrin (BLf) corona onto silver nanoparticle (AgNP) interface is studied with reference to BLf conformational stability and the resulting complex’s cytotoxic and adjuvant properties. The adsorption of BLf onto AgNP interface is reflected by change in the particle-specific surface plasmon resonance (SPR). Additionally, the molecular dynamics (MD) simulation deciphered the binding energy and molecular recognition in BLf and AgNP complex. Protein adsorption onto the interface is majorly driven by van der Waals interactions and hydrogen bonds, without any significant effect on the protein conformation and stability. BLf retains bacteriostatic property in the conjugate, and the presence of BLf corona ameliorated the particle-mediated cytotoxicity, despite the enhanced cellular internalization. Additionally, BLf adsorbed AgNP formulation shows better adjuvanticity than AgNP only or BLf only formulation, as demonstrated using Bacillus anthracis protective antigen protein, in vivo.","AgNPsilver nanoparticles,BLfbovine lactoferrin,SPRsurface plasma resonance,ITCisothermal calorimetry,MDmolecular dynamics,MTCCmicrobial type culture collection,SECsize exclusion chromatography,EDXenergy dispersive X-ray,TEMtransmission electron microscopy,CDcircular dichroism,PAProtective antigen,TCSPCtotal correlated single photon counting,IgGImmunoglobulin G.,Keywords,Nanoparticle-protein interaction,Lactoferrin,Corona,Molecular dynamics,Cytotoxicity,Adjuvanticity","Parth SarathiNayaka,Sapna M.Borahb,HimanshuGogoic,ShreyasiAsthanaa,RakeshBhatnagarc,Anupam NathJhab,SumanJhaa","Chemical Engineering Journal","https://doi.org/10.1016/j.cej.2018.12.084","https://www.sciencedirect.com/science/article/pii/S1385894718325713"
"A196","A novel unified model of keyhole plasma arc welding","Keyhole plasma arc welding (PAW) has great potential in the advanced manufacturing industry. Previous research on PAW mainly concerns heat transfer in workpiece without plasma arc. Only several researchers constructed unified models of plasma arc and weld pool to investigate the keyhole welding process by Volume of Fluid (VOF) technique, while it takes too much computational time and resources. A novel unified heat transfer model was developed to demonstrate the keyhole-mode heat transfer in weld pool avoiding the cumbersome VOF technique. With a simple tip to exert the arc pressure calculated from plasma arc region into the weld pool, the model presents equivalent effects like a keyhole model. Electro-magneto-thermal conversion and the resulting thermal-mechanical interaction between plasma arc and weld pool are revealed. Heat flux and arc pressure both display a Gaussian distribution on the workpiece surface, and metal within r<U+202F>=<U+202F>4<U+202F>mm is mostly affected. Weld pool gradually increases into a “reversed bugle-like” configuration due to the coupled thermal-mechanical effects from plasma arc. Two opposite circular flows appear at the bottom and the top edge of weld pool, which are dominated by the plasma arc force and Marangoni force, respectively. Calculated arc pressure distributions generally coincide with experimental results and previous research, and calculated weld pool geometry agrees well with experimental result, as well as the time for full penetration welding. The new model shows quite good applicability and simplicity.","Unified model,Plasma arc welding,Keyhole-mode heat transfer,Electro-magneto-thermal conversion,Weld pool","YanLiab,LingWanga,ChuansongWuc","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.12.130","https://www.sciencedirect.com/science/article/pii/S0017931018338687"
"A197","Maestro: The INTO-CPS co-simulation framework","Cyber-Physical Systems (CPSs) often operate in a critical context where it is crucial that they behave as intended. However, the heterogeneous nature of CPSs makes them inherently challenging to develop. To assist in the development process, one can perform co-simulation, where models of constituents of a CPS are coupled to jointly simulate the full system. The challenge herein is to combine heterogeneous formalisms in a sound fashion and address practical needs such as stability, performance, platform compatibility and so forth. To address this, Maestro is a tool for co-simulation using models adhering to the Functional Mock-up Interface standard for co-simulation. Its development was driven by needs from different industry domains such as railways, agriculture, building automation and automotive. It supports both a fixed and variable constraint-based iteration scheme along with platform distribution capabilities. The tool is open-source as an attempt to increase adoption of co-simulation and encourage researchers to collaborate. Maestro has been validated by industry through application in the aforementioned domains. It is a step in the direction of the two-folded long-term goals: ensure trustworthy co-simulation results and make co-simulation a technology taken for granted.","Co-simulation,Hybrid co-simulation,Discrete-event simulation,Continuous-time simulation,Distributed simulation,Functional mock-up interface","CasperThulea,KennethLausdahla,CláudioGomesb,GerdMeislc,Peter GormLarsena","Simulation Modelling Practice and Theory","https://doi.org/10.1016/j.simpat.2018.12.005","https://www.sciencedirect.com/science/article/pii/S1569190X1830193X"
"A198","WRKY transcription factors in the response of table grapes (cv. Autumn Royal) to high CO2 levels and low temperature","WRKY transcription factors are regulated by biotic and abiotic stress in Vitis vinifera, although little is known about their role in grape berries. The latest V. vinifera reference genome (PN40024 12<U+2009>×<U+2009>.v2, VCOST.v3 annotation) gave us a good opportunity to perform an analysis of VviWRKYs, identifying 61 genes. Our study examines whether the application of high CO2 levels for 3 d to maintain table grape quality activated the gene expression of 15 WRKYs in the skin and pulp of grapes (cv. Autumn Royal) stored at 0<U+2009>°C. Results showed that the induction of VviWRKYs gene expression by CO2 was tissue dependent, being this effect mainly observed in the pulp where 9 out of the 15 genes analyzed were activated by the gaseous treatment. The expression analysis of genes associated with ethylene (ACC synthase1 (ACS1) and ACC oxidase1 (ACO1)) and ABA (9-cis-epoxycarotenoid dioxygenase1 (NCED1)) biosynthesis indicated that the expression of ACO1 in the skin of non-treated samples and in the pulp of CO2-treated ones correlated with the changes observed in VviWRKYs. In addition, we studied the role of WRKYs in the modulation of genes encoding pathogenesis-related proteins (PRs) in table grapes. Results showed there was a significant positive correlation between WRKYs modulated by CO2 in the skin and pulp with a ß-1,3-glucanase (Vcgns1) and a thaumatin (VvTL1), respectively. Through electrophoretic mobility shift assay (EMSA) we observed that VviWRKYIIa_3 recombinant protein was able to in vitro bind to the W-box present in the promoter of the three PRs analyzed while VviWRKYIII_3 was only able to specifically bind to the Vcgns1 probe. Our results support the fact that high CO2 treatment is an active process that requires the activation of transcription factors, such as those of the WRKY family, which could participate in the molecular events involved in maintaining table grape quality during postharvest.","WRKY,Transcription factor,Vitis vinifera,Carbon dioxide,Low temperature,Pathogenesis-Related proteins","IreneRomero,EstibalizAlegria-Carrasco,AlfonsoGonzalez de Pradena,MariaVazquez-Hernandez,M. IsabelEscribano,CarmenMerodio,M. TeresaSanchez-Ballesta","Postharvest Biology and Technology","https://doi.org/10.1016/j.postharvbio.2018.12.011","https://www.sciencedirect.com/science/article/pii/S0925521418308196"
"A199","Effect of air jet momentum on the topological features of turbulent CNG inverse jet flame","Inverse jet flame (IJF) configuration is a variant of coaxial nonpremixed jet flame which can produce a nonluminous compact blue flame with independent control of air and fuel jet momentum. In the present work, the effect of central air jet velocity on visible topological features such as, visible flame height and base flame height is investigated experimentally. Also the fluid dynamics behind the evolution of base flame in IJF configuration is unraveled in this study. Notably, buoyancy induced oscillations of IJF, which is relatively unexplored in open literature is studied in this work. Moreover, a systematic classification of IJF based on the evolution of its visible flame features with variation in the central air jet and annular fuel jet velocities is reported. In addition, a semi-empirical correlation for visible flame height of IJF with air-fuel momentum ratio is arrived in the present work which can be useful in the design of IJF based burners utilized for impingement heat transfer applications.","Inverse diffusion flame,Nonpremixed flame,Base flame height,Buoyancy induced oscillations,Flame impingement heat transfer.","MaheshS.1,D.P.Mishra","Fuel","https://doi.org/10.1016/j.fuel.2018.12.089","https://www.sciencedirect.com/science/article/pii/S0016236118321562"
"A200","Decreased circulating ErbB4 ectodomain fragments as a read-out of impaired signaling function in amyotrophic lateral sclerosis","ErbB4 is a transmembrane receptor tyrosine kinase that binds to neuregulins to activate signaling. Proteolytic cleavage of ErbB4 results in release of soluble fragments of ErbB4 into the interstitial fluid. Disruption of the neuregulin-ErbB4 pathway has been suggested to be involved in the pathogenesis of amyotrophic lateral sclerosis (ALS). This study assesses whether soluble proteolytic fragments of the ErbB4 ectodomain (ecto-ErbB4) can be detected in cerebrospinal fluid (CSF) and plasma, and if the levels are altered in ALS. Immunoprecipitation combined with mass spectrometry or western blotting analyses confirmed the presence of ecto-ErbB4 in human CSF. Several anti-ErbB4-reactive bands, including a 55<U+202F>kDa fragment, were detected in CSF. The bands were generated in the presence of neuregulin-1 (Nrg1) and were absent in plasma from ErbB4 knockout mice. Ecto-ErbB4 levels were decreased in CSF from ALS patients (n<U+202F>=<U+202F>20) and ALS with concomitant frontotemporal dementia patients (n<U+202F>=<U+202F>10), compared to age-matched controls (n<U+202F>=<U+202F>13). A similar decrease was found for the short ecto-ErbB4 fragments in plasma of the same subjects. Likewise, the 55-kDa ecto-ErbB4 fragments were decreased in the plasma of the two transgenic mouse models of ALS (SOD1G93A and TDP-43A315T). Intracellular ErbB4 fragments were decreased in the frontal cortex from SOD1G93A mice, indicating a reduction in Nrg-dependent induction of ErbB4 proteolytic processing, and suggesting impaired signaling. Accordingly, overexpression of Nrg1 induced by an adeno-associated viral vector increased the levels of the ecto-ErbB4 fragment in the SOD1G93A mice. We conclude that the determination of circulating ecto-ErbB4 fragments could be a tool to evaluate the impairment of the ErbB4 pathway and may be a useful biomarker in ALS.","Amyotrophic lateral sclerosis,ErbB4,Biomarker,Cerebrospinal fluid,Brain,Plasma,ALS transgenic mouse,Abbreviations,ErbB4Erb-B2 Receptor Tyrosine Kinase 4,ecto-ErbB4ErbB4 ectodomain,ErbB4-CTFErbB4 C-terminal fragment,ErbB4-ICDErbB4 intracellular domain,ALSamyotrophic lateral sclerosis,FTDfrontotemporal dementia,ALS-FTDALS with concomitant frontotemporal dementia,CSFcerebrospinal fluid,Nrg1neuregulin-1,AAVadeno-associated viral","InmaculadaLopez-Fontab1,AitanaSogorb-Esteveab1,MíriamJavier-Torrentbc,GunnarBrinkmalmde,MireiaHerrando-Grabulosabf,BelenGarcía-Lareubc,JaninaTuron-Sansgh,RicardoRojas-Garcíagh,AlbertoLleóbi,Carlos A.Saurabc,HenrikZetterbergdejk,KajBlennowde,AssumpcióBoschbc,XavierNavarrobf,JavierSáez-Valeroab","Neurobiology of Disease","https://doi.org/10.1016/j.nbd.2018.12.021","https://www.sciencedirect.com/science/article/pii/S0969996118303176"
"A201","The linguistic modeling of interval-valued time series: A perspective of granular computing","Modeling interval-valued time series (ITS) is an ongoing timely issue in the domain of time series analysis. Many researchers proposed diverse numeric models showing better performance of these models at the numeric level. However, a question how to establish a linguistic model of ITS exhibiting both high accuracy and interpretability is rarely studied. In this study, a linguistic modeling approach of ITS is presented by following the design methodology of granular computing. The crux of the proposed approach involves the formation of granular codebook consisting of a series of fundamental concepts describing amplitude characteristics of ITS, the granular expression mechanism of ITS and the realization of granular mapping based on multilayer perceptrons (MLPs). Further, the topology of neural network of the formed linguistic model is also presented to show the characteristics of layered processing information of granular computing (GrC). Experimental studies are reported for several publicly available financial ITS showing different dynamic characteristics, which offer a useful insight into the effectiveness of the proposed approach as well as reveal the impact of their parameter on the performance of the established linguistic model.","Granular computing,Granular fuzzy modeling,Linguistic models,Interval-valued time series","WeiLua,WeiZhoua,DanShanb,LiyongZhanga,JianhuaYanga,XiaodongLiua","Information Sciences","https://doi.org/10.1016/j.ins.2018.11.024","https://www.sciencedirect.com/science/article/pii/S0020025518309113"
"A202","LightweightNet: Toward fast and lightweight convolutional neural networks via architecture distillation","In recent years, deep neural networks have achieved remarkable successes in many pattern recognition tasks. However, the high computational cost and large memory overhead hinder them from applications on resource-limited devices. To address this problem, many deep network acceleration and compression methods have been proposed. One group of methods adopt decomposition and pruning techniques to accelerate and compress a pre-trained model. Another group designs single compact unit to stack their own networks. These methods are subject to complicated training processes, or lack of generality and extensibility. In this paper, we propose a general framework of architecture distillation, namely LightweightNet, to accelerate and compress convolutional neural networks. Rather than compressing a pre-trained model, we directly construct the lightweight network based on a baseline network architecture. The LightweightNet, designed based on a comprehensive analysis of the network architecture, consists of network parameter compression, network structure acceleration, and non-tensor layer improvement. Specifically, we propose the strategy of low-dimensional features of fully-connected layers for substantial memory saving, and design multiple efficient compact blocks to distill convolutional layers of baseline network with accuracy-sensitive distillation rule for notable time saving. Finally, it can effectively reduce the computational cost and the model size by >4× with negligible accuracy loss. Benchmarks on MNIST, CIFAR-10, ImageNet and HCCR (handwritten Chinese character recognition) datasets demonstrate the advantages of the proposed framework in terms of speed, performance, storage and training process. In HCCR, our method even outperforms traditional handcrafted features-based classifiers in terms of speed and storage while maintaining state-of-the-art recognition performance.","Deep network acceleration and compression,Architecture distillation,Lightweight network","Ting-BingXuab,PeipeiYanga,Xu-YaoZhangab,Cheng-LinLiuabc","Pattern Recognition","https://doi.org/10.1016/j.patcog.2018.10.029","https://www.sciencedirect.com/science/article/pii/S0031320318303807"
"A203","A numerical study on smoke back-layering length and inlet air velocity of fires in an inclined tunnel under natural ventilation with a vertical shaft","When a fire occurs in an inclined tunnel, the tunnel inlet air velocity induced by the stack effect will help to prevent the smoke backflow. This work presents numerical studies on the smoke flow behaviors induced by fires in inclined tunnels under natural ventilation with a vertical shaft. The tunnel slope, heat release rate (HRR) and distance from the fire source to the downhill inlet of tunnel were varied. The effect of tunnel slope on temperature distributions in the shaft and tunnel, smoke back-layering length and tunnel inlet air velocity were specifically focused. Results showed that the maximum ceiling gas temperatures are presented in the downstream of fire axis for all slopes (5%–25%). The plug-holing phenomenon occurs for small slopes and disappears for large slopes. Increasing the slope can help to diminish the plug-holing while it decreases the smoke temperature in the inner region of shaft as well. The established correlation shows that the ratio of the back-layering length to the hydraulic tunnel height (which is defined as the 4 times the tunnel cross-sectional area to the tunnel perimeter) is proportional to -1.57 power of the slope, while it is independent on the HRR and fire source location. The tunnel inlet air velocity increases with increasing the tunnel slope and HRR while it decreases as the fire source placed far away from the downhill inlet of tunnel. Based on dimensional analysis and using the hydraulic tunnel height as the characteristic length, the final equation suggests that the normalized tunnel inlet air velocity is proportional to 0.42 power of the normalized HRR and -0.57 power of the normalized fire source location and it increases exponentially with the tunnel slope.","Inclined tunnel fire,Vertical shaft,Temperature distribution,Plug-holing,Back-layering length,Inlet air velocity","HuaxianWana,ZiheGaoa,JianyunHanb,JieJiac,MeijuanYea,YongmingZhanga","International Journal of Thermal Sciences","https://doi.org/10.1016/j.ijthermalsci.2019.01.004","https://www.sciencedirect.com/science/article/pii/S1290072918301212"
"A204","Measurement and structural invariance of cognitive ability tests after computer-based training","Ability tests are core elements in performance research as well as in applied contexts and are increasingly carried out using computer-based versions. In the last few decades a whole training and coaching industry has developed to prepare individuals for computer-based assessments. Evidence suggests that such commercial training programs can result in score gains in ability tests, thereby creating an advantage for those who can afford it and challenging the fairness of ability assessment. As a consequence, several authors recommended freely offering training software to all participants to increase measurement fairness. However, it is still an open question whether the unsupervised use of training software could have an impact on the measurement properties of ability tests. The goal of the present study is to fill this gap by examining the subjects' ability scores for measurement and structural invariance across different amounts of computer-based training. Structural equation modeling was employed in a sample of 15,752 applicants who participated in high-stakes assessments with computer-based ability tests. Across different training amounts, our analyses supported measurement and structural invariance of ability scores. In conclusion, free training software is a means that provides fair preparation opportunities without changing the measurement properties of the tests.","Computer-based training,Computer-based testing,Cognitive ability,Measurement invariance,Test fairness","MichaelHermesa,FrankAlbersa,Jan R.Böhnkeb,GerritHuelmanna,JuliaMaiera,DirkStellinga","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2018.11.040","https://www.sciencedirect.com/science/article/pii/S0747563218305752"
"A205","Data mining based on clustering and association rule analysis for knowledge discovery in multiobjective topology optimization","Optimum design problems, including structural optimization problems, often include multiple objectives. A multiobjective optimization problem usually provides a number of optimal solutions, called non-dominated solutions or Pareto-optimal solutions. In multiobjective topology optimization scenarios, decision makers face the challenging task of choosing the most effective solution that meets their needs; serial comparisons among a set of Pareto-optimal solution are cumbersome, as are trial-and-error attempts to find an appropriate solution among a host of alternatives. On the other hand, the recent integration of data mining techniques in multiobjective optimization methods can provide decision makers with important, highly pertinent, and useful knowledge.In this paper, we propose a data mining technique for knowledge discovery in multiobjective topology optimization. The proposed method sequentially applies clustering and association rule analysis to a Pareto-optimal solution set. First, clustering is applied in the design space and the result is then visualized in the objective space. After clustering, detailed features in each cluster are analyzed based on the concept of association rule analysis, so that characteristic substructures can be extracted from each cluster of solutions. In four numerical examples, we demonstrate that the proposed method provides pertinent knowledge that aids comprehension of the key substructures responsible for one or more desired performances, thereby giving decision makers a useful tool for discovery of particularly effective design solutions.","Data mining,Optimum design,Clustering,Association analysis,Topology optimization","YukiSato,KazuhiroIzui,TakayukiYamada,ShinjiNishiwaki","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.047","https://www.sciencedirect.com/science/article/pii/S095741741830705X"
"A206","Fault diagnosis of wind turbine based on Long Short-term memory networks","Time-series data is widely adopted in condition monitoring and fault diagnosis of wind turbines as well as other energy systems, where long-term dependency is essential to form the classifiable features. To address the issues that the traditional approaches either rely on expert knowledge and handcrafted features or do not fully model long-term dependencies hidden in time-domain signals, this work presents a novel fault diagnosis framework based on an end-to-end Long Short-term Memory (LSTM) model, to learn features directly from multivariate time-series data and capture long-term dependencies through recurrent behaviour and gates mechanism of LSTM. Experimental results on two wind turbine datasets show that our method is able to do fault classification effectively from raw time-series signals collected by single or multiple sensors and outperforms state-of-art approaches. Furthermore, the robustness of the proposed framework is validated through the experiments on small dataset with limited data.","Wind turbine,Fault diagnosis,Long short-term memory (LSTM)","JinhaoLeiab,ChaoLiuac,DongxiangJiangab","Renewable Energy","https://doi.org/10.1016/j.renene.2018.10.031","https://www.sciencedirect.com/science/article/pii/S0960148118312151"
"A207","Short-term traffic flow prediction in smart multimedia system for Internet of Vehicles based on deep belief network","In the multimedia system for Internet of Vehicles (IoVs), accurate traffic flow information processing and feedback can give drivers guidance. In traditional information processing for IoVs, few researches deal with traffic flow information processing by deep learning. Specially, most of the existing prediction technologies adopt shallow neural network, and their models for chaotic time series are prone to be restricted by multiple parameters. Over the last few years, the dawning of the big data era creates opportunities for the intelligent traffic control and management. In this paper, we take Restricted Boltzmann Machine (RBM) as the method for traffic flow prediction, which is a typical algorithm based on deep learning architecture. Considering traffic big data aggregation in IoVs, multimedia technologies provide enough real sample data for model training. RBM constructs the long-term model of polymorphic for chaotic time series, using phase space reconstruction to recognize the data. To the best of our knowledge, it is the first time apply RBM model to short-term traffic flow prediction, which can improve the performance of multimedia system in IoVs. Moreover, experimental results show that the proposed method has superior performance than traditional shallow neural network prediction methods.","Chaotic time series prediction,Traffic flow data in multimedia system,Internet of Vehicles (IoVs),Restricted Boltzmann Machine (RBM)","FanhuiKonga,JianLia,BinJiangbc,HoubingSongc","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.10.052","https://www.sciencedirect.com/science/article/pii/S0167739X18320326"
"A208","A hybrid decision support system for analyzing challenges of the agricultural supply chain","Agricultural supply chain management includes all the events involved in moving products of the agricultural sector from the field to the customer, and is a crucial aspect ensuring the rich contribution of the agricultural sector to the economic growth of the nation. The purpose of this paper is to add value to the present knowledge base by ascertaining the challenges of the agricultural supply chain in India on the basis of a thorough literature survey and the Delphi technique. Following this, the decision-making trial and evaluation laboratory approach was used to model the identified challenges, explore the cause–effect interrelationship, and to develop the systematic hierarchical structures of challenges through an interpretive structural modeling methodology. The implementation of the approach in the Indian context led to the inference that two factors, namely limited integration among the national agricultural markets, and limited agricultural market infrastructure were the most important ones. The integrated model obtained as an output of this study intends to guide the agricultural policy- and decision-makers to improve the performance of the agricultural supply chain in India. Also, some essential recommendations have been given to improve the efficiency of the agricultural supply chain management.","Agricultural supply chain management,Multi-criteria decision making,Decision-making trial and evaluation laboratory,Interpretive structural modeling,India","Bhaskar B.Gardasa,Rakesh D.Rautb,NaoufelCheikhrouhouc,Balkrishna E.Narkheded","Sustainable Production and Consumption","https://doi.org/10.1016/j.spc.2018.11.007","https://www.sciencedirect.com/science/article/pii/S2352550918303129"
"A209","Experimental evaluation of thermal radiation effects on natural convection with a Rayleigh number of 108–109 by using an interferometer","In this study, the radiation effects on the temperature field and perturbation of the thermal boundary layer of natural convection for gas were evaluated by an interferometer. The natural convection investigated in this study was that of a cavity, which had differentially heated vertical walls, surrounded by adiabatic walls. The target Rayleigh number was of the order of 108–109. By using the interferometer adopted in a phase-shifting technique, surface and gas radiation effects were evaluated. To compare the experimental results, a numerical calculation was also conducted using a large-eddy simulation coupled with radiative heat transfer. By varying the emissivity of the adiabatic walls while maintaining the emissivity of the isothermal walls, the surface radiation effect on the natural convection was analyzed. To neglect the gas radiation effect, air was used as the working fluid. When the adiabatic walls were black-body surfaces, the temperature difference around the adiabatic walls was higher than that of the reflective surface as a result of the optical path difference. From this result, the high temperature difference due to the surface radiation effect was confirmed. To investigate the gas radiation effect on natural convection, trifluoromethane gas, which has significant radiative absorption, was used as a working fluid. By evaluating the interference fringe by the interferometer, the wave motion of the thermal boundary layer around the heated and adiabatic walls was visualized. Comparing the numerical calculation results (when varying the calculation conditions) revealed that the wave motion and turbulence boundary layer around the heated and adiabatic walls were caused by the gas radiation effect.","Natural convection,Turbulence,Interferometer,Gas radiation,Surface radiation,LES,REM2","TakumaKogawaa,EitaShojib,JunnosukeOkajimac,AtsukiKomiyac,ShigenaoMaruyamaa","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.11.162","https://www.sciencedirect.com/science/article/pii/S0017931018339231"
"A210","Impact of Cr(VI) on the oxidation of polyunsaturated fatty acids in Helianthus annuus roots studied by metabolomic tools","The impact of Cr(VI) in sunflower roots has been studied, focusing on the oxidation of polyunsaturated fatty acids. Plants were grown hydroponically in the presence of 0, 1.0, 5.0 and 25<U+202F>mgCr L-1. Methanolic root extracts were analyzed by capillary liquid chromatography coupled through negative electrospray ionization to a quadrupole-time of flight mass spectrometry (capHPLC-ESI-QTOF-MS). Using partial least squares algorithm, eighteen features strongly affected by Cr(VI) were detected and annotated as linoleic acid (LA), alpha-linolenic acid (ALA) and sixteen oxidation products containing hydroperoxy-, epoxy-, keto-, epoxyketo- or hydroxy-functionalities, all of them classified as oxylipins. Inspection of the MS/MS spectra acquired for features eluting at different retention times but assigned as a sole compound, confirmed isomers formation: three hydroperoxy-octadecadienoic acids (HpODE), two oxo-octadecadienoic acids (OxoODE) and four epoxyketo-octadecenoic acids (EKODE). Around 70% of metabolites in sunflower LA metabolic pathway were affected by Cr(VI) stress and additionally, four EKODE isomers not included in this pathway were found in the exposed roots. Among ALA-derived oxylipins, 13-epi-12-oxo-phytodienoic acid (OPDA) is of relevance, because of its participation in the activation of secondary metabolism. The abundances of all oxylipins were directly dependent on the Cr(VI) concentration in medium; furthermore, autooxidation of LA to HpODE isomers was observed after incubation with Cr(VI). These results point to the direct involvement of Cr(VI) in non-enzymatic oxidation of fatty acids; since oxylipins are signaling molecules important in plant defensive response, their synthesis under Cr(VI) exposure sustains the ability of sunflower to grow in Cr(VI)-contaminated environments.","Oxylipins,Chromium(VI),Helianthus annuus,metabolomics,Liquid chromatography,Mass spectrometry","Alan AlexanderGonzalez Ibarraa,KatarzynaWrobela,EuniceYanez Barrientosa,Alma RosaCorrales Escobosaa,J. FelixGutierrez Coronab,IsraelEnciso Donisa,KazimierzWrobela","Chemosphere","https://doi.org/10.1016/j.chemosphere.2018.12.145","https://www.sciencedirect.com/science/article/pii/S0045653518324809"
"A211","Long-term forecasting of fuel demand at theater entry points","Managing the distribution of fuel in theater requires Army fuel planners to forecast demand at the strategic level to ensure that fuel will be in the right place, at the right time, and in the amounts needed. This work presents a simulation approach to forecasting that accounts for the structure of the supply chain network when aggregating the demand of war fighters across the theater over the forecasting horizon. The resulting empirical distribution of demand at the theater entry point enables planners to identify forecast characteristics that impact their planning process, including the amplitudes and temporal positions of peaks in demand, and the estimated lead time to the point of use. Experimentation indicates that the forecasts are sensitive to the pattern of war fighter demand, the precise structure of the in-theater supply chain network, and the constraints and uncertainty present in the network, all of which are critical planning considerations.","Demand forecasting,Long term forecasting,Simulation,Army logistics,Fuel supply chain","Benjamin J.Loboa,Donald E.Browna,Peter J.Grazaitisb","International Journal of Forecasting","https://doi.org/10.1016/j.ijforecast.2018.09.001","https://www.sciencedirect.com/science/article/pii/S016920701830150X"
"A212","Variations on the theme of podosomes: A matter of context","Extensive in vitro studies have described podosomes as actin-based structures at the plasma membrane, connecting the cell with its extracellular matrix and endowed with multiple capabilities. Contractile actin-myosin cables assemble them into a network that constitutes a multifaceted cellular superstructure taking different forms – with common characteristics – but manifesting different properties depending on the context of study. Their morphology and their role in cell functioning and behavior are therefore now apprehended in in vivo or in vitro situations relevant to physiological processes. We focus here on three of them, namely: macrophage migration, antigen presentation by dendritic cells and endothelial cell sprouting during angiogenesis to highlight the characteristics of podosomes and their functioning shaped by the microenvironment.","Podosomes,Microenvironment,Extracellular matrix,Basement membrane,Invasion,Mechanosensing","FlorianAlonsoa,PirjoSpuulb,ThomasDaubonc,IJsbrandKramera,ElisabethGénota","Biochimica et Biophysica Acta (BBA) - Molecular Cell Research","https://doi.org/10.1016/j.bbamcr.2018.12.009","https://www.sciencedirect.com/science/article/pii/S0167488918305317"
"A213","Experimental characterization of heat transfer within a pallet of product generating heat","Along the cold chain, cheese product temperatures need to be maintained below 6<U+202F>°C. However, cheese generates heat via the metabolism of the micro-organisms. Therefore, to ensure the uniformity of temperature within a pallet of cheese, it is important to take into account this amount of heat. This work aimed to study the influences of different parameters on the heat transfer for which forced convection around the pallet interacts with free/mixed convection inside it. An experimental device was used in which cheese was replaced by plaster blocks; each block being equipped with a heating resistance to simulate the product heat generation. Two upwind air velocities were selected: 0.31<U+202F>m<U+202F>s-1 and 0.73<U+202F>m<U+202F>s-1; the heat generating varied between 0.05<U+202F>W and 0.30<U+202F>W per product of 0.25<U+202F>kg; two pallet orientations were studied. The results of the present study can also benefit fresh horticultural products which generate heat and require temperature-controlled equipment.","Heat transfer,Temperature distribution,Heat transfer coefficient,Correlation,Cheese,Heat generating product","Anh ThuPhamabc,JeanMoureha,DenisFlickb","Journal of Food Engineering","https://doi.org/10.1016/j.jfoodeng.2018.12.003","https://www.sciencedirect.com/science/article/pii/S0260877418305144"
"A214","Imaging and quantification of magnetic nanoparticles: Comparison of magnetic resonance imaging and magnetic particle imaging","Quantification and imaging of magnetic nanoparticles is of vital importance for various novel biomedical applications, like cell tracking, drug targeting or hyperthermia treatments. In this work we studied the performance of magnetic resonance imaging (MRI) and magnetic particle imaging (MPI) for quantitative imaging of magnetic nanoparticles (MNP). This was done by measurements of serial dilutions of MNP (Ferucarbotran) in two different media (water and CuSO4 solution). The concentration range in which quantification was possible was determined for each technique, and the influence of the environment was analyzed and discussed. This revealed a significantly stronger influence of the surrounding medium on MRI performance as compared to MPI. All results were validated by measurements using their respective zero-dimensional (spectroscopic) techniques nuclear magnetic resonance and magnetic particle spectroscopy, showing similar behavior compared to the imaging modalities. Physical explanations of all observed effects are given, and a concentration range is determined in which the advantages of both imaging techniques can be utilized.","Magnetic nanoparticles,Magnetic particle imaging,Magnetic resonance imaging,Quantification,Magnetic particle spectroscopy,Nuclear magnetic resonance","HendrikPaysen,NorbertLoewa,KarolWeber,OlafKosch,JamesWells,TobiasSchaeffter,FrankWiekhorst","Journal of Magnetism and Magnetic Materials","https://doi.org/10.1016/j.jmmm.2018.10.082","https://www.sciencedirect.com/science/article/pii/S0304885318319735"
"A215","Identifying the essential flood conditioning factors for flood prone area mapping using machine learning techniques","River flooding can be a highly destructive natural hazard. Numerous approaches have been used to study the phenomenon; however, insufficient knowledge regarding flood conditioning factors continues to hinder prevention and control measures. This research examines the hypothesis that by adding further conditioning factors to a dataset used in river flood modeling, increases the accuracy of the final susceptibility mapping result. Additionally, this study assesses the impact of individual conditioning factors on flood susceptibility mapping and their importance in the construction of precise mapping of potential flood regions. Two robust machine learning approaches, Decision Tree (DT) and Support Vector Machine (SVM), were utilized to evaluate spatial correlations between flood conditioning factors and rate their level of importance for mapping the flood prone areas. For this purpose, two datasets were used; dataset 1 (DS1): Light Detection and Ranging (LiDAR) derived factors of altitude, slope, aspect, curvature, Stream Power Index (SPI), Topographic Wetness Index (TWI), Topographic Roughness Index (TRI), and Sediment Transport Index (STI) and dataset 2 (DS2): a combination of LiDAR derived factors supplemented by geology, soil, landuse/cover (LULC), distance from roads and distance from rivers parameters. An extreme flood event in 2011 in Brisbane, Australia was used as a case study, in which DT and SVM techniques were both applied, using both datasets. In addition, multi-collinearity, variance inflation factors (VIF), Pearson's correlation coefficients and Cohen's kappa analysis provided useful information regarding the inter-relationships of factors, as well as the influence of each factor on the precision of the final map. The area under curve (AUC) method was used for accuracy assessment. SVM and DT produced the highest accuracies of prediction, with rates of 85.52% and 88.47% respectively, using DS1 (the LiDAR dataset). Altitude, SPI and TRI were found to have a significant impact on the precision of the outcomes. It was concluded that the inclusion of additional factors in the modeling, does not necessarily guarantee the achievement of greater accuracy. However, the modeling method, can significantly alter outcomes.","Flood,Conditioning factors,Spatial correlation,Decision tree,Support vector machine","Mahyat ShafapourTehranya,SimonJonesa,FarzinShabanibc","CATENA","https://doi.org/10.1016/j.catena.2018.12.011","https://www.sciencedirect.com/science/article/pii/S0341816218305472"
"A216","Multifunctional a-amylase Amy19 possesses agarase, carrageenase, and cellulase activities","The open reading frame of an a-amylase coding gene, amy19, was obtained from a fosmid genomic library of hot spring bacterium Bacillus BI-19 by a plate-based assay of carrageenase activity. After heterologous expression of the gene, the recombinant Amy19 was found to possess a-amylase, agarase, carrageenase, and cellulase activities, and could degrade soluble starch, agarose, carrageen, and sodium cellulose into oligosaccharides with low degrees of polymerization. To explore the multifunctional mechanism of Amy19, three continuous glycosyl hydrolase 70 (GH70) motifs in the Amy19 encoding sequence were deleted one by one, then in pairs, then all at once. The GH70 motifs may play an important role in the multifunctionality of Amy19, but the multifunctionality was not determined by the GH70 motifs alone. To our knowledge, this is the first report of an a-amylase from a hot spring bacterium with additional agarase, carrageenase, and cellulase activities.","Multifunctional enzyme,a-Amylase,Glycosyl hydrolase 70","JiangLia,XiaoqianGua,AihongPanb","International Journal of Biological Macromolecules","https://doi.org/10.1016/j.ijbiomac.2018.12.217","https://www.sciencedirect.com/science/article/pii/S0141813018359282"
"A217","A hybrid metaheuristic for the minimum labeling spanning tree problem","An edge-labeled graph (ELG) is a graph in which each edge has a label associated. Given G, an ELG, the minimum labeling spanning tree problem (MLSTP) is an NP-hard problem that consists in finding a spanning tree in G by using a minimum number of labels. The MLSTP has applications in areas such as computer networks, multimodal transportation networks, and data compression. This paper introduces new concepts, presents a revised version of the maximum vertex covering algorithm and provides a tighter bound to its time complexity. Further, a new MIP-based metaheuristic is proposed for solving the MLSTP, the multi-start local branching (MSLB). It combines the efficiency of the proposed constructive heuristics with the capacity of exploration of a new local search method based on MIP. The computational experiments performed show that the MSLB is superior to the current state-of-the-art metaheuristics in respect to quality of the solutions and processing times.","Metaheuristic,Edge-labeled graph,Spanning tree,Complexity analysis,MSC,90C59,65Y20","Thiago Gouveia daSilvaabd,EduardoQueirogac,Luiz SatoruOchib,Lucídio dos Anjos FormigaCabralc,SerigneGueyed,PhilippeMichelond","European Journal of Operational Research","https://doi.org/10.1016/j.ejor.2018.09.044","https://www.sciencedirect.com/science/article/pii/S0377221718308269"
"A218","Operations research for sustainability assessment of products: A review","The environmental and social impacts of products are being increasingly scrutinized. This necessitates systematic assessment methods. Life Cycle Sustainability Assessment (LCSA) provides a framework to addresses diverse sustainability issues over the product's life cycle, but its application is complicated. Major challenges, such as the selection of relevant indicators, multi-criteria comparisons of alternatives, the treatment of uncertainties, or the integration of spatially differentiated data, can be facilitated by adopting advanced analytical methods from Operations Research. This paper reviews 142 articles that use Operations Research methods for product-related sustainability assessments. The articles were selected from peer-reviewed scientific literature in a systematic search and screening process. Descriptive analysis shows that related publication output is growing over time and originates mainly in journals related to Environmental Management. While ecological indicators are considered by most articles, the integration of economic and social indicators is emerging. Focusing on the contributions of Operations Research, a detailed analysis shows that more than half of the articles adopt methods from Multi-Attribute Decision Making (MADM), followed by Data Envelopment Analysis (DEA) and Multi-Objective Decision Making (MODM). Uncertainties with regard to inventory data and decision makers’ preferences are addressed using fuzzy logic, stochastic models, or sensitivity analysis. The use of spatially differentiated data is not frequently found in the reviewed articles. Research needs derived from this analysis comprise the integration of qualitative and semi-quantitative (social) indicators, the simultaneous consideration of global and local sustainability objectives, and the application of systematic procedures to address uncertainty.","OR in environment and climate change,Product sustainability,Multiple criteria analysis,Data envelopment analysis,Literature review","ChristianThiesa,KarstenKieckhäfera,Thomas S.Spenglerab,Manbir S.Sodhib","European Journal of Operational Research","https://doi.org/10.1016/j.ejor.2018.04.039","https://www.sciencedirect.com/science/article/pii/S037722171830359X"
"A219","Mass transfer from a soluble wall into gas-liquid slug flow in a capillary tube","The mechanism of wall-liquid mass transfer of a solute in micro-scale systems has a huge relevance in many practical scenarios with particular interest for medical devices. A possible enhancement on this kind of phenomenon through the application of slug flow regime was studied with CFD techniques. Different flow conditions were considered to enable the inspection on the distinct hydrodynamics that may occur on the Taylor bubble surroundings in micro-scale. The VOF methodology was used to track the gas–liquid interface and the mass and hydrodynamic fields were simultaneously solved.The effects of the bubble passage on the mass transfer from a finite soluble wall to the flowing fluid were analyzed for each flow condition, and the corresponding mass transfer coefficients were quantified.Overall, this numerical work indicates that the flow due to the presence of one Taylor bubble leads to a moderate increase of the wall-liquid mass transfer coefficients. This increase can be enhanced if, instead of one, a continuous flow of bubbles is considered. The abrupt variation on the wall shear stress induced by the bubble movement is important to promote the referred increase.","Mass transfer,Taylor bubble,CFD,VOF,Capillary tube","M.C.F.Silva,J.B.L.M.Campos,J.D.P.Araújo","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.12.025","https://www.sciencedirect.com/science/article/pii/S0017931018342947"
"A220","Temperature effects on static and dynamic behavior of Consoli Palace in Gubbio, Italy","In recent years, the development of long-term structural health monitoring systems for preventive conservation of historic monumental buildings is receiving a growing trend of scientific interest. Nevertheless, the damage detection effectiveness of these systems is still debated, especially in respect to complex masonry palaces where both local and global failure mechanisms can be activated, whereby the majority of the documented successful applications are limited to masonry towers. In particular, one major issue that needs to be solved in order to derive damage sensitive features is associated to the removal of the effects of changes in environmental conditions and, primarily, of ambient temperature, from static and dynamic signatures. This paper aims to contribute to improving knowledge in this field, by investigating temperature effects on static and dynamic response of an iconic Italian monumental palace: the Consoli Palace in Gubbio. With the purpose of early detecting earthquake-induced damages, as well as damages caused by material degradation associated to awkward environmental conditions, a simple low-cost mixed static and dynamic long-term structural health monitoring system has been installed on the Palace by the authors in July 2017. After discussing surveys, ambient vibration tests, diagnostic investigations, numerical modeling and model calibration of the Palace, the analysis of the first year of monitoring data is presented. This analysis shows that, differently from what observed in other literature works on historic masonry towers, the natural frequencies of the Palace show a marked and sometimes non-linear decreasing trend with increasing ambient temperature, that can be effectively removed through linear statistical filtering provided that dynamic regression models, using past values of predictors, are used. On the other side, the evolution of the amplitudes of two major cracks monitored within the building also shows a marked linear decreasing trend with increasing ambient temperature. These results are meaningful towards the use of monitoring data for assessing the initial health conditions of a structure, as well as in a damage detection perspective.","Structural health monitoring,Temperature effects,Heritage preservation,Masonry buildings,Automated modal identification,FE model updating","AlbanKita,NicolaCavalagli,FilippoUbertini","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.10.021","https://www.sciencedirect.com/science/article/pii/S0888327018306915"
"A221","Crossroads of the mesoscale circulation","Quantifying the mechanisms of tracer dispersion in the ocean remains a central question in oceanography, for problems ranging from nutrient delivery to phytoplankton, to the early detection of contaminants. Until now, most of the analysis has been based on Lagrangian concepts of transport, often focusing on the identification of features that minimize fluid exchange among regions, or more recently, on network tools which focus instead on connectivity and transport pathways. Neither of these approaches, however, allows us to rank the geographical sites of major water passage, and at the same time, to select them so that they monitor waters coming from separate parts of the ocean. These are instead key criteria when deploying an observing network. Here, we address this issue by estimating at any point the extent of the ocean surface which transits through it in a given time window. With such information we are able to rank the sites with major fluxes that intercept waters originating from different regions. We show that this allows us to optimize an observing network, where a set of sampling sites can be chosen for monitoring the largest flux of water dispersing out of a given region. When the analysis is performed backward in time, this method allows us to identify the major sources which feed a target region. The method is first applied to a minimalistic model of a mesoscale eddy field, and then to realistic satellite-derived ocean currents in the Kerguelen area. In this region, we identify the optimal location of fixed stations capable of intercepting the trajectories of 43 surface drifters, along with statistics on the temporal persistence of the stations determined in this way. We then identify possible hotspots of micro-nutrient enrichment for the recurrent spring phytoplanktonic bloom occurring here. Promising applications to other fields, such as larval connectivity, marine spatial planning or contaminant detection, are then discussed.","","AlbertoBaudenaa,EnricoSer-Giacomia,CristóbalLópezb,EmilioHernández-Garcíab,Francescod’Ovidioa","Journal of Marine Systems","https://doi.org/10.1016/j.jmarsys.2018.12.005","https://www.sciencedirect.com/science/article/pii/S092479631830040X"
"A222","Assessment of groundwater quality and remediation in karst aquifers: A review","Karst aquifers, capable of storing and transmitting large amount of water, are the main source of drinking water in many regions worldwide. Their excessive permeability leads to an enhanced vulnerability to retain and spread the contamination accordingly. From sustainability perspective, the environmental, economic and social impacts of karst contamination on water resources management are gaining more attention. In this study, an overview of hydrogeological processes and concepts regarding groundwater flow and contaminant transport in karstic systems is presented, followed by a short discussion on surface water and groundwater interaction. Due to the complexity of karstic systems, different approaches have been developed by researchers for investigating and understanding hydrogeological processes and groundwater behavior in karst which are reviewed herein. Additionally, groundwater contamination issues and the most common and effective remediation techniques in karstic terrains are discussed. Lastly, modeling techniques and remote sensing methods, as beneficial and powerful tools for assessing groundwater flow and contaminant transport in karst terrains, are reviewed and evaluated. In each section, relevant research works conducted for Puerto Rico are discussed and some recommendations are presented to complement the ongoing hydrogeological investigations on this island.","Groundwater,Karst,Remediation,Hydrogeology,Modeling,Puerto Rico","KooshaKalhor1,RezaGhasemizadeh,LjiljanaRajic,AkramAlshawabkeh","Groundwater for Sustainable Development","https://doi.org/10.1016/j.gsd.2018.10.004","https://www.sciencedirect.com/science/article/pii/S2352801X18301632"
"A223","Digital support for academic writing: A review of technologies and pedagogies","This paper presents a review of the technologies designed to support writing instruction in secondary and higher education. The review covers tools to support first and second language writers and focuses on instructional affordances based on their technological specifications. Previous studies in this field centred on Automated Writing Evaluation, Automated Essay Scoring and the rarer Intelligent Tutoring Systems, addressing mainly essay writing needs in US secondary school instruction. With technology-enhanced learning becoming more ubiquitous and widespread, new technologies and tools catering to a broader range of genres, pedagogical settings, and approaches are emerging. We present a systematic analysis of 44 tools across 26 quantitative and qualitative features related to writing processes, pedagogical approaches, feedback modalities and technological specifications. The results uncover an imbalance of available tools with regard to supported languages, genres, and pedagogical focus. While a considerable number of tools support argumentative essay writing in English, other academic writing genres (e.g., research articles) and other languages are under-represented. With regard to the pedagogical focus, automated support for revising on the micro-level targeting factual knowledge (e.g., grammar, spelling, word frequencies) is well represented, whereas tools that support the development of writing strategies and encourage self-monitoring to improve macro-level text quality (e.g., argumentative structure, rhetorical moves) are infrequent. By mapping the state of the art and specifying direction for further research and development, this review is of interest to researchers, policymakers, tool developers, and practitioners of writing instruction in higher and secondary education institutions.","Distance education and telelearning,Evaluation of CAL systems,Interactive learning environments,Pedagogical issues","CarolaStrobla,EmilieAilhaudb,KalliopiBenetosc,AnnDevittd,OttoKrusee,AntjeProskef,ChristianRappg","Computers & Education","https://doi.org/10.1016/j.compedu.2018.12.005","https://www.sciencedirect.com/science/article/pii/S036013151830318X"
"A224","Expression and characterization of an esterase belonging to a new family via isolation from a metagenomic library of paper mill sludge","A new bacterial lipolytic enzyme Est903 was obtained from paper mill sludge via metagenomic approach. Est903 displayed moderate similarities to two lipolytic enzymes from Rhodopirellula islandica and contained a distinctive pentapeptide motif (GFSAG) that differed from those of all known fourteen families of bacterial lipolytic enzymes. Est903 was regarded as from a new bacterial lipolytic enzyme family through multiple sequence alignment and phylogenetic analysis.The recombinant Est903 showed the highest activity for <U+03C1>-nitrophenol butyrate. The pH optimum and temperature optimum of the recombinant enzyme was 9.0 and 51<U+202F>°C, respectively. Also, this enzyme displayed moderate thermostability, high activity under alkaline conditions, and good tolerance against several organic solvents. In addition, the compatibility test and washing performance analysis revealed that Est903 had good compatibility with commercial laundry detergent and high cleaning ability of oil stains. These good properties make Est903 a potential candidate in organic synthesis or detergent industry.","Esterase,Functional metagenomics,New lipolytic enzyme family,Alkali-resistance,Organic solvent tolerance,Detergent compatibility","Mei-LuJiaa,Xiao-LinZhonga,Zhi-WeiLina,Bing-XueDongb,GangLia","International Journal of Biological Macromolecules","https://doi.org/10.1016/j.ijbiomac.2019.01.025","https://www.sciencedirect.com/science/article/pii/S0141813018365036"
"A225","Gadoxetic acid-enhanced dynamic magnetic resonance imaging using optimized integrated combination of compressed sensing and parallel imaging technique","PurposeTo evaluate the feasibility of optimized integrated combination of compressed sensing and parallel imaging technique (prototype Compressed SENSE) in gadoxetic acid-enhanced dynamic magnetic resonance (MR) imaging.,Materials and methodsSixty-one patients underwent gadoxetic acid-enhanced dynamic imaging using enhanced T1 high-resolution isotropic volume excitation (eTHRIVE) with the Compressed SENSE (CS-eTHRIVE; C SENSE factor, 3.4; acquisition time, 10<U+202F>s). Results were compared with 61 propensity score-matched patients who underwent conventional eTHRIVE (eTHRIVE; acquisition time, 20<U+202F>s). For quantitative image analyses, signal intensity ratio (SIR) and signal-to-noise ratio (SNR), coefficient of variation (CV) of liver parenchyma were calculated in each dynamic phase. For qualitative image analyses, two radiologists rated the homogeneity of liver parenchyma, sharpness of liver edge and left external lobe, motion artifacts, and overall image quality in each dynamic phase using a five-point scale.,ResultsSIRs of liver parenchyma with CS-eTHRIVE were significantly higher than with eTHRIVE in the hepatic arterial phase (HAP) (1.70 vs. 1.52) and transitional phase (TP) (2.18 vs. 2.06) (P<U+202F>=<U+202F>0.030). SNR of liver parenchyma were comparable between the two sequences in all phases. CV of liver parenchyma in HAP with eTHRIVE (0.079) was significantly higher than with CS-eTHRIVE (0.065) (P<U+202F><<U+202F>0.001). Motion artifacts were significantly reduced with CS-eTHRIVE compared with eTHRIVE in all phases (P<U+202F>=<U+202F>0.005). The appearance ratio of extensive motion artifacts in HAP with CS-eTHRIVE (0/61; 0%) were significantly reduced compared with eTHRIVE (4/61; 6.6%) (P<U+202F>=<U+202F>0.042). Overall image quality with CS-eTHRIVE was significantly better than with eTHRIVE in all phases (P<U+202F>=<U+202F>0.039).,ConclusionCS-eTHRIVE compared with eTHRIVE effectively reduced the acquisition time and extensive motion artifacts without degradation of image quality.","","NobuyukiKawaia,SatoshiGoshimaa,YoshifumiNodaa,KimihiroKajitab,HiroshiKawadaa,YukichiTanahashia,ShomaNagataa,MasayukiMatsuoa","Magnetic Resonance Imaging","https://doi.org/10.1016/j.mri.2018.11.004","https://www.sciencedirect.com/science/article/pii/S0730725X18304375"
"A226","Uncertainty-aware visual analysis of radiofrequency ablation simulations","Radiofrequency (RF) ablation is a medical procedure for treating tumors by generating heat with RF current using needle-like probes that are inserted into the tumor. During RF ablation the entire tumor shall be destroyed to avoid recurrence while keeping the destruction of surrounding healthy tissue minimal. As the ablation area is affected by surrounding structures such as vessels, developing biomedical simulations that support treatment planning is an active research field. The simulations assess the area based on patient-specific imaging data to lower the risk of under- or over-ablation. However, there are several simulation parameters whose precise values are unknown. We capture and propagate these uncertainties by deploying a stochastic simulation model and computing the uncertainties in the resulting ablation probabilities. We propose an uncertainty-aware interactive visual analysis system of the probabilities based on coordinated views of volume visualizations, a slice-based visualization of 2D uncertainty glyphs with a perceptually uniform color-coding, and parameter analysis plots. Using our interactive system, simulation experts can analyze the influence of their parameter choices on the ablation probabilities and their uncertainties. Moreover, our glyph encoding provides an inherent continuous level-of-detail approach during zooming interaction that makes it suitable for application in clinical settings. We apply our techniques to RF ablation simulations for liver tumor treatment and document their value within a controlled user study.","Uncertainty visualization,Medical visualization","GordanRistovskia,NicoleGarbersa,Horst K.Hahnab,TobiasPreusserab,LarsLinsenac","Computers & Graphics","https://doi.org/10.1016/j.cag.2018.12.005","https://www.sciencedirect.com/science/article/pii/S0097849318301973"
"A227","Subclass-based semi-random data partitioning for improving sample representativeness","In machine learning tasks, it is essential for a data set to be partitioned into a training set and a test set in a specific ratio. In this context, the training set is used for learning a model for making predictions on new instances, whereas the test set is used for evaluating the prediction accuracy of a model on new instances. In the context of human learning, a training set can be viewed as learning material that covers knowledge, whereas a test set can be viewed as an exam paper that provides questions for students to answer. In practice, data partitioning has typically been done by randomly selecting 70% instances for training and the rest for testing. In this paper, we argue that random data partitioning is likely to result in the sample representativeness issue, i.e., training and test instances show very dissimilar characteristics leading to the case similar to testing students on material that was not taught. To address the above issue, we propose a subclass-based semi-random data partitioning approach. The experimental results show that the proposed data partitioning approach leads to significant advances in learning performance due to the improvement of sample representativeness.","Machine learning,Classification,Data mining,Decision tree learning,Rule learning,If-then rules","HanLiua,Shyi-MingChenb,MihaelaCoceac","Information Sciences","https://doi.org/10.1016/j.ins.2018.11.002","https://www.sciencedirect.com/science/article/pii/S0020025518308910"
"A228","Functional requirements of automotive head-up displays: A systematic review of literature from 1994 to present","Despite the long history of automotive head-up displays (HUDs), what information they should display in different situations to best serve the driver remains unanswered. The lack of understanding hinders designing useful automotive HUD systems. In an effort to address this, the current study investigated the developer, researcher and user perspectives on the functional requirements of automotive HUDs through literature review. The review results indicated that: 1) the existing commercial HUDs perform largely the same functions as the conventional in-vehicle displays, 2) past research studies proposed various HUD functions for improving driver situation awareness and driving safety, 3) autonomous driving and other new technologies are giving rise to new HUD information, and 4) little research is currently available on HUD users’ perceived information needs. Based on the review results, this study provides insights into the functional requirements of automotive HUDs and also suggests some future research directions for automotive HUD design.","Automotive head-up displays,Functional requirements,Head-up display design","JuheePark,WoojinPark","Applied Ergonomics","https://doi.org/10.1016/j.apergo.2018.12.017","https://www.sciencedirect.com/science/article/pii/S0003687018307592"
"A229","Putting electric vehicles on the map: A policy agenda for residential charging infrastructure in Canada","Electric vehicles (EVs), when powered with sustainable sources of electricity, can contribute to the mitigation of climate change through reduced greenhouse gas emissions. The Canadian province of British Columbia (BC) is an attractive location for EV deployment because ~85% of its electricity is sourced from large hydropower. The driving ranges of EVs and their potential to reduce local emissions mean they are well suited to urban contexts, where most residential buildings in BC are located. The challenges associated with installing new charging stations, particularly in Multi-Unit Residential Buildings (MURBs), can become barriers to uptake of EVs. In this study, we develop a conceptual framework to identify the challenges, potential barriers and stakeholders involved in the process of charging infrastructure installation in MURBs. We establish four main domains to this problem, each of which involves specific stakeholders: charging infrastructure installation, building limitations, governance issues and parking availability. Mapping out these problem domains using decision-making flow diagrams allows us to characterize their internal dynamics and the relationships between stakeholders. As EV markets continue to grow both in Canada and across the world, a better understanding of barriers to stakeholders in these residential settings is essential for informing policy interventions.","Energy infrastructure,Energy policy,Alternative fuel vehicles,Climate change","DianaLopez-Behara,MartinoTranb,Jerome R.Mayaudb,ThomasFroesea,Omar E.Herrerac,WalterMeridac","Energy Research & Social Science","https://doi.org/10.1016/j.erss.2018.11.009","https://www.sciencedirect.com/science/article/pii/S2214629618306285"
"A230","Hydrophobin-stabilized nanoemulsion produced by a low-energy emulsification process: A promising carrier for nutraceuticals","Hydrophobin II (HFBII) is an amphiphilic biopolymer that could be explored to stabilize oil-in-water nanoemulsions as nutraceutical delivery systems. This study reports the production of HFBII-stabilized nanoemulsions by a spontaneous emulsification process using copaiba oil as a bioactive lipid. HFBII was isolated from a wild-type Trichoderma reesei and characterized. A 23 full factorial design with three central points was used to obtain an optimal nanoemulsion system, whose physical-chemical properties were studied under different ionic strength and pH. The peptide similarity search allowed the identification of a series of 6 ion fragments from the isolated fraction, which can be attributed to the amino acid sequences of the HFBII database. The optimal nanoemulsion system presented a nanoscale droplet size (<200<U+202F>nm), a narrow size distribution (PDI <0.2) and a negative zeta potential of<U+202F>˜<U+202F>-30<U+202F>mV, which was stable at low salt content and pH values close to the neutrality. These results demonstrated the feasibility of using HFBII as a biopolymer to stabilize nanoemulsion systems. Furthermore, the HFBII-stabilized nanoemulsion is a promising carrier for nutraceuticals in food technology applications.","Hydrophobin,HFBII,Copaiba oil,Nanoemulsion,Nutraceutical","Christian MeloOliveiraa,Francisco HumbertoXavier-Jrb,Andreza Rochelle do ValeMoraisa,Iasmim LopesLimab,Roberto AfonsoSilvab,Andre Ezequiel GomesNascimentoc,Nathalia KellyAraújod,Mariane Cajuba de Britto LiraNogueirab,Arnobio AntonioSilva-Jr.d,Matheus de Freitas FernandesPedrosad,Eryvaldo Socrates TabosaEgitoa","Food Hydrocolloids","https://doi.org/10.1016/j.foodhyd.2018.11.057","https://www.sciencedirect.com/science/article/pii/S0268005X18311731"
"A231","Comparative transcriptomic analysis reveals different responses of Arabidopsis thaliana roots and shoots to infection by Agrobacterium tumefaciens in a hydroponic co-cultivation system","Agrobacterium tumefaciens-Arabidopsis thaliana provides an excellent model system to study bacterial pathogenesis and plant interactions. It is well established that, upon recognizing plant-derived signals, A. tumefaciens activates its virulence programing, culminated by the transfer and integration of T-DNA into the plant genome. However, the initial signaling and response of the plant host during A. tumefaciens -plant interactions is less understood. In this study, A. thaliana were co-cultivated (infected) with A. tumefaciens in a sterile hydroponic system for 8<U+202F>h, and the transcriptome profiles of root and shoot were determined by microarray analysis. Overall, hundreds of genes involved in plant responses to stress, regulation of transcription, signal transduction or plant metabolism are differentially expressed in roots and shoots upon A. tumefaciens infection. In total, 323 genes were up-regulated and 226 were down-regulated by a log2 transformed fold change of at least 2 in roots upon A. tumefaciens infection, as compared with mock-inoculated plants. In the shoot, 249 genes were up-regulated and 152 were down-regulated in response to A. tumefaciens infection in the roots. Functional classification and comparative analysis revealed that, in response to pathogen attack, the host plant demonstrated significantly differential signaling loops between locally (roots) and distally (shoots) affected sites, despite of little overlap between transcriptome responses. Upon A. tumefaciens infection, roots displayed a strong induction of defense and hormone signaling pathways involving salicylic acid, abscisic acid, ethylene, and auxins, which play essential roles in plant acclimation responses in the root. On the contrary, jasmonic acid and gibberellic acid signaling processes were most activated in the shoots. The identification of genes and signaling pathways that are differentially regulated in roots and shoots may serve as possible targets in molecular breeding for disease tolerant plants or for improving Agrobacterium-mediated plant transformation.","Molecular plant-microbe interaction,Agrobacterium tumefaciens,Arabidopsis thaliana,Hydroponics,Co-cultivation,Plant response,Virulence","NaeemNathooa,JacquelineMacDonaldb,BrianWeselowskia,Ze-ChunYuanab","Physiological and Molecular Plant Pathology","https://doi.org/10.1016/j.pmpp.2019.01.001","https://www.sciencedirect.com/science/article/pii/S0885576518303436"
"A232","Encoding sparse and competitive structures among tasks in multi-task learning","Multi-task learning (MTL) aims to enhance generalization performance by exploring the inherent structures across tasks. Most existing MTL methods are based on the assumption that the tasks are positively correlated, and utilize the shared structures among tasks to improve learning performance. By contrast, there also exist competitive structure (negative relationships) among tasks in some real-world applications, and conventional MTL methods which explore shared structures across tasks may lead to unsatisfactory performance in this setting. Another challenge, especially in a high dimensional setting, is to exclude irrelevant features (sparse structure) from the final model. For this purpose, this work propose a new method, which is referred to as Sparse Exclusive Lasso (SpEL) for multi-task learning. The proposed SpEL is able to capture the competitive relationship among tasks (competitive structure), while remove unimportant features which are common across the tasks from the final model (sparse structure). Experimental studies on synthetic and real data indicate that the proposed method can significantly improve learning performance by identifying sparse and task-competitive structures simultaneously.","Multi-task learning,Sparse exclusive lasso,Task-competitive","ChengLiuac,Chu-TaoZhenga,ShengQiana,SiWub,Hau-SanWonga","Pattern Recognition","https://doi.org/10.1016/j.patcog.2018.12.018","https://www.sciencedirect.com/science/article/pii/S0031320318304394"
"A233","A meta-model for software protections and reverse engineering attacks","Software protection techniques are used to protect valuable software assets against man-at-the-end attacks. Those attacks include reverse engineering to steal confidential assets, and tampering to break the software’s integrity in unauthorized ways. While their ultimate aims are the original assets, attackers also target the protections along their attack path. To allow both humans and tools to reason about the strength of available protections (and combinations thereof) against potential attacks on concrete applications and their assets, i.e., to assess the true strength of layered protections, all relevant and available knowledge on the relations between the relevant aspects of protections, attacks, applications, and assets need to be collected, structured, and formalized. This paper presents a software protection meta-model that can be instantiated to construct a formal knowledge base that holds precisely that information. The presented meta-model is validated against existing models and taxonomies in the domain of software protection, and by means of prototype tools that we developed to help non-modelling-expert software defenders with populating a knowledge base and with extracting and inferring practically useful information from it. All discussed tools are available as open source, and we evaluate their use as part of a software protection work flow on an open source application and industrial use cases.","Software protection,Security knowledge base,Decision support,Attack modelling,Reverse engineering,Meta-model","CataldoBasilea,DanieleCanavesea,LeonardoReganoa,PaoloFalcarinb,Bjorn DeSutterc","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2018.12.025","https://www.sciencedirect.com/science/article/pii/S0164121218302838"
"A234","Not whether, but where? Pell grants and college choices","Pell grants are the largest financial aid vehicle in the United States, and yet, their role in shaping students' college choices is not clear. Drawing on the enrollment decisions of four cohorts of Tennessee high school graduates and quasi-experimental Pell eligibility derived from federal formulas, we find little evidence that marginal Pell eligibility affects whether or where students enroll in college. Inframarginal estimates suggest that students sort into colleges with 11.6 cents higher tuition per dollar of Pell aid, although other measures of college quality do not significantly improve over the counterfactual. An investigation into mechanisms that might be muting student responses to Pell favors the application process itself over grant size or institutional aid flexibility.","I22,I23,H75,Keywords,Education policy,Higher education,Financial aid","Celeste K.Carruthersa,Jilleah G.Welchb","Journal of Public Economics","https://doi.org/10.1016/j.jpubeco.2018.11.006","https://www.sciencedirect.com/science/article/pii/S0047272718302251"
"A235","The adsorption of sulfur trioxide and ozone molecules on stanene nanosheets investigated by DFT: Applications to gas sensor devices","Recent findings shed light on performing fundamental experiments for preparation of metal monolayer stanene, which is a zero band gap semiconductor material with buckled honeycomb structure. Stanene possesses outstanding physical and mechanical properties, and has been extensively investigated in the field of nanoelectronic devices. We performed a theoretical study on the adsorption behaviors of O3 and SO3 molecules on two-dimensional stanene sheet in order to fully exploit the promising gas sensing capability of these materials. We examined the most stable structures of O3 and SO3 molecules adsorbed on the stanene, and examined the adsorption process in view of the energetics, charge transfers and electronic structure of the adsorption systems. The results indicate that the adsorption of gas molecules on the B-doped stanene is more favorable in energy than that on the pristine one, representing the superior sensing performance of B-doped system. Our charge analysis based on Mulliken charges reveals a charge transfer from the stanene sheet to the adsorbed O3 and SO3 molecules, as evidenced by charge accumulation on the adsorbed molecules. This indicates the gas molecules act as charge acceptors from the stanene sheet. The significant overlaps between the PDOS spectra of the interacting atoms indicate the formation of chemical bonds between these atoms. Our findings thus suggest that B-doped stanene could be a highly efficient gas sensor device for SO3 and O3 detection in the environment.","SO3,Stanene sheet,DFT,O3,Charge density difference,Adsorption","AmiraliAbbasiabc,Jaber JahanbinSardroodiabc","Physica E: Low-dimensional Systems and Nanostructures","https://doi.org/10.1016/j.physe.2018.05.004","https://www.sciencedirect.com/science/article/pii/S1386947717316739"
"A236","Security in networks of unmanned aerial vehicles for surveillance with an agent-based approach inspired by the principles of blockchain","Unmanned aerial vehicles (UAVs) can support surveillance even in areas without network infrastructure. However, UAV networks raise security challenges because of its dynamic topology. This paper proposes a technique for maintaining security in UAV networks in the context of surveillance, by corroborating information about events from different sources. In this way, UAV networks can conform peer-to-peer information inspired by the principles of blockchain, and detect compromised UAVs based on trust policies. The proposed technique uses a secure asymmetric encryption with a pre-shared list of official UAVs. Using this technique, the wrong information can be detected when an official UAV is physically hijacked. The novel agent based simulator ABS-SecurityUAV is used to validate the proposed approach. In our experiments, around 90% of UAVs were able to corroborate information about a person walking in a controlled area, while none of the UAVs corroborated fake information coming from a hijacked UAV.","Agent-based simulator,Blockchain,Multi-agent system,Security,Surveillance,Unmanned aerial vehicle","IvánGarcía-Magariñoab,RaquelLacuestaab,MuttukrishnanRajarajanc,JaimeLloretd","Ad Hoc Networks","https://doi.org/10.1016/j.adhoc.2018.11.010","https://www.sciencedirect.com/science/article/pii/S1570870518301689"
"A237","Flow and heat transfer analysis of hybrid cooling schemes: Adding micro-jets to a micro-gap","An extensive, combined experimental and numerical analysis is presented as a method for physically-driven, systematic improvement of heat transfer, applied to a single-phase hybrid quasi-2D cooling scheme, merging impinging flow with that parallel to a heated plate. Thereby cooling fluid is introduced into a micro-gap in a gradual way, through a succession of impinging micro-slot jets. Both the distributed inflow and impinging flows improve heat transfer and especially wall temperature uniformity. For a specific micro-fabricated system, the influence of flow rate is examined in an experimental study employing wall-side infrared thermography and flow visualization by micro-PIV. The measurements reveal the location of standing vortices and jet's deflection of the main flow towards the wall, and the characteristics of these flow patterns, associated with around 20% heat transfer enhancement. These flow patterns and wall heat transfer are quantitatively reproduced by numerical simulation spanning the transitional flow regime. From insights gained, the base configuration is varied numerically in terms of jet array location and pitch, micro-jet slot hydraulic diameter and initial flow distribution. As a result, a much improved configuration is identified, yielding a total heat transfer enhancement of almost 60%, as compared to a plain gap at the same overall flow rate, while attaining even more significant improvement in wall temperature uniformity. The systematic method followed to obtain such improvement is described in detail to facilitate future studies.","Liquid cooling,Heat transfer enhancement,Micro gap,Jet array,Micro-PIV,IR thermography,Numerical simulation","AmirGorodetskya,TomerRozenfeldb,Herman D.Hausteina,GennadyZiskindb","International Journal of Thermal Sciences","https://doi.org/10.1016/j.ijthermalsci.2019.01.015","https://www.sciencedirect.com/science/article/pii/S1290072918311384"
"A238","Symbiotic organisms search algorithm: Theory, recent advances and applications","The symbiotic organisms search algorithm is a very promising recent metaheuristic algorithm. It has received a plethora of attention from all areas of numerical optimization research, as well as engineering design practices. it has since undergone several modifications, either in the form of hybridization or as some other improved variants of the original algorithm. However, despite all the remarkable achievements and rapidly expanding body of literature regarding the symbiotic organisms search algorithm within its short appearance in the field of swarm intelligence optimization techniques, there has been no collective and comprehensive study on the success of the various implementations of this algorithm. As a way forward, this paper provides an overview of the research conducted on symbiotic organisms search algorithms from inception to the time of writing, in the form of details of various application scenarios with variants and hybrid implementations, and suggestions for future research directions.","Symbiotic organisms search algorithm,Swarm intelligence,Metaheuristic algorithms,Optimization","Absalom E.Ezugwua,DoddyPrayogob","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.045","https://www.sciencedirect.com/science/article/pii/S0957417418307036"
"A239","Towards sustainable smart cities: An empirical comparative assessment and development pattern optimization in China","Dramatically increased societal demands on the municipal services that contradict environmental protection and information processing capability oriented to resource utilization efficiency suffer from opposing simultaneous requirements. The smart city provides better solutions for urban areas which are increasing at an unprecedented speed. This paper presents an empirical study carried out to assess and analyze the development pattern of 35 smart cities in China using the principal component analysis (PCA) and back propagation (BP) neural network techniques. The proposed PCA-BP neural network assessment processing model is applied with six dimensional factors and twenty-two operating indices. With the feature extraction and performance score calculated via PCA, BP neural network is adopted for city classification to recognize the development differences in smart cities. The results indicate that the factor-driven impetus evolves into innovation-driven impetus, narrowing the gap from the holistic perspective between the first and middle-ranking groups, while two middle-ranking groups show a similar upward trend in terms of developing a smart economy through sustainable productivity in innovative enterprises and high-tech industry. To some extent, in response to a similar improving trend in the application of smart services, a distinct advantage of an individual index can be a complementary offset to unapparent holistic highlighting the reception of the lowest average points. Unbalanced development exists in two subaverage groups that are deficient in the initial inventory of smart infrastructure and demands. A relatively large difference exists in the smart mobility index among cities, whereas the opposite case is found concerning the smart environment index. Finally, corresponding optimized development pattern are recommended for building a sustainable smart city.","Sustainable smart city,Principal component analysis,BP neural network,Assessment processing model,Development pattern","XiaLia,Patrick S.W.Fongb,ShengliDaic,YingchunLic","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2019.01.046","https://www.sciencedirect.com/science/article/pii/S0959652619300538"
"A240","Synergistic activity of BET inhibitor MK-8628 and PLK inhibitor Volasertib in preclinical models of medulloblastoma","Medulloblastoma is the most prevalent central nervous system tumor in children. Targeted treatment approaches for patients with high-risk medulloblastoma are needed as current treatment regimens are not curative in many cases and cause significant therapy-related morbidity. Medulloblastoma harboring MYC amplification have the most aggressive clinical course and worst outcome. Targeting the BET protein BRD4 has significant anti-tumor effects in preclinical models of MYC-amplified medulloblastoma, however, in most cases these are not curative. We here assessed the therapeutic efficacy of the orally bioavailable BRD4 inhibitor, MK-8628, in preclinical models of medulloblastoma. MK-8628 showed therapeutic efficacy against in vitro and in vivo models of MYC-amplified medulloblastoma by inducing apoptotic cell death and cell cycle arrest. Gene expression analysis of cells treated with MK-8628 showed that anti-tumor effects were accompanied by significant repression of MYC transcription as well as disruption of MYC-regulated transcriptional programs. Additionally, we found that targeting of MYC protein stability through pharmacological PLK1 inhibition showed synergistic anti-medulloblastoma effects when combined with MK-8628 treatment. Thus, MK-8628 is effective against preclinical high-risk medulloblastoma models and its effects can be enhanced through simultaneous targeting of PLK1.","BRD4,MYC,PLK1,Pediatric brain tumors,Targeted therapy","YoujiaHana,SvenLindnerb,YiBeia,Heathcliff DoradoGarciaa,NatalieTimmea,KristinaAlthoffb,AndreaOderskyb,AlexanderSchrammb,AndrejLissata,AnnetteKünkeleacd,Hedwig E.Deubzeracde,AngelikaEggertac,Johannes H.Schulteac,Anton G.Henssenacd","Cancer Letters","https://doi.org/10.1016/j.canlet.2018.12.012","https://www.sciencedirect.com/science/article/pii/S0304383518307274"
"A241","Identification and expression profiles of putative leaf growth related microRNAs in maize (Zea mays L.) hybrid ADA313","Throughout the plant life cycle, growth of new leaves is governed by cell division and cell expansion. During steady-state growth of the maize leaf, these processes are spatially separated between the meristem zone, consisting of dividing cells at the leaf base, the elongation zone, consisting of expanding cells moving upwards from the meristem, and the mature zone containing differentiated mature cells. Increased leaf size can be achieved through increasing cell number or cell size, for example by manipulating the genes controlling the transition between those zones. In this study, microRNA (miRNA) genes, which are a class of endogenous small, non-coding gene regulatory RNAs, were investigated in the growth zones, to gain insight into their role in the transition between cell division and cell expansion. A genome-wide survey was conducted using a miRNA-microarray and 59 miRNA genes were detected to be differentially expressed between the growth zones. miR160, miR166, miR168, miR172, miR319 and miR390 families were significantly up-regulated in the meristem relative to the elongation and mature zones. In contrast, expression of the miR167 and miR396 families was lower in the meristem and higher in the mature zone. Therefore, these were considered to be candidate growth-regulated miRNAs that control cell division processes indirectly by repressing target genes. The miR156, miR166, miR167, miR399, miR408 and miR2275 families were expressed most highly in the elongation zone, and so were classified as elongation-specific, with possible roles in switching from cell division to cell elongation during leaf differentiation. In silico target prediction analysis showed that these miRNAs target several transcription factors and metabolic genes, and a reciprocal relationship between the expression levels of miR319 and miR396 and their targets was confirmed by qRT-PCR. Furthermore, 12 candidate novel miRNAs were identified from the microarray data and computationally verified. Three out of twelve were also validated by qRT-PCR. These findings provide important information regarding the regulatory functions of miRNAs in controlling progression of growth mechanisms.","miRNAmicroRNA,ma-miRNAmature miRNA,pre-miRNAprecursor miRNA,pri-miRNAprimary miRNA,ncRNAnon-coding RNA,GRFsGrowth-regulating Factors,TCPs(TEOSINTE BRANCHED1 CYCLOIDEA PCF (proliferating cell nuclear antigen factor),MYBGA/GAMYBMYB transcription factor regulated by Giberellic acid,BRsbrassinosteroids,GAsgiberellins,ZmPLA1the maize PLASTOCHRON1,ARGOSauxin-regulated gene involved in organ size,ZAR1Zea mays ARGOS,CYP78A1cytochrome P450 protein,DCLDicer like proteins,AGOArgonaute protein,RISCRNA-induced silencing complex,HEN1hua enhancer,HASTYthe Exportin 5 homolog,MFEMinimum Folding free Energy,MFEIMinimum Folding Energy Index,qRT-PCRQuantitative Real-Time Polymerase Chain Reaction,mRNAmessenger RNA,UTRuntranslated region,siRNAsmall interfering RNA,TACTranscription Analysis Console,GIFGRF Interacting Factor,Keywords,Maize,Leaf growth,Plant microRNA,miRNome","FatmaAydinoglua,Stuart JamesLucasb","Gene","https://doi.org/10.1016/j.gene.2018.12.042","https://www.sciencedirect.com/science/article/pii/S0378111918313040"
"A242","Untargeted food contaminant detection using UHPLC-HRMS combined with multivariate analysis: Feasibility study on tea","Powerful data pretreatment strategies inspired from the field of metabolomics were adapted to chemical food safety context to enable samples discrimination by multivariate methods based on low abundance ions. A highly automated workflow was produced. The open-source XCMS package was used and efficient data filtration strategies were set up. Data were treated using Independent Components Analysis, and data mining strategies developed to automatically detect and annotate ions of low abundance by coupling blind data exploration strategies with a broad scale database approach. Our method was efficient in discriminating tea samples based on their contamination levels (even at 10<U+202F>µg.kg-1) and detecting unexpected impurities in the spiking mix. Several “tracer” contaminants were considered, covering a broad range of physicochemical properties and structural diversity with overall 66% detected and annotated blindly. The methodology was successfully applied to a data set exhibiting only 3 “tracer” contaminants (at 50<U+202F>µg.kg-1) and more product diversity.","Independent Components Analysis,XCMS,ToF,Chemical food safety,Non-targeted approaches,Unexpected contaminants","GrégoireDelaporte,MathieuCladière,DelphineJouan-Rimbaud Bouveresse1,ValérieCamel","Food Chemistry","https://doi.org/10.1016/j.foodchem.2018.10.089","https://www.sciencedirect.com/science/article/pii/S0308814618318648"
"A243","Bacterial and microeukaryotic plankton communities in a semi-intensive aquaculture system of sea bass (Dicentrarchus labrax): A seasonal survey","The importance of microbial diversity and their role in the maintenance of fish health in aquaculture systems has been increasingly recognized in recent years. However, there is still a major knowledge gap regarding the ecology, composition and dynamics of microbial plankton assemblages during fish production. In this study, we aimed to investigate the seasonal dynamics and potential interactions of bacterial and microeukaryotic plankton communities in a semi-intensive aquaculture for European sea bass (Dicentrarchus labrax) cultured together with low density of gilthead sea bream (Sparus aurata) over a one-year period (January/2014 – November/2014). While the most abundant bacterial classes were Gammaproteobacteria, Flavobacteriia and Alphaproteobacteria; microeukaryotic communities were dominated by Ochrophyta, Chlorophyta and Ciliophora groups. Temperature and salinity were identified as significant drivers of the overall microbial community composition, which varied congruently along the seasons. However, while the dominant (more abundant) groups of bacteria occurred in the warmest months, the dominant groups of microeukaryotes occurred in the coldest months. There was also an inverse relationship between abundances of grazers and bacterial operational taxonomic units (OTUs). Overall, besides the potential effects of the abiotic parameters on the microbial plankton communities, the correlation between bacteria and microeukaryotic populations observed here may be an indication of trophic and/or metabolic interdependence between these two domains. Future studies should focus on the underlying mechanisms of this interdependence for a better understand of the impact of microeukaryotic communities on aquaculture bacterioplankton structure and function. In addition, this knowledge could be of interest in the development of microbial management strategies for aquaculture systems.","Bacteria,Microeukaryote,Plankton,Aquaculture microbiome,Seasonal variation","Letícia N.Duarte,Francisco J.R.C.Coelho,Daniel F.R.Cleary,DanielBonifácio,PatríciaMartins,Newton C.M.Gomes","Aquaculture","https://doi.org/10.1016/j.aquaculture.2018.12.066","https://www.sciencedirect.com/science/article/pii/S0044848618308998"
"A244","Protein analysis of moro blood orange pulp during storage at low temperatures","A protein analysis in the pulp of Moro blood oranges (Citrus sinensis L. Osbeck) at the onset and after 30<U+202F>days of storage at either 4 or 9<U+202F>°C was performed. All differential proteins belonged to different functional classes (sugar, amino acid and secondary metabolism, defense, stress response, oxidative process, transport and cellular component biogenesis), displaying a differential accumulation in those Moro oranges kept at 9 versus 4<U+202F>°C, and in those stored at 4<U+202F>°C versus onset. Anthocyanin biosynthesis structural proteins chalcone synthases and flavonone 3-hydroxylase and different glutathione S-transferases related with their vacuolar transport were up-accumulated in fruits kept at 9 versus 4<U+202F>°C and versus the onset. Proteins related with defense and oxidative stress displayed a similar pattern, concomitant with a higher anthocyanin content, denoting a possible role of defense and other stress response pathways in anthocyanin production/accumulation.","Blood oranges,Anthocyanins,Cold storage,Purple juice,Proteome","L.Carmonaa,B.Alquézarab,S.Tárragab,L.Peñaab","Food Chemistry","https://doi.org/10.1016/j.foodchem.2018.10.108","https://www.sciencedirect.com/science/article/pii/S0308814618318831"
"A245","Issues on characterization of cement paste microstructures from µ-CT and virtual experiment framework for evaluating mechanical properties","There are issues on the microstructure characterization of cement paste obtained from µ-CT due to resolution limits, and evaluation of properties through virtual experiments. A phase separation procedure between the solid and pore phases, which can be used for pure cement paste microstructures, is proposed. The problems of underestimation of microstructural characteristics such as porosity in virtual specimens from µ-CT, as compared to real specimens, are addressed. Reflecting such underestimation, the process of input modeling parameter determination for virtual experiments on mechanical property evaluation using the phase field fracture model is elaborated. Through virtual tests, the effects of domain size and mesh resolution on the evaluated properties are investigated, and the correlation between the microstructural characterization parameters and mechanical properties is reconfirmed. It is shown that the virtual experiment framework proposed in this study can be used as a loading tool to supplement time and effort consuming real experiments for evaluating the mechanical properties of cement paste at the micro-scale.","Cement paste,Microstructures,Mechanical properties,µ-CT,Phase field fracture model","Ji-SuKima,Sang-YeopChungbc,DietmarStephanb,Tong-SeokHana","Construction and Building Materials","https://doi.org/10.1016/j.conbuildmat.2019.01.030","https://www.sciencedirect.com/science/article/pii/S0950061819300303"
"A246","Genetic variability of human papillomavirus type 51 E6, E7, L1 and L2 genes in Southwest China","Genetic variations among HR-HPV types lead to altered biological functions with possible clinical significance in different geographical locations. To explore intratype genetic variations of HPV51 E6, E7, L1 and L2 genes originating from Southwest China, a total of 5204 cervical scraped cell samples were collected for DNA extraction and HPV typing. And then the E6, E7, L1 and L2 genes of HPV51 (n<U+202F>=<U+202F>79) were sequenced and compared to the reference sequence (M62877). The ConSurf server was used for identification of conserved structural and functional amino acids of the E6 and E7 oncogenes, and the changes of the secondary structure were analyzed by PSIPred software. Phylogenetic trees were constructed by the maximum likelihood method implemented in IQ-TREE. The selection pressure acting on the E6, E7, L1 and L2 genes was estimated by Datamonkey web server. 13 nucleotide polymorphism sites were observed in E6-E7 gene and the most common mutation sites were C395T (S100L), C756T (S66L), C796T, A832G. 36 nucleotide polymorphism sites were identified in full length L1 gene and the non-synonymous mutations T6311G, A6312T (V264G), G6313A (G265S) A5674C (I52L), A6335C (N272T), A6586C (T354P) and synonymous mutations A5649T, C6147T, A6435G, G6570A, A6651G, T6774C, A6784C, A6882G, C6918A, and G6984A were the most common mutations. 53 nucleotide variation sites were identified in full-length L2 gene including four insertion sites (4418A, 4670G, 4693A, 4694C) and one deletion site (A4430). Besides, the non-synonymous mutations G4227A (V32I), A4407G (I92V), G4945A (D271N), C4985A (T284K), T5260G (L376V), A5335C (T401P) and the synonymous mutations A4166G, G4229A, G4283A, T4453C, C4566A, T4596C, C4695T, C4830T, G4839A, A5160C, and T5286G were the most common mutations. Specially, a triallelic mutation site (G4461C/A) in L2 was identified, with 26% G4461C (E109D) being non-synonymous mutation. Selective pressure analysis showed that only codon site 66 in E7 and 52 in L1 were the positively selected sites and codon sites 72, 107, 342, 412, 427 were negatively selected sites in L2 gene. Our investigation also suggests that A2 and A4 were the most frequent HPV51 lineage in Southwest China.","HPV51,Genetic variability,E6, E7, L1 and L2 genes,Southwest China,Cervical cancer,Lineage phylogeny","JianjuXu,LipingTan,TaoWang,FangyingCui,XianpingDing,QiulingWan,DanDeng,ZuyiChen","Gene","https://doi.org/10.1016/j.gene.2018.12.032","https://www.sciencedirect.com/science/article/pii/S0378111918312897"
"A247","GIS-based groundwater potential mapping in Shahroud plain, Iran. A comparison among statistical (bivariate and multivariate), data mining and MCDM approaches","In arid and semi-arid areas, groundwater resource is one of the most important water sources by the humankind. Knowledge of groundwater distribution over space, associated flow and basic exploitation measures can play a significant role in planning sustainable development, especially in arid and semi-arid areas. Groundwater potential mapping (GWPM) fits in this context as the tool used to predict the spatial distribution of groundwater. In this research we tested four GIS-based models for GWPM, consisting of: i) random forest (RF); ii) weight of evidence (WoE); iii) binary logistic regression (BLR); and iv) technique for order preference by similarity to ideal solution (TOPSIS) multi-criteria. The Shahroud plain located in Iran, was selected to research the water scarcity and over-exploitation of groundwater resources over the past 20<U+202F>years. In this research, using Iranian Department of Water Resources Management data, and extensive field surveys, 122 groundwater well data with high potential yield of =11<U+202F>m3<U+202F>h-1 were selected for GWPM. Specifically, we generated four different models selecting 70% (n<U+202F>=<U+202F>85) of the wells and validated the resulting GWP maps upon the complementary 30% (n<U+202F>=<U+202F>37).A total of fifteen ground water conditioning factors to explain the groundwater well distribution over the Shahroud plain were selected. From the Advanced Land Observing Satellite (ALOS), a DEM (30<U+202F>m resolution) was extracted to calculate a set of morphometric properties which were combined with thematic ones such as land use/land cover (LU/LC) and Soil Type (ST). Results show that in RF (LU/LC), LR (ST), and AHP (Slope) are the most relevant contributors to groundwater occurrence. After that, using the natural break method, final maps were divided into five susceptibility classes of very low, low, moderate, high, and very high. The accuracy of models was ultimately tested using prediction rate (validation data), success rate (training data) and the seed cell area index (SCAI) indicators. Results of validation show that BLR with prediction rate of 0.905 (90.5%) and success rate of 0.918 (91.8%) had higher accuracy than WoE, RF and TOPSIS models with respective prediction rates of 0.885, 0.873 and 0.870 (88.5%, 87.3%, and 87%) and success rate of 0.900, 0.889, and 0.881 (90%, 88.9%, and 88.1%). SCAI results show that all models have acceptable classification accuracy although BLR outperformed the other models in terms of accuracy. Results show that the combination of remote sensing (RS) data and geographic information system (GIS) with new approaches can be used as a powerful tool in GWPM in arid and semi-arid areas. The results of this investigation introduced a potential novel methodology that could be used by decision-makers for the sustainable management of ground water resources.","Random forest,Weight of evidence,Binary logistic regression,Decision making,Semi-arid region","AlirezaArabameria,KhalilRezaeib,ArtemiCerdac,LuigiLombardod,JesúsRodrigo-Cominoe","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.12.115","https://www.sciencedirect.com/science/article/pii/S0048969718349593"
"A248","Soil available phosphorus content drives the spatial distribution of archaeal communities along elevation in acidic terrace paddy soils","Archaea play crucial roles in geochemical cycles and influence the emission of greenhouse gases in acidic soils. However, little is known about the distribution pattern of total archaeal diversity and community composition with increasing elevation, especially in acidic agricultural ecosystems. Terraces, characterized by vertical climate changes and unique hydrological properties, are “natural experiments” to explore the spatial distribution of microorganisms along elevation in paddy soils. Here we investigated the diversity and structure of soil archaeal communities in nine increasingly elevated acidic paddy soils of the Yunhe terrace, China. Archaeal communities were dominated by Methanomicrobia of Euryarchaeota (38.5%), Group 1.1a-associated cluster (SAGSCG-1) of Thaumarchaeota (22.0%) and Subgroup-6 (previously described as crenarchaeotal group 1.3b) of Bathyarchaeota (17.8%). The archaeal phylotype richness decreased with increasing elevation. Both the species richness and phylogenetic diversity of the archaeal communities were significantly negatively correlated with soil available phosphorus (AP) content according to linear regression analyses. The archaeal communities differed greatly between soils of increasing elevation, and were roughly clustered into three groups, mostly in relation to AP contents. A variation partitioning analysis further confirmed that edaphic factors including the content of AP (17.1%), nitrate (7.83%), soil organic carbon (4.69%), dissolved organic carbon (4.22%) and soil pH (4.07%) shaped the archaeal community. The variation of soil properties were probably induced by elevation. The co-occurrence network indicated a modular structure of the archaeal community. Overall, our results emphasized that soil AP content was the best predictor of archaeal diversity and community structure, and the impacts of elevation on soil archaeal communities were not diminished by long-term rice cultivation, although minor compared with the effects of soil properties.","Acidic terrace paddy soils,Archaeal diversity,Elevational distribution,Archaeal community structure,Available phosphorus content,Network analysis","QianZhangab1,YongLiab1,JiajiaXinga,Philip C.Brookesa,JianmingXuab","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.12.144","https://www.sciencedirect.com/science/article/pii/S0048969718349891"
"A249","iTRAQ-based quantitative proteomics reveals the neuroprotection of rhubarb in experimental intracerebral hemorrhage","Ethnopharmacological relevanceRhubarb is a traditional Chinese medicine(TCM), that possesses neuroprotective, anti-inflammatory, antibacterial, antioxidative, purgative and anticancer properties, and has been used to treat intracerebral hemorrhage (ICH) and many other diseases.,Aims of the studyThis study aimed to investigate the changes of brain protein in ICH rats treated with rhubarb and to explore the multi-target mechanism of rhubarb in the treatment of ICH via bioinformatics analysis of differentially expressed proteins (DEPs).,Materials and methodsRats were subjected to collagenase-induced ICH and then treated orally with 3 or 12<U+202F>g/kg rhubarb daily for 2 days following ICH. After sacrifice, total protein of brain tissue was extracted, and isobaric tag for relative and absolute quantification (iTRAQ)-based liquid chromatography-tandem mass spectrometry (LC-MS/MS) analysis was employed to quantitatively identify of the DEPs in two treatment groups compared with the vehicle group. The DEPs were analyzed by Gene Ontology (GO), Kyoto Encyclopedia of Genes and Genomes (KEGG) and STRING databases. Bioinformatics Analysis Tool for Molecular mechanism of TCM (BATMAN-TCM) was used to predict the target of rhubarb and western blotting was used for verification.,ResultsIn total, 1356 proteins were identified with a 1% false discovery rate (FDR). Among them, 55 DEPs were significantly altered in the sham, vehicle, low dose rhubarb group (LDR, 3<U+202F>g/kg), and high dose rhubarb group (HDR, 12<U+202F>g/kg). Enrichment analysis of GO annotations indicated that rhubarb mainly regulated expression of some neuron projection proteins involved in the response to drug and nervous system development. The dopaminergic synapse pathway was found to be the most significant DEP in the combined analysis of the KEGG and BATMAN-TCM databases. Based on the results of the STRING analysis, oxidative stress (OS), calcium binding protein regulation, vascularization, and energy metabolism were important in the rhubarb therapeutic process.,ConclusionRhubarb achieves its effects mainly through the dopaminergic synapse pathway in ICH treatment. The ICH-treating mechanisms of rhubarb may also involve anti-OS, calcium binding protein regulation, angiogenic regulation, and energy metabolism improvement. This study adds new evidence to clinical applications of rhubarb for ICH.","","TaoLiuab,JingZhoua,HanjinCuia,PengfeiLia,JiekunLuoa,TengLia,FengHec,YangWangad,TaoTangad","Journal of Ethnopharmacology","https://doi.org/10.1016/j.jep.2018.11.032","https://www.sciencedirect.com/science/article/pii/S0378874118306160"
"A250","Transformation of dissolved organic matter during advanced coal liquefaction wastewater treatment and analysis of its molecular characteristics","Coal liquefaction wastewater (CLW) contains numerous toxic and biorefractory organics. A series of advanced treatment processes were designed to remove the dissolved organic matter (DOM) from CLW. Here, the reactivity and state of the DOM in the treatment train were studied in relation to its chemical composition by a Fourier transform ion cyclotron resonance mass spectrometry (FT-ICR-MS) analysis. Within an isobaric group, the raw CLW possessed a high average double-bond equivalent (DBEwa) and low H/Cwa values with the N- and S-containing compounds accounting for approximately 77% of the raw CLW, which represented lignin (73.6%) and condensed aromatic structures (19.8%). In addition, the flotation process removed some hydrophobic DOM compounds with highly unsaturated states, which were biorefractory compounds. Ozonation and catalytic oxidation processes preferentially removed the highly unsaturated compounds and produced more oxidized molecules. The biofiltration process impacted the organics composition by consuming oxygen-rich substances, whereas the anoxic/oxic (A/O) process converted the reactive compounds into newly formed compounds through the loss of hydrogen (unsaturation) from the original compounds. The membrane bioreactor (MBR) process was more efficient in removing the N-containing compounds with higher unsaturated states. The compounds resistant to the applied CLW treatment processes were characterized by lower molecular weights (approximately 250–350<U+202F>Da), higher oxidation states (O/S<U+202F>><U+202F>6), numerous carboxylic groups, and non-biodegradable features.","Fourier transform ion cyclotron resonance,Coal liquefaction wastewater,Dissolved organic matter,Molecular-level characterization,Treatment train","LiZhang,YongzhenPeng,JiachunYang","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.12.218","https://www.sciencedirect.com/science/article/pii/S0048969718350812"
"A251","Modifying internal organization and surface morphology of siRNA lipoplexes by sodium alginate addition for efficient siRNA delivery","Vectorized small interfering RNAs (siRNAs) are widely used to induce specific mRNA degradation in the intracellular compartment of eukaryotic cells. Recently, we developed efficient cationic lipid-based siRNA vectors (siRNA lipoplexes or siLex) containing sodium alginate (Nalg-siLex) with superior efficiency and stability properties than siLex. In this study, we assessed the physicochemical and some biological properties of Nalg-siLex compared to siLex. While no significant differences in size, <U+03B6> potential and siRNA compaction were detected, the addition of sodium alginate modified the particle morphology, producing smoother and heterogeneous particles characterized by transmission electron microscopy. We also noted that Nalg-siLex have surface differences observed by X-ray photoelectron spectroscopy. These differences could arise from an internal reorganization of components induced by the addition of sodium alginate, that is indicated by Small-Angle X-ray Scattering results. Moreover, Nalg-siLex did not trigger significant hepatotoxicity nor inflammatory cytokine secretion compared to siLex. Taken together these results suggest that sodium alginate played a key role by structuring and reinforcing siRNA lipoplexes, leading to more stable and efficient delivery vector.","RNA interference,Cationic lipid,Nanoparticle,Delivery system,Structure,Anionic polymer","Danielle CampiolArrudaabcde,Ismael JoséGonzalezf,StéphanieFinetghij,LuisCordovaklm,ValérieTrichetlm,Gracielle FerreiraAndradea,CélineHoffmannbcde,PascalBigeybcde,Waldemar Augustode Almeida Macedof,ArmandoDa Silva CunhaJra,AngeloMalachias de Souzan,VirginieEscrioubcde","Journal of Colloid and Interface Science","https://doi.org/10.1016/j.jcis.2019.01.043","https://www.sciencedirect.com/science/article/pii/S0021979719300542"
"A252","Multi-walled carbon nanotubes reinforced interpenetrating polymer network with ultrafast self-healing and anti-icing attributes","HypothesisFabrication of polymeric nanocomposites with suitable nanomaterial via an in-situ polymerization approach results in multifunctional advanced materials.,ExperimentsThe present work demonstrates the fabrication of interpenetrating polymer network (IPN)-based smart nanocomposites of polyurethane and polystyrene (PS) with different weight percentages of multi-walled carbon nanotubes (MWCNT). The MWCNT was grafted with pre-polymer of PS. The grafted-MWCNT and the nanocomposites were analyzed by Fourier transform infrared and Raman spectroscopic, X-ray diffraction, transmission electron microscopic studies. Further, different properties of the nanocomposites were evaluated.,FindingsThe fabricated nanocomposites showed excellent enhancement in mechanical (tensile strength: 175.9%; elongation at break: 161.9%; and toughness: 279.8%) and thermal (initial degradation temperature: 107.8%) properties compared to the pristine IPN. The improved properties are because of strong interfacial matrix-nanomaterial interactions. In addition, the nanocomposites demonstrated high water repellence (static contact angle varied from 127.9° to 143.6°), outstanding self-cleaning and anti-icing (freezing delay time of 1850–2700<U+202F>s) behaviors. Most interestingly, the fabricated nanocomposites exhibited excellent self-healing ability under the exposure of microwave (within 46–22<U+202F>s at 300<U+202F>W power input) and sunlight (within 318–257<U+202F>s, light intensity: 0.9–1.1<U+202F>×<U+202F>105<U+202F>lux). Therefore, the studied nanocomposites hold significant potential to be used in the domains of advanced smart materials.","IPN,PS-grafted-MWCNT,Nanocomposite,Self-cleaning,Anti-icing,Self-healing","TuhinGhosh,NiranjanKarak","Journal of Colloid and Interface Science","https://doi.org/10.1016/j.jcis.2019.01.006","https://www.sciencedirect.com/science/article/pii/S0021979719300062"
"A253","Rich liquid crystal phase behavior of novel alkyl-tri(ethylene glycol)-glucoside carbohydrate surfactants","Carbohydrates are appealing non-ionic surfactant head-groups as they are naturally abundant, generally biocompatible and biodegradable, and readily functionalized. Herein, we explore the phase behavior of seven novel carbohydrate-based surfactants (CBS) containing a tri-ethylene glycol (TEG) linker between a glucose head-group and alkyl tail-group, with linear saturated (C8–18) and cis-unsaturated (C18:1) alkyl chains. At high aqueous concentrations, these glycolipid-like surfactants transition into a variety of lyotropic liquid crystalline phases following an expected concentration phase sequence: hexagonal (H1) <U+2192> bicontinuous cubic (V1) <U+2192> lamellar (La). Using polarizing light microscopy (PLM), a binary (surfactant–water) phase diagram for each surfactant was constructed across a temperature range (25–80<U+202F>°C) revealing thermotropic behavior and a broadening of liquid crystal phase regions with increasing alkyl chain length. There was also a significant difference between saturated and unsaturated alkyl chains, due to the cis-unsaturated ‘statistical bend’ lowering the melting point. Small-angle X-ray scattering (SAXS) measurements were performed to characterize the liquid crystal phases, identifying highly-ordered p6m,Ia3d, and La crystallographic space-groups with up to 7 resolved Bragg peaks, likely due to the highly anisometric nature of the TEG-linked surfactants. The phases were shown to be more numerous and exhibited greater thermal-stability compared to well-characterized alkyl glucoside surfactants lacking an oligoethylene spacer in the literature. Finally, the characteristic dimensions of each phase were determined to enable visualization of the internal microstructures, providing insight into the impact of molecular shape and the distribution of hydro-philicity/phobicity on the formation and stability of liquid crystalline mesophases.","Alkyl glucosides,Glycolipids,Liquid crystals,Polarizing light microscopy,Small-angle X-ray scattering","Jackson E.Moorea,Thomas M.McCoya,Joshua B.Marlowa,Matthew J.Pottagea,Stephen T.Mudieb,Graeme R.Pearsonc,Brendan L.Wilkinsond,Rico F.Tabora","Journal of Colloid and Interface Science","https://doi.org/10.1016/j.jcis.2018.12.092","https://www.sciencedirect.com/science/article/pii/S0021979718315339"
"A254","Reversibly responsive microemulsion triggered by redox reactions","HypothesisStimuli-responsive surfactants (also known as switchable surfactants) can undergo reversible conversions between active and inactive forms under particular stimuli, affecting surface and interfacial activity, aggregation structure, emulsification and solubilisation. Selenium-containing surfactants are of reversibly redox-responsive. Hence, microemulsions (MEs) stabilized by selenium-containing surfactants should reversibly respond to redox reactions.,ExperimentsThe formation of MEs, consisting of sodium dodecylselanylpropyl sulfate (reduced form, SDSePS-Re) or its oxidized form (SDSePS-Ox), n-butanol, n-heptane, and water, was verified based on a pseudo-ternary phase diagram. Changes in molecular structure between SDSePS-Re and SDSePS-Ox were verified by nuclear magnetic resonance spectrometry and electrospray ionization mass spectrometry. The transition between SDSePS-Re- and SDSePS-Ox -based MEs was systematically characterized through electrical conductivity measurements, cryo-transmission electron microscopy and dynamic light-scattering.,FindingsBoth SDSePS-Re and SDSePS-Ox could stabilize the mixture of n-butanol–n-heptane–water to form MEs. A reversible transition between an SDSePS-Re-based ME and the corresponding SDSePS-Ox-based ME was achieved, which was realized by the oxidation of SDSePS-Re with H2O2 and then reduction with N2H4. Compared with SDSePS-Re, SDSePS-Ox has a lower surface activity, resulting in a difference in solubilization capacity of the oil between SDSePS-Re- and SDSePS-Ox -based MEs. After oxidation with H2O2, phase separation could be observed in some SDSePS-Re-based MEs; however, the SDSePS-Re-based MEs could be recovered after reduction of SDSePS-Ox-based MEs with N2H4.","Microemulsion,Reversible responsiveness,Redox,Selenium-containing surfactant","YingLia,LianLiua,XuefengLiua,ShuangChenb,YunFanga","Journal of Colloid and Interface Science","https://doi.org/10.1016/j.jcis.2018.12.109","https://www.sciencedirect.com/science/article/pii/S0021979718315509"
"A255","Incumbents and business model innovation for the sharing economy: Implications for sustainability","In addition to fostering the rise of new players in various sectors, the sharing economy has attracted the attention of established companies, the so-called ‘incumbents’. Some incumbents have joined the sharing economy to both reap its emerging opportunities and tackle newcomers' competition. The entry of incumbents comes at a time in which the sharing economy, still in its initial stages, is the ‘battlefield’ between actors defending its original sustainability promise, based on the efficient use of resources, social bonding, non-monetized relationships and power of the communities, and those supporting the need to compromise on the principles, to ensure the sharing economy's expansion. Given incumbents' size and power, their entry is likely to significantly affect the shape of the sharing economy. Our study explores the implications for environmental, social and economic value creation of the different ways in which incumbents are changing their existing business models to join the sharing economy. We develop a typology of business model innovation for sharing, which stems from the literature on sustainable business models in particular, and present illustrative cases of incumbents' entry in the sharing economy. For every type adopted by incumbents, the sustainability dimensions are subsequently explored, considering both the benefits and drawbacks of incumbents' entry in the sharing economy. The final section concludes, and discusses implications for research, practice and policy.","Incumbent,Sharing economy,Sustainability,Business model,Business model innovation,Value proposition","FrancescaCiulli,AnsKolk","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.12.295","https://www.sciencedirect.com/science/article/pii/S0959652618340253"
"A256","Using a combination of PLFA and DNA-based sequencing analyses to detect shifts in the soil microbial community composition after a simulated spring precipitation in a semi-arid grassland in China","Increased spring precipitation in semi-arid grasslands could improve annual primary productivity. However, little is known about the responses of soil microbes to individual spring precipitation. In this study, we combined phospholipid fatty acid (PLFA) and DNA-based high-throughput sequencing analyses to investigate short-term (days) shifts in the soil microbial community composition after a simulated spring precipitation. Under field conditions, the soils (approx. -0.3<U+202F>MPa) were exposed to either a watering of 20<U+202F>cm or natural drought, and soil samples were collected at days 1, 3, 5, 8, and 12 after watering. Soil labile organic carbon (C) and nitrogen (N) as well as microbial biomass C (MBC) were positively correlated with soil water content (SWC). Spring watering significantly increased plant phosphorus (P) uptake, but had no impact on soil available P (AP). Watering increased the PLFA biomarkers indicative for Gram-negative (G-) bacteria and fungi. Two phyla of G- bacteria, Proteobacteria and Bacteroidetes, as well as the fungal phylum Ascomycota were more abundant when SWC increased. In addition to SWC and its related environmental factors such as C and N availabilities, AP appeared to be an important factor in shaping the soil microbial community composition. The study highlights the combination use of the methods based on different microbial biomarkers (PLFA vs. DNA), and the results were in line with each other. While the PLFA-based method was more sensitive to short-term shifts in soil microbial community composition in response to a precipitation event, DNA-based method could provide more information on the microbial taxa at a finer taxonomic resolution. Our results provide methodological insights for future research on short-term response of soil microbial community to changing environmental conditions.","Semi-arid grasslands,Spring watering,Microbial community composition,PLFA,DNA-based high-throughput sequencing","HaoChenabc,XiaorongZhaoab,QimeiLinab,GuitongLiab,WeidongKongcd","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.12.126","https://www.sciencedirect.com/science/article/pii/S0048969718349775"
"A257","Storylines of combined future land use and climate scenarios and their hydrological impacts in an Alpine catchment (Brixental/Austria)","In this paper, the hydrological impacts of future socio-economic and climatic development are assessed for a regional-scale Alpine catchment (Brixental, Tyrol, Austria). Therefore, coupled storylines of future land use and climate scenarios were developed in a transdisciplinary stakeholder process by means of questionnaire analyses and interviews with local experts from various relevant societal sectors. Resulting future land use maps for each decade were used as spatial input in the hydrological model WaSiM, to which a new module for the consideration of snow-canopy interaction processes has been added. Simulation results for three developed storylines, each combined with a moderate (A1B) and an extreme (RCP8.5) climate future, show that in a warmer and dryer climate the amount of annual simulated streamflow at the gauge of the catchment undergoes a significant reduction. The (mainly natural) reforestation of the catchment – caused by abandonment of previously cultivated areas – leads to additional losses of water by enhanced interception and evapotranspiration processes. Further cultivation of the current mountain pasture areas has a certain potential to attenuate undesirable long-term impacts of climate change on the catchment water balance.","Mountain hydrology,Regional catchment,Land use,Climate change,Numerical modelling,Storyline development","UlrichStrassera,KristianFörsterb,HerbertFormayerc,FlorentinHofmeistera,ThomasMarkea,GertraudMeißla,ImranNadeemc,RikeStottend,MarkusSchermerd","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.12.077","https://www.sciencedirect.com/science/article/pii/S0048969718349179"
"A258","Transcriptomic and evolutionary analyses of white pear (Pyrus bretschneideri) ß-amylase genes reveals their importance for cold and drought stress responses","ß-amylase (BAM) genes play essential roles in plant abiotic stress responses. Although the genome of Chinese white pear (Pyrus bretschneideri) has recently been made available, knowledge regarding the BAM family in pear, including gene function, evolutionary history and patterns of gene expression remains limited. In this study, we identified 17 PbBAMs in the pear genome. Of these, 12 PbBAM members were mapped onto 9 chromosomes and 5 PbBAM genes were located on scaffold contigs. Based on gene structure, protein motif analysis, and the topology of the phylogenetic tree of the PbBAM family, we classified member genes into 4 groups. All PbBAM genes were found to contain typical glycosyl hydrolysis 14 domain motifs. Interfamilial comparisons revealed that the phylogenetic relationships of BAM genes in other Rosaceae species were similar those found in pear. We also found that whole-genome duplication (WGD)/segmental duplication events played critical roles in the expansion of the BAM family. Next, we used transcriptomic data to study gene expression during the response of drought and low temperate responses, and found that genes in Group B were related to drought and cold stress. We identified four PbBAM genes associated with abiotic stress in Pear. Finally, by analyzing co-expression networks and co-regulatory genes, we found that PbBAM1a and PbBAM1b were associated with the pear abiotic stress response.","Pear,BAM gene family,Abiotic stress,Co-expression network","LiangyiZhao1,XinGong1,JunzhiGao,HuizhenDong,ShaolingZhang,ShutianTao,XiaosanHuang","Gene","https://doi.org/10.1016/j.gene.2018.11.092","https://www.sciencedirect.com/science/article/pii/S0378111918312447"
"A259","Influence of the initial water content in flash calcined metakaolin-based geopolymer","This study assesses the influence of the initial amount of water in metakaolin-based geopolymer on some of its properties in the hardened state. Results suggest a linearly decreasing influence of the amount of water on the mechanical performance of the geopolymer and showed that the majority of this water was not bonded to the structure. Moreover, it was found that whatever the amount of water initially introduced, all the samples contained the same amount of water after a drying period. The study of the porous network showed a large pore volume of 50% of the total volume which corresponds to the volume of water initially introduced. Finally, the observation of numerous macropore helped to explain the high transfer coefficients measured on the geopolymer.","Geopolymer,Metakaolin,Water content,Compressive strength,Porous network,Transfer properties","PouhetRaphaëlle,CyrMartin,BucherRaphaël","Construction and Building Materials","https://doi.org/10.1016/j.conbuildmat.2018.12.201","https://www.sciencedirect.com/science/article/pii/S0950061818331994"
"A260","The effects of urbanization on China's forest loss from 2000 to 2012: Evidence from a panel analysis","Forest loss has severe impacts on global environment change and biodiversity. However, few studies have used panel models to analyze forest loss at the national level, attributed to the limited time-space-series data on the forest loss at such large scale. The freely accessible Landsat images provide data to derive the global forest loss at a high spatial resolution of 30<U+202F>m (Hansen et al., 2013), which make it possible to carry out this study. Here we used the global forest loss dataset as a data source, a space-time panel model for 31 provinces, autonomous regions, or municipalities in mainland of China from 2000 to 2012 were built to investigate the relationship between the urbanization process and the forest loss both at the national and regional level. The results indicated that (1) the forest loss area of each province were between 3 and 89<U+202F>ha to more than 89<U+202F>ha during 2001 and 2012, with larger area of forest loss in the southern and north-eastern regions, while less forest loss in the central and western region. (2) In the study period, the forest loss rates were more than 4% in the southern China, while the rates were less than 0.1% in most of the northwest China; and the annual forest loss demonstrated an aggravated trend in most provinces of China. (3) There exists a scale effect and regional divergence in the impact of urbanization on forest loss: urbanization level is among the most critical factor affecting forest loss at the national level; while at the regional level, the most sensitive factor for forest loss is road mileage in the eastern region, urban green area in the central region, while urban level in the western region. This study may help to advance the understanding of the impact of urbanization process on China's forest loss, and therefore it provides good policy implications to make more effective and comprehensive solutions to reduce the loss of forests.","Forest cover change,Forest loss,Urbanization,Panel model,China","YuyingLina,RongzuQiua,JixueYaoa,XishengHua,JinguoLinb","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.12.317","https://www.sciencedirect.com/science/article/pii/S0959652618340484"
"A261","Rescuing things: Food waste in the rural environment in the Czech Republic","Although household food waste has been scrutinized from various angles, less attention has been paid to rural areas viewed through the prism of everyday life. The purpose of this study is to investigate household food wasting in rural environment in West Bohemia, Czech Republic. This case study combines waste composition analysis of household waste and ethnographic research in a village conducted throughout 2013 and 2014. We describe the nature of waste itself, estimate its financial value using a method combining direct data from wasted packaging and retail survey, explore the differences among the households, interpret local understanding of food, and contribute to the theoretical debates concerning thrift. Our results show low degree of wasting of edible food (7.9<U+202F>kg corresponding to 13.5 EUR per capita per year) but high variation among the households. Instead of searching for a single-causal explanation we explore a complex set of factors and relationships that shape everyday food-related practices. We approach the local discard practices via the concept of thrift and argue that it should be understood as a multi-dimensional domain that includes economizing via self-denial or creative management of resources, moral discourse entangled with care or responsibility, and social relations that shape the flows of value.","Consumption,Discard,Ethnography,Garbology,Selfprovisioning,Waste composition analysis","DanielSosnaab,LenkaBrunclíkováb,PatrikGaletab","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.12.214","https://www.sciencedirect.com/science/article/pii/S0959652618339349"
"A262","SWATH based quantitative proteomics analysis reveals Hfq2 play an important role on pleiotropic physiological functions in Aeromonas hydrophila","The RNA-binding protein Hfq protein is a well-characterized post-transcriptional regulator and plays an important role in the regulation of various physiological functions. Most bacterial genomes have only one copy of hfq, but a few bacterial species carry another distinct copy of hfq (hfq2) on the chromosome. However, the physiological properties of Hfq2 remain elusive. Here, we successfully constructed an hfq2 knock-out strain of Aeromonas hydrophila ATCC 7966. Phenotype assays showed that hfq2 deletion significantly increased extracellular protease activity, chemotaxis and swarming motility; increased low temperature, acidic pH, and basic pH resistance; and increased sensitivity to H2O2 stress and high temperatures. A SWATH-based quantitative proteomics method was used to compare the differential expression of proteins between the <U+2206>hfq2 mutant and the wild-type strain. Bioinformatic analysis showed that proteins associated with metabolic pathways were mostly upregulated, while those associated with ribosome subunits were mostly downregulated. Moreover, the deletion of hfq2 leads to the increased expression of several DNA- or RNA-binding regulators, including Hfq and the catabolite gene activator (Crp), and the decreased expression of OmpR. To our knowledge, this is the first study to demonstrate the effects of Hfq2 on physiological function at the protein level.,Biological significanceMost of bacterial genome has only one hfq copy, while only few bacterial species have two distinct copies in chromosome, and there are few documents about the biological functions of Hfq2. The current phenotype assays showed that Hfq2 plays important roles on bacterial physiological functions such as chemotaxis, swarming motility, ECPase activity and response to various environmental stresses. To better understanding the biological behavior of this protein, a SWATH based quantitative proteomics method was used to compare the altered proteins between <U+2206>hfq2 and wide type strain. Bioinformatics analysis showed that <U+2206>hfq2 significantly affects central metabolic pathway and translation related proteins. Moreover, the deletion of hfq2 lead to the increased expression of post-transcriptional regulator Hfq and catabolite gene activator Crp, and the down regulation of two-component regulatory system regulator OmpR. Our results indicate that Hfq2 is not a pseudogene but plays important roles on the essential physiological functions in A. hydrophila. To our knowledge, this is the first report to demonstrate the molecular function of Hfq2 at proteomics level.","Hfq2,Post-transcriptional regulator,SWATH,Quantitative proteomics,Aeromonas hydrophila","QilanCaiab1,GuibinWangab1,ZeqiLiab,LishanZhangab,YuyingFuab,XiaojunYangab,WenxiongLinab,XiangminLinab","Journal of Proteomics","https://doi.org/10.1016/j.jprot.2018.12.030","https://www.sciencedirect.com/science/article/pii/S1874391918304597"
"A263","Ecosystem restoration in Europe: Can analogies to Traditional Chinese Medicine facilitate the cross-policy harmonization on managing socio-ecological systems?","EU's Biodiversity Strategy to 2020 sets a 15% restoration target. However, the understanding of restoration as a management tool remains ambiguous at EU and Member State levels.As a country with rich biodiversity but low GDP, a well-defined priority setting approach is key for Bulgaria. The “Methodological framework for assessment and mapping of ecosystem condition and ecosystem services in Bulgaria” proposes a transition towards ecosystem management and monitoring of the Socio-Ecological System (SES), to be embedded in the environmental policy framework.We extend the analogy between SES and the human body's system in the Traditional Chinese Medicine (TCM) as a way to inform restoration priority setting and development of restoration and monitoring tools at several levels:1.Overall objective: the sustainability goals correspond to the TCM's objective of a healthy, balanced body2.Restoration objectives and functioning: the desired ecosystem state can be better understood in analogy between the ecosystem structure and functioning framework for multiparametric optimization, and the TCM framework of Ying-Yang, Eight principles, Five elements and organs3.Ecosystem monitoring: Integrated monitoring may benefit from comparison to TCM diagnostics4.Ecosystem management approaches can benefit from the analogy to the TCM system of meridiansWe apply the analogy and find that spatially explicit decision making on restoration, streamlined ecosystem monitoring and a number of other issues (green infrastructure, designation of protected areas, defragmentation and connectivity, cumulative impact assessment, etc.), are easier to understand, communicate, account for and manage. Ecosystem restoration is priority for China and the country has accumulated research and practical experience, including study of links between ecosystem management and the historical principles of Chinese philosophy.The Bulgarian and European approach to ecosystem based management can benefit from analogies to TCM. We derive policy recommendations by analogy, and illustrate them on the example of Natural Capital Accounting.","Socio-ecological system,Ecosystem based management and monitoring,Traditional Chinese Medicine,Ecosystem restoration targets,Trade-offs,Multi-parametric optimization of ecosystem services production","KremenaGochevaa,YiheLüb,FengLib,SvetlaBratanova-Donchevaa,NeshoChipeva","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.11.192","https://www.sciencedirect.com/science/article/pii/S0048969718345480"
"A264","Subsurface biogeochemistry is a missing link between ecology and hydrology in dam-impacted river corridors","Global investment in hydropower is rapidly increasing, fueled by a need to manage water availability and by incentives promoting renewable energy sources. This expansion poses unrecognized risks to the world's vulnerable freshwater ecosystems. While many hydropower impacts have been investigated, dam-induced alterations to subsurface processes influence river corridor ecosystem health in ways that remain poorly understood. We advocate for a better understanding of dam impacts on subsurface biogeochemical activity, its connection to hydrology, and follow-on trophic cascades within the broader river corridor. We delineate an integrated view of hydropower impacts in which dam-induced changes to surface water flow regimes generate changes in surface-subsurface hydrologic exchange flows (HEFs) that subsequently (1) regulate resource availability for benthic microorganisms at the base of aquatic food webs and (2) impose kinetic constraints on biogeochemical reactions and organismal growth across a range of trophic levels. These HEF-driven effects on river corridor food webs, as mediated by subsurface biogeochemistry, are a key knowledge gap in our assessment of hydropower sustainability and putatively combine with other, more well-known dam impacts to result in significant changes to river corridor health. We suggest targeted laboratory and field-based studies to link hydrobiogeochemical models used to predict heat transport, biogeochemical rates, and hydrologic flow with ecological models that incorporate biomass changes in specific categories of organisms. Doing so will enable predictions of feedbacks among hydrology, temperature, biogeochemical rates, organismal abundances, and resource transfer across trophic levels. This understanding of dam impacts on subsurface hydrobiogeochemistry and its connection to the broader aquatic food web is fundamental to enabling mechanism-based decision making for sustainable hydropower operations.","Hyporheic zone,Hydropeaking,Organic matter,Temperature,Groundwater-surface water mixing,Biogeochemical hotspot","Emily B.Graham,James C.Stegen,MaoyiHuang,XingyuanChen,Timothy D.Scheibe","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.11.414","https://www.sciencedirect.com/science/article/pii/S0048969718347697"
"A265","Local bending stiffness identification of beams using simultaneous Fourier-series fitting and shearography","In this paper, we present a novel method for the identification of the local bending stiffness of beams. We use shearography to capture measurements of vibrating beams, so the input data for the identification is the modal slope – the differential of the modal shape. The modal slope is fitted by two Fourier-series functions, one of which is derived from a thin-beam model. The local bending stiffness is identified as the one corresponding with the best match between the measured and the two fitted modal slopes. This identification method, which we call simultaneous Fourier-series fitting, is demonstrated on numerically-generated inputs, as well as on experimental measurements. We use a flat, concave and convex beam, as well as beams with locally varying bending stiffness mimicking local damage to verify the method. It is shown that the method gives accurate results and is robust to noise. Additionally, it has advantageous properties that make it useful and practical: using this method, it is possible to perform the identification from only a sub-region of a beam and even without specifying the boundary conditions.","Local bending stiffness identification,Shearography,Fourier-series fitting","FilipZastavnik,RikPintelon,MathiasKersemans,WimVan Paepegem,LincyPyl","Journal of Sound and Vibration","https://doi.org/10.1016/j.jsv.2018.12.004","https://www.sciencedirect.com/science/article/pii/S0022460X18308216"
"A266","When providing optimistic and pessimistic scenarios can be detrimental to judgmental demand forecasts and production decisions","This paper examines the accuracy of judgmental forecasts of product demand and the quality of subsequent production level decisions under two different conditions: (i) the availability of only time series information on past demand; (ii) the availability of time series information together with scenarios that outline possible prospects for the product in the forthcoming period. An experiment indicated that production level decisions made by participants had a greater deviation from optimality when they also received optimistic and pessimistic scenarios. This resulted from less accurate point forecasts made by these participants. Further analysis suggested that participants focussed on the scenario that was congruent with the position of the latest observation relative to the series mean and discounted the opposing scenario. This led to greater weight being attached to this observation, thereby exacerbating the tendency of judgmental forecasters to see systematic changes in random movements in time series.","Forecasting,Judgment,Extrapolation,Scenarios,Production planning","PaulGoodwina,M. SinanGönülb,DilekÖnkalb","European Journal of Operational Research","https://doi.org/10.1016/j.ejor.2018.09.033","https://www.sciencedirect.com/science/article/pii/S0377221718308105"
"A267","Optimized Multi-Algorithm Voting: Increasing objectivity in clustering","Currently, the influence of a single statistical cluster algorithm on the results of clustering procedures represents a major threat to the objectivity in clustering. To exemplify this question, this paper refers to country clustering in cross-cultural research. In this field, previous research has determined differing numbers of clusters, depending on choices available for the clustering procedure, leading to a high number of inconsistent results. Hence, it is argued that the variety in cluster solutions induced by the choice of different statistical cluster algorithms should be reduced. To this end, this study builds on Multi-Algorithm Voting (MAV) procedure introduced by Bittmann and Gelbard (2007) and presents an advancement to the MAV method. Specifically, MAV procedure is refined for the analysis of larger data sets using the simulated annealing algorithm for optimization. The use of this Optimized MAV (OMAV) is then demonstrated for country clustering in cross-cultural research. Specifically, a set of 57 countries is divided into 12 clusters based on work-related values obtained from GLOBE database reported in House et al. (2004). Thus, results clearly show that the objectivity of clustering results can be significantly improved based on OMAV. Implications for expert and intelligent systems on the use of OMAV are discussed. Namely, OMAV represents a powerful tool supporting the decision-making process in cluster analysis reducing the number of subjective and arbitrary decisions. Taken together, this study contributes to existing literature by providing an integrative and robust method of country clustering using OMAV and by presenting country clusters applicable to various settings.","Clustering,Integrative methods,Multi-algorithm voting,Work-related values","ReginaKempena,AlexanderMeiera,JensHascheb,KarstenMuellera","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.09.047","https://www.sciencedirect.com/science/article/pii/S0957417418306249"
"A268","A local Zernike moment-based unbiased nonlocal means fuzzy C-Means algorithm for segmentation of brain magnetic resonance images","Clustering based unsupervised segmentation approaches have become important tools to model data and infer knowledge. Such approaches are often used in various biomedical applications to assist experts in analyzing the data. Segmentation of brain magnetic resonance (MR) images has become a very challenging task due to the presence of Rician noise and intensity inhomogeneity. The existing methods dealing with such issues work in the spatial domain. These methods are prone to losing image details while reducing the effect of noise. The proposed method works in the moment domain, and for this purpose, we have selected Zernike moments (ZMs). The ZMs are orthogonal, rotation invariant and robust to image noise. The proposed method is based on our previous work on Zernike moments-based unbiased nonlocal means (ZM-UNLM) approach for denoising MR images affected by the Rician noise. The ZM-UNLM-based approach uses both the local and nonlocal information while eliminating Rician noise from brain MR images which have fine image details along with the noise components. Keeping in view the superior performance of the ZM-UNLM, we extend it to segment brain MR images and propose a method called local ZMs (LZM)-based unbiased nonlocal means fuzzy C-means (LZM-UNLM-FCM) approach which provides much-improved segmentation accuracy as compared to the existing spatial domain-based state-of-the-art techniques. It is shown how the LZMs based technique reduces the effect of the Rician noise while retaining the fine structures, edges, and other image details in the moment domain. The complete framework consists of an intelligent knowledge-driven approach that segments tissues from brain MR images using both the local and nonlocal information in the moment domain. The proposed approach has significance in developing future expert and intelligent systems that do not require any human intervention to manually annotate data and saves time for diagnostic related tasks. Detailed experimental results are provided to demonstrate the superior performance of the proposed method over the existing state-of-the-art methods.","MR image segmentation,Zernike moments,Local Zernike moments,Fuzzy C-means,Rician noise","ChandanSingh,AnuBala","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.023","https://www.sciencedirect.com/science/article/pii/S0957417418306730"
"A269","Mass spectrometric imaging of cysteine rich proteins in human skin","Looking insight pathological processes, metallothioneins (MTs) are considered to be potential biomarkers for monitoring of a development of various types of diseases, such as cancer. The early identification of the MTs in biological tissues could be important tool for the estimation of appropriate clinical therapy. Therefore, here we investigated the application of matrix assisted laser desorption/ionization mass spectrometry imaging (MALDI MSI) together with immunohistochemical analyses (IHC) using MT-1/2 antibody for MT detection in formalin-fixed paraffin-embedded (FFPE) biopsy specimens of human skin. Principal component analyses revealed differences in the peptide/protein profiles separating healthy skin from the carcinoma specimens. Statistically significant ion peaks at m/z 6038, 6300, 6676, and 7026 were more frequently detected in squamous cell carcinoma (SCC), basal cell carcinoma (BCC) and melanoma. Using IHC, we found that MT-1/2 was significantly higher in SCC and melanoma compared to healthy skin. Surprisingly, significantly low levels of MT-1/2 were found in BCC. On one side, the results indicate important role of MTs in melanoma occurrence and progression, as on the second side, there are hidden processes associated with MTs based on differences of the occurrence of the MS peaks, which could be associated with cycling of MTs isoforms.","Metallothionein,Squamous cell carcinoma,Melanoma,MALDI MSI,Immunohistochemistry","LucieVanickovaab,RomanGuranab,SándorKollárc,GabriellaEmrid,SonaKrizkovaab,TomasDoa,ZbynekHegerab,OndrejZitkaab,VojtechAdamab","International Journal of Biological Macromolecules","https://doi.org/10.1016/j.ijbiomac.2018.11.272","https://www.sciencedirect.com/science/article/pii/S0141813018356241"
"A270","Applying moderate or intense low-oxygen dilution combustion to a co-axial-jet I-shaped recuperative radiant tube for further performance enhancement","The major aim of the present work is to use the self-made burner with the co-axial jet pattern to achieve the Moderate or Intense Low-oxygen Dilution (MILD) combustion in a I-shaped Recuperative Radiant Tube (RRT) and demonstrate its potentiality and superiority using experiments. For this end, the performances (e.g. uniformity of tube wall temperature as well as NOX emission) should be first explored using the traditional firing (conventional combustion) mode. The conclusions drawn suggest that, despite considerable efforts to burner optimization, it is still relatively difficult to further improve the performances. As a result, we modified the structure of I-shaped RRT to transfer the mode from conventional to MILD combustion and the remarkable upgraded performances are yielded. Moreover, the MILD combustion characteristics are verified to be governed by three critical factors (i.e., the recirculation ratio KA, flue gas temperature Tf and oxygen volumetric fraction in oxidizer fO2), and the quantitative relationship between the noted three for establishment conditions are discussed. It is found that, increasing fO2 from 0.18 to 0.30 makes the prerequisite KA significantly rise from 0.36 to 0.49 and the corresponding Tf increase from 994<U+202F>K to 1341<U+202F>K, to sustain the MILD combustion mode. Based on the experimental data, the analysis of stability limits suggests the narrowed MILD combustion region with the increase in fO2, especially at the situation of fO2 over 0.25. The results obtained overcame the substantial gap between the MILD technology achievement and co-axial-jet pattern in a narrow and small space. Accordingly, the present work seeks to further effectively extend the establishment mechanism of MILD combustion and theoretically guide the parameter optimization of such a common industrial heating item as the I-shaped RRT.","I-shaped radiant tube,MILD combustion,Recirculation ration,Co-axial jet,Performance optimization","YeTianab,XiongZhoua,XuanyuJia,JisongBaiab,LiangYuanc","Energy","https://doi.org/10.1016/j.energy.2019.01.008","https://www.sciencedirect.com/science/article/pii/S0360544219300106"
"A271","Efficient uncertainty quantification method applied to structural fire engineering computations","Probabilistic Risk Assessment methodologies are gaining traction in fire engineering practice as a (necessary) means to demonstrate adequate safety for uncommon buildings. This induces a need to apply uncertainty quantification to structural fire engineering problems. Yet, the combination of probabilistic methods and advanced numerical fire engineering tools has been limited due to the absence of a methodology which is both efficient (i.e. requires a limited number of model evaluations) and unbiased (i.e. without prior assumptions regarding the output distribution type). In this paper, the recently proposed MaxEnt method is combined with the dedicated structural fire engineering software SAFIR to evaluate the ability of the method to achieve efficient, unbiased assessments of structural fire performance. The case studies include the probability density function (PDF) of (i) the standard fire resistance of a composite column; (ii) the load bearing capacity of a composite floorplate exhibiting tensile membrane action, after 90<U+202F>min of standard fire exposure; (iii) the load bearing capacity of the same composite floorplate, considering a parametric fire exposure including cooling phase; and (iv) the maximum temperature reached in a protected steel element under realistic fire exposure. In the first application, the MaxEnt PDF correctly and efficiently captures the distribution obtained using Monte Carlo Simulations. The floorplate example under parametric fire exposure shows the true strength of the MaxEnt method as an unbiased assessment, as different failure modes are observed in the cooling phase resulting in an irregular shape of the load-bearing capacity PDF. For this case, reliance on a traditional assumption of lognormality for the capacity would result in an overestimation of the capacity at lower quantiles. The last case study yields a bi-modal output due to the physics-based duality between localized (traveling) and post-flashover fire development. While the MaxEnt captures this bi-modality, it does not accurately reproduce the distribution obtained by Monte Carlo Simulation. Limitations of the MaxEnt method and needs for further research are discussed at the end of the paper.","","ThomasGernaya,RubenVan Coileb,NegarElhami Khorasanic,DannyHopkinde","Engineering Structures","https://doi.org/10.1016/j.engstruct.2019.01.002","https://www.sciencedirect.com/science/article/pii/S0141029618322338"
"A272","Quantification of the structure evolution in a garden soil over the course of two years","In this proof-of-concept, we demonstrate the potential of quantifying the structural evolution in an individual soil sample with the help of X-ray imaging. The soil sample was acquired in summer 2013 after a manual seedbed preparation and scanned with X-ray CT on six occasions during the following two years. After each imaging session, the soil sample was re-installed into the field. We focused on analyzing the evolution of soil morphologic measures that are thought to be fundamental to air and water flow in soil. We also quantified deformation of the soil matrix during the experiment. Our results illustrate the effects of several biotic and abiotic processes on the evolution of soil structure. A well-connected inter-aggregate pore network after seedbed preparation was replaced by a sparser network of larger biopores. Macro-faunal burrowing activity generally increased morphological measures associated with larger air and hydraulic conductivity as well as a better aeration. Soil settling and the growth of a dandelion tap-root acted in the opposite direction. Soil settling and compaction continued during the entire experimental period, but was restricted to soil depths below 20<U+202F>mm. Other noteworthy observations that appear worth investigating in follow-up experiments were i.) the strong variation in the critical pore diameter, which could explain the commonly noted large temporal variability of saturated hydraulic conductivity, ii) the much greater extent of lateral compaction due to tap root growth than macro-faunal burrowing, and iii.) the short life-span of large biopores. We conclude that the approach presented here shows great potential for quantifying soil structural dynamics pertaining to individual structure-forming and degrading processes under field conditions. This kind of data could also prove very useful for constructing and testing ‘next-generation’ models that link a dynamic description of soil structure to various processes and functions in the soil-plant system.","","JohnKoestela,SteffenSchlüterb","Geoderma","https://doi.org/10.1016/j.geoderma.2018.12.030","https://www.sciencedirect.com/science/article/pii/S0016706118313144"
"A273","Quantitative structure-activity relationship models for predicting reaction rate constants of organic contaminants with hydrated electrons and their mechanistic pathways","The hydrated electron (eaq-)-based reduction processes are promising for removing organic pollutants in water engineering systems. The reductive kinetics, especially the second order rate constants (keaq-) of eaq- with organic compounds, is important for evaluating and modeling the advanced reduction processes. In this study, the keaq-values for aliphatic compounds and phenyl-based compounds are, for the first time, modeled by the quantitative structure-activity relationship (QSAR) method. The structural features governing the reactivity of two classes of organic compounds toward eaq- were revealed, and the energy of the lowest unoccupied molecular orbital (ELUMO), one-electron reduction potential (ERED) and polarizability (a) were found to be the important molecular parameters in both two models. The built QSAR models provide robust predictive tools for estimating the removal of emerging pollutants using eaq- during wastewater treatment processes. Additionally, quantum chemical calculations were employed to probe into the mechanism and feasibility of the single electron transfer (SET) pathway in the eaq--based reduction process. The thermodynamic investigation suggests that the compounds with electron-withdrawing groups tend to possess higher keaq- and lower Gibbs free energy (<U+0394>GSET) and Gibbs free energies of activation (<U+2206>‡GSET°) than the ones with electron-donating groups, indicating the SET process occurs more readily. It is also found that the refractory halogenated compounds can achieve dehalogenation via the SET pathway.","Hydrated electron (eaq-),Second order rate constants,QSAR models,Single electron transfer,Quantum chemical calculation","ChaoLia,ShanshanZhenga1,TiantianLia,JingwenChenb,JunhuiZhoua,LiminSua,Ya-NanZhanga,John C.Crittendenc,SuiyiZhua,YuanhuiZhaoa","Water Research","https://doi.org/10.1016/j.watres.2018.12.010","https://www.sciencedirect.com/science/article/pii/S0043135418310248"
"A274","Bovine eggs release zinc in response to parthenogenetic and sperm-induced egg activation","Upon fertilization or parthenogenesis, zinc is released into the extracellular space through a series of exocytic events termed zinc sparks, which are tightly coordinated with intracellular calcium transients. The zinc spark reduces the total amount of intracellular zinc, and this reduction is necessary and sufficient to induce egg activation even in the absence of calcium transients. In addition, this zinc release contributes to the block to polyspermy through modification of the zona pellucida. The zinc spark has been documented in all organisms examined to date including the mouse, two species of nonhuman primates, and human. Here we determined whether zinc sparks occur in the bovine, an important model of gamete development in mono-ovulatory mammalian species. We obtained metaphase II-arrested (MII) bovine eggs following in vitro maturation. Total zinc, assessed in single cells using X-Ray Fluorescence Microscopy, was significantly more abundant in the bovine egg compared to iron and copper. Studies with intracellular fluorescent probes revealed that labile zinc pools are localized to discrete cytoplasmic punctae enriched at the cortex. To determine whether zinc undergoes dynamic fluxes during egg activation, we parthenogenetically activated bovine eggs using two approaches: ionomycin or bovine phospholipase C zeta (bPlc<U+03B6>). Both these methods induced zinc sparks coordinately with intracellular calcium transients. The zinc spark was also observed in bovine eggs following intracytoplasmic sperm injection. These results establish that zinc is the most abundant transition metal in the bovine egg, and zinc flux during egg activation - induced by chemical activation or sperm - is a highly conserved event across mammalian species.","Bovine,Egg activation,Zinc,Calcium,Gamete","Emily L.Quea1,Francesca E.Duncanb1,Hoi ChangLeeb1,Jessica E.Hornickb,StefanVogtc,Rafael A.Fissored,Thomas V.O'Halloranaef,Teresa K.Woodruffabf","Theriogenology","https://doi.org/10.1016/j.theriogenology.2018.12.031","https://www.sciencedirect.com/science/article/pii/S0093691X18309117"
"A275","The passion fruit liana (Passiflora edulis Sims, Passifloraceae) is tolerant to ozone","Passiflora edulis Sims is a liana species of high economic interest and is an interesting model plant for understanding ozone action on disturbed vegetation. In this work we hypothesized that P. edulis has adaptive responses to oxidative stress that enable it to tolerate ozone damage based on its capacity to grow under a diversity of environmental conditions and to dominate disturbed areas. We exposed seedlings to three levels of ozone in a Free-Air Controlled Exposure (FACE) system (22, 41 and 58<U+202F>ppb<U+202F>h AOT40 and 13.52, 17.24 and 20.62<U+202F>mmol<U+202F>m-2 POD0, over 97<U+202F>days) for identifying its tolerance mechanisms. Anatomical (leaf blade structure and fluorescence emission of chloroplast metabolites), physiological (leaf gas exchange, growth rate and biomass production) and biochemical (pigments, total sugars, starch, enzymatic and non-enzymatic antioxidant metabolites, reactive oxygen species and lipid peroxidation derivatives) responses were assessed. Ozone caused decreased total number of leaves, hyperplasia and hypertrophy of the mesophyll cells, and accelerated leaf senescence. However, O3 did not affect carbohydrates content, net photosynthetic rate, or total biomass production, indicating that the carboxylation efficiency and associated physiological processes were not affected. In addition, P. edulis showed higher leaf contents of ascorbic acid, glutathione (as well high ratio between their reduced and total forms), carotenoids, and flavonoids located in the chloroplast outer envelope membrane. Our results indicate that P. edulis is an O3-tolerant species due to morphological acclimation responses and an effective antioxidant defense system represented by non-enzymatic antioxidants, which maintained the cellular redox balance under ozone.","Anatomical acclimatization,Antioxidant system,Liana,Oxidative stress,Polyphenols,Tropical environment,Vine species","Francine FaiaFernandesa,Marisia PanniaEspositoa,Marcela Regina Gonçalvesda Silva Engelaa,PolianaCardoso-Gustavsonb,Claudia MariaFurlanc,YasutomoHoshikad,ElisaCarrarid,GiadaMagnid,MarisaDomingosa,ElenaPaolettid","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.11.425","https://www.sciencedirect.com/science/article/pii/S0048969718347806"
"A276","A reflectionless discrete perfectly matched layer","Perfectly Matched Layer (PML) is a widely adopted non-reflecting boundary treatment for wave simulations. Reducing numerical reflections from a discretized PML has been a long lasting challenge. This paper presents a new discrete PML for the multi-dimensional scalar wave equation which produces no numerical reflection at all. The reflectionless discrete PML is discovered through a straightforward derivation using Discrete Complex Analysis. The resulting PML takes an easily-implementable finite difference form with compact stencil. In practice, the discrete waves are damped exponentially in the PML, and the error due to domain truncation is maintained at machine zero by a moderately thick PML. The numerical stability of the proposed PML is also demonstrated.","Perfectly matched layers,Absorbing boundary,Discrete complex analysis,Scalar wave equation","AlbertChern","Journal of Computational Physics","https://doi.org/10.1016/j.jcp.2018.12.026","https://www.sciencedirect.com/science/article/pii/S0021999119300075"
"A277","Applying mutual information for discretization to support the discovery of rare-unusual association rule in cerebrovascular examination dataset","In knowledge discovery studies, association rules mining has been extensively studied to discover hidden knowledge and relationships among set of items in a transactional dataset. Most research on association rule mining focuses on discovering frequent patterns based on the most frequent items occurring in the dataset. However, the process of extracting rare rules has received less attention. In medical dataset studies, the discovery of rare association rules (RARs) is more challenging, because it could likely be used to obtain more potentially rare and unusual knowledge for physicians, beside frequent association rules. Hence, the aim of this paper is to discover non-frequent or rare-unusual association rules (RUARs) from a stroke medical dataset to provide potential meaningful knowledge to the user domain.A discretization method needs to be performed as the data preprocessing step before generating rules. To the best of our knowledge, fewer studies have focused on the role of discretization results to support the extraction of a better amount and quality of RUARs, particularly for medical datasets. In addition, the extracted RUARs is expected to provide potential new unusual insights on stroke risk patterns. This paper applies mutual information measure to discretize a stroke examination dataset collected from a medical center in Taiwan. The interval merging method was proposed to simplify the discrete form and enrich the quality of generated rules. Towards the end, rare association rules, with relatively low support, were generated by employing the Apriori-Rare method accordingly. In addition, a filtering process was applied to the content of the rule itemsets to discover the expected set of RUARs for physicians. Furthermore, the extracted RUARs was analyzed based on the relative risk values toward the occurrence of stroke.Results indicated that the mutual information discretization outperformed the traditional discretization methods in terms of how the discretization scheme can support the extraction of RUARs with a better quantity and quality measurements for further analysis purpose in medical point of view. Moreover, the proposed method had a relatively higher number of RUARs. The knowledge of unusual rule patterns from rare association rules might provide potential new and unusual insights for medical pratitioners and increase the awareness of stroke examination results.","Rare-unusual association rules,Discretization,Apriori-Rare,Data mining,Cerebrovascular disease","Chandrawati PutriWulandariab,Ou-YangChaoa,WangHan-Chengcde","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.09.044","https://www.sciencedirect.com/science/article/pii/S0957417418306213"
"A278","Optimal learning group formation: A multi-objective heuristic search strategy for enhancing inter-group homogeneity and intra-group heterogeneity","In modern education systems, plenty of research suggests that clustering the learners into optimal learning groups based on their multiple characteristics is a determining effort in enhancing the effectiveness of collaborative learning. Although there have been several evidences on developing and implementing appropriate computational tools to handle classification processes in expert and intelligent systems, the effectiveness and accuracy of optimal grouping algorithms are still worth improving. For instance, the majority of grouping processes in collaborative learning environments is orchestrated through single-objective optimization algorithms, which need to be revisited due to some intrinsic limitations. In this paper, we propose a novel algorithm capable of properly addressing a variety of optimization problems in optimal learning group formation processes. To this end, a multi-objective version of Genetic Algorithms, i.e. Non-dominated Sorting Genetic Algorithm, NSGA-II, was successfully implemented and applied to improve the performance and accuracy of optimally formed learning groups. In contrast to the previous related works applying single-objective algorithms, the main advantage of our work is simultaneous satisfaction of multiple targets predefined for the formation of optimal learning groups, especially the inter-homogeneity and intra-heterogeneity of each learning group, which significantly enhance both effectiveness and accuracy of optimal grouping processes in the underlying intelligent systems. Challenging the proposed optimization algorithms, both single- and multi-objective optimizers, with a similar grouping problem, clearly proved that the single-objective optimization technique has limited control and sensitivity to the quality of individual groups. Contrary to single-objective optimization techniques, which are mainly governed by adjusting the quality of the groups altogether in average, the proposed multi-objective algorithm not only takes the average desirability of all formed groups into account but also precisely monitors the fitness of each group in a potential solution distinctively. The generality of the proposed algorithm makes it a suitable candidate not only to handle optimal grouping in learning environments but also to be competent enough for grouping problems in other domains as well.","Group formation,Multi-objective optimization,Collaborative learning,Inter-group homogeneity,Intra-group heterogeneity,Computational intelligence","SoheilaGarshasbia,YousefMohammadib,SabineGrafc,SamiraGarshasbid,JunShene","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.034","https://www.sciencedirect.com/science/article/pii/S0957417418306845"
"A279","Gene cloning, expression, molecular modeling and docking study of the protease SAPRH from Bacillus safensis strain RH12","The sapRH gene, which encodes the serine alkaline protease SAPRH, from Bacillus safensis RH12, was isolated and its DNA sequence was determined. The deduced amino-acid sequence showed strong homology with other Bacillus proteases. The highest sequence identity value (97%) was obtained with SAPB from B. pumilus CBS, with only 9 amino-acids of difference. The region, encoding SAPRH was heterologously expressed in E. coli BL21-AI™ cells using GATEWAY™ pDEST™17 expression-vector. The recombinant (His)6-tag enzyme (His6-rSAPRH) was purified in a single affinity chromatography step and its biochemical properties were determined and compared to those of SAPRH and rSAPB. Interestingly, His6-rSAPRH showed improved thermostability compared to SAPRH and rSAPB. The molecular dynamics of SAPRH compared to SAPB revealed a more thermostable structure, thus confirming the in vitro results showing that His6-rSAPRH has a t1/2 of 120<U+202F>min against 90 and 30<U+202F>min for SAPRH and rSAPB, respectively, at 70<U+202F>°C and different kinetic parameters to synthetic peptides. The docking simulations data allow in getting an insight into the involvement of some key amino-acids in substrate binding and account for the selectivity. Overall, this is the first report of a sapRH gene cloned from B. safensis which can be a promising potential candidate for future applications in detergent formulations.","Bacillus safensis,Protease,Expression,Homology modeling,Docking simulations","HatemRekikabc,FakherFrikhaa,NadiaZaraî Jaouadiab,FaresGargouria,NajahJmalc,SamirBejarab,BassemJaouadiab","International Journal of Biological Macromolecules","https://doi.org/10.1016/j.ijbiomac.2018.12.103","https://www.sciencedirect.com/science/article/pii/S0141813018349845"
"A280","Draft genome analysis of lignocellulolytic enzymes producing Aspergillus terreus with structural insight of ß-glucosidases through molecular docking approach","Members of the genus Aspergillus are extensively studied ascomycetes because of their ability to synthesize high value-added compounds and enzymes of industrial interest. Precise whole genome assembly and gene annotation are significant for gene functional analyses. Here, we report the draft genome sequencing, assembly and whole genome analysis of Aspergillus terreus P14_T3, isolated from rumen sample of cattle fed with coconut-coir. A total of 13,340 protein-coding genes were predicted, among them 493 are involved in degradation of complex carbohydrate polysaccharides. Further, it was found that 29 genes, encoding ß-glucosidase belong to Glycosyl hydrolase (GH) family 1 (3 gene), 3 (17 gene), 5 (4 gene), 17 (3 gene), 132 (2 gene). The tertiary structure of all the ß-glucosidases was designed by homology modeling; modeled structure AtBgl1.3 (GH1), AtBgl3.1 (GH3), AtBgl5.4 (GH5), AtBgl17.1 (GH17) show classical (a/ß) TIM-like barrel motif. Molecular docking of different ß-glucosidases with cellobiose revealed that conserved amino acids i.e. Glu, Trp, Arg, His, Tyr and Asp are taking part in substrate hydrolysis. Moreover, some other amino acids i.e. Ser, Phe, Gln and Asn are found to be involved in hydrogen bond formation and catalysis. These findings may provide valuable insights in designing ß-glucosidases with higher cellulose-hydrolyzing efficiency.","Draft genome sequencing,Homology modeling,Molecular docking","TriptiDadheecha,SubhashJakhesarab,Prakram SinghChauhanc,RameshPanditb,AnkitHinsub,AnjuKunjadiyad,DharamshibhaiRanka,ChaitanyaJoshib","International Journal of Biological Macromolecules","https://doi.org/10.1016/j.ijbiomac.2018.12.020","https://www.sciencedirect.com/science/article/pii/S0141813018349420"
"A281","Flexible, durable and thermal conducting thiol-modified rGO-WPU/cotton fabric for robust electromagnetic interference shielding","In this paper, we proposed a novel method to fabricate thiol-modified reduced graphene oxide-waterborne polyurethane/cotton (M-rGO-WPU/cotton) fabric that provided a robust electromagnetic interference (EMI) shielding performance and excellent thermal conductivity. The WPU molecules with ene groups at the both ends were synthesized and acted as a polymer matrix to connect the rGO and cotton substrate with the thiols via the synchronous thiol-ene click reaction, respectively. The introduction of click reaction effectively improved the durability in its practical daily use, realizing the true meaning of all-in-one structure. The results of Raman, FTIR and XRD confirmed the preparation route and chemical compositions. The SEM images and EDS mapping illustrated that a uniform and thin M-rGO-WPU film was attached tightly on cotton fiber. The conductive interconnected network in M-rGO-WPU/cotton imparted it with excellent electrical conductivity and enhanced mechanical properties. The EMI shielding effectiveness of M-rGO-WPU/cotton reached 48.1<U+202F>dB, which was superior to that of rGO-WPU/cotton with a thickness of ~1<U+202F>mm at only 2<U+202F>wt% nanofillers loadings. The high electromagnetic shielding performance of M-rGO-WPU/cotton was attributed to strong dielectric loss, more interfaces for multiple reflections and scattering. Furthermore, the performance related to practical application including high capability of heat transmission, durability, flexibility and processability were also investigated and showed its great potential in advanced EMI shielding applications.","Shielding effectiveness,Thermal conductivity,Thiol-ene click reaction,Reduced graphene oxide (rGO),Waterborne polyurethane (WPU)","YuWanga,WeiWangab,RuiXua,MeifangZhua,DanYua","Chemical Engineering Journal","https://doi.org/10.1016/j.cej.2018.12.045","https://www.sciencedirect.com/science/article/pii/S1385894718325178"
"A282","Analysis of viral and bacterial communities in groundwater associated with contaminated land","This work aimed at the comprehensive analysis of total microbial communities inhabiting a typical hydrocarbon-polluted site, where chemical characteristics of the groundwater were readily available. To achieve this, a joint metagenomic characterization of bacteria and viruses surrounding a contaminant plume was performed over a one-year period. The results presented demonstrated that both potential hydrocarbon degraders and their bacteriophages were dominant around the plume, and that the viral and bacterial diversities found at the site were probably influenced by the pH of the groundwater. Niche-specific and dispersed associations between phages and bacteria were identified. The niche phage-host associations were found at the edge of the site and at the core of the plume where pH was the highest (9.52). The identified host populations included several classes of bacteria (e.g. Clostridia and Proteobacteria). Thirty-six viral generalists were also discovered, with BGW-G9 having the broadest host range across 23 taxa, including Pseudomonas, Polycyclovorans, Methylocaldum and Candidatus Magnetobacterium species. The phages with broad host ranges are presumed to have significant effects on prokaryotic production and horizontal gene transfer, and therefore impact the biodegradation processes conducted by various bacteria of the environment studied. This study for the first time characterized the phages and their bacterial hosts associated with a contaminant plume.","Bacteria,Bacteriophages,Water resources,Gasworks,Bioremediation,Metagenomics","RicardoCosteiraa,RoryDohertyb,Christopher C.R.Allenac,Michael J.Larkina,Leonid A.Kulakova","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.11.429","https://www.sciencedirect.com/science/article/pii/S0048969718347879"
"A283","Multilayered Maxwell’s fisheye lens as waveguide crossing","The Maxwell’s fisheye (MFE) lens, due to its focusing properties, is an interesting candidate for implementing the crossing of multiple waveguides. The MFE lens is implemented by two different structures: concentric cylindrical multilayer and radially diverging gourd-shaped rods. Realization of the refractive index profile of the lens is achieved by controlling the thickness ratio of the alternating Si and SiO2 layers determined by effective medium theory. Both structures are optimized to cover the entire C-band in the single mode implementation. The transmission efficiency of the ring-based structure is superior to the radial-based implementation, however, the radial-based structure almost covers the entire U-band as well. Other communication bands are partially covered in both cases. Full-wave simulations prove that the performance of multimode waveguide crossing based on the MFE lens with a radius of 2.32µm is promising with the average insertion loss of 0.17 dB and crosstalk levels below -24.2 dB in the C-band for TM0 and TM1 modes. The multimode intersection almost covers the entire C, L, and U bands of optical communication.","Photonic crystal,Multimode waveguide crossing,Maxwell’s fisheye lens,Multilayer metamaterial,Gradient index lens,Effective medium theory","M.M.Gilarluea,J.Nouriniaa,Ch.Ghobadia,S. HadiBadrib,H.Rasooli Saghaic","Optics Communications","https://doi.org/10.1016/j.optcom.2018.11.057","https://www.sciencedirect.com/science/article/pii/S003040181831023X"
"A284","A hybrid route planning approach for logistics with pickup and delivery","With the busy life of modern people, more and more consumers are preferring to shop online. This change on shopping behavior results in large volumes of packages must be transported, and thus research on logistics planning considering real constraints has increased. To solve this problem, several heuristics or evolutionary methods with expert knowledge were proposed previously, but they are usually inefficient or need a large amount of memory. In this paper, we propose a hybrid approach called Iterative Logistics Solution Planner (ILSP) for not only quickly finding a nice logistics solution but also iteratively improving the solution quality while meeting the real logistics constraints. ILSP contains two main phases including initial logistics solution generation and iterative logistics solution improvement based on the intelligence and knowledge from domain experts. Several algorithms and strategies are designed in ILSP for package partitioning, route planning and quality improvement. From the view of expert systems, the significance and impact of ILSP are simultaneously taking both computational efficiency and iterative quality improvement based on the expert knowledge into account on logistics planning problem with pickup and delivery. Through the rigorous experimental evaluations of real logistics data, the results demonstrated the excellent performance of ILSP.","Hybrid approach,Logistics planning,Smart city,Expert system","Eric Hsueh-ChanLu,Ya-WenYang","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.031","https://www.sciencedirect.com/science/article/pii/S095741741830681X"
"A285","Activity-dependent development of GABAergic synapses","In the brain, dendrites of pyramidal neurons contain intermingled excitatory and inhibitory synapses. Synaptic connections dynamically change during development and throughout our lifetime, yet the brain can properly maintain an optimal ratio of synaptic excitation to inhibition. Despite recent advances in our understanding of the formation and refinement of excitatory glutamatergic synapses, little is known about signals that regulate inhibitory GABAergic synapse development. In this review, we discuss previous and recent insights in the cellular and molecular mechanisms that underlie GABAergic synapse formation and plasticity, with a specific focus on the key roles of synaptic activity and postsynaptic membrane molecules.","GABA,GABAergic synapse,GABAA receptors,Synapse development,Synapse plasticity,Synaptogenic cell adhesion molecules","Won ChanOh,Katharine R.Smith","Brain Research","https://doi.org/10.1016/j.brainres.2018.11.014","https://www.sciencedirect.com/science/article/pii/S0006899318305663"
"A286","Evaporation and instability of an unbounded-axisymmetric liquid bridge between chemically similar and different substrates","HypothesisIn this manuscript we examine the stability of an evaporating-unbounded axisymmetric liquid bridge confined between parallel-planar similar or chemically different substrates using both theory and experiments. With a quasistatic assumption we use hydrostatics to estimate the minimum stable volume Vmin via the Young-Laplace equation for Bond numbers 0<U+2A7D>Bo<U+2A7D>1, and top/bottom wall contact angles 5°<<U+03B8><175° although the primary focus is on wetting and partial wetting fluids. Solving the Young-Laplace equation requires knowledge of appropriate capillary pressure values, which appear as a constant, and may not provide unique solution. To examine uniqueness of numerical solutions and volume minima determined from the Young-Laplace equation for unbounded-axisymmetric liquid bridges we analyzed capillary pressure for large and small liquid volume-asymptotic limits at zero Bond number.,ExperimentsExperiments were performed to compare with the volume minima calculations for Bond numbers 0.04<U+2A7D>Bo<U+2A7D>0.65. Three substrates of varying surface energy were used, with purified water as the primary liquid. Volume estimates and contact angle data were extracted via image analysis and evaporation rates measured from this data are reported.,FindingsVolume minima were in the range 0.1<Vmin<20<U+202F>µl depending on Bond number. There was good agreement when comparing predicted volume minima and those determined from experiments for the range of parameters studied.","Evaporation,Liquid-bridge,Capillary,Young-Laplace,Wetting","TejaswiSoori,ThomasWard","Journal of Colloid and Interface Science","https://doi.org/10.1016/j.jcis.2018.12.025","https://www.sciencedirect.com/science/article/pii/S0021979718314590"
"A287","Synthesis, structural characterization, DFT calculations and antiproliferative evaluation of novel spirohydantoin derivatives containing a substituted benzyl moiety","Two series of cycloalkanespiro-5-hydantoins, namely cyclohexanespiro-5-hydantoins and cycloheptanespiro-5-hydantoins with a 4-substituted benzyl or a 2-(4-substituted phenyl)-2-oxoethyl group at N3 position, were synthesized and their effects on proliferation of human colon (HCT-116), leukemia (K562) and breast (MDA-MB-231) cancer cell lines were tested. For comparison, we also described the 5,5-diphenylhydantoin analogues. The structural features of the investigated compounds were characterized by elemental analysis, FT-IR, UV–Vis, 1H and 13C NMR spectroscopy and X-ray crystallography. Regarding their structure–activity relationships, it was shown that the substitution on the benzyl moiety with the methoxy, chloro or bromo group potentiated the antiproliferative activity relative to the parent compounds, while an increase in the size of the cycloalkyl group resulted mostly in a decrease of the antiproliferative activity. The single crystal X-ray analysis revealed the existence of dimers and chains formed by the NH<U+22EF>O hydrogen bonds. The analysis of the molecular descriptors of Lipinski demonstrated that all investigated compounds obeyed the rule of five. To further understand their geometry and electronic structure, DFT calculations with B3LYP method using 6-311++G(d,p) basic set were performed. In this context, the UV–Vis spectra of the investigated compounds were analyzed in detail, whereby the predicted absorption spectra from DFT calculation matched the experimentally obtained ones, with a good correlation. The interesting physico-chemical and pharmacologically relevant properties of the investigated compounds warrant their further investigation.","Spirohydantoin,Antiproliferative activity,X-ray structure determination,DFT calculation","Anita M.Lazica,Lidija D.Radovanovica,Bojan Ð.Božicb,Biljana Ð.Božic Nedeljkovicb,Vesna D.Vitnikc,Željko J.Vitnikc,Jelena R.Rogand,Nataša V.Valenticd,Gordana S.Ušcumlicd,Nemanja P.Trišovicd","Journal of Molecular Structure","https://doi.org/10.1016/j.molstruc.2018.11.071","https://www.sciencedirect.com/science/article/pii/S002228601831384X"
"A288","Neutron grating interferometry investigation of punching-related local magnetic property deteriorations in electrical steels","Mechanical residual stress induced by manufacturing influences the magnetic behavior of non-grain oriented electrical steels, which are used for producing rotors and stators of electrical machines. The impairment occurs mainly along the cutting line of stator and rotor laminations. A locally resolved assessment of the magnetic material behavior of punched electrical steels is possible by using the neutron grating interferometry. In addition to this in situ measurement method, additional ex-situ measurements allow correlating local domain wall mobility and global magnetic polarization. Four different non-grain oriented electrical steels are investigated in this paper. This includes two sheet thicknesses of 0.35<U+202F>mm and 0.65<U+202F>mm both available having silicon contents of 2.30<U+202F>wt-% as well as 2.74<U+202F>wt-%. The specimens are produced by wire cutting and by punching using different process parameters, i.e., two relative cutting clearances of 5% and 10% plus a sharp and worn cutting edge wear state. The cutting method’s influence on the four different electrical steel’s magnetic behavior is discussed with respect to the local polarization distributions at varying magnetic field strengths next to the cutting lines. This novel approach for the first time allows an in situ investigation of altered magnetic properties with respect to the punching induced residual stress along the cutting line. Not only the maximum deterioration of the polarization next to the cutting line but also the extent of the magnetic property deterioration is pointed out. The effect of punching parameter variations is further verified using global magnetic measurements. The knowledge about the local polarization distribution next to the cutting line is critical for an improved development and design of electrical machines.","Punching,Shear cutting,Residual stress,Non-oriented electrical steel,Magnetic property degradation,Neutron grating interferometry","H.A.Weissa,S.Steentjesb,P.Tröbera,N.Leuningb,T.Neuwirthc,M.Schulzc,K.Hameyerb,R.Gollea,W.Volka","Journal of Magnetism and Magnetic Materials","https://doi.org/10.1016/j.jmmm.2018.10.098","https://www.sciencedirect.com/science/article/pii/S0304885318318201"
"A289","Squeal analysis based on the laboratory experimental bench “Friction-Induced Vibration and noisE at École Centrale de Lyon” (FIVE@ECL)","This paper presents a new experimental test bench, called Friction-Induced Vibration and noisE at École Centrale de Lyon (FIVE@ECL). This experimental bench aims at discussing some of the open issues in understanding squealing disc brakes. Measurements for friction-induced vibration and squeal noise are performed to investigate the dynamic behavior of the system under study and its squeal characterization through experiments.One of the main original contributions is to share the data sets to give the opportunity to researchers for conducting new analysis and testing numerical models of brake system with the proposed data of squeal noise. The data provided include all the measurements on the two pads, the caliper and the disc, as well as the measurement of pressure in near-field and in far-field.","Experiments,Friction-induced vibration,Squeal noise,Brake system,Open data","J-J.Sinouab,D.Lenoira,S.Besseta,F.Gillota","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.07.006","https://www.sciencedirect.com/science/article/pii/S0888327018304072"
"A290","Queuing theory guided intelligent traffic scheduling through video analysis using Dirichlet process mixture model","Intelligent traffic signaling is an important part of city road traffic management systems. In many countries, it is done through supervised/semi-supervised ways. With the advances in computer vision and machine learning, it is now possible to develop expert systems guided intelligent traffic signaling systems that are unsupervised in nature. In order to schedule traffic signals, it is essential to learn the traffic characterization parameters such as the number of vehicles, their arrival and departure rates, etc. In this work, we use unsupervised machine learning with the help of a modified Dirichlet Process Mixture Model (DPMM) to measure the aforementioned traffic parameters. This has been done using a new feature, named temporal clusters or tracklets extracted using DPMM. Detailed analysis on tracklet behavior during signal on/off period has been carried out to derive a queuing theory-based method for signal duration prediction. The queuing behavior at a junction is analyzed using tracklets for understanding their applicability. Queue clearance time at the junction has been used for predicting the signal duration with the help of Gaussian regression of historical data.Two publicly available video datasets, namely QMUL and MIT have been used for verification of the hypothesis. The mean absolute error (MAE) of the proposed method using tracklets has been reduced by a factor of 2.4 and 6.3 when compared with the tracks generated using Kernel Correlation Filters (KCF) and Kanade–Lucas–Tomasi (KLT), respectively. Through experiments, we are also able to establish that KCF and KLT tracks do not consider spatial occupancy of the vehicles on roads, leading to error in the estimation. The results reveal that the proposed queuing theory-based approach predicts the signal duration for the next cycle more accurately as compared to the ground truths. The method can be used for building intelligent traffic control systems for roadway junctions in cities and highways.","Traffic intersection management,Signal duration prediction,Dirichlet process,Queuing theory,Unsupervised learning,Visual surveillance","SanthoshKelathodi Kumarana,DebiProsad Dograa,ParthaPratim Royb","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.09.057","https://www.sciencedirect.com/science/article/pii/S0957417418306420"
"A291","Hybrid artificial intelligence models based on a neuro-fuzzy system and metaheuristic optimization algorithms for spatial prediction of wildfire probability","This study provides a new comparative analysis of four hybrid artificial intelligence models for the spatially explicit prediction of wildfire probabilities. Each model consists of an adaptive neuro-fuzzy inference system (ANFIS) combined with a metaheuristic optimization algorithm, i.e., genetic algorithm (GA), particle swarm optimization (PSO), shuffled frog leaping algorithm (SFLA), and imperialist competitive algorithm (ICA). A spatial database was constructed based on 159 fire events from the Hyrcanian ecoregion (Iran) for which a suite of predictor variables was derived. Each predictor variable was discretized into classes. The step-wise weight assessment ratio analysis (SWARA) procedure was used to assign weights to each class of each predictor variable. Weights indicate the strength of the spatial relationship between each class and fire occurrence and were used for training the hybrid models. The hybrid models were validated using several performance metrics and compared to the single ANFIS model. Although the single ANFIS model outperformed the hybrid models in the training phase, its accuracy decreased considerably in the validation phase. All hybrid models performed well for both training and validation datasets, but the ANFIS-ICA hybrid showed superior predictive performance of spatially explicit wildfire prediction and mapping for the dataset. The results clearly demonstrate the ability of the optimization algorithms to overcome the over-fitting problem of the single ANFIS model at the learning stage of the fire pattern. This study contributes to the suite of research that seeks to obtain reliable estimates of relative likelihoods of natural hazards.","Genetic algorithm (GA),Particle swarm optimization (PSO),Shuffled frog leaping algorithm (SFLA),Imperialist competitive algorithm (ICA),Wildfire prediction,Hyrcanian ecoregion","AbolfazlJaafaria,Eric K.Zennerb,MahdiPanahic,HimanShahabid","Agricultural and Forest Meteorology","https://doi.org/10.1016/j.agrformet.2018.12.015","https://www.sciencedirect.com/science/article/pii/S0168192318304088"
"A292","Time-of-day-dependent behavior of surficial lunar hydroxyl/water: Observations and modeling","In this study we determine the depth of the absorption band around 3 µm wavelength, which indicates the presence of OH/H2O in a thin surficial layer of the lunar regolith, for 18 lunar highland regions observed by the Moon Mineralogy Mapper (M3) instrument at 4–8 different local times of day. For removing the thermal emission component, a physically motivated thermal equilibrium based method is used, which also takes into account the roughness of the regolith surface. We propose a continuity equation based model of the time-of-day-dependent column densities of surficial atomic hydrogen (H) and hydroxyl (OH). The considered source processes for H are implantation of solar wind protons and photolysis of OH, and for OH the reaction H+O<U+2192>OH. Sink processes are diffusive loss for H and OH, and photolysis for OH. Sputtering of H and OH is found to be negligible in comparison to the other sink processes. Additionally, we suggest a similar differential equation based model to describe the time-of-day-dependent behavior of micrometeoroid-delivered OH and H2O. The observed 3 µm band depth values indicate that the surficial OH/H2O does not vanish even at local midday at low latitudes, while the model predicts nearly complete removal of surficial OH/H2O at midday. This apparent contradiction between model and observations is reconciled by adding to the model a region-specific “offset” OH component which is assumed to be stable against diffusive loss and photolysis and is therefore interpreted as a strongly bounded OH component. Meteoroid bombardment is found to be negligible in comparison with the solar wind source of OH. Fitting the model to the observed 3 µm band depth values allows for estimating the H activation energy, the OH photolysis time, region-specific values of the offset OH component, and the proportionality factor between OH column density and 3 µm band depth. The observed time-of-day-dependent behavior of the 3 µm band depth at low and high latitudes can be explained convincingly by the modeled source and sink processes. The best-fit OH photolysis time is much shorter than the lunar day and corresponds to 1–3 times the gas-phase value, which indicates that photolysis is a mechanism of high relevance for the behavior of solar wind induced surficial OH. The surface roughness assumed in the M3 data analysis does not have a major influence on the modeling results. The strongly bounded OH component is nearly latitude-independent for low latitudes but decreases sharply for high latitudes. As a possible mode of origin, we suggest slow diffusion of solar wind induced OH to depths inaccessible for ultraviolet photons and into binding states of higher energy, counteracted by sputtering.","Moon,Hydroxyl,Water,NIR reflectance spectroscopy,Column density modeling,Solar wind,Diffusive loss,Photolysis,Surface roughness","ArneGrumpea,ChristianWöhlera,Alexey A.Berezhnoyb,Vladislav V.Shevchenkob","Icarus","https://doi.org/10.1016/j.icarus.2018.11.025","https://www.sciencedirect.com/science/article/pii/S0019103517305572"
"A293","Excited state dipole moment of the fluorescein molecule estimated from electronic absorption spectra","The solvatochromic study of fluorescein is performed in order to obtain information on both the interactions with solvents in which it is dissolved and the electro-optical parameters of the molecule in the first excited electronic state. The shifts of the visible absorption spectral band of fluorescein dissolved in several solvents were experimentally measured and correlated to solvent parameters such as the refractive index, electrical permittivity and the Kamlet-Taft parameters (hydrogen bond acidity and basicity, respectively). A quantum-mechanical study of the fluorescein molecule was additionally performed to determine some parameters of the fluorescein molecule in the ground electronic state. Following McRae's hypothesis, according to which the molecular polarizability does not change in the absorption process, the data obtained from the solvatochromic analysis and quantum-mechanical calculations were corroborated in order to estimate the dipole moment of fluorescein in its first excited electronic state.","Fluorescein,Solvatochromism,Quantum-mechanical characterization,Dipole moment in the first excited electronic state","Ana CezarinaMorosanu,Dan GheorgheDimitriu,Dana OrtansaDorohoi","Journal of Molecular Structure","https://doi.org/10.1016/j.molstruc.2018.12.057","https://www.sciencedirect.com/science/article/pii/S0022286018314844"
"A294","Fully automated multi-parametric brain tumour segmentation using superpixel based classification","This paper presents a fully automated brain tissue classification method for normal and abnormal tissues and its associated region from Fluid Attenuated Inversion Recovery modality of Magnetic Resonance (MR) images. The proposed regional classification method is able to simultaneously detect and segment tumours to pixel-level accuracy. The region-based features considered in this study are statistical, texton histograms, and fractal features. This is the first study to address the class imbalance problem at the regional level using Random Majority Down-sampling-Synthetic Minority Over-sampling Technique (RMD-SMOTE). A comparison of benchmark supervised techniques including Support Vector Machine, AdaBoost and Random Forest (RF) classifiers is presented, where the RF-based regional classifier is selected in the proposed approach due to its better generalization performance. The robustness of the proposed method is evaluated on the standard publicly available BRATS 2012 dataset using five standard benchmark measures. We demonstrate that the proposed method consistently outperforms three benchmark tumour classification methods in terms of Dice score and obtains significantly better results as compared to its SVM and AdaBoost counterparts in terms of precision and specificity at the 5% confidence interval. The promising results of the proposed method support its application for early detection and diagnosis of brain tumours in clinical settings.","Brain tumour,Segmentation,Localization,FLAIR,Support vector machine,Random forest classifier,BRATS","Zaka UrRehmana,Syed S.Naqvia,Tariq M.Khana,Muhammad A.Khanb,TariqBashira","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.040","https://www.sciencedirect.com/science/article/pii/S0957417418306985"
"A295","TCFACO: Trust-aware collaborative filtering method based on ant colony optimization","Recommender systems (RSs) aim to help users to find relevant information based on their preferences instead of searching through extensive volume of information using search engines. Accurate prediction of unknown ratings is one of the key challenges in the analysis of RSs. Collaborative Filtering (CF) is a well-known recommendation method that estimates missing ratings by employing a set of similar users to the target user. An outstanding topic in CF is picking out an appropriate set of users and using them in the rating prediction process. In this paper, a novel CF method is proposed to predict missing ratings accurately. The proposed method called TCFACO uses trust statements as a rich side information with Ant Colony Optimization (ACO) method. TCFACO consists of three main steps. In the first step, users are ranked considering available rating values and social trust relationships. Then, in the second step, the ACO method is utilized to assign proper weight values to users to show how they are similar to the target user. A set of top similar users is filter out in the third step to be used in predicting unknown ratings for the target user. In other words, to speed up identifying similar users, the proposed method first filters out a majority part of dissimilar users and then runs the ACO on only a reduced set of users to weight them. Several experiments were performed on three real-world datasets to evaluate the effectiveness of the proposed method and the results show that the proposed method performs better than the state-of-the-art methods.","Collaborative filtering,Recommender systems,Social trustinformation,Similarity measures,Ant colonyoptimization","HashemParvina,ParhamMoradia,ShahrokhEsmaeilib","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.09.045","https://www.sciencedirect.com/science/article/pii/S0957417418306225"
"A296","A new graphic kernel method of stock price trend prediction based on financial news semantic and structural similarity","Lots of researches try to predict the stock price movement using financial news based on machine learning represented by SVM (Support Vector Machine). But almost all of them focus on the news contents while very few consider the information hiding in the relationship between different news. In this paper, we proposed a new kernel based on SVM concerning not only the contents themselves but also the information structures among them. As both the news contents and the information structures are imported into our kernel, this kernel is named as semantic and structural kernel, referred to S&S kernel. Medical industry financial news is used to illustrate the efficiency of our kernel. By comparing the predicting accuracy of S&S kernel with other kernels, such as linear kernel, we find our method outperforms the others by at least 5% on accuracy, which is a quite meaningful promotion. The result also confirms the information structure contained in daily financial news can offer extra information helping to predict the trend of stock price.","Stock price movement prediction,Financial news,Information structure,S&S kernel","LongWenabc,SongLinqiuabc,TianYingjieabc","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.008","https://www.sciencedirect.com/science/article/pii/S095741741830650X"
"A297","Indirect health monitoring of bridges using Mel-frequency cepstral coefficients and principal component analysis","Bridge health monitoring is a very important part for infrastructure maintenance. Traditional bridge health monitoring techniques require sensors to be installed on bridges, which is costly and time consuming. In order to resolve this issue, new damage detection techniques by installing sensors on passing-by vehicles on bridges and considering vehicle bridge interaction (VBI) have gained much attention from researchers in last decade. In this paper, a novel damage detection technique utilizing data collected from sensors mounted on a large number of passing-by vehicles is developed. First, an approach based on Mel-frequency cepstral coefficients (MFCCs) is introduced. Then, an improved version based on MFCCs and principal component analysis (PCA) taking advantage of mobile sensor network is proposed to overcome the deficiencies in the approaches that utilize single measurement. In the improved approach, the acceleration data is first collected from all the vehicles within a certain period. Then, the transformed features that are related to bridge damage are extracted from MFCCs and PCA. The damage can be identified by comparing the distributions of these transformed features. The results from the numerical analysis and lab experiments show that the approach not only identifies the existence of the damage, but also provides useful information about severity.","Structural health monitoring,Vehicle-bridge interaction,Mobile sensor network,Mel-frequency cepstral coefficients,Principal component analysis","QipeiMei,MustafaGül,MarcusBoay","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.10.006","https://www.sciencedirect.com/science/article/pii/S0888327018306678"
"A298","Developing a Twitter-based traffic event detection model using deep learning architectures","In recent years, several studies have harnessed Twitter data for detecting traffic incidents and monitoring traffic conditions. Researchers have utilized the bag-of-words representation for converting tweets into numerical feature vectors. However, the bag-of-words not only ignores the order of tweet's words but suffers from the curse of dimensionality and sparsity. A common approach in literature for dimensionality reduction is to build the bag-of-words on the top of pre-defined traffic keywords. The immediate criticisms to such a strategy are that the pre-defined set of keywords may not include all traffic keywords and the tweet language is subjected to change over time. To address these shortcomings, we utilize the power of deep-learning architectures for both representing tweets in numerical vectors and classifying them into three categories: 1) non-traffic, 2) traffic incident, and 3) traffic information and condition. First, we map tweets into low-dimensional vector space through word-embedding tools, which are also capable of measuring the semantic relationship between words. Supervised deep-learning algorithms including convolutional neural network (CNN) and recurrent neural network (RNN) are then deployed on the top of word-embedding models for detecting traffic events. For training and testing our proposed model, a large volume of traffic tweets is collected through Twitter API endpoints and labeled through an efficient strategy. Experimental results on our labeled dataset show that the proposed approach achieves clear improvements over state-of-the-art methods.","Deep learning,Twitter,Recurrent and Convolutional Neural Networks,Traffic information systems","SinaDabiriab,KevinHeaslipa","Expert Systems with Applications","https://doi.org/10.1016/j.eswa.2018.10.017","https://www.sciencedirect.com/science/article/pii/S0957417418306651"
"A299","WearGP: A computationally efficient machine learning framework for local erosive wear predictions via nodal Gaussian processes","Computational fluid dynamics (CFD)-based wear predictions are computationally expensive to evaluate, even with a high-performance computing infrastructure. Thus, it is difficult to provide accurate local wear predictions in a timely manner. Data-driven approaches provide a more computationally efficient way to approximate the CFD wear predictions without running the actual CFD wear models. In this paper, a machine learning (ML) approach, termed WearGP, is presented to approximate the 3D local wear predictions, using numerical wear predictions from steady-state CFD simulations as training and testing datasets. The proposed framework is built on Gaussian process (GP) and utilized to predict wear in a much shorter time. The WearGP framework can be segmented into three stages. At the first stage, the training dataset is built by using a number of CFD simulations in the order of O(102). At the second stage, the data cleansing and data mining processes are performed, where the nodal wear solutions are extracted from the solution database to build a training dataset. At the third stage, the wear predictions are made, using trained GP models. Two CFD case studies including 3D slurry pump impeller and casing are used to demonstrate the WearGP framework, in which 144 training and 40 testing data points are used to train and test the proposed method, respectively. The numerical accuracy, computational efficiency and effectiveness between the WearGP framework and CFD wear model for both slurry pump impellers and casings are compared. It is shown that the WearGP framework can achieve highly accurate results that are comparable with the CFD results, with a relatively small size training dataset, with a computational time reduction on the order of 105 to 106.","Wear,Machine learning,Gaussian process,Multiphase computational fluid dynamics,Slurry pump","AnhTranab,John M.Furlanb,Krishnan V.Pagalthivarthib,Robert J.Visintainerb,TimWildeyc,YanWanga","Wear","https://doi.org/10.1016/j.wear.2018.12.081","https://www.sciencedirect.com/science/article/pii/S0043164818311529"
"A300","Reduction of chromatin heteroaggregates by acid precipitation of mammalian cell culture and ramification in protein A chromatography for recombinant immunoglobulin G purification","Acid precipitation has been demonstrated as a clarification method for cell culture supernatant (CCS) pretreatment during Immunoglobulin G (IgG) purification. In this study, the responses of IgG, non-histone host cell protein (n-hHCP), histone, and DNA to different pHs in the presence of salt (NaCl) at various concentrations were systematically studied. IgG loss was closely associated with the precipitation of chromatin heteroaggregates, in which DNA/histone showed significant decreases along with the acidification of buffer environment. In addition, DNA showed full recovery after pH neutralization, while the low pH treatment induced histone precipitation was permanent and could not be reverted upon pH increase. Analytical size exclusion chromatography (SEC) profiles further indicated the agglomeration and reduction of chromatin heteroaggregates along with lower pH. Protein A chromatography benefited from the reduction of chromatin heteroaggregates and showed significant enhancement of the removal of impurities as well as for IgG recovery. For the first time, this study correlated CCS acidification with chromatin heteroaggregate removal and illustrated its ramification for the subsequent purification process.","Chromatin heteroaggregates,Immunoglobulin G,Purification,Acid precipitation,Protein A chromatography","WenshuaiLiu,DongyanZhou,YueSun,JianliYu,QuanChen,ZixianBao,XiyingFan,YunlongLiang,XinyingPeng,MoXian,RuiNian","Biochemical Engineering Journal","https://doi.org/10.1016/j.bej.2018.12.012","https://www.sciencedirect.com/science/article/pii/S1369703X18304339"
"A301","Signature of Phobos’ interior structure in its gravity field and libration","The interior of the Martian moon Phobos has not been precisely determined yet, in spite of space missions sent at close distance to the body. The current measurements (imagery, astrometric, etc.) lead to controversial conclusions about the level of heterogeneity inside Phobos. Yet, the inside mass distribution is a signature of the conditions prevailing at its formation as well as of its evolution. Here, we study possible heterogenous mass distributions based on internal models built from surface observables and available bulk density and shape measurements. We identify four different families of mass distribution involving rocky material, (macro-)porosity and ice. Mass heterogeneities correspond to either an excess of porosity or a compaction of material under Stickney crater, or a deficit of porosity in the upper layers of Phobos, or a concentration of ice either in depth inside Phobos or in shallow layers. We then discretize the shape of Phobos using 500m-length cubes to fit its volume and total mass. We compute the possible distribution of these cubes for each family of internal mass heterogeneity model. We deduce the possible values of the principal moments of inertia as well as of the geodetic observables such as the libration amplitude and the gravity field anomalies (up to degree and order 10) associated with these models. A comparison of these computed observables between the different heterogeneity models and with their expected homogenous mass distribution values allow us to quantify the possible heterogeneity degree within Phobos. The computed heterogeneity observables can depart by tens of percent from the homogenous values. The most striking departures are from the interior model with mass excess (less porosity) or deficit (more porosity) beneath Stickney crater. In turn, measurements of libration amplitude and low degree coefficients of the gravity field at a precision better than 5% can allow to identify such kinds of heterogeneities mainly located beneath Stickney. Mass excess or deficit can therefore be also distinguished, which is of importance to identify whether Phobos was already porous or monolithic before the formation of Stickney. The current measurements of libration amplitude and degree-two gravity coefficient are quite uncertain, but seem to reject models with higher porosity under Stickney, favoring a pre-impact porous body. The icy models depart less from the homogenous signatures, hence requiring more precise measurements of the geodetic observables and of the shape of Phobos. The improvement of these measurements by the Mars Moon Explorer mission for instance could thus allow for better constraining our model of Phobos’ interior and bring further constraints for its formation.","","S.Le Maistre,A.Rivoldini,P.Rosenblatt","Icarus","https://doi.org/10.1016/j.icarus.2018.11.022","https://www.sciencedirect.com/science/article/pii/S0019103518304019"
"A302","Novel ecological insights and functional roles during anaerobic digestion of saccharides unveiled by genome-centric metagenomics","In typical anaerobic digestion (AD) systems, the microbial functional assertion is hampered by synchronised versatile metabolism required for heterogeneous substrates degradation. Thus, the intricate methanogenic process from organic compounds remains an enigma after decades of empirical operation. In this study, simplified AD microbial communities were obtained with substrate specifications and continuous reactor operation. Genome-centric metagenomic approach was followed to holistically investigate the metabolic pathways of the AD and the microbial synergistic networks. In total, 63 metagenome assembled genomes (MAGs) were assembled from 8 metagenomes acquired in specific methanogenic niches. The metabolic pathways were reconstructed from the annotated genes and their dynamicity under experimental conditions. The results show that the methanogenic niches nourish unique metabolism beyond current knowledge acquired from cultivation-based methods. A novel glucose mineralization model without acetate formation was proposed and asserted in a pair of syntrophs: Clostridiaceae sp. and Methanoculleus thermophilus. Moreover, the catabolic pathway was elucidated in uncharacterized syntrophic acetate oxidizers, Synergistaceae spp. A remarkable evolutionary insight is the discovery that electron transport and energy conservation mechanisms impose selective pressure on syntrophic partners. Overall, the functional roles of the individual microbes tightly rely on the catabolic pathways and cannot always be physiologically defined in accordance with conventional four-step AD concept. The substrate-specific systems provided a traceable microbial community to dissecting the AD process. The genome-centric metagenomics successfully constructed genomes of microbes that have not been previously isolated and illustrated metabolic pathways that beyond the current knowledge of AD process. This study provides new perspectives to unravel the AD microbial ecology and suggests more attention should be paid on uncharacterized metabolism specifically harboured by AD microbial communities.","Microbial community,Methane,Metagenomics assembled genome,Pathway reconstruction,Syntrophic,Energy conservation","XinyuZhua,StefanoCampanarob,LauraTreuab,Panagiotis G.Kougiasa,IriniAngelidakia","Water Research","https://doi.org/10.1016/j.watres.2018.12.041","https://www.sciencedirect.com/science/article/pii/S0043135418310595"
"A303","Calcium complexing behaviour of lactate in neutral to highly alkaline medium","The calcium complexing properties as well as the acid-base behaviour of d,l-lactate have been investigated in both neutral and alkaline media by Ca-ISE potentiometry, 13C NMR spectroscopy, ESI-MS spectroscopy and solubility measurements. In close to neutral solutions the formation of the CaLac+ and CaLac20 complexes were detected with formation constants of logK1,1<U+202F>=<U+202F>0.99<U+202F>±<U+202F>0.02 and logß1,2<U+202F>=<U+202F>1.42<U+202F>±<U+202F>0.03 (I<U+202F>=<U+202F>4<U+202F>M, T<U+202F>=<U+202F>25<U+202F>°C). These data are consistent with previously reported literature data measured at lower ionic strengths. The alkaline deprotonation constant of lactate has been determined to be pKa<U+202F>=<U+202F>15.8<U+202F>±<U+202F>0.2. In highly alkaline medium, the formation of the CaLacOH0 and CaLac(OH)2– complexes were detected with the corresponding formation constants being logß1,1,1<U+202F>=<U+202F>1.35<U+202F>±<U+202F>0.09 and logß1,1,2<U+202F>=<U+202F>1.43<U+202F>±<U+202F>0.06. The structures of the CaLac+ and CaLacOH0 complexes were optimized by molecular modelling calculations.","Ca complexing properties of D,L lactate,Neutral and alkaline medium,NMR spectroscopy,ESI-MS spectroscopy,Molecular modelling","CsillaDudása,BenceKutusa,ÉvaBöszörményia,GáborPeintlera,Amr A.A.Attiab,AlexandruLupanb,ZoltánKelec,PálSiposa,IstvánPálinkóa","Journal of Molecular Structure","https://doi.org/10.1016/j.molstruc.2018.12.020","https://www.sciencedirect.com/science/article/pii/S0022286018314418"
"A304","Role of big data analytics in developing sustainable capabilities","The purpose of this study is to examine the extent of sustainable capabilities driven by corporate commitment resulting from the integration of big data technologies, green supply chain management, and green human resource management practices, and the extent to which these capabilities can enhance the broader firm performance. The study was also designed to investigate the degree to which green human resource management practices influence the integration of big data technologies with processes and enhance the relationships between green supply chain management practices, both internal and external, as well as their influence on sustainable performance. We used dynamic capabilities theory and proposed a conceptual research model which was tested empirically. The findings of our study establish the influence of big data driven strategies on business growth in terms of sustainable performance by considering internal processes that constitute sustainable capabilities. The study recommends the integration of green supply chain management, green human resource management practices, and big data management to enhance firms’ sustainable capabilities that lead to better sustainable performance.","Sustainable capabilities,Big data,Corporate commitment,Green supply chain management,Green human resource management practices,And environmental & organizational performance","Sanjay KumarSingha,Abdul-NasserEl-Kassarb","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.12.199","https://www.sciencedirect.com/science/article/pii/S0959652618339155"
"A305","Analysis on the theory and practice of industrial symbiosis based on bibliometrics and social network analysis","Industrial symbiosis (IS) can generate economic, social, and environmental benefits, and support sustainable development; thus, many governments and scholars are devoted to exploring it. To analyze and evaluate the current status and development trends of industrial symbiosis, this study selects “industrial symbiosis” as a research title to search the Web of Science (core collection) database, and uses the bibliometrics and social network analysis (SNA) methods. The results turn out that an increasing amount of research has been devoted to industrial symbiosis in recent years. They also show that the study of industrial symbiosis has obvious cross-disciplinary characteristics. Current research on industrial symbiosis mainly focuses on four issues: evolution and development, operation carriers, driving mechanisms, and efficiency evaluation of industrial systems. The research of the industrial symbiosis network will greatly promote the industrial green development for the industrial transformation and upgrading of various countries. Many methods are used to examine these four questions, including case studies, life cycle assessment (LCA), material flow analysis (MFA), data envelopment analysis (DEA), multi-criteria decision making (MCDM), emergy analysis, and SNA. This article provides the trends of industrial symbiosis research for further study. The data mining can be used in the industrial symbiosis network and a dynamic simulation industry symbiotic evolutionary process model can be discussed in the future.","Industrial symbiosis,Co-word analysis,Bibliometrics,Social network analysis (SNA)","MaoxingHuang,ZhenzhenWang,TingChen","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.12.131","https://www.sciencedirect.com/science/article/pii/S0959652618338435"
"A306","Salino-alkaline lime of anthropogenic origin a reservoir of diverse microbial communities","This paper presents study on the microbiome of a unique extreme environment - saline and alkaline lime, a by-product of soda ash and table salt production in Janikowo, central Poland. High-throughput 16S rDNA amplicon sequencing was used to reveal the structure of bacterial and archaeal communities in the lime samples, taken from repository ponds differing in salinity (2.3–25.5% NaCl). Surprisingly abundant and diverse bacterial communities were discovered in this extreme environment. The most important geochemical drivers of the observed microbial diversity were salinity, calcium ions, nutrients, and water content. The bacterial and archaeal communities in saline, alkaline lime were similar to those found in natural haloalkaline environments. Although the archaeal contribution to the whole microbial community was lower than 4%, the four archaeal genera Natronomonas, Halorubrum, Halobellus, and Halapricum constituted the core microbiome of saline, alkaline lime - a set of OTUs (> 0.1% of total archaeal relative abundance) present in all samples under study. The high proportion of novel, unclassified archaeal and bacterial sequences (not identified at 97% similarity level) in the 16S rRNA gene libraries indicated that potentially new genera, especially within the class of Thermoplasmata inhabit this unique environment.","Archaeal community,Bacterial community,Haloalkaline environment,Halophiles,Alkalophiles","AgnieszkaKalwasinskaa,EdytaDeja-Sikorabc,AttilaSzabód,TamásFelföldid,PrzemyslawKosobuckie,Maria SwiontekBrzezinskaa,MaciejWalczaka","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.11.246","https://www.sciencedirect.com/science/article/pii/S0048969718346035"
"A307","Carbon nanodot-decorated alveolate N, O, S tridoped hierarchical porous carbon as efficient electrocatalysis of polysulfide conversion for lithium-sulfur batteries","Rechargeable lithium-sulfur (Li-S) batteries are a significant energy-storage device owing to their eco-friendliness and high theoretical energy density. However, the shuttle effect of soluble polysulfides as well as the slow redox kinetics constrains the development of Li-S batteries. Herein, carbon nanodots-decorated alveolate N, O, S tridoped hierarchical porous carbon (a-NOSPC) material is synthesized via facile pyrolysis of tobacco stem. The coexistence of micropores, mesopores, and macropore in the hierarchical porous carbon are beneficial for physical accommodating/immobilizing active materials sulfur and rapid charge/ion transfer. Meanwhile, the N, O, S dopants provide rich electrocatalytic active site in chemical binding of polysulfides and their accelerated redox kinetics, thus guaranteeing high utilization on active materials. The resultant a-NOSPC/S cathode with an 2.7<U+202F>mg<U+202F>cm-2 areal sulfur loading delivers a high reversible areal capacity of 2.90<U+202F>mAh cm-2 at 0.1 C, maintaining 2.01<U+202F>mAh cm-2 over 100 cycles, which is obviously superior to the most reported biochar-based electrodes. Our results provide an appealing avenue to the design of multifunctional sulfur host for advanced Li-S batteries.","Lithium-sulfur batteries,Tobacco stem,Nanodots-decorated,Alveolate,Tridoped","Mei-eZhonga,JindiaoGuana,JingchunSuna,HuiGuoa,ZhubingXiaob,NanZhoua,QingwenGuia,DaoxinGongc","Electrochimica Acta","https://doi.org/10.1016/j.electacta.2019.01.024","https://www.sciencedirect.com/science/article/pii/S0013468619300337"
"A308","Consolidated vs new advanced treatment methods for the removal of contaminants of emerging concern from urban wastewater","Urban wastewater treatment plants (WWTPs) are among the main anthropogenic sources for the release of contaminants of emerging concern (CECs) into the environment, which can result in toxic and adverse effects on aquatic organisms and consequently on humans. Unfortunately, WWTPs are not designed to remove CECs and secondary (e.g., conventional activated sludge process, CAS) and tertiary (such as filtration and disinfection) treatments are not effective in the removal of most CECs entering WWTP. Accordingly, several advanced treatment methods have been investigated for the removal of CECs from wastewater, including consolidated (namely, activated carbon (AC) adsorption, ozonation and membranes) and new (such as advanced oxidation processes (AOPs)) processes/technologies. This review paper gathers the efforts of a group of international experts, members of the NEREUS COST Action ES1403 who for three years have been constructively discussing the state of the art and the best available technologies for the advanced treatment of urban wastewater. In particular, this work critically reviews the papers available in scientific literature on consolidated (ozonation, AC and membranes) and new advanced treatment methods (mainly AOPs) to analyse: (i) their efficiency in the removal of CECs from wastewater, (ii) advantages and drawbacks, (iii) possible obstacles to the application of AOPs, (iv) technological limitations and mid to long-term perspectives for the application of heterogeneous processes, and (v) a technical and economic comparison among the different processes/technologies.","Activated carbon,Advanced oxidation processes,Oxidation by-products,Ozonation,Photocatalysis,Urban wastewater","LuigiRizzoa,SixtoMalatob,DemetAntakyalic,Vasiliki G.Beretsoude,Maja B.Ðolicf,WolfgangGernjakgh,EsterHeathi,IvanaIvancev-Tumbasj,PopiKaraoliad,Ana R.Lado Ribeirok,GiuseppeMascolol,Christa S.McArdellm,HeidemarieSchaarn,Adrián M.T.Silvak,DespoFatta-Kassinosde","Science of The Total Environment","https://doi.org/10.1016/j.scitotenv.2018.11.265","https://www.sciencedirect.com/science/article/pii/S0048969718346229"
"A309","Mapping the bike sharing research published from 2010 to 2018: A scientometric review","An increasing number of studies since 2010 have examined bike sharing from diverse perspectives to provide the best travel practices of “the last mile”. However, few studies have attempted to comprehensively review existing literature over the past decade. The present study aims to map bike sharing research published between 2010 and 2018. A total of 208 relevant articles were collected to conduct scientometric analysis. The results revealed that the most significant contributions in bike sharing research primarily originated from the US, China, Canada, England and Australia. Critical institutions, publications and articles were also identified. The knowledge domains of bike sharing research focus mainly on topic categories of factors & barrier, system optimization, behavior & impact, safety & health, and sharing economy. Evolutionary trends in bike sharing research tend to move from the safety and benefits of bike usage to more complex external impacts, system optimization, design and integration with public transit. Furthermore, increasing interests and outputs in the new generation of dockless bike sharing programs were observed from the research community for the past two years. The present study contributes to the existing body of knowledge on bike sharing by presenting a new, integrated and holistic knowledge map. This study offers valuable guidance and in-depth understanding to researchers, operators and policy makers who wish to promote bike sharing sustainability, as well as for follow-up studies, updates and management.","Bike sharing,Review,Scientometric,Knowledge map,Sustainable transportation","HongyunSia,Jian-gangShia,GuangdongWub,JindaoChenac,XianboZhaod","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.12.157","https://www.sciencedirect.com/science/article/pii/S0959652618338678"
"A310","Stochastic modeling reveals how motor protein and filament properties affect intermediate filament transport","Intermediate filaments are a key component of the cytoskeleton. Their transport along microtubules plays an essential role in the control of the shape and structural organization of cells. To identify the key parameters responsible for the control of intermediate filament transport, we generated a model of elastic filament transport by microtubule-associated dynein and kinesin. The model is also applicable to the transport of any elastically-coupled cargoes. We investigate the effect of filament properties such as number of motor binding sites, length, and elasticity on motion of filaments. Additionally, we consider the effect of motor properties, i.e. off rates, on filament transport. When one motor has a catch bond off rate it dictates the motion, whereas when motors have the same type of off rate filaments can alternate between retrograde and anterograde motions. The elasticity of filaments optimizes the filament transport and the coordination of motors along the length of the filament.","Intermediate filaments,Dynein,Kinesin,Vimentin,Molecular motors,Stochastic","J.C.Dallona,CécileLeducb,SandrineEtienne-Mannevilleb,StéphaniePortetc","Journal of Theoretical Biology","https://doi.org/10.1016/j.jtbi.2018.12.022","https://www.sciencedirect.com/science/article/pii/S0022519318306192"
"A311","Bioinspired crystallization, sensitized luminescence and cytocompatibility of citrate-functionalized Ca-substituted europium phosphate monohydrate nanophosphors","Biocompatible nanosystems exhibiting long-lifetime (~millisecond) luminescence features are particularly relevant in the field of bioimaging. In this study, citrate-functionalized calcium-doped europium phosphates nanophosphors of the rhabdophane type were prepared at different synthesis times by a bioinspired crystallization route, consisting in thermal decomplexing of Ca2+/Eu3+ /citrate/phosphate/carbonate solutions. The general formula of this material is CaaEu1-a(PO4)1-a(HPO4)a·nH2O, with a ranging from 0 to 0.58 and n<U+202F>~<U+202F>1. A thorough characterization of the nanoparticles has been carried out by XRD (including data processing with Topas 6.0), HR-TEM, TEM, FTIR, TG/DTA, ICP, dynamic light scattering (DLS), electrophoretic mobility, and fluorescence spectroscopy. Based on these results a crystallization mechanism involving the filling of cationic sites with Ca2+ions associated to a concomitant adjustment of the PO4/HPO4 ratio was proposed. Upon calcium doping, the aspect ratio of the nanoparticles as well as of the crystalline domains decreased and the relative luminescence intensity (R.L.I.) could be modulated. Neither the pH nor the ionic strength, nor the temperature (from 25 to 37<U+202F>°C) affected significantly the R.L.I. of particles after resuspension in water, leading to rather steady luminescence features usable in a large domain of conditions. This new class of luminescent compounds has been proved to be fully cytocompatible relative to GTL-16 human carcinoma cells and showed an improved cytocompatibility as the Ca2+ content increased when contacted with the more sensitive m17. ASC murine mesenchymal stem cells. These biocompatible nanoparticles thus appear as promising new tailorable tools for biomedical applications as luminescent nanoprobes.","Ca-doped europium phosphates,Nanophosphors,Luminescence,Cytocompatibility","JaimeGómez-Moralesa,CristóbalVerdugo-Escamillaa,RaquelFernández-Penasa,CarmenMaria Parra-Millaa,ChristopheDrouetbc,MicheleIafiscoc,FrancescaOltolinad,MariaPratd,Jorge FernandoFernández-Sáncheze","Journal of Colloid and Interface Science","https://doi.org/10.1016/j.jcis.2018.11.083","https://www.sciencedirect.com/science/article/pii/S0021979718314048"
"A312","Acylguanidine-BACE1 complex: Insights of intermolecular interactions and dynamics","Alzheimer disease (AD) is a harmful neurodegenerative disorder which arises mainly due to awful deposition of amyloid ß (Aß) peptide in the brain of AD patients. Aß aggregates from the amyloid precursor protein (APP) by the sequential action of ß-Secretase (Beta site APP Cleaving Enzyme, BACE1); hence, inhibition of BACE1 is the primary target for the treatment of AD. As per the experimental report, acylguanidine is a synthetic inhibitor of BACE1, it exhibits high binding affinity towards BACE1. In the present computational study, we aimed to understand the molecular binding mechanism of acylguanidine with BACE1 from the structure and conformation, intermolecular interactions, charge density and electrostatic properties, stability and binding free energy of acylguanidine molecule in the active site of BACE1. To investigate this, molecular docking, QM/MM based charge density analysis and MD simulation have been performed on acylguanidine with BACE1. Acylguanidine shows large binding affinity towards BACE1 and it gives strong hydrogen bonding and hydrophobic interactions with the active site amino acid residues of BACE1. In addition, QM/MM based charge density analysis of acylguanidine was carried out to understand its charge density distribution in the active site of BACE1. The conformational flexibility, charge density redistribution and the modification of electrostatic properties of acylguanidine in the active site have been compared to its corresponding gas phase structure. Further, the molecular dynamics simulation on acylguanidine-BACE1 was carried out, which gives the stability of acylguanidine in the active site of BACE1. The MM-GBSA free energy displays the binding affinity of the acylguanidine and further the decomposition energy reveals the validity of intermolecular interactions.","Acylguanidine-ß Secretase complex,Intermolecular interaction,QM/MM based Charge density,Molecular dynamics,Binding Free energy","KandasamySaravanan,PoomaniKumaradhas","Journal of Theoretical Biology","https://doi.org/10.1016/j.jtbi.2018.12.020","https://www.sciencedirect.com/science/article/pii/S0022519318306167"
"A313","Conformational and solution dynamics of hemoglobin (Hb) in presence of a cleavable gemini surfactant: Insights from spectroscopy, atomic force microscopy, molecular docking and density functional theory","Herein, we have explored the conformational alterations of hemoglobin (Hb) in presence of a cleavable gemini surfactant (C16-C4O2-C16). The concerned surfactant was found to induce significant structural perturbations in Hb. UV–vis spectroscopy, steady-state/time-resolved fluorescence, and other utilized techniques have authenticated the complexation of Hb with the gemini surfactant. CD has demonstrated the alterations in secondary structural elements (a-helicity, ß-sheet, ß-turn, and random coil) of Hb upon C16-C4O2-C16 addition. Atomic force microscopy (AFM) has revealed the existence of unique star-shaped gemini surfactant microstructures aligned to Hb in a necklace pattern. The 1H NMR peak broadening and lower delta values hint at the binding of the concerned gemini surfactant to Hb. Molecular docking and DFT calculations have further substantiated the Hb-gemini complex formation and the involvement of electrostatic/hydrophobic forces therein. In future, these results might pave-the-way to construct self-assembled, sustainable, and green surfactant-protein mixtures for their end-use in industrial, engineering, biomedical, drug delivery, gene transfection, and other relevant excipient formulations.","Green gemini surfactant,Hb,AFM,1H NMR,DFT,Docking","Imtiyaz AhmadBhata,BibhisanRoya,ParthaHazraa,Kabir-ud-Dinb","Journal of Colloid and Interface Science","https://doi.org/10.1016/j.jcis.2018.12.008","https://www.sciencedirect.com/science/article/pii/S0021979718314437"
"A314","Controlled coagulation and redispersion of thermoresponsive poly di(ethylene oxide) methyl ether methacrylate grafted cellulose nanocrystals","HypothesisCellulose nanocrystals (CNCs) undergo precipitation in the presence of high concentrations of cationic surfactants in aqueous solutions. To avoid such behavior and/or to promote redispersion of CNC/surfactant mixtures, the CNC surface was grafted with poly di(ethylene oxide) methyl ether methacrylate, P(MEO2MA).,ExperimentsCNC-g-P(MEO2MA) was characterized using the following techniques 13C solid-state nuclear magnetic resonance (13C SSNMR), Fourier-transform infrared spectroscopy – attenuated total reflection spectroscopy (FTIR-ATR) and thermal gravimetric analysis (TGA). Isothermal titration calorimetry (ITC), electrophoretic mobility, light scattering and high sensitivity differential scanning calorimetry (HSDSC) were used to study the interaction between CNC-g-P(MEO2MA) and ionic surfactants, dodecyltrimethylammonium bromide (C12TAB, cationic) and sodium dodecylsulfate (SDS, anionic) at temperatures below and above the LCST.,FindingsCNC-g-P(MEO2MA) underwent phase separation above its lower critical solution temperature (LCST<U+202F>~<U+202F>25<U+202F>°C) and precipitated from solution as seen by HSDSC and transmittance experiments. When C12TAB was added to CNC-g-P(MEO2MA) it induced the precipitation that prevented the redispersion due to strong electrostatic interactions with the negative charges on the CNC surface. With increasing concentrations of SDS, the polymer phase transition temperature was increased, which can be used to redisperse the CNC complexes. By removing SDS from the mixture via dialysis, the CNC-g-P(MEO2MA) underwent subsequent phase transition.","Cellulose nanocrystals,PEO-based polymer grafting,Anionic surfactant,Temperature-induced phase transition","CésarBrinattia,Seyedeh ParinazAkhlaghia,RafaelPires-Oliveiraa,Oigres DanielBernardinellia,Richard M.Berryb,Kam ChiuTamc,WatsonLoha","Journal of Colloid and Interface Science","https://doi.org/10.1016/j.jcis.2018.11.071","https://www.sciencedirect.com/science/article/pii/S0021979718313857"
"A315","The capability of commercial CFD code to predict organic peroxide fireball characteristics","Fireballs of liquid organic peroxides differ from those of liquid hydrocarbon fuels. Modified equations for predicting the fireball diameter, height, surface emissive power and the duration in dependence of the fuel mass are presented for di-tert-butyl peroxide. They base on 13 steel drum tests with fuel masses from 10<U+202F>kg to 168<U+202F>kg. Moreover, computational fluid dynamics simulations are performed using the laminar flamelet approach and a statistically turbulence treatment. Fireballs involving peroxide from 10 kg to 80 kg were simulated and their properties compared to the experimentally developed models. The deviations of each property are partially compensating each other leading to an adequate prediction of thermal safety distances for both, a time-independent and a time-averaged treatment. Simulations prove to be a good tool for predicting thermal radiation hazards of fireball scenarios.","Fireball,CFD simulation,Organic peroxide,Fire safety,DTBP","PaulBlankenhagela,Klaus-DieterWehrstedta,Kirti BhushanMishrab,JörgSteinbachc","Journal of Hazardous Materials","https://doi.org/10.1016/j.jhazmat.2018.11.011","https://www.sciencedirect.com/science/article/pii/S0304389418310306"
"A316","Synthesis, characterization and electrochemical monitoring of drug release properties of dual stimuli responsive mesoporous GdPO4:Eu3+ nanoparticles","The drug loading and release properties of Eu3+ doped GdPO4 nanoparticles (NPs) were studied using a simple electrochemical protocol in an in-vitro environment, taking acetaminophen as a model drug. The electrochemical monitoring of drug release was also validated with absorption spectroscopy technique. For this purpose, dual stimuli (pH and temperature) responsive monoclinic mesoporous GdPO4 nanoparticles of size ~22<U+202F>nm were synthesized by a simple hydrothermal method. Crystal structure, size, shape, morphology, porosity, optical property and magnetic properties of the obtained product were studied by different characterization techniques. Successful loading of drug in NPs was investigated by Fourier transform infrared spectroscopy (FT-IR). Photoluminescence (PL) measurement shows orange-red color emission corresponding to 5D0<U+2192>7F2 transitions of Eu3+ ions. The vibrating sample magnetometer (VSM) measurements showed negligible hysteresis in both samples, suggesting retention of the superparamagnetic behavior of GdPO4 NPs. The high loading capacity of 79% and encapsulation efficiency of 83% is observed when acetaminophen, an anti-fever drug, was loaded on these mesoporous GdPO4 NPs. The drug was attached on NPs surfaces via absorption, without any special surface modification. During drug release studies, a spontaneous and smooth release from these mesoporous NPs was observed at a moderate-high temperature (37<U+202F>°C) and low pH (pH 5) with no sign of burst release. These nanoparticles were capable of targeting and specific release of the loaded drug in response to pH and temperature and hence may serve as a potential drug carrier for in-vivo applications.","Mesoporous nanoparticles,Magnetic materials,Structural property,Optical property,Drug release,Electrochemical monitoring.","ManishaKumari,ShrabaniMondal1,Prashant K.Sharma","Journal of Alloys and Compounds","https://doi.org/10.1016/j.jallcom.2018.10.286","https://www.sciencedirect.com/science/article/pii/S0925838818339604"
"A317","Ensemble Kalman filter-based data assimilation for three-dimensional multi-phase-field model: Estimation of anisotropic grain boundary properties","Data assimilation (DA) has been used as a machine learning approach to estimate a system's state and the unknown parameters in its numerical model by integrating observed data into model predictions. In this paper, we propose using the DA methodology based on the ensemble Kalman filter (EnKF) to improve the accuracy of microstructure prediction using three-dimensional multi-phase-field (3D-MPF) model and estimate the model parameters simultaneously. To demonstrate the applicability of the DA methodology, we performed numerical experiments in which a priori assumed true parameters related to the grain boundary (GB) energy cusp and GB mobility peak of S7 coincidence site lattice GB were estimated from synthetic data of time-evolving polycrystalline microstructure. Four model parameters related to the S7 GB properties were successfully estimated by assimilating the synthetic microstructure data to the 3D-MPF model predictions using the EnKF-based DA method. Furthermore, we accurately reproduced the preliminarily assumed true shapes of GB energy cusp and GB mobility peak by using the estimated parameters. The results suggest that implementation of the EnKF-based DA method in the MPF model has great potential for identifying unknown material properties and estimating unmeasurable microstructure evolutions in polycrystalline materials based on real time-series 3D microstructure observation data.","Multi-phase-field model,Data assimilation,Ensemble Kalman filter,Grain boundary","AkinoriYamanakaa,YuriMaedab,KengoSasakibc","Materials & Design","https://doi.org/10.1016/j.matdes.2018.107577","https://www.sciencedirect.com/science/article/pii/S0264127518309419"
"A318","Model updating of periodic structures based on free wave characteristics","Many civil engineering structures have a repetitive or quasi-periodic geometry. Such structures have clustered modes with closely spaced natural frequencies corresponding to mode shapes with similar wavelengths. Such modes may be difficult to distinguish in modal tests and lead to difficulties when pairing calculated and experimentally determined modal characteristics in vibration-based model updating. For repetitive structures, the free wave characteristics, i.e. propagation constants and free waves, can be used alternatively to characterize their dynamic behaviour. The free wave characteristics can therefore be used instead of modal characteristics as data features in model updating of repetitive structures. This paper investigates the feasibility of model updating of repetitive structures based on free wave characteristics. First, the identification of the free wave characteristics from the measured vibration responses of a periodic structure is investigated. A stabilization diagram is constructed to pick up the stable free waves. Second, model updating of repetitive structures is performed through a match of the calculated and experimentally identified free wave characteristics. A least-squares cost function is formulated and minimized using a gradient-based optimization algorithm. This algorithm requires the sensitivity of the free wave characteristics to the model parameters that need to be updated. The analytical expressions for the free wave sensitivities are therefore derived. The proposed model updating procedure is demonstrated and validated by a numerical case study involving a repetitive frame structure and by an experiment on a four-storey steel frame structure. The results confirm the feasibility of model updating based on free wave characteristics for repetitive structures.","Free wave characteristics,Free wave identification,Model updating,Periodic structures","JieZhang,EdwinReynders,GuidoDe Roeck,GeertLombaert","Journal of Sound and Vibration","https://doi.org/10.1016/j.jsv.2018.10.054","https://www.sciencedirect.com/science/article/pii/S0022460X1830734X"
"A319","Alterations in white matter microstructure and regional volume are related to motor functions in boys with autism spectrum disorder","BackgroundAltered inter-regional structural connectivity related to higher cognitive functions has been commonly reported in individuals with autism spectrum disorder (ASD). However, whether these alterations similarly involve cortico-cerebellar motor circuitries remains largely elusive.,MethodsUsing a cross-modality approach accounting for in-scanner motion levels, we investigated white matter (WM) properties in motor circuits of 55 boys with ASD (aged 8–18<U+202F>years) and 68 age-matched typically developing boys. Regional WM volumes in the primary motor, supplementary motor, somatosensory, and cerebellar areas were investigated using voxel-based morphometry. Diffusion spectrum imaging tractography was used to estimate WM integrity of the corticospinal, cortico-ponto-cerebellar (including fronto-ponto-cerebellar and parieto-ponto-cerebellar), and dentato-rubro-thalamo-cortical tracts. The reaction time test in the Cambridge Neuropsychological Test Automated Battery was used to assess motor performances.,ResultsBoys with ASD had shorter movement time, increased WM volumes in the left somatosensory area, but decreased generalized fractional anisotropy value in the left parieto-ponto-cerebellar tract, compared to controls. A positive correlation between movement time and microstructural properties of the left parieto-ponto-cerebellar tract was found in boys with ASD.,ConclusionsAs the first study to demonstrate altered WM properties in the left somatosensory area, and its descending pathway connecting to the cerebellum in ASD, current results may highlight a potential new target of interventions for motor performance in ASD.","Autism spectrum disorder,Motor, white matter,Voxel-based morphometry,Diffusion spectrum imaging","Chia-WeiLina,Hsiang-YuanLinb,Yu-ChunLoc,Yu-JenChenc,Yung-ChinHsuc,Yi-LungChenbd,Wen-Yih IsaacTsengce,Susan Shur-FenGaubde","Progress in Neuro-Psychopharmacology and Biological Psychiatry","https://doi.org/10.1016/j.pnpbp.2018.11.008","https://www.sciencedirect.com/science/article/pii/S0278584618303798"
"A320","Effect of porous structure and spreading pressure on the storage stability of red onion microcapsules produced by spray freezing into liquid cryogenic and spray drying","Red onion microcapsules were produced by spray freezing into liquid cryogenic (SFLC) and spray drying (SD) and their anthocyanin contents were evaluated kinetically at different water activities (aw) at 35<U+202F>°C. The spreading pressure-area isotherms were determined at 35<U+202F>°C. These isotherms provide important information about the different phases of adsorbed water present in SD and SFLC capsules, which can be related to minimal integral entropy and to chemical stability during storage. The porosity of the microcapsules was examined using low-temperature adsorption of nitrogen. The maximum anthocyanin stability occurred at aw from 0.108 to 0.318, and 0.108 to 0.515, for SD and SFLC, respectively. SD products were nonporous whereas SFLC were mesoporous. The tendency to contraction of the adsorbed water film was compared with the minimum integral entropy and was proposed as a new stability criterion to predict suitable storage conditions of dehydrated foods.","Minimum integral entropy,Monolayer,Spreading pressure,Spray freezing into liquid nitrogen","L.A.Pascual-Pinedaa,M.P.Rascónb,M.X.Quintanilla-Carvajalc,M.Castillo-Moralesb,U.R.Marínb,E.Flores-Andradeb","Journal of Food Engineering","https://doi.org/10.1016/j.jfoodeng.2018.10.018","https://www.sciencedirect.com/science/article/pii/S0260877418304539"
"A321","The Utilization of Video Technology in Surgical Education: A Systematic Review","BackgroundThe use of surgical video has great potential to enhance surgical education, but there exists limited information about how to effectively use surgical videos. We performed a systematic review of video technology in surgical training and provided evidence-based recommendations for its effective use.,Materials and methodsA systematic review of literature on surgical video in residency education was conducted. All articles meeting inclusion criteria were evaluated for technical characteristics pertaining to video usage. Included studies were critically appraised using a quality-scoring system. Recommendations were provided for the effective implementation of video in surgical education based on associations with improved training outcomes.,ResultsTwenty articles met inclusion criteria. In these studies, the source of video acquisition was primarily laparoscopy (40.0% of papers), and the main perspective of video was endoscopy (45.0%). Features of videos included supplementation with other educational tools (55.0%), schematic diagrams or images (50.0%), audio (40.0%), and narration (25.0%). Videos were primarily viewed preoperatively (60.0%) or postoperatively (50.0%). The intended viewer for videos was usually residents (70.0%) but also included attendings/faculty (30.0%). When compared with a nonvideo training group, video training was associated with improved resident knowledge (100%), improved operative performance (81.3%), and greater participant satisfaction (100%).,ConclusionsBased on this review, we recommend that surgical training programs incorporate schematics and imaging into video, supplement video with other education tools, and utilize audio in video. For video review, we recommend that residents review video preoperatively and postoperatively for learning and that attendings review video postoperatively for assessment.","Surgery,Video,Residency,Education,Systematic review","Jason L.GreenBSa,VisakhaSureshBSEa,PeterBittarBS, BAa,LeilaLedbetterMLIS, BSb,Suhail K.MithaniMDcd,AlexanderAlloriMD, MPHe","Journal of Surgical Research","https://doi.org/10.1016/j.jss.2018.09.015","https://www.sciencedirect.com/science/article/pii/S0022480418306401"
"A322","Technology advances in sugarcane propagation: A patent citation study","Sugarcane propagation technologies have, in recent years, been the focus of interest of large corporations involved in the sugar and ethanol business. The objective of this study is to present the methodology used to identify the technology domain found in different sugarcane propagation technologies. The methodology was based on the bibliometric analysis of patents, including a meticulous selection of the most representative technologies used by the sugarcane market and the application of patent citation. The results report the process developed to identify a novel technology domain of high complexity involving different fields of science resulting in a set of sugar cane propagation technologies and show that the main technology advances have happened in the last decade (2005–2015), especially in seedling containers and the use of chemical compounds for seedling treatment. Further studies are recommended to help understand how these new technologies will impact the sugarcane production-chain in Brazil.","Sugarcane,Seedlings,Patent citations,Technology domain","CeciliaHasnera,Araken Alves deLimab,EduardoWinterc","World Patent Information","https://doi.org/10.1016/j.wpi.2018.09.001","https://www.sciencedirect.com/science/article/pii/S0172219017300571"
"A323","Variable augmented neural network for decolorization and multi-exposure fusion","This paper shows how to convert a color image to grayscale using convolutional neural network (CNN), that preserves visual contrast via gradient domain modeling. We propose to explore the auxiliary variable principle to make the input and output variable dimensions to be the same, and use L1-norm error of the image gradients as the loss function criterion. The similarity measure calculates the summation of the gradient correlation between each channel of the color image and the transformed grayscale image. The final gray mapping result is then obtained by reconstruction from a globally initial grayscale image and locally derived gradient images. A weighted objective is proposed to balance the robustness and visual appearance of color images. Furthermore, by revealing the relation between color-to-gray and multi-exposure fusion, the network is applied to multi-exposure fusion. Both quantitative and qualitative evaluations on decolorization and multi-exposure fusion consistently demonstrate the potential of the proposed method against existing state-of-the-art algorithms.","Color-to-gray conversion,Multi-exposure fusion,Convolutional neural network,Auxiliary variables,L1-norm,Gradient domain","QiegenLiuab,HenryLeungb","Information Fusion","https://doi.org/10.1016/j.inffus.2018.05.007","https://www.sciencedirect.com/science/article/pii/S1566253517305298"
"A324","Rapid tracking of extrinsic projector parameters in fringe projection using machine learning","In this work, we propose to enable the angular re-orientation of a projector within a fringe projection system in real-time without the need for re-calibrating the system. The estimation of the extrinsic orientation parameters of the projector is performed using a convolutional neural network and images acquired from the camera in the setup. The convolutional neural network was trained to classify the azimuth and elevation angles of the projector approximated by a point source through shadow images of the measured object. The images used to train the neural network were generated through the use of CAD rendering, by simulating the illumination of the object model from different directions and then rendering an image of its shadow. The accuracy to which the azimuth and elevation angles are estimated is within 1 classification bin, where 1 bin is designated as a ±10° patch of the illumination dome. To evaluate use of the proposed system in fringe projection, a pyramidal additively manufactured object was measured. The point clouds generated using the proposed method were compared to those obtained by an established fringe projection calibration method. The maximum dimensional error in the point cloud generated when using the convolutional network as compared to the established calibration method for the object measured was found to be 1.05<U+202F>mm on average.","","PetrosStavroulakisa,ShuxiaoChena,ClementDelormeb,PatrickBointona,GeorgiosTzimiropoulosc,RichardLeacha","Optics and Lasers in Engineering","https://doi.org/10.1016/j.optlaseng.2018.08.018","https://www.sciencedirect.com/science/article/pii/S0143816618304809"
"A325","Evolving rule-based classifiers with genetic programming on GPUs for drifting data streams","Designing efficient algorithms for mining massive high-speed data streams has become one of the contemporary challenges for the machine learning community. Such models must display highest possible accuracy and ability to swiftly adapt to any kind of changes, while at the same time being characterized by low time and memory complexities. However, little attention has been paid to designing learning systems that will allow us to gain a better understanding of incoming data. There are few proposals on how to design interpretable classifiers for drifting data streams, yet most of them are characterized by a significant trade-off between accuracy and interpretability. In this paper, we show that it is possible to have all of these desirable properties in one model. We introduce ERulesD2S: evolving rule-based classifier for drifting data Streams. By using grammar-guided genetic programming, we are able to obtain accurate sets of rules per class that are able to adapt to changes in the stream without a need for an explicit drift detector. Additionally, we augment our learning model with new proposals for rule propagation and data stream sampling, in order to maintain a balance between learning and forgetting of concepts. To improve efficiency of mining massive and non-stationary data, we implement ERulesD2S parallelized on GPUs. A thorough experimental study on 30 datasets proves that ERulesD2S is able to efficiently adapt to any type of concept drift and outperform state-of-the-art rule-based classifiers, while using small number of rules. At the same time ERulesD2S is highly competitive to other single and ensemble learners in terms of accuracy and computational complexity, while offering fully interpretable classification rules. Additionally, we show that ERulesD2S can scale-up efficiently to high-dimensional data streams, while offering very fast update and classification times. Finally, we present the learning capabilities of ERulesD2S for sparsely labeled data streams.","Machine learning,Data streams,Concept drift,Genetic programming,Rule-based classification,GPU,High-performance data mining","AlbertoCano,BartoszKrawczyk","Pattern Recognition","https://doi.org/10.1016/j.patcog.2018.10.024","https://www.sciencedirect.com/science/article/pii/S0031320318303765"
"A326","Associative knowledge feature vector inferred on external knowledge base for dialog state tracking","The dialog state tracker is one of the most important modules on task-oriented dialog systems, its accuracy strongly affects the quality of the system response. The architecture of the tracker has been changed from pipeline processing to an end-to-end approach that directly estimates a user’s intention from each current utterance and a dialog history because of the growth in the use of the neural-network-based classifier. However, tracking appropriate slot-value pairs of dialog states that are not explicitly mentioned in user utterances is still a difficult problem. In this research, we propose creating feature vectors by using inference results on an external knowledge base. This inference process predicts associative entities in the knowledge base, which contribute to the dialog state tracker for unseen entities of utterances. We extracted a part of a graph structure from an external knowledge base (Wikidata). Label propagation was used for inferring associative nodes (entities) on the graph structure to produce feature vectors. We used the vectors for the input of a fully connected neural network (FCNN) based tracker. We also introduce a convolutional neural network (CNN) tracker as a state-of-the-art tracker and ensemble models of FCNN and CNN trackers. We used a common test bed, Dialog State Tracking Challenge 4 for experiments. We confirmed the effectiveness of the associative knowledge feature vector, and one ensemble model outperformed other models.","Dialog state tracking,Knowledge base,Knowledge graph,Associative knowledge inference","YukitoshiMurasea,YoshinoKoichiroabc,SatoshiNakamuraa","Computer Speech & Language","https://doi.org/10.1016/j.csl.2018.08.003","https://www.sciencedirect.com/science/article/pii/S0885230818300986"
"A327","Gaussian process approach for metric learning","Learning appropriate distance metric from data can significantly improve the performance of machine learning tasks under investigation. In terms of the distance metric representation forms in the models, distance metric learning (DML) approaches can be generally divided into two categories: parametric and non-parametric. The first category needs to make parametric assumption on the distance metric and learns the parameters, easily leading to overfitting and limiting model flexibility. The second category abandons the above assumption and instead, directly learns a non-parametric distance metric whose complexity can be adjusted according to the number of available training data, and makes the model representation relatively flexible. In this paper we follow the idea of the latter category and develop a non-parametric DML approach. The main challenge of our work concerns the formulation and learning of non-parametric distance metric. To meet this, we use Gaussian Process (GP) to extend the bilinear similarity into a non-parametric metric (here we abuse the concept of metric) and then learn this metric for specific task. As a result, our approach learns not only nonlinear metric that inherits the flexibility of GP but also representative features for the follow-up tasks. Compared with the existing GP-based feature learning approaches, our approach can provide accurate similarity prediction in the new feature space. To the best of our knowledge, this is the first work that directly uses GP as non-parametric metric. In the experiments, we compare our approach with related GP-based feature learning approaches and DML approaches respectively. The results demonstrate the superior performance of our approach.","Metric learning,Gaussian process,Bilinear similarity,Non-parametric metric","PingLi,SongcanChen","Pattern Recognition","https://doi.org/10.1016/j.patcog.2018.10.010","https://www.sciencedirect.com/science/article/pii/S0031320318303571"
"A328","Identifying spatial interaction patterns of vehicle movements on urban road networks by topic modelling","The development of mobile positioning technologies makes massive individual trajectory data easily accessible, which facilitates the revisit of spatial interaction issue in recent years. Researchers have proposed many methods to investigate the spatial interactions derived from human movements, such as the gravity model and radiation model. However, these studies have mainly focused on the interactions among areal units at an aggregated level, neglecting that in most cases, human movements are carried by vehicles and constrained by the underlying road network, which causes the interactions among roads. To fill this gap, we propose a novel approach to identify spatial interaction patterns of vehicle movements on urban road network. As the topic model originating from the domain of natural language processing has powerful advantages in extracting semantic relations of words from corpus, we utilize it to extract interaction relations of urban roads from massive vehicle trajectories. First, \"strokes\" (i.e., natural streets) are chosen as geographical units to represent the vehicle moving paths. Then, an analogy between geographical elements (i.e., stroke, moving path) and textual elements (i.e., word, document) is established, and a topic model is applied to the moving paths to identify the spatial interaction patterns on road network. From a mass of trajectory data collected by GNSS-equipped taxis in Beijing, the \"topic patterns\", which can be viewed as clusters of spatially interacted strokes, are identified, visualized and verified. It is argued that our proposed approach is effective in identifying spatial interaction patterns, which provides a new perspective for spatial interaction modelling and enriches the current spatial interaction studies.","Spatial interaction,Vehicle movement,Stroke,Road network,Topic model","KangLiuab,SongGaoc,FengLubdef","Computers, Environment and Urban Systems","https://doi.org/10.1016/j.compenvurbsys.2018.12.001","https://www.sciencedirect.com/science/article/pii/S0198971518302898"
"A329","Status and future perspectives of reliability assessment for electric vehicles","Using clean energy sources has contributed to various industries, especially the automotive industry. In this regard, large companies have taken a significant step in the field of renewable energy by introducing Electric Vehicles (EVs). One of the main challenges in the EVs area is evaluating the reliability and safety of these vehicles. Thus, the concept of the reliability and safety of EV's components is considered a significant issue. In general, reliability and safety assessment of important electrical components of EVs, i.e. i) the battery pack, ii) power electronic converters, and iii) the electric motor, plays a significant role in the lifetime performance of EVs’ electrical system. This paper presents a comprehensive review of the reliability of EVs’ components from different points of view. Also, the challenges and future perspective of EVs relating to the reliability and safety, which need to be considered have been investigated.","Reliability assessment,Safety,Electric vehicles,Failure analysis,Electrical components","Foad H.Gandomanab,AbdollahAhmadic,Peter Van denBosscheab,JoeriVan Mierloab,NoshinOmarab,Ali EsmaeelNezhadd,HaniMavalizadehe,ClémentMayetab","Reliability Engineering & System Safety","https://doi.org/10.1016/j.ress.2018.11.013","https://www.sciencedirect.com/science/article/pii/S0951832018306215"
"A330","Dynamic modelling and non-linear control of TLP supported offshore wind turbine under environmental loads","Offshore wind turbines (OWT) can be promising renewable energy devices. The motions of the turbine may be considerably high in severe sea-states and therefore they need to be operational after transition of such states. This work proposes a novel controller technique and its application in tension leg platform(TLP) supported OWT to harvest optimized power. It is achieved using the nonlinear quadratic regulator based algorithm wherein the state dependent structural system matrices are modified appropriately to account for the fluctuating dynamics. Three wind speeds (15<U+202F>m/s, 21<U+202F>m/s and 25<U+202F>m/s) along with turbulence intensity of 0.1 are selected which are above the rated wind speed as the controller mechanism is effective for those regions. Since the wind and wave loads are taken as random, Monte Carlo method is used for the analysis to rule out epistemic uncertainty by ensemble statistics. The results show that the proposed nonlinear quadratic regulator is able to control the power, generator torque and rotor speed effectively without additional increase in platform motions vis-á-vis existing conventional Baseline controller. It is also observed that there are lesser fluctuations using the proposed controller compared to existing controller. The ensemble statistics –maxima and mean— are close to the reference value when wind speeds are close to rated-wind speed; whereas the platform motions and tower base forces is less using the proposed NQR controller or at least similar to the Baseline controller. The ensemble standard deviation are far less which shows the output power is controlled effectively.","Nonlinear control and dynamics,Wind and wave loads,Quadratic regulator,Response statistics,Offshore wind turbines,Tension leg platform","R.Manikandan,NilanjanSaha","Marine Structures","https://doi.org/10.1016/j.marstruc.2018.10.014","https://www.sciencedirect.com/science/article/pii/S0951833918301011"
"A331","Numerical study of boiling around wires and influence of active or passive neighbours on vapour film dynamics","In the present study pool boiling around a heated wire has been simulated at atmospheric pressure, considering the wire to be at the constant temperature heat source. Film dynamics, bubble nucleation, growth, merging and pinch off has been observed in with perfectly smooth and uniform horizontal wire without any nucleation site. Effect of increase of the degree of superheat on boiling rate, measured in terms of vapour generation and bubble population has been studied next. Similar studies have been done by inclining the wire at different angles (10°, 45°, 60° and vertical), where axial and azimuthal bubble sliding and more efficient bubble merging have been observed. Bubble size and population distribution have been investigated along the length of the inclined wire to link up with corresponding enhancement in boiling rate. For understanding the effect of active and passive neighbour, horizontal boiling around two-wire system has been studied. First horizontal wires have been stacked at the same vertical plane and different active and passive combination have been simulated. Also boiling from two active wires placed at same horizontal plane has been studied for different wire spacings. For all these cases bubble life cycle has been investigated to understand the role of neighbouring wire. Effect of these neighbouring wires on boiling heat transfer and vapour generation rate has been reported.","Wire,Film,Boiling,Inclination,Active,Passive,Merging,Sliding","AvikSaha,Arup KumarDas","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.10.117","https://www.sciencedirect.com/science/article/pii/S0017931018337657"
"A332","Membrane targeting cationic antimicrobial peptides","Many short cationic peptides are amphiphilic and are often termed antimicrobial peptides (AMPs) as they can kill various microorganisms. These AMPs have largely been discovered from nature, but over the past two decades many biomimetic and de novo designed AMPs have been reported, offering a huge variety of attractive properties for further exploitation. Under the current global endeavour of fighting against antimicrobial resistance, it is useful to introduce AMPs to the biointerface research community and compare their modes of action with conventional antibiotics. Because natural AMPs often have long sequences and other biological functions implicated, they can’t be used as antimicrobial agents. However, rational AMP design helps eliminate their shortcomings and more importantly, optimise their structure-function relationship. This review will first introduce the key approaches recently utilised in structural design of AMPs and then introduce the main lipid membrane models such as spread lipid monolayers and vesicles together with the characterisation techniques adopted in early AMP design and development. These studies are crucial towards understanding key factors affecting their efficacy and toxicity. Thus, various interfacial measurements facilitated by different forms of lipid monolayers and bilayers provide valuable support to the selective responses of AMPs to different cell types used in bactericidal assays and cytotoxicity tests, emphasising the link between molecular models and cell models. A number of clinical trials of AMPs have been either under way or completed, demonstrating the huge potential of AMPs in a range of applications.","Peptide amphiphiles,Peptide surfactants,Antimicrobial peptides,Cationic peptides,Lipid membrane,Antimicrobial resistance,Biocompatibility,Toxicity,Neutron reflection,Biophysics,Abbreviations,aaamino acid,ABCATP-binding cassette,AFMatomic force microscopy,AMPantimicrobial peptide,AMRantimicrobial resistance,ATPadenosine triphosphate,BAMBrewster angle microscopy,BLMblack lipid membrane,CDcircular dichroism,CLcardiolipin,CLSMconfocal laser scanning microscope,DGDGdigalactosyldiacylyglycerol,DHBdroplet hydrogel bilayer,DIBdroplet interface bilayer,DMPC1,2-dimyristoyl-sn-glycero-3-phosphocholine,DMPG1,2-dimyristoyl-sn-glycero-3-phospho-(1'-rac-glycerol),DNAdeoxyribonucleic acid,DPCdodecylphosphocholine,DPIdual polarisation interferometry,DPPC1,2-dipalmitoyl-sn-glycero-3-phosphocholine,DPPG1,2-dipalmitoyl-sn-glycero-3-phospho-(1'-rac-glycerol),DOPC1,2-dioleoyl-sn-glycero-3-phosphocholine,DOPE1,2-dioleoyl-sn-glycero-3-phosphoethanolamine,DOPG1,2-dioleoyl-sn-glycero-3-phosphoglycerol,DOPS1,2-dioleoyl-sn-glycero-3-phospho-L-serine,EC50concentration to induce 50% lysis of erythrocytes,ER-FTIRexternal reflection Fourier transform infrared,ESBLextended-spectrum ß-lactamase,FITCfluorescein isothiocyanate,GPLglycerophospholipids,GUVgiant unilamellar vesicle,hBDhuman ß-defensin,HNPhuman neutrophil peptide,IC50concentration causing 50% tumour cell growth inhibition,IMinner cytoplasmic membrane,IMSintermembrane side,IRRASinfrared reflection absorption spectroscopy,ITCisothermal titration calorimetry,LPSlipopolysaccharide,LTAlipoteichoic acid,LUVlarge unilamellar vesicle,MDmolecular dynamics,MDRmultidrug resistance,MGDGmonogalactosyldiacylglycerol,MICminimum inhibitory concentration,MMMontal-Mueller,MRSAmethicillin-resistant S. aureus,mtrmultiple transferrable resistance,NMRnuclear magnetic resonance,NRneutron reflectivity,NRWnull reflecting water,OMouter membrane,OMMouter mitochondrial membrane,OprIouter membrane protein I,PAphosphatidic acid,PBSphosphate buffered saline,Pcpreclinical,PCphosphatidylcholine,PEphosphatidylethanolamine,PGphosphatidylglycerol,PG-1protegrin-1,PIphosphatidylinositol,PIPphosphatidylinositol 4-phosphate,PMPplatelet microbicidal protein,POPC1-palmitoyl-2-oleoyl-glycero-3-phosphocholine,POPE1-palmitoyl-2-oleoyl-sn-glycero-3-phosphoethanolamine,POPG1-palmitoyl-2-oleoyl-sn-glycero-3-phospho-(1'-rac-glycerol),PSphosphatidylserine,RBCred blood cell,RNAribonucleic acid,ROSreactive oxygen species,SDSsodium-dodecyl-sulfate,SEMscanning electron microscope,SFGsum frequency generation,SLBsupported lipid bilayer,SMsphingomyelin,SUVsmall unilamellar vesicle,SVCsmall colony variant,TAteichoic acid,TIRFtotal internal reflection fluorescence,tPMPthrombin-induced PMP,VREvancomycin-resistant Enterococcus,XRX-ray reflectivity","DanielaCiumac,HaoningGong,XuzhiHu,Jian RenLu","Journal of Colloid and Interface Science","https://doi.org/10.1016/j.jcis.2018.10.103","https://www.sciencedirect.com/science/article/pii/S0021979718313006"
"A333","Design and mechanism of action of multifunctional BPE’s with high performance in the separation of hazardous metal ions from polluted water Part I: Chitosan-poly(N-vinylcaprolactam) and its derivatives","This paper presents the design and mechanism of action of multifunctional biopolyelectrolytes (BPE’s) with high performance in the separation of hazardous metal ions from polluted water. The first part of a series of BPE’s is the chitosan-poly(vinylcaprolactam) and its derivatives that were synthethized based on chitosan (Ch) and poly (N-vinylcaprolactam) (PNVCL) to obtain three chitosan derivative (Ch’s derivatives), phosphonomethylated chitosan and dendrimeric chitosan and a copolymer of ChPNVCL. The chemical synthesis was carried out varying their chemical structure and surface charge density. They are proposed as innovative multifunctional biopolyelectrolytes were evaluated in aqueous medium and performance in the separation of seven metal cations frequently present in plating wastewater. The physicochemical characterization included FTIR, MP-EAS, SEM-EDS of Ch, PNVCL and Ch's derivatives and the flocs recovered after solid-liquid separation, as well as, analysis of colloidal stability and zeta potential. The zeta potential measurements were used as a key tool to perform the design of the multifunctional chitosan derivatives, predict their behavior in the coagulation flocculation of simulated wastewater and determine their BPE-metal ion interaction mechanisms. The investigation of the multifunctional performance of the BPE shows that dendronized chitosan (ChDCOOH) has functional activities such as chelating coagulant and flocculant, being a macromolecule bearing suitable ligand groups that can interact with heavy metal ions. The ChDCOOH has a coagulation-flocculation window (97–140.2<U+202F>mg/L) allowed the simultaneous separation of the seven metal ions at pH 4.7: Cr3+ (0.00)<U+202F>><U+202F>Pb2+ (0.05)<U+202F>><U+202F>Cu2+ (0.60)<U+202F>><U+202F>Ni2+ (1.51)<U+202F>><U+202F>Zn2+ (3.42)<U+202F>><U+202F>Ca2+ (5.60)<U+202F>><U+202F>Cd2+ (4.78), and fast of the seven metal ions; clarification (423 %T/h) and sedimentation kinetics (140.0<U+202F>mm/h).","Biopolyelectrolytes,Zeta potential,Chitosan,Heavy metals,Macromolecular metal complex,Poly (N-vinylcaprolactam)","Oscar Gabriel ZavalaGarcíab,Mercedes TeresitaOropeza-Guzmánb,Waldo M.Argüelles Monalc,Eduardo AlbertoLópez-Maldonadoa","Chemical Engineering Journal","https://doi.org/10.1016/j.cej.2018.11.134","https://www.sciencedirect.com/science/article/pii/S1385894718323684"
"A334","Flow control for a car-mounted rear wing","In this paper, experimental and numerical results are presented on an active car wing with a moving spoiler placed beneath it. It was shown that movement of a small element, i.e., the spoiler, can result in a significant change of downforce generated by the car body, equivalent to changing the rear wing's angle of attack by several degrees. A 1:2.5 scale car model, equipped with several moving surfaces, was tested in a wind tunnel to establish the aerodynamic coefficients. During wind tunnel tests, all force components were measured for various wing and spoiler configurations. Visualization techniques such as oil and mini-tufts were used. Numerical simulations of wind tunnel configurations were validated with the use of wind tunnel test data. Different turbulence models were considered and a good accuracy with the wind tunnel results was achieved.","Wind tunnel tests,CFD,Automobile aerodynamics,Active aerodynamics,Rear wing,Aerodynamic loads","KrzysztofKureca,MichalRemera,TobiaszMayerc,SylwesterTudrujb,JanuszPiechnaa","International Journal of Mechanical Sciences","https://doi.org/10.1016/j.ijmecsci.2018.12.034","https://www.sciencedirect.com/science/article/pii/S0020740318318484"
"A335","A model-driven IT governance process based on the strategic impact evaluation of services","Model-driven engineering is used for managing software systems development. In most cases, requirements representations are transformed into design diagrams themselves transformed into code, ensuring traceability. Such an approach can nevertheless take roots on a more abstract level and be used for IT governance. Goal-oriented requirements engineering can be adapted to model strategic objectives aimed to lead the organization to an enhanced competitive position in the long-term. Most IT governance and management frameworks are driven by the concept of service. The latter allows to package the work offer of an IT provider. Within their realization, such services align or misalign with strategic objectives. This paper proposes a model-driven IT governance process allowing to evaluate the alignment of business IT services to strategic objectives; it follows the 3 stages of IT governance: evaluate, direct and monitor. The approach allows to integrate the governance level as a (graphical) strategic layer made of long-term objectives that business IT services potentially contribute or hamper to attain. The strategic layer is custom developed for each organization and linked with organizational representations in a model-driven fashion to study business and IT alignment. The framework is called MoDrIGo; it is applied onto a case study in a hospital.","IT Governance,Service-based modeling,I*,Model-Driven engineering,Business strategy,IT Strategy","YvesWautelet","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2018.12.024","https://www.sciencedirect.com/science/article/pii/S0164121218302826"
"A336","Endometrial Epithelial Cell Apoptosis Is Inhibited by a ciR8073-miR181a-Neurotensis Pathway during Embryo Implantation","","receptive endometrium,ceRNA,ciR8073-miR181a-NTS,endometrial epithelial cells,EECs,dairy goats","LeiZhang12,XiaoruiLiu12,SichengChe12,JiuzengCui1,XingnaMa1,XiaopengAn1,BinyunCao1,YuxuanSong1","Molecular Therapy - Nucleic Acids","https://doi.org/10.1016/j.omtn.2018.12.005","https://www.sciencedirect.com/science/article/pii/S2162253118303202"
"A337","Blind fMRI source unmixing via higher-order tensor decompositions","BackgroundThe growing interest in neuroimaging technologies generates a massive amount of biomedical data of high dimensionality. Tensor-based analysis of brain imaging data has been recognized as an effective analysis that exploits its inherent multi-way nature. In particular, the advantages of tensorial over matrix-based methods have previously been demonstrated in the context of functional magnetic resonance imaging (fMRI) source localization. However, such methods can also become ineffective in realistic challenging scenarios, involving, e.g., strong noise and/or significant overlap among the activated regions. Moreover, they commonly rely on the assumption of an underlying multilinear model generating the data.,New methodThis paper aims at investigating the possible gains from exploiting the 4-dimensional nature of the brain images, through a higher-order tensorization of the fMRI signal, and the use of less restrictive generative models. In this context, the higher-order block term decomposition (BTD) and the PARAFAC2 tensor models are considered for the first time in fMRI blind source separation. A novel PARAFAC2-like extension of BTD (BTD2) is also proposed, aiming at combining the effectiveness of BTD in handling strong instances of noise and the potential of PARAFAC2 to cope with datasets that do not follow the strict multilinear assumption.,Comparison with existing methodsThe methods were tested using both synthetic and real data and compared with state of the art methods.,ConclusionsThe simulation results demonstrate the effectiveness of BTD and BTD2 for challenging scenarios (presence of noise, spatial overlap among activation regions and inter-subject variability in the haemodynamic response function (HRF)).","FMRI,Tensors,PARAFAC2,Block term decomposition (BTD),BTD2","ChristosChatzichristosab,EleftheriosKofidisac,ManuelMoranteab,SergiosTheodoridisabd","Journal of Neuroscience Methods","https://doi.org/10.1016/j.jneumeth.2018.12.007","https://www.sciencedirect.com/science/article/pii/S0165027018303996"
"A338","A coupled multivariate statistics, geostatistical and machine-learning approach to address soil pollution in a prototypical Hg-mining site in a natural reserve","The impact of mining activities on the environment is vast. In this regard, many mines were operating well before the introduction of environmental law. This is particularly true of cinnabar mines, whose activity has declined for decades due to growing public concern regarding Hg high toxicity.Here we present the exemplary case study of an abandoned Hg mine located in the Somiedo Natural Reserve (Spain). Until its closure in the 1970s, this mine operated under no environmental regulations, its tailings dumped in two spoil heaps, one of them located uphill and the other in the surroundings of the village of Caunedo. This study attempts to outline the degree to which soil and other environmental compartments have been affected by the two heaps. To this end, we used a novel combination of multivariate statistical, geostatistical and machine-learning methodologies. The techniques used included principal component and clustering analysis, Bayesian networks, indicator kriging, and sequential Gaussian simulations.Our results revealed high concentrations of Hg and, secondarily, As in soil but not in water or sediments. The innovative methodology abovementioned allowed us to identify natural and anthropogenic associations between 25 elements and to conclude that soil pollution was attributable mainly to natural weathering of the uphill heap. Moreover, the probability of surpassing the threshold limits and the local backgrounds was found to be high in a large extension of the area.The methodology used herein demonstrated to be effective for addressing complex pollution scenarios and therefore they are applicable to similar cases.","Mercury,Multivariate statistics,Soil pollution,Machine learning,Geostatistics","C.Boentea,M.T.D.Albuquerqueb,S.Gerassisc,E.Rodríguez-Valdésa,J.R.Gallegoa","Chemosphere","https://doi.org/10.1016/j.chemosphere.2018.11.172","https://www.sciencedirect.com/science/article/pii/S0045653518322677"
"A339","Open-access cloud resources contribute to mainstream REDD+: The case of Mozambique","The objective of this work is to investigate how Earth Observation data and processing platforms accessible on the cloud can facilitate the implementation of REDD+ in developing countries. For that, we explore newly available open-access satellite data, cloud processing, and a ready-made land cover map to assess the extent to which such resources can directly respond to monitoring and measuring, reporting, and verification requisites. Mozambique is one of the 47 countries selected to benefit from the Forest Carbon Partnership Facility to implement REDD+ strategies. However, to meet funding agreements, the country needs to periodically produce national land cover and land cover change maps at given resolution and accuracy levels. The work presented here shows that the land cover mapping requisites of REDD+ may be quickly and cost-effectively met through the development and use of newly available cloud resources. The study relies on an experimental design that tests the results of image processing approaches with algorithms available or developed in Google Earth Engine against country-wide reference data collected by a team of national experts. The results show that, in addition to pre-processing advantages, which facilitate multi-temporal compositing and mosaicking of very large and heavy data sets, developments in cloud processing and image classification swiftly produce large extent and high-resolution land cover maps, tailored to a specific objective. The comparison of results between the in-house map obtained using Google Earth Engine, and the pan-African map produced by the European Space Agency (2016) at the same spatial resolution, reveals that both maps meet REDD+ requirements for a binary Forest/Non-forest legend. However, the in-house map is more accurate and reaches considerably better results if a more complex, six class IPCC legend is required. Nevertheless, this study shows that, given adequate reference data, the need to periodically produce high resolution land cover maps for national forest monitoring purposes is no longer an obstacle for mainstreaming the implementation of REDD+.","REDD+,Mozambique,GEE,Sentinel2,Land cover","CatarinaLopesa1,AnaLeiteab1,Maria JoséVasconcelosb","Land Use Policy","https://doi.org/10.1016/j.landusepol.2018.11.049","https://www.sciencedirect.com/science/article/pii/S0264837718302709"
"A340","Construction site accident analysis using text mining and natural language processing techniques","Workplace safety is a major concern in many countries. Among various industries, construction sector is identified as the most hazardous work place. Construction accidents not only cause human sufferings but also result in huge financial loss. To prevent reoccurrence of similar accidents in the future and make scientific risk control plans, analysis of accidents is essential. In construction industry, fatality and catastrophe investigation summary reports are available for the past accidents. In this study, text mining and natural language process (NLP) techniques are applied to analyze the construction accident reports. To be more specific, five baseline models, support vector machine (SVM), linear regression (LR), K-nearest neighbor (KNN), decision tree (DT), Naive Bayes (NB) and an ensemble model are proposed to classify the causes of the accidents. Besides, Sequential Quadratic Programming (SQP) algorithm is utilized to optimize weight of each classifier involved in the ensemble model. Experiment results show that the optimized ensemble model outperforms rest models considered in this study in terms of average weighted F1 score. The result also shows that the proposed approach is more robust to cases of low support. Moreover, an unsupervised chunking approach is proposed to extract common objects which cause the accidents based on grammar rules identified in the reports. As harmful objects are one of the major factors leading to construction accidents, identifying such objects is extremely helpful to mitigate potential risks. Certain limitations of the proposed methods are discussed and suggestions and future improvements are provided.","Construction site accident analysis,Machine learning,Text mining,Natural language processing,Sequential quadratic programming,Optimization","FanZhanga,HasanFleyeha,XinruWangb,MinghuiLuc","Automation in Construction","https://doi.org/10.1016/j.autcon.2018.12.016","https://www.sciencedirect.com/science/article/pii/S0926580518306137"
"A341","Neurofeedback training protocols based on selecting distinctive features and identifying appropriate channels to enhance performance in novice visual artists","Differences in brain signals between skilled and non-skilled individuals led to the idea of using neurofeedback (NFB) in order to imitate brain activity patterns in skilled individuals, reinforce performance of novice people, and ultimately help them in terms of achieving skills in a faster manner. This study shed light on visual skills and aimed at designing a NFB training protocol specifically enhancing the performance of novice visual artists. For this purpose, a set of features (energy, mean and standard deviation of wavelet and cepstral coefficients, wavelength, the first zero crossing of autocorrelation function, correlation and fractal dimensions, approximate and sample entropy and scaling exponent) of EEG signals recorded from two groups of visual artists and non-artists were obtained during observation and mental imagery of several images. Then, the most effective distinctive features of the two groups and the associated channel were established by means of genetic algorithm. Fitness function in genetic algorithm was also defined using Mann-Whitney U test and Davies-Bouldin index (DB). Finally, the increase in the first zero crossing of the autocorrelation function in C4 channel was proposed as the protocol enhancing visual perception performance. Moreover, increased approximate entropy (ApEn) in Fp1 channel was suggested as a protocol for enhancing mental imagery among novice visual artists.","EEG,Neurofeedback,Artist,Visual perception,Mental imagery,Genetic algorithm,Davies-Bouldin index","NasrinSho'ouriab,MohammadFiroozabadic,KambizBadied","Biomedical Signal Processing and Control","https://doi.org/10.1016/j.bspc.2018.12.013","https://www.sciencedirect.com/science/article/pii/S1746809418303124"
"A342","WSV181 inhibits JAK/STAT signaling and promotes viral replication in Drosophila","The Janus kinase/signal transducers and activators of transcription (JAK/STAT) pathway plays a critical role in host defense against viral infections. Here, we report the use of the Drosophila model system to investigate the modulation of the JAK/STAT pathway by the white spot syndrome virus (WSSV) protein WSV181. WSV181 overexpression in transgenic flies resulted in the downregulation of STAT92E and STAT92E-targeted genes. This result indicates that WSV181 can suppress JAK/STAT signaling by controlling STAT92E expression. An infection experiment was carried out on transgenic Drosophila infected with Drosophila C virus and on Litopenaeus vannamei injected with recombinant WSV181 and WSSV. The increased viral load and suppressed transcript levels of JAK/STAT pathway components indicate that WSV181 can promote viral proliferation by inhibiting the JAK/STAT pathway. This study provided evidence for the role of WSV181 in viral replication and revealed a new mechanism through which WSSV evades host immunity to maintain persistent infection.","WSSV,WSV181,JAK/STAT pathway,Viral replication","WeiWanga1,ChangkunPanb1,ZongliangHuangc,HuifangYuand,JianmingChena","Developmental & Comparative Immunology","https://doi.org/10.1016/j.dci.2018.11.003","https://www.sciencedirect.com/science/article/pii/S0145305X18303562"
"A343","Student in the shell: The robotic body and student engagement","The purpose of this case study was to explore how the embodiment of graduate students in robotic surrogates was related to their engagement in a class with other robotically and non-robotically embodied classmates. Using a mixed methods design, we collected survey and in-class observational data on the students' perceptions of their robotic bodies and their engagement in the course. Applying linear models and thematic analysis, we sought to identify prevailing patterns of students' use their robotic bodies to engage in their learning. Our findings suggest that nonverbal communication with one's robotic body is a dominant form of interaction and engagement in synchronous learning contexts and multiple contextual factors affect robotic students' engagement. Specifically, the capabilities of the robotic surrogate and the student's perceptions of the surrogate as an extension of their own body may influence their engagement in educational contexts. Patterns of robotic and nonverbal behaviors may also vary with instructional context and social learning. For robotically telepresent students, embodiment becomes a central factor to their engagement and should be included in theories of engagement in technology-mediated contexts that involve surrogate bodies.","Robots,Embodiment,Social presence,Student engagement,Synchronous learning","MingLei,Ian M.Clemente,YingHu","Computers & Education","https://doi.org/10.1016/j.compedu.2018.11.008","https://www.sciencedirect.com/science/article/pii/S0360131518303051"
"A344","Numerical tornado modeling for common interpretation of experimental simulators","Numerical simulation of tornado-like vortices, like those produced in experimental facilities, poses many challenges. This is attributed to the complexity of vortical flow-field and the common practice of directly using the geometric dimensions and configuration of physical elements like guide vane angle, ceiling height, etc. of experimental simulators as a measure of parameters needed to characterize the generated vortices. The inherent differences in geometric dimensions and vortex generation mechanisms of the existing experimental tornado simulators makes such vortex characterization very ad-hoc in nature and hinders direct comparison and validation of results. Therefore, to facilitate a common interpretation of experimental simulators, a simplified numerical tornado model, representing the three types of existing experimental tornado simulators, is developed in this study. The three experimental simulators in consideration are VorTECH at Texas Tech University, Tornado Simulator at Iowa State University and WindEEE Dome at Western University as representatives of “Ward” type, “top-down” type and “3-D wind chamber” type designs, respectively. First, the numerically generated flow-field for each simulator obtained by modelling full experimental system is validated with experimental results. Then the simplification of these full laboratory models into a cylindrical computational domain is carried out by extracting vortex characterizing parameters strictly from the flow-field for various configurations. The dimensions and inlet boundary condition of the cylindrical model vary from one configuration to other and are dictated by vortex characterizing parameters like inflow depth, radius of updraft, swirl ratio etc. The result of this study is a simplified generic numerical tornado model that (i) can reproduce the flow-field of the original experimental systems, (ii) shows a direct dependence of the vortex flow-structure on parameters obtained from flow-field (as opposed to extracting them directly from the physical dimensions of experimental simulators).","Tornado-like vortices,Experimental tornado simulators,Flow-field characterization,Numerical tornado simulation,VorTECH (TTU),Tornado simulator (ISU),WindEEE dome (WU)","AnantGairola,GirmaBitsuamlak","Journal of Wind Engineering and Industrial Aerodynamics","https://doi.org/10.1016/j.jweia.2018.12.013","https://www.sciencedirect.com/science/article/pii/S016761051730939X"
"A345","Variational approach to cancerous tissue identification from in vivo Raman spectra","In biomedical applications, the human factor represents the major obstacle in the processing and classification of in vivo Raman spectra. Although several methods of statistical classification have been employed to address this issue, the outcomes thereof vary depending on the selection of spectral bands used for the evaluation. To avoid the use of such discrete values, we developed a variational classifier based on spectrum weighting, weight smoothing and regularization and the selection of a support vector set. Embedded regularization of the variational classifier smooths weight function and therefore original Raman spectra preprocessing don’t need to include spectra smoothing. Due to a small data set, we proposed a hierarchical cross-validation technique performing better data generalization and overfitting avoiding. Accuracy of variational classifier obtained by hierarchical cross-validation for the data set, involving 30 Raman spectra of which 13 represent cancerous and 17 healthy tissues, was 93% with sensitivity of 92% and specificity of 94%.","Variational classifier,Cancerous tissue identification,Raman spectra,Hierarchical cross-validation","ZuzanaKrbcovaa,JaromirKukala,JanMaresa,LucieHabartovab,VladimirSetnickab","Biomedical Signal Processing and Control","https://doi.org/10.1016/j.bspc.2018.12.026","https://www.sciencedirect.com/science/article/pii/S1746809418303252"
"A346","A family of heuristic search algorithms for feature model optimization","Feature models are a well-known formalism for capturing variability, commonalities and configuration rules of software systems. These models are a compact representation of the set of products in a software product line or configurations of a system at runtime, in terms of features and logical relationships among them. The feature model optimization problem consists of selecting a valid product from the model that satisfies a set of resource or business restrictions and optimizes an objective function commonly related to user preferences. This problem, although computationally intractable, has been addressed in several works with different algorithms. However, these approaches appeal to simplifications of the problem or present drawbacks that limit their application. For example, several approaches do not contemplate feature interactions, and some of them do not guarantee exact solutions or even valid solutions satisfying complex constraints. In this article, we propose a novel algorithm called CSA that overcomes the performance and common weaknesses of existing approaches. CSA can be parameterized with a set of classic search strategies (Backtracking, Branch & Bound, and Best-First Search) and heuristics that allow us to leverage solution optimality and search efficiency. This makes CSA appropriate for automating decisions both at design-time, where exact solutions are generally required, and at run-time, where selection must be done efficiently but sub-optimal solutions are acceptable. The algorithm supports different formats of objective functions, including multi-linear polynomial functions that are capable of representing feature interactions. We present an analysis to validate algorithm properties, and then a series of experiments with synthetic and real models to empirically compare CSA with existing alternatives to show the benefits of our approach. In our analysis, CSA showed to be complete, exact, and scalable for searching approximate solutions. The empirical results showed that the approximate variant of CSA can reach an optimality degree of 99%, against a 84% and 93% reached by other approximate alternatives based on genetic and greedy algorithms respectively. In terms of response time, CSA performed a 72% better than other approximate algorithms. Compared to other exact approaches, CSA improves response time on specific problem types. Furthermore, CSA was evaluated with problem instances involving feature interactions, showing that performance properties scale properly when the number of feature interactions increases.","Search-based software engineering,Feature modeling,Software product line,Optimization,Heuristic search","Luis EmilianoSánchez,Jorge AndrésDiaz-Pace,AlejandroZunino","Science of Computer Programming","https://doi.org/10.1016/j.scico.2018.12.002","https://www.sciencedirect.com/science/article/pii/S0167642318304350"
"A347","Distance-based customer detection in fake follower markets","As the Online Social Networks (OSNs) have become popular, more and more people want to increase their influence not only in the real world but also in the OSNs. However, increasing the influence in OSNs is time-consuming job, so some users want to find a shortcut to increase their relationships. The demand for quick increasement of relationship has led to the growth of the fake follower markets that cater to customers who want to grow their relationships rapidly. However, customers of fake follower markets cannot manipulate legitimate user’s relationship perfectly. Existing approaches explore node’s relationships or features to detect customers. But none of them combines the relationships and node’s features directly. In this article, we propose a model that directly combines the relationship and node’s feature to detect customers of fake followers. Specifically, we study the geographical distance for 1-hop-directional links using the nodes geographical location. Motivated by the difference of a distance ratio for 1-hop directional links, the proposed method is designed to generate a 1-hop link distance ratio, and classifies a node as a customer or not. Experimental results on a Twitter dataset demonstrate that the proposed method achieves higher performance than other baseline methods.","Online social networks,Twitter,Fake follower,Follower spam,Geographical distance,Small-world phenomenon","BoyeonJang,SihyunJeong,Chong-kwonKim","Information Systems","https://doi.org/10.1016/j.is.2018.12.001","https://www.sciencedirect.com/science/article/pii/S030643791830214X"
"A348","Advances in Raman spectroscopy and imaging techniques for quality and safety inspection of horticultural products","This paper gives an overview of Raman technology for inspecting quality and safety of horticultural products. Emphasis is put on introduction and demonstration of Raman spectroscopy and imaging techniques for practical uses to assess the horticultural products. Raman scattering principles are presented first, followed by introduction and comparison to Raman measurement techniques, such as backscattering Raman spectroscopy, transmission Raman spectroscopy, spatially offset Raman spectroscopy, Raman chemical imaging, surface-enhanced Raman spectroscopy, etc. Raman measurement instruments, including excitation sources, wavelength separation devices, detectors, commercial integrated and custom-developed systems, and system calibration methods, are discussed and compared. Raman data analysis methods, such as data preprocessing, spectral mixture analysis, and quantitative analysis, are presented with examples for analyzing Raman spectral and image data of selected horticultural products including tomato and carrot. Raman spectroscopy and imaging applications for quality and safety evaluation of the horticultural products are also reviewed.","Raman spectroscopy,Chemical imaging,Horticultural products,Lasers,Quality,Safety","JianweiQina,Moon S.Kima,KuanglinChaoa,SagarDhakala,Byoung-KwanChob,SantoshLohumib,ChangyeunMoc,YankunPengd,MinHuange","Postharvest Biology and Technology","https://doi.org/10.1016/j.postharvbio.2018.11.004","https://www.sciencedirect.com/science/article/pii/S0925521418307658"
"A349","The whole blood transcriptome at the time of maternal recognition of pregnancy in pigs reflects certain alterations in gene expression within the endometrium and the myometrium","","","B.Wojciechowicz,J.Kolakowska,K.Zglejc-Waszak,M.Martyniak,G.Kotwica,A.Franczak","Theriogenology","https://doi.org/10.1016/j.theriogenology.2018.11.015","https://www.sciencedirect.com/science/article/pii/S0093691X18303728"
"A350","Improving creative self-efficacy and performance through computer-aided design application","This paper discusses the effect of the application of three-dimensional computer-aided design (3D-CAD) on the creative self-efficacy and performance of student designers. A nonequivalent pretest–posttest quasi-experimental design was applied, and 164 students from a high school in Taipei City were sampled. The conclusions are summarized as follows: 1. Low–moderate positive correlations were identified between the total score and individual items of the creative self-efficacy of the students and those of the creative performance of the students. 2. Using 3D-CAD significantly enhanced the creative performance of the students, particularly the usefulness of their products. 3. Using 3D-CAD strengthened the creative self-efficacy of the students, particularly in countering external negative assessment of their creative products with positive beliefs.","Creativity,Creative self-efficacy,Creative design,Three-dimensional computer-aided design","Yu-shanChang,Mavis Yi-ChingChen,Meng-JungChuang,Chia-huiChou","Thinking Skills and Creativity","https://doi.org/10.1016/j.tsc.2018.11.007","https://www.sciencedirect.com/science/article/pii/S1871187118301974"
"A351","Experience based knowledge representation for Internet of Things and Cyber Physical Systems with case studies","Cyber Physical Systems and Internet of Things have grown significant attention from industry and academia during the past decade. The main reason behind this interest is the capabilities of such technologies to revolutionize human life since they appear as seamlessly integrating classical networks, networked objects and people to create more efficient environments. However, enhancing these technologies with intelligent skills becomes an even more interesting and enticing scenario. In this paper, we propose and illustrate through a number of case studies how Decisional DNA, a multi-domain knowledge structure based on experience, can be implemented as a comprehensive embedded knowledge representation for Internet of Things and Cyber Physical Systems. Decisional DNA gathers explicit experiential knowledge based on formal decision events and uses this knowledge to support decision-making processes. The main advantages of using Decisional DNA are as follows: (i) offers a standardized form of the collected knowledge and experience, (ii) provides versatility and dynamicity of the knowledge structure, (iii) stipulates storage of day-to-day explicit experience in a single configuration, (iv) delivers transportability and shareability of the knowledge, and (v) provides predicting capabilities based on the collected experience. Consequently, test and results of the presented implementation of Decisional DNA case studies support it as a technology that can improve and be applied to the aforementioned technologies enhancing them with intelligence by predicting capabilities and facilitating knowledge engineering processes.","Decisional DNA,Set of experience knowledge structure,Cyber Physical Systems,Internet of Things,Factory 4.0,Knowledge representation,Knowledge engineering,Decision making,Artificial intelligence,Virtual engineering object,Virtual engineering process,Virtual engineering factory","CesarSanina,ZhangHaoxib,ImranShafiqc,Md MaqboolWarisa,CaterineSilva de Oliveiraa,EdwardSzczerbickid","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.01.062","https://www.sciencedirect.com/science/article/pii/S0167739X17316965"
"A352","Computational sustainability and the PHESS platform: Using affective computing as social indicators","The use of ubiquitous devices on intelligent environment enables opportunities to solve complex problems and react to changes quicker. Namely the use of computational resources to assist the management of environment through predicament of parameters based on sustainable indicators applied to social indicators and intelligent environments. This paper considers a computational sustainability platform which manages contexts supported by principles of computational sustainability and the assurance of sustainable scenarios. An application case study based on the definition of social indicators based on mood analysis demonstrates the application of the platform and some of its innovative functionalities. It uses different types of indicators from classical sustainability dimensions in order to demonstrate the platform. Context gathering and predicative services are used based on these indicators obtained from the environment over public services, sensors networks and ubiquitous devices which are used to create indicators based on the fusion of data.","Intelligent environments,Affective computing,Internet of things,Computational sustainability","FábioSilva,CesarAnalide","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.10.006","https://www.sciencedirect.com/science/article/pii/S0167739X17328856"
"A353","Relations between numerical, spatial, and executive function skills and mathematics achievement: A latent-variable approach","Current evidence suggests that numerical, spatial, and executive function (EF) skills each play critical and independent roles in the learning and performance of mathematics. However, these conclusions are largely based on isolated bodies of research and without measurement at the latent variable level. Thus, questions remain regarding the latent structure and potentially shared and unique relations between numerical, spatial, EF, and mathematics abilities. The purpose of the current study was to (i) confirm the latent structure of the hypothesized constructs of numerical, spatial, and EF skills and mathematics achievement, (ii) measure their unique and shared relations with one another, and (iii) test a set of novel hypotheses aimed to more closely reveal the underlying nature of the oft reported space-math association. Our analytical approach involved latent-variable analyses (structural equation modeling) with a sample of 4- to 11-year-old children (N<U+202F>=<U+202F>316, Mage<U+202F>=<U+202F>6.68<U+202F>years). Results of a confirmatory factor analysis demonstrated that numerical, spatial, EF, and mathematics skills are highly related, yet separable, constructs. Follow-up structural analyses revealed that numerical, spatial, and EF latent variables explained 84% of children’s mathematics achievement scores, controlling for age. However, only numerical and spatial performance were unique predictors of mathematics achievement. The observed patterns of relations and developmental trajectories remained stable across age and grade (preschool – 4th grade). Follow-up mediation analyses revealed that numerical skills, but not EF skills, partially mediated the relation between spatial skills and mathematics achievement. Overall, our results point to spatial visualization as a unique and robust predictor of children’s mathematics achievement.","Spatial skills,Spatial visualization,Numerical skills,Executive functions,Mathematics achievement,Latent-variable analysis (SEM)","ZacharyHawesa,JoanMossb,BeverlyCaswellb,JisooSeob,DanielAnsaria","Cognitive Psychology","https://doi.org/10.1016/j.cogpsych.2018.12.002","https://www.sciencedirect.com/science/article/pii/S0010028518302548"
"A354","Effects of high-soy diet on S100 gene expression in liver and intestine of rainbow trout (Oncorhynchus mykiss)","The current study examines expression of S100 genes, a group of calcium-sensing proteins poorly characterized in fishes. In mammals, these proteins are known to play roles beyond calcium-signaling, including mediation of inflammatory processes. Some S100 proteins also serve as biomarkers for a variety of autoinflammatory conditions. It is well known that salmonids exhibit varying degrees of intestinal enteritis when exposed to alternative feed ingredients containing antinutritional factors, with soybean meal (SBM) being one of the best characterized. The etiology of soy-caused distal enteritis isn't entirely understood but displays similar histopathological alterations to the gut observed in human mucosal inflammatory bowel diseases. We sought to determine if teleost S100 genes show a concomitant response like that observed in mammals, utilizing rainbow trout fed high-soy diets as a model for intestinal inflammation. We examined expression of fourteen known salmonid S100 genes in the liver, first segment of the mid-intestine (proximal intestine), and second segment of the mid-intestine (distal intestine). After 12 weeks on a high-soy diet containing 40% SBM, we observed upregulation of several S100 genes in the distal intestine (S100I2, A10a, V1, V2, and W), no changes in the proximal intestine, and downregulation of S100V2 in the liver. Overall, our results provide further knowledge of the expression of S100 genes and provide targets for future research regarding inflammatory processes in the rainbow trout gut.","S100,Enteritis,Soy,Salmonid","Patrick C.Blaufussa,T. GibsonGaylordb,Wendy M.Sealeyb,Madison S.Powella","Fish & Shellfish Immunology","https://doi.org/10.1016/j.fsi.2018.12.025","https://www.sciencedirect.com/science/article/pii/S1050464818308246"
"A355","Identification of thioredoxin domain-containing protein 17 from big-belly seahorse Hippocampus abdominalis: Molecular insights, immune responses, and functional characterization","Thioredoxin domain-containing protein 17 (TXNDC17) is a small protein (~14<U+202F>kDa) involved in maintaining cellular redox homeostasis via a thiol-disulfide reductase activity. In this study, TXNDC17 was identified and characterized from Hippocampus abdominalis. The open reading frame (ORF) consisted of 369 bp and 123 amino acids. Similar to the other thioredoxins, TXNDC17 contained a conserved WCXXC functional motif. The highest spatial mRNA expressions of HaTXNDC17 were observed in the muscle, brain, and intestine. Interestingly, the mRNA expression of HaTXNDC17 in blood showed significant upregulation at 48<U+202F>h against all the pathogen associated molecular patterns (PAMPs) and bacteria. Further, HaTXNDC17 transcripts in the trunk kidney were significantly upregulated at 24–48<U+202F>h by bacterial endotoxin lipopolysaccharides (LPS), viral mimic polyinosinic: polycytidylic acid (poly I:C), and gram-negative bacteria (Edwardsiella tarda). The DPPH assay showed that the radical scavenging activity varies in a concentration-dependent manner. The insulin reduction assay demonstrated a significant logarithmic relationship with the concentration of rHaTXNDC17. Moreover, FHM cells treated with recombinant HaTXNDC17 significantly enhanced cellular viability under oxidative stress. Together, these results show that HaTXNDC17 function is important for maintaining cellular redox homeostasis and that it is also involved in the immune mechanism in seahorses.","Antioxidant protein,Hippocampus abdominalis,Redox balance,Temporal expression analysis,Thioredoxin domain-containing protein 17","D.S.Liyanagea,W.K.M.Omekaa,HyerimYanga,G.I.Godahewaa,HyukjaeKwona,Bo-HyeNamb,JeheeLeea","Fish & Shellfish Immunology","https://doi.org/10.1016/j.fsi.2018.11.040","https://www.sciencedirect.com/science/article/pii/S1050464818307599"
"A356","Large-scale grid integration of residential thermal energy storages as demand-side flexibility resource: A review of international field studies","Power imbalances from fluctuating renewable electricity generators are counteracted by often expensive flexibility services. Heating, cooling, and air-conditioning (HVAC) of buildings, or domestic power-to-heat (P2H), are end uses of electricity that allow flexible load patterns due to the inertia of an attached thermal storage while meeting their quality constraints. Compared to smart appliances or electric vehicle charging, P2H exhibits large and predictable capacities of demand response (DR), because buildings in many countries account for 30–40% of the final energy demand, a large part of which is thermal. Yet, its practical flexibility potential remains largely unknown: is DR from P2H a mature technology for mass usage; is it cost-efficient, socially attractive, and ready to make key contributions to flexibility comparable to backup generators or battery storage? In the present paper, we review recent international field studies that are paving the way from research to practice. These field trials include real customers but have a broader research focus and a wider outreach than rolling out a new DR tariff or program or a specific new technology for DR. Their experience mirrors the technology readiness beyond revenue or policy studies, optimization frameworks or laboratory-scale micro-grids. We analyze the adequacy of the pricing mechanisms deployed for incentivization and remuneration and review the coordination mechanisms for balancing on different timescales including fast ancillary services. We conclude that current control and information technology and economic and regulatory frameworks which have been field-tested do not yet meet the flexibility challenges of smart grids with a very high share (>50%) of intermittent renewable generation.","Demand response,Load management,Power-to-Heat,Thermal energy storage,Flexibility service,Scheduling,Dispatching,Electricity market,Field testing","PeterKohlheppa1,HassanHarbb,HenrykWoliszb,SimonWaczowicza,DirkMüllerb,VeitHagenmeyera","Renewable and Sustainable Energy Reviews","https://doi.org/10.1016/j.rser.2018.09.045","https://www.sciencedirect.com/science/article/pii/S1364032118306944"
"A357","Reduced-order description of phase fraction data measured using wire-mesh sensor in two-phase pipe flows","Proper Orthogonal Decomposition (POD) technique has been applied to the three dimensional (cross-sectional and time) void fraction data acquired by the application of wire-mesh sensor (WMS) measurement technique. The measurements are performed in a 76.2<U+202F>mm ID horizontal pipe with air and water as fluids, and with 16<U+202F><U+202F>×<U+202F><U+202F>16 WMS located at a distance of 17<U+202F>m from the inlet (L/D=223). In order to perform the detailed analysis using the POD technique, flow patterns covering stratified-wavy, slug, pseudo-slug, and annular low liquid loading are investigated in the paper. Thanks to the time-resolved data obtained using the WMS, classical POD method is applied in spectral space after converting time-dependence to frequency. The analysis showed that for all the cases considered, substantial part of the original data can be recovered using a couple POD modes and a few frequency modes. The most dominant two phase flow features are captured at near perfect accuracy. The global flow parameters like space- and time-averaged liquid holdup values are compared between the original and reconstructed fields and the agreement is found to be very good. The phase portraits obtained from the random coefficients associated with different POD mode diagrams correlate with the characteristics of the flow pattern, such that it is possible to observe two distinct orbits in slug and pseudo slug flow cases, and single orbit indicating more random behaviour for the stratified wavy and annular flow cases.","Flow patterns,Wire-mesh sensor,Proper orthogonal decomposition,Reduced order description","Netaji R.Kesana,MuratTutkun","International Journal of Multiphase Flow","https://doi.org/10.1016/j.ijmultiphaseflow.2018.12.008","https://www.sciencedirect.com/science/article/pii/S0301932218307602"
"A358","Turbulence modulation by finite-size spherical particles in Newtonian and viscoelastic fluids","We experimentally investigate the influence of finite-size spherical particles in turbulent flows of a Newtonian and a drag reducing viscoelastic fluid at varying particle volume fractions and fixed Reynolds number. Experiments are performed in a square duct at a Reynolds number Re2H of nearly 1.1<U+202F>×<U+202F>104, Weissenberg number Wi for single phase flow is between 1 and 2 and results in a drag-reduction of 43% compared to a Newtonian flow (at the same Re2H). Particles are almost neutrally-buoyant hydrogel spheres having a density ratio of 1.0035<U+202F>±<U+202F>0.0003 and a duct height 2H to particle diameter dp ratio of around 10. We measure flow statistics for four different volume fractions <U+03D5> namely 5, 10, 15 and 20% by using refractive-index-matched Particle Image Velocimetry (PIV). For both Newtonian Fluid (NF) and Visceolastic Fluid (VEF), the drag monotonically increases with <U+03D5>. For NF, the magnitude of drag increase due to particle addition can be reasonably estimated using a concentration dependent effective viscosity for volume fractions below 10%. The drag increase is, however, underestimated at higher <U+03D5>. For VEF, the absolute value of drag is lower than NF but, its rate of increase with <U+03D5> is higher. Similar to particles in a NF, particles in VEF tend to migrate towards the center of the duct and form a layer of high concentration at the wall. Interestingly, relatively higher migration towards the center and lower migration towards the walls is observed for VEF. The primary Reynolds shear stress reduces with increasing <U+03D5> throughout the duct height for both types of fluid.","Turbulent flow,Newtonian fluid,viscoelastic fluid,drag reduction,particle-laden flow","SagarZade,FredrikLundell,LucaBrandt","International Journal of Multiphase Flow","https://doi.org/10.1016/j.ijmultiphaseflow.2018.12.015","https://www.sciencedirect.com/science/article/pii/S0301932218306955"
"A359","Contrasting roles of oxidized lipids in modulating membrane microdomains","Lipid rafts display a lateral heterogeneity forming membrane microdomains that hold a fundamental role on biological membranes and are indispensable to physiological functions of cells. Oxidative stress in cellular environments may cause lipid oxidation, changing membrane composition and organization, thus implying in effects in cell signaling and even loss of homeostasis. The individual contribution of oxidized lipid species to the formation or disruption of lipid rafts in membranes still remains unknown. Here, we investigate the role of different structures of oxidized phospholipids on rafts microdomains by carefully controlling the membrane composition. Our experimental approach based on fluorescence microscopy of giant unilamellar vesicles (GUV) enables the direct visualization of the impact of hydroperoxidized POPC lipid (referred to as POPCOOH) and shortened chain lipid PazePC (1-palmitoyl-2-azelaoyl-sn-glycero-3-phosphocholine) on phase separation. We found that the molecular structure of oxidized lipid is of paramount importance on lipid mixing and/or demixing. The hydrophobic mismatch promoted by POPCOOH coupled to its cylindrical molecular shape favor microdomains formation. In contrast, the conical shape of PazePC causes disarrangement of lipid 2D organized platforms. Our findings contribute to better unraveling how oxidized phospholipids can trigger formation or disruption of lipid rafts. As a consequence, phospholipid oxidation may indirectly affect association or dissociation of key biomolecules in the rafts thus altering cell signaling and homeostasis.","Oxidized lipids,Membrane domains,Lipid rafts,GUV","Tayana MazinTsubonea1,Helena CoutoJunqueirab1,Maurício S.Baptistab,RosangelaItria","Biochimica et Biophysica Acta (BBA) - Biomembranes","https://doi.org/10.1016/j.bbamem.2018.12.017","https://www.sciencedirect.com/science/article/pii/S0005273618303730"
"A360","A survey on software coupling relations and tools","ContextCoupling relations reflect the dependencies between software entities and can be used to assess the quality of a program. For this reason, a vast amount of them has been developed, together with tools to compute their related metrics. However, this makes the coupling measures suitable for a given application challenging to find.,GoalsThe first objective of this work is to provide a classification of the different kinds of coupling relations, together with the metrics to measure them. The second consists in presenting an overview of the tools proposed until now by the software engineering academic community to extract these metrics.,MethodThis work constitutes a systematic literature review in software engineering. To retrieve the referenced publications, publicly available scientific research databases were used. These sources were queried using keywords inherent to software coupling. We included publications from the period 2002 to 2017 and highly cited earlier publications. A snowballing technique was used to retrieve further related material.,ResultsFour groups of coupling relations were found: structural, dynamic, semantic and logical. A fifth set of coupling relations includes approaches too recent to be considered an independent group and measures developed for specific environments. The investigation also retrieved tools that extract the metrics belonging to each coupling group.,ConclusionThis study shows the directions followed by the research on software coupling: e.g., developing metrics for specific environments. Concerning the metric tools, three trends have emerged in recent years: use of visualization techniques, extensibility and scalability. Finally, some coupling metrics applications were presented (e.g., code smell detection), indicating possible future research directions. Public preprint [https://doi.org/10.5281/zenodo.2002001].","Software engineering,Coupling relations,Software metrics,MSC,00-01,99-00","EnricoFregnana,TobiasBaumb,FabioPalombaa,AlbertoBacchellia","Information and Software Technology","https://doi.org/10.1016/j.infsof.2018.11.008","https://www.sciencedirect.com/science/article/pii/S0950584918302441"
"A361","An extensible collaborative framework for monitoring software quality in critical systems","ContextCurrent practices on software quality monitoring for critical software systems development rely on the manual integration of the information provided by a number of independent commercial tools for code analysis; some external tools for code analysis are mandatory in some critical software projects that must comply with specific norms. However, there are no approaches to providing an integrated view over the analysis results of independent external tools into a unified software quality framework.,ObjectiveThis paper presents the design and development of ESQUF (Enhanced Software Quality Monitoring Framework) suitable for critical software systems. It provides the above enriched quality results presentation derived not only from multiple external tools but from the local analysis functions of the framework.,MethodAn analysis of the norms and standards that apply to critical software systems is provided. The detailed and modular design of ESQUF adjusts to the integration requirements for external tools. UML is used for designing the framework, and Java is used to provide the detailed design. The framework is validated with a prototype implementation that integrates two different external tools and their respective quality results over a real software project source code.,ResultsThe integration of results files and data from external tools as well as from internal analysis functions is enabled. The analysis of critical software projects is made posible yielding a collaborative space where verification engineers share information about code analysis activities of specific projects; and single presentation space with rich static and dynamic analysis information of software projects that comply with the required development norms.","Software quality,Open source framework,Quality monitoring,Source code analysis,Critical systems development","MarisolGarcía-Vallsa,JulioEscribano-Barrenob,JavierGarcía-Muñoza","Information and Software Technology","https://doi.org/10.1016/j.infsof.2018.10.005","https://www.sciencedirect.com/science/article/pii/S095058491830209X"
"A362","Exploratory testing: Do contextual factors influence software fault identification?","Context: Exploratory Testing (ET) is a manual approach to software testing in which learning, test design and test execution occurs simultaneously. Still a developing topic of interest to academia, although as yet insufficiently investigated, most studies focus on the skills and experience of the individual tester. However, contextual factors such as project processes, test scope and organisational boundaries are also likely to affect the approach.Objective: This study explores contextual differences between teams of testers at a MedTec firm developing safety-critical products to ascertain whether contextual factors can influence the outcomes of ET, and what associated implications can be drawn for test management.Method: A development project was studied in two iterations, each consisting of a quantitative phase testing hypotheses concerning when ET would identify faults in comparison to other testing approaches and a qualitative phase involving interviews.Results: Influence on ET is traced to how the scope of tests focus learning on different types of knowledge and imply an asymmetry in the strength and number of information flows to test teams.Conclusions: While test specialisation can be attractive to software development organisations, results suggest changes to processes and organisational structures might be required to maintain test efficiency throughout projects: the responsibility for test cases might need to be rotated late in projects, and asymmetries in information flows might require management to actively strengthen the presence and connections of test teams throughout the firm. However, further research is needed to investigate whether these results also hold for non safety-critical faults.","Exploratory testing,Knowledge management,Test management","FredrikAsplund","Information and Software Technology","https://doi.org/10.1016/j.infsof.2018.11.003","https://www.sciencedirect.com/science/article/pii/S0950584918302325"
"A363","Vehicle joint make and model recognition with multiscale attention windows","Vehicle Make and Model Recognition (VMMR) deals with the problem of classifying vehicles whose appearance may vary significantly when captured from different perspectives. A number of successful approaches to this problem rely on part-based models, requiring however labor-intensive parts annotations. In this work, we address the VMMR problem proposing a deep convolutional architecture built upon multi-scale attention windows. The proposed architecture classifies a vehicle over attention windows which are predicted to minimize the classification error. Through these windows, the visual representations of the most discriminative part of the vehicle are aggregated over different scales which in fact provide more representative features for the classifier. In addition, we define a loss function accounting for the joint classification error across make and model. Besides, a training methodology is devised to stabilize the training process and to impose multi-scale constraints on predicted attention windows. The proposed architecture outperforms state-of-the-art schemes reducing the model classification error over the Stanford dataset by 1.7 % and improving the classification accuracy by 0.2 % and 0.3 % on model and make respectively over the CompCar dataset.","Vehicle classification,Convolutional neural network,Attention windows,Residual network","SinaGhassemia,AttilioFiandrottia,EmanueleCaimottia,GianlucaFrancinib,EnricoMaglia","Signal Processing: Image Communication","https://doi.org/10.1016/j.image.2018.12.009","https://www.sciencedirect.com/science/article/pii/S0923596518307331"
"A364","Effect of triblock copolymer surfactant composition on flow-induced phase inversion emulsification in a tapered channel","HypothesisPhase inversion emulsification (PIE) is a process that inverts the dispersed and continuous phases of an emulsion and is useful for preparing emulsions that are challenging to produce using conventional techniques. A recent work has shown that PIE can be induced by flowing an emulsion through a tapered channel. Although prior studies have shown that flow-induced PIE (FIPIE) is influenced by the flow conditions and wetting properties of the channel surface, little is known about the effect of surfactant structure on FIPIE. We hypothesize that FIPIE is affected by the composition and structure of the surfactant used for emulsion stabilization.,ExperimentsWe use Pluronics, a series of ABA triblock copolymers composed of hydrophilic poly(ethylene oxide) (PEO) and hydrophobic poly(propylene oxide) (PPO) with various lengths (A<U+202F>=<U+202F>PEO, B<U+202F>=<U+202F>PPO), as model surfactants to test this hypothesis. We observe that triblock copolymer surfactants with long PEO blocks suppress FIPIE. A scaling analysis based on a polymer brush model qualitatively agrees with the experimental observation. We also show that for small molecular weight Pluronics, FIPIE is significantly suppressed when Pluronics with large PPO blocks are used.,FindingsOur results strongly indicate that the steric repulsion provided by the PEO blocks as well as the dilatational elasticity provided by the PPO blocks are key factors that control the FIPIE process.","Pluronic,Emulsions,Block copolymers,Droplets,Surfactants,Microfluidics","GangDuana,AnkitKumara1,ShigengLib,Chieh-MinChengb,DaeyeonLeea","Journal of Colloid and Interface Science","https://doi.org/10.1016/j.jcis.2018.11.014","https://www.sciencedirect.com/science/article/pii/S0021979718313274"
"A365","Efficacy of different dynamic functional connectivity methods to capture cognitively relevant information","Given the dynamic nature of the human brain, there has been an increasing interest in investigating short-term temporal changes in functional connectivity, also known as dynamic functional connectivity (dFC), i.e., the time-varying inter-regional statistical dependence of blood oxygenation level-dependent (BOLD) signal within the constraints of a single scan. Numerous methodologies have been proposed to characterize dFC during rest and task, but few studies have compared them in terms of their efficacy to capture behavioral and clinically relevant dynamics. This is mostly due to lack of a well-defined ground truth, especially for rest scans. In this study, with a multitask dataset (rest, memory, video, and math) serving as ground truth, we investigated the efficacy of several dFC estimation techniques at capturing cognitively relevant dFC modulation induced by external tasks. We evaluated two framewise methods (dFC estimates for a single time point): dynamic conditional correlation (DCC) and jackknife correlation (JC); and five window-based methods: sliding window correlation (SWC), sliding window correlation with L1-regularization (SWC_L1), a combination of DCC and SWC called moving average DCC (DCC_MA), multiplication of temporal derivatives (MTD), and a variant of jackknife correlation called delete-d jackknife correlation (dJC). The efficacy is defined as each dFC metric's ability to successfully subdivide multitask scans into cognitively homogenous segments (even if those segments are not temporally continuous). We found that all window-based dFC methods performed well for commonly used window lengths (WL<U+202F>=<U+202F>30sec), with sliding window methods (SWC, SWC_L1) as well as the hybrid DCC_MA approach performing slightly better. For shorter window lengths (WL<U+202F>=<U+202F>15sec), DCC_MA and dJC produced the best results. Neither framewise method (i.e., DCC and JC) led to dFC estimates with high accuracy.","Dynamic functional connectivity,Cognitive information,Sliding window correlation,Dynamic conditional correlation,Multiplication of temporal derivatives,Jackknife correlation","HuaXieab,Charles Y.Zhengc,Daniel A.Handwerkerb,Peter A.Bandettinibd,Vince D.Calhounef,SunandaMitraa,JavierGonzalez-Castillob","NeuroImage","https://doi.org/10.1016/j.neuroimage.2018.12.037","https://www.sciencedirect.com/science/article/pii/S1053811918321815"
"A366","Absence of the foveal avascular zone in a nanophthalmic child revealed by optical coherence tomography angiography","PurposeOptical coherence tomography angiography (OCTA) is a new non-invasive imaging technique that does not require the use of contrast agents and that allows the visualization of the retinal microvasculature in a layer-by-layer manner without bright light. This merit allows us to obtain the fundus image in children. Retinal vessels are typically absent from the center of the fovea, an area known as the foveal avascular zone (FAZ). The purpose of the present case study was to evaluate the FAZ in a nanophthalmic pediatric patient with OCTA.,ObsevationsA 6-year-old girl was referred to the Hiroshima University Hospital because of her poor vision. She had a best-corrected visual acuity of 20/125 in the right eye and of 20/100 in the left eye. The refractive errors after the administration of atropine sulfate eye drops were +13.00D in the right eye and +14.00D in the left eye. The axial lengths were 17.03 mm in the right eye and 16.90 mm in the left eye. At 9 years of age, the patient was diagnosed with nanophthalmos and OCTA was used to investigate the superficial and deep retinal layers. We demonstrated that the FAZ could not be observed in either eye, whereas the FAZ was readily observed in both eyes of a control subject of similar age.,Conclusion and ImportanceOCTA is a useful technique to reveal the absence of the FAZ in cases of nanophthalmos. Because OCTA is a non-invasive and rapid procedure that is ideal for use with children.","Nanophthalmos,OCT angiography,Absence of foveal avascular zone","ShunsukeFunakoshi,TomokoYoshikawa,YosukeHarada,TaiichiroChikama,YoshiakiKiuchi","American Journal of Ophthalmology Case Reports","https://doi.org/10.1016/j.ajoc.2018.09.007","https://www.sciencedirect.com/science/article/pii/S2451993618300914"
"A367","Experimental analysis of velocity reduction in bends related to vertical pipes in dilute phase pneumatic conveying","The behavior of particles in dilute phase pneumatic conveying is a rather complex phenomenon. For example, particle velocities and their trajectories owing to particle-particle and particle-wall collisions are unpredictable. In this study, we focus on particle velocity reduction in horizontal-vertical (H-V) and vertical-horizontal (V-H) bends. A new terminology, ‘bend point’, is introduced to compare different bends on common measures. A broad range of materials (Archimedes numbers<U+202F>=<U+202F>102 to 106) was investigated using six different bends (blind-T, R/D<U+202F>=<U+202F>1.5, 4.5, 6.6, 10, and 20) and wide range of conveying velocities (10<U+202F>m/s<U+202F><<U+202F>ua<U+202F><<U+202F>35<U+202F>m/s). Small material quantities (e<U+202F>˜<U+202F>1) were fed at zero velocity through the flowing air stream in the pipeline (D<U+202F>=<U+202F>50<U+202F>mm). The particle velocities were measured along the axial direction. Visuals of the particle flow were recorded using a high-speed camera and analyzed by a Matlab program specially developed for this analysis. The experimental results demonstrate that materials must be conveyed in vertical pipes at higher than the terminal velocity, while the Reynolds and Archimedes numbers have a significant effect on the flow development. A new correlation of the bend point particle velocity ratio (BR) was developed based on the statistical velocity distribution of particles at different locations along the pipeline. The analysis of the results for both the H-V and V-H bends illustrates that the BR increases with the bend ratio (R/D), but after a certain limit, a further increase in the bend ratio causes a reduction in BR. This analysis will aid in the design of pneumatic conveying pipelines by selecting appropriate conveying criteria and proper bends at different orientations.","Pneumatic conveying,Dilute phase,Bend,Vertical pipe, particle velocity,Bend point,Experimental","Naveen ManiTripathia,NirSantoa,AviLevya,HaimKalmanab","Powder Technology","https://doi.org/10.1016/j.powtec.2019.01.001","https://www.sciencedirect.com/science/article/pii/S0032591019300014"
"A368","Hypomethylated drm1 drm2 cmt3 mutant phenotype of Arabidopsis thaliana is related to auxin pathway impairment","DNA methylation carried out by different methyltransferase classes is a relevant epigenetic modification of DNA which plays a relevant role in the development of eukaryotic organisms. Accordingly, in Arabidopsis thaliana loss of DNA methylation due to combined mutations in genes encoding for DNA methyltransferases causes several developmental abnormalities.The present study describes novel growth disorders in the drm1 drm2 cmt3 triple mutant of Arabidopsis thaliana, defective both in maintenance and de novo DNA methylation, and highlights the correlation between DNA methylation and the auxin hormone pathway. By using an auxin responsive reporter gene, we discovered that auxin accumulation and distribution were affected in the mutant compared to the wild type, from embryo to adult plant stage. In addition, we demonstrated that the defective methylation status also affected the expression of genes that regulate auxin hormone pathways from synthesis to transport and signalling and a direct relationship between differentially expressed auxin-related genes and altered auxin accumulation and distribution in embryo, leaf and root was observed. Finally, we provided evidence of the direct and organ-specific modulation of auxin-related genes through the DNA methylation process.","Arabidopsis thaliana,Epigenetics,DNA methyltransferases,Auxin pathway","IvanoForgioneabc,MagdalenaWoloszynskabc,MariannaPacenzaa,AdrianaChiappettaa,MariaGrecoad,FabrizioAranitie,Maria RosaAbenavolie,MiekeVan Lijsebettensbc,Maria BeatriceBitontia,LeonardoBrunoa","Plant Science","https://doi.org/10.1016/j.plantsci.2018.12.029","https://www.sciencedirect.com/science/article/pii/S0168945218312524"
"A369","Do certain personality traits provide a mating market competitive advantage? Sex, offspring & the big 5","This study uses the BIG 5 personality traits to quantitatively explore correlates of sexual frequency and reproductive success of a large sample (NMale<U+202F>=<U+202F>2998; NFemale<U+202F>=<U+202F>1480) of heterosexuals advertised to on an Australian dating website. Consistent with previous research we find that for both sexes, extraversion has a positive linear relationship with sexual frequency. The same is also observable for males that are more conscientious, more emotionally stable, and less agreeable; indicating that for men, a greater number of personality factors matter in explaining the variation in sexual activity. Higher extraversion or lower openness in males correlates with more offspring. Conversely, only more agreeable females have more offspring. Our non-parametric thin-plate spline analysis suggests certain combinations of the traits extraversion & agreeableness, extraversion & conscientiousness, and agreeableness & conscientiousness provide select males a mating market competitive advantage in relation to sexual frequency, compared to other males. Our findings suggest that greater variance in male traits and their particular combinations thereof may provide a fitness comparative advantage for males, but not necessarily for females.","BIG 5 personality traits,Sex,Sex difference,Offspring,Mate choice,Mating market","StephenWhytea,Robert C.Brooksb,Ho FaiChana,BennoTorglerac","Personality and Individual Differences","https://doi.org/10.1016/j.paid.2018.11.019","https://www.sciencedirect.com/science/article/pii/S0191886918306159"
"A370","Working memory affine technological support functions improve decision performance","While working memory limits constrain the complexity of manageable tasks, technological devices offer vast information processing capacity and thus the potential to improve individual information processing capabilities and task performance. We explored the effects of providing individuals with intuitive, working memory affine information structuring support functionalities on a multi-touch table on decision performance. In the employed hidden profile personnel selection task (Stasser & Titus, 1985) support should enable participants to offload cognitive processing, thus improving information processing and decision quality. In Experiment 1 (N<U+202F>=<U+202F>76) we compared decision performance without vs. with technological support (self-directed and automatic structuring functionalities). Support led to higher chances for a correct decision, more appropriate candidate suitability ratings and better information recognition compared to no support. In Experiment 2 (N<U+202F>=<U+202F>81) we focused on self-directed structuring, comparing conditions with vs. without detailed usage instructions for self-structuring functionalities. While there was no difference with regard to decision quality, participants displayed more appropriate candidate suitability ratings and better recognition performance with detailed usage instructions than without. Our findings indicate that offering working memory affine technological support functions to ameliorate cognitive limitations is effective and highlight that detailed instructions might amplify this potential.","Offloading,Decision making,Working memory,Multi-touch table,Hidden profile","Irina R.Bricha,Inga M.Bausea,Friedrich W.Hessea,Ann-KatrinWessleinb","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2018.11.014","https://www.sciencedirect.com/science/article/pii/S0747563218305491"
"A371","Fast isotropic volumetric magnetic resonance imaging of the ankle: Acceleration of the three-dimensional fast spin echo sequence using compressed sensing combined with parallel imaging","ObjectivesTo investigate the feasibility of three-dimensional fast spin echo (3D-FSE) imaging with compressed sensing (CS) and parallel imaging (PI) compared to 3D-FSE imaging with only PI in evaluating ankle joint pathologies.,Materials and methodsTwenty consecutive patients underwent ankle magnetic resonance imaging (MRI), including acquisition of image sets of 2D-FSE sequences, and 3D-FSE sequences without and with CS, between June 2016 and November 2017. Three MR image sets were independently rated by two radiologists for the presence/absence of ankle pathology. Quantitative image similarity and subjective image quality were evaluated using 3D-FSE images without CS and those with CS-PI. Inter-sequence agreement between 3D-FSE sequences without CS and with CS-PI in both readers was evaluated.,ResultsInterobserver agreements were nearly perfect for sprain of the anterior talofibular ligament (ATFL, <U+03BA>=0.77), osteochondral lesion of the talus (OLT, <U+03BA>=0.76-0.88), osteochondral lesion of the distal tibia (OLTi, <U+03BA>=0.74) and os subfibulare (OSF, <U+03BA>=0.62-0.64). The structural similarity index (mean, 0.996; range, 0.990-0.997) between the 3D-FSE sequences without CS and with CS-PI was acceptable. There was no significant difference in subjective image quality between the two imaging sequences (ATFL, p<U+2009>=<U+2009>0.317; bone marrow, p<U+2009>=<U+2009>0.083; cartilage, p<U+2009>=<U+2009>1.000, tendon, p<U+2009>=<U+2009>1.000). Intersequence agreement between the 3D-FSE sequences with and without CS was nearly perfect (ATFL and OLTi, <U+03BA>=1.00; OLT, <U+03BA>=0.87-0.96; OSF, <U+03BA>=0.62-0.64) in both readers.,ConclusionsIsotropic 3D-FSE ankle MRI with CS provides acceptable diagnostic performance with reduced scan time. Compressed sensing-related artifacts could be minimized with CS reconstruction enhancement, allowing for better image quality for evaluating ankle joint pathologies.","Compressed sensing,MR,Ankle","JisookYi1,Young HanLee,SeokHahn1,Salman S.Albakheet,Ho-TaekSong,Jin-SuckSuh","European Journal of Radiology","https://doi.org/10.1016/j.ejrad.2019.01.009","https://www.sciencedirect.com/science/article/pii/S0720048X19300099"
"A372","The efficacy of 3,4-dimethylpyrazole phosphate on N2O emissions is linked to niche differentiation of ammonia oxidizing archaea and bacteria across four arable soils","The nitrification inhibitor, 3,4-dimethylpyrazole phosphate (DMPP), can be used to reduce N2O emissions from agricultural ecosystems. However, the effectiveness of DMPP varies among soils, and this is due to both abiotic (e.g. soil properties) and biotic factors (e.g. ammonia oxidizers and denitrifier communities). Understanding the nature of these effects is necessary to improve the efficacy of DMPP, therefore encouraging wider adoption and environmental benefits. In particular, soil microbial properties associated with variation in efficacy remain largely unknown. In this study four contrasting arable soils (a grey desert soil, an alluvial paddy soil, a loess-formed paddy soil, and a red soil), were characterized based on DMPP inhibition of N2O emissions and associated microbial functional guilds. DMPP significantly inhibited nitrification and N2O emissions, with an average inhibitory rate ranging from 41.7% in a red soil to 90.0% in a grey desert soil. Ammonia oxidizing bacteria (AOB) and archaea (AOA) exhibited contrasting response patterns to DMPP addition. Notably, suppression of N2O emissions by DMPP only occurred alongside fluctuations in AOB abundance. However, when AOB were inhibited, AOA abundance increased. Soil-dependent response patterns to DMPP were observed for ammonia oxidizers and denitrifiers in terms of community structure. Partial least squares path modeling (PLS-PM) found that abiotic factors, particularly pH, and biological factors such as ammonia oxidizer communities, were closely linked to N2O emissions. Our findings provide evidence that: (i) DMPP effectively inhibits nitrification through inhibiting the abundance of AOB across soil types; (ii) releasing AOA from the competition with AOB allows AOA to efficiently grow and multiply, even under high ammonium conditions; and (iii) abiotic factors play a more important role than biotic factors in soil N2O emissions.","3,4-Dimethylpyrazole phosphate (DMPP),Nitrous oxide,Ammonia oxidizing bacteria,Ammonia oxidizing archaea,Niche differentiation","XiaopingFana,ChangYina,HaoChena,MujunYea,YuhuaZhaob,TingqiangLia,Steven A.Wakelinc,YongchaoLianga","Soil Biology and Biochemistry","https://doi.org/10.1016/j.soilbio.2018.11.027","https://www.sciencedirect.com/science/article/pii/S0038071718304103"
"A373","An integrated framework for course adapted student learning analytics dashboard","The advanced learning analytics research of the last years converges with the industry demand to enhance famous learning management systems with learning analytics capabilities promoting the efficiency of higher education. The exploitation of big volume learning data, is a critical challenge for the design of personalized curricula and learning experiences. The purpose of this research paper is to communicate a framework for Learning Analytics aiming to support the integrated management of end-to-end learning data. We present the research foundations of a research prototype for the integration of a Learning Analytics Dashboard: The AMBA Prototype with famous Learning Management Systems. Finally, we present the main findings of an empirical study that proves the capacity of learning analytics to enhance the learners' ecosystem with value adding learning services. The proposed framework exploits cognitive computing for the enhancement of decision making in education by proving the capacity of Learning Analytics to reveal hidden patterns of learners’ behaviour and attitude.","Learning analytics,Learning management systems,Learning framework,Blackboard,Cognitive computing","Naif RadiAljohania,AliDauda,Rabeeh AyazAbbasia,Jalal S.Alowibdib,MohammadBasheria,Muhammad AhtishamAslama","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2018.03.035","https://www.sciencedirect.com/science/article/pii/S0747563218301407"
"A374","Analysing spatial–temporal changes in rice cultivation practices in the Senegal River Valley using MODIS time-series and the PhenoRice algorithm","In this study we used the PhenoRice algorithm to track recent variations of rice cultivation practices along the Senegal River Valley. Time series of MODIS imagery with 250<U+202F>m spatial resolution and a nominal 8-days frequency were used as input for the algorithm to map the spatial and temporal variations of rice cultivated area and of several important phenological metrics (e.g., crop establishment and harvesting dates, length of season) for the 2003–2016 period in both the dry and the wet rice cultivation seasons. Comparison between PhenoRice results and ancillary and field data available for the Senegal part of the study area showed that the algorithm is able to track the interannual variations of rice cultivated area, despite the total detected rice area being consistently underestimated. PhenoRice estimates of crop establishment and harvesting dates resulted accurate when compared with field observations available for two sub-regions for a period of 10 years, and thus allow assessing interannual variability and tracking changes in agronomic practices. An analysis of interannual trends of rice growing practices based on PhenoRice results highlighted a clear shift of rice cultivation from the wet to the dry season starting approximately from 2008. The shift was found to be particularly evident in the delta part of the SRV. Additionally, a statistically significant trend was revealed starting 2006 towards a longer dry season (r2<U+202F>=<U+202F>0.81; Slope<U+202F>=<U+202F>1.24 days y-1) and a shorter wet season (r2<U+202F>=<U+202F>0.65; Slope<U+202F>=<U+202F>0.53 days y-1). These findings are in agreement with expert knowledge of changes ongoing in the area. In particular the shorter wet season is attributed to shortage of labor and equipment leading to a delay in completion of harvesting operations in the dry season, which led to the adoption of short-duration rice varieties by farmers in the wet season to avoid risk of yield losses due to climatic constraints. Aforementioned results highlight the usefulness of the PhenoRice algorithm for providing insights about recent variations in rice cultivation practices over large areas in developing countries, where high-quality up to date information about changes in agricultural practices are often lacking.","Rice,MODIS,PhenoRice,Phenology,Cropping intensity,Agro-practices,West Africa","LorenzoBusettoa,Sander J.Zwartbc,MircoBoschettia","International Journal of Applied Earth Observation and Geoinformation","https://doi.org/10.1016/j.jag.2018.09.016","https://www.sciencedirect.com/science/article/pii/S0303243418304860"
"A375","GaitGANv2: Invariant gait feature extraction using generative adversarial networks","The performance of gait recognition can be adversely affected by many sources of variation such as view angle, clothing, presence of and type of bag, posture, and occlusion, among others. To extract invariant gait features, we proposed a method called GaitGANv2 which is based on generative adversarial networks (GAN). In the proposed method, a GAN model is taken as a regressor to generate a canonical side view of a walking gait in normal clothing without carrying any bag. A unique advantage of this approach is that, unlike other methods, GaitGANv2 does not need to determine the view angle before generating invariant gait images. Indeed, only one model is needed to account for all possible sources of variation such as with or without carrying accessories and varying degrees of view angle. The most important computational challenge, however, is to address how to retain useful identity information when generating the invariant gait images. To this end, our approach differs from the traditional GAN in that GaitGANv2 contains two discriminators instead of one. They are respectively called fake/real discriminator and identification discriminator. While the first discriminator ensures that the generated gait images are realistic, the second one maintains the human identity information. The proposed GaitGANv2 represents an improvement over GaitGANv1 in that the former adopts a multi-loss strategy to optimize the network to increase the inter-class distance and to reduce the intra-class distance, at the same time. Experimental results show that GaitGANv2 can achieve state-of-the-art performance.","Gait recognition,Generative adversarial networks,Invariant feature","ShiqiYua,RijunLiaoa,WeizhiAna,HaifengChena,Edel B.Garcíab,YongzhenHuangcd,NormanPohe","Pattern Recognition","https://doi.org/10.1016/j.patcog.2018.10.019","https://www.sciencedirect.com/science/article/pii/S0031320318303649"
"A376","Model order reduction for parametrized nonlinear hyperbolic problems as an application to uncertainty quantification","In this work, we present a model order reduction (MOR) technique for hyperbolic conservation laws with applications in uncertainty quantification (UQ). The problem consists of a parametrized time dependent hyperbolic system of equations, where the parameters affect the initial conditions and the fluxes in a non- linear way. The procedure utilized to reduce the order is a combination of a Greedy algorithm in the parameter space, a proper orthogonal decomposition (POD) in time and empirical interpolation method (EIM) to deal with non-linearities (Drohmann, 2012). We provide under some hypothesis an error bound for the reduced solution with respect to the high order one. The algorithm shows small errors and savings of the computational time up to 90% in the UQ simulations, which are performed to validate the algorithm.","65M08,65M15,65J15,76L05,35L65,35R60,Keywords,Reduced order modeling,Nonlinear hyperbolic problems,UQ,Empirical interpolation method,POD–Greedy,Residual distribution","R.Crisovan,D.Torlo,R.Abgrall,S.Tokareva","Journal of Computational and Applied Mathematics","https://doi.org/10.1016/j.cam.2018.09.018","https://www.sciencedirect.com/science/article/pii/S0377042718305636"
"A377","A review on lubricant condition monitoring information analysis for maintenance decision support","Lubrication Condition monitoring (LCM) is not only utilized as an early warning system in machinery but also, for fault diagnosis and prognosis under condition-based maintenance (CBM). LCM is considered as an important condition monitoring technique, due to the ample information derived from lubricant testing, which demonstrates an introspective reflection on the condition and state of the machinery and the lubricant. Central to the entire LCM program is the application concept, where information from lubricant analysis is evaluated (for knowledge extraction) and analyzed with a view of generating an output which is interpretable and applicable for maintenance decision support (knowledge application). For robust LCM, varying techniques and approaches are used for extracting, processing and analyzing information for decision support. For this reason, a comprehensive overview of applicative approaches for LCM is necessary, which would aid practitioners to address gaps as far as LCM is concerned in the context of maintenance decision support. However, such an overview, is to the best of our knowledge, lacking in the literature, hence the objective of this review article. This paper systematically reviews recent research trends and development of LCM based approaches applied for maintenance decision support, and specifically, applications in equipment diagnosis and prognosis. To contextualize this concern, an initial review of base oils, additives, sampling and testing as applied for LCM and maintenance decision support is discussed. Moreover, LCM tests and parameters are reviewed and classified under varying categories which include, physiochemical, elemental, contamination and additive analysis. Approaches applicable for analyzing data derived from LCM, here, lubricant analysis for maintenance decision support are also classified into four categories: statistical, model-based, artificial intelligence and hybrid approaches. Possible improvement to enhance the reliability of the judgement derived from the approaches towards maintenance decision support are further discussed. This paper concludes with a brief discussion of plausible future trends of LCM in the context of maintenance decision making. This present study, not only highlights gaps in existing literature, by reviewing approaches applicable for extracting knowledge from LCM data for maintenance decision support, it also reviews the functional and technical aspects of lubrication. This is expected to address gaps in both theory and practice as far as LCM and maintenance decision support are concerned.","LCMlubricant condition monitoring,CBMcondition based maintenance,RULremaining useful life,CdMcondition monitoring,AIartificial intelligence,ISOinternational standards organization,APIAmerican Petroleum Institute,OEMOriginal Equipment Manufacturer,SAESociety of Automotive Engineers,PAOpolyalfaolefin,UOAused oil analysis,ASTMAmerican society for testing and materials,TBNtotal base number,TANtotal acid number,mgKOHmilligrams of potassium hydroxide,EPextreme pressure,MANOVAmultivariate analysis of variance,PCRprincipal component regression,PLSpartial least squares,CLSclassical least squares,PHMproportional hazard model,GMMGrey Markov model,HMMHidden Markov model,MLmachine learning,DTdecision trees,LRlogistic regression,NNneural network,SVMsupport vector machine,RFrandom forest,DLdeep learning,RBrule-based,RLrepresentation learning,PCAprincipal component analysis,SOMself-organizing maps,CAcluster analysis,FT-IRfourier transform infra-red,GAgenetic algorithm,GRNgeneral regression neural network,ESexpert systems,IRinfra-red,KBknowledge-based,KFKalman filtering,FLfuzzy logic,ANNartificial neural network,OCdMother condition monitoring,FHTFirst hitting time,Keywords,Lubricant condition monitoring,Condition-based maintenance,Maintenance decision support,Prognosis,Diagnosis","James M.Wakiruab,LilianePintelona,Peter N.Muchirib,Peter K.Chemwenoc","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.08.039","https://www.sciencedirect.com/science/article/pii/S0888327018305788"
"A378","Anisotropy of volume change and permeability evolution of hard sandstones under triaxial stress conditions","Volumetric strain and permeability are strictly interconnected properties and important controlling parameters for deformation patterns in rock masses. Under reservoir conditions, stresses may be highly inhomogeneous and anisotropic, leading to porosity changes and consequently affecting fluid flow. Therefore, it turns out be a challenging issue in rock mechanics to evaluate volume change based on traditional soil mechanics background, originally intended for soft materials under low and mostly isotropic pressures. In this respect, triaxial compression tests were carried out to describe the interplay between physical properties, volume change and permeability of two hard sandstones by quantifying porefluid volume change with fully water saturated rock specimens (14<U+202F>cm length and 7<U+202F>cm radius). The investigated sedimentary rocks are (1) the greyish Trendelburg beds, a silica cemented subarkose Bunter Sandstone of Triassic age (porosity of ca. 12%), and (2) the red-brownish Rotliegend Sandstone (Bebertal), a carbonate and silica cemented sandstone of Permian age, clearly less porous (ca. 6% of effective porosity) and less permeable (3.5<U+202F>×<U+202F>10-10<U+202F>m/s) than the Bunter Sandstone. Both materials present a pronounced brittle behaviour influenced by coring direction: permeability, volumetric strain and fracture pattern are direction-dependent. Effective porosity and pore pressure level affect the fracturing development, which therefore influences the permeability after stress fall. For the Bunter Sandstone, increasing porefluid pressure leads to an earlier microcraking stage, which shortens the forestage of compaction and induces a more pronounced dilatant behaviour with decreased compressive strength. For the Rotliegend, the increase of pore fluid pressure enhances compaction. Altogether, this examination is valuable to understand the combined effects of pore pressure change and pore space quality on the mechanical behaviour of rock masses.","Triaxial testing,Volume change,Fracture pattern,Permeability,Bunter Sandstone,Rotliegend","FloraFeitosa Menezes","Journal of Petroleum Science and Engineering","https://doi.org/10.1016/j.petrol.2018.11.079","https://www.sciencedirect.com/science/article/pii/S0920410518310751"
"A379","Biochemical characterization of the venom of Central American scorpion Didymocentrus krausi Francke, 1978 (Diplocentridae) and its toxic effects in vivo and in vitro","Venoms of medically important scorpions from Buthidae family have been intensively studied, in contrast to non-buthid venoms, for which knowledge is scarce. In this work, we characterized the venom of a Diplocentridae species, Didymocentrus krausi, a small fossorial scorpion that inhabits the Tropical Dry Forest of Central America. D. krausi venom soluble fraction contains proteases with enzymatic activity on gelatin and casein. Mass spectrometry and venomic analysis confirmed the presence of elastase-like, cathepsin-O-like proteases and a neprilysin-like metalloproteinase. We did not detect phospholipase A2, C or D, nor hyaluronidase activity in the venom. By homology-based venom gland transcriptomic analysis, NDBPs, a ß-KTx-like peptide, and other putative toxin transcripts were found, which, together with a p-benzoquinone compound present in the venom, could potentially explain its direct hemolytic and cytotoxic effects in several mammalian cell lines. Cytotoxicity of D. krausi venom was higher than the effect of venoms from two buthid scorpion species distributed in Costa Rica, Centruroides edwardsii and Tityus pachyurus. Even though D. krausi venom was not lethal to mice or crickets, when injected in mouse gastrocnemius muscle at high doses it induced pathological effects at 24<U+202F>h, which include myonecrosis, weak hemorrhage, and inflammatory infiltration. We observed an apparent thrombotic effect in the skin blood vessels, but no in vitro fibrinogenolytic activity was detected. In crickets, D. krausi venom induced toxicity and paralysis in short periods of time.","Cytotoxicity,Myotoxicity,Paralysis,Peptides,Toxins,Scorpion venom","DanielaRojas-Azofeifaab1,MahmoodSasabc,BrunoLomonteb,EliaDiego-Garcíade2,NataliaOrtizab1,FabiánBonillab,RenatoMurillof,JanTytgate,CeciliaDíazab","Comparative Biochemistry and Physiology Part C: Toxicology & Pharmacology","https://doi.org/10.1016/j.cbpc.2018.11.021","https://www.sciencedirect.com/science/article/pii/S1532045618302126"
"A380","Modeling head-related transfer functions with spherical wavelets","The head-related transfer function (HRTF) describes the sound transmission characteristics from a sound source to a listener’s ears. Recently, spherical harmonic decomposition has been extensively used for modeling the HRTF spatial patterns. Despite its advantage of approximating the coarse structure of HRTF spatial variations with modeling up to a low order, there are still some limitations since spherical harmonics take significant values in all directions. First, rapidly changing HRTF spatial variations in some local regions may require modeling up to a rather high order; this is not wise in terms of the modeling efficiency. Second, the expansion coefficients of the spherical harmonics describe the spatial frequency of the target dataset in all directions, and thus have difficulties in revealing the direction dependent HRTF characteristics. In this study, a method for locally modeling HRTF spatial patterns is proposed based on spherical wavelets, which take significant values only over a local region on the sphere. Results of numerical experiments show that our proposed method yields smaller approximation errors than the conventional method when representing HRTFs inside the local regions under evaluation. Furthermore, the expansion coefficients in the proposed method could well correspond to the HRTF local features on the sphere, which makes it a useful tool for the analysis and visualization of HRTF spatial patterns.","Spherical acoustics,Head-related transfer function,Spherical wavelets,Spherical harmonics,Binaural audio,Auditory display","ShichaoHu,JorgeTrevino,CésarSalvador,ShuichiSakamoto,YôitiSuzuki","Applied Acoustics","https://doi.org/10.1016/j.apacoust.2018.10.026","https://www.sciencedirect.com/science/article/pii/S0003682X18301397"
"A381","Effect of material parameter variability on vibroacoustic response in wood floors","The use of wood as construction material in multi-story buildings increased in Europe during the last decades. Wood buildings are more sensitive to dynamic loading compared to conventional concrete buildings, especially in terms of vibroacoustic comfort. Furthermore, it is more difficult to predict the accurate response due to dynamic loading for wood buildings. This is due to factors such as a complex structure involving many connections which vary in their mechanical behavior and the variability in the material parameters of wood. In the study, a reduced-order finite element model correlated to measurement data is used to examine the effect of experimentally obtained variability in material parameters on the vibroacoustic response of a wooden floor. The floor is subjected to surface loading. Monte Carlo simulations are conducted and in order to execute the probabilistic analysis in an efficient manner, the use of various sampling techniques is investigated. It was concluded that the variability in material parameters of wood significantly affects the predicted low-frequency vibrations, and thereby also affects the transmission of structure-borne sound.","Floor vibrations,Structure-borne sound,Wood buildings,Monte Carlo simulations,Finite element method,Probabilistic analysis","PeterPerssona,OlaFlodénb","Applied Acoustics","https://doi.org/10.1016/j.apacoust.2018.10.034","https://www.sciencedirect.com/science/article/pii/S0003682X18306297"
"A382","Smart finite elements: A novel machine learning application","Many multiscale finite element formulations can become computationally expensive because they rely on detailed models of the element’s internal displacement field. This issue is exacerbated in the presence of nonlinear problems, where numerical iterations are generally needed. We propose a method that utilizes machine learning to generate a direct relationship between the element state and its forces, which avoids the complex task of finding the internal displacement field and eliminates the need for numerical iterations. To generate our model, we choose an existing finite element formulation, extract data from an instance of that element, and feed that data to the machine learning algorithm. The result is an approximated model of the element that can be used in the same context. Unlike most data-driven techniques applied to individual elements, our method is not tied to any particular machine learning algorithm, and it does not impose any restriction on the solver of choice. In addition, we guarantee that our elements are physically accurate by enforcing frame indifference and conservation of linear and angular momentum. Our results indicate that this can considerably reduce the error of the method and the computational cost of producing and solving the model.","Machine learning,Finite elements,Multiscale models","GermanCapuano,Julian J.Rimoli","Computer Methods in Applied Mechanics and Engineering","https://doi.org/10.1016/j.cma.2018.10.046","https://www.sciencedirect.com/science/article/pii/S0045782518305541"
"A383","Parametric design for human body modeling by wireframe-assisted deep learning","Statistical learning of human body shape can be used for reconstructing or estimating body shapes from incomplete data, semantic parametric design, modifying images and videos, or simulation. A digital human body is normally represented in a high-dimensional space, and the number of vertices in a mesh is far larger than the number of human bodies in public available databases, which results in a model learned by Principle Component Analysis (PCA) can hardly reflect the true variety in human body shapes. While deep learning has been most successful on data with an underlying Euclidean or grid-like structure, the geometric nature of human body is non-Euclidean, it will be very challenging to perform deep learning techniques directly on such non-Euclidean domain. This paper presents a deep neural network (DNN) based hierarchical method for statistical learning of human body by using feature wireframe as one of the layers to separate the whole problem into smaller and more solvable sub-problems. The feature wireframe is a collection of feature curves which are semantically defined on the mesh of human body, and it is consistent to all human bodies. A set of patches can then be generated by clustering the whole mesh surface to separated ones that interpolate the feature wireframe. Since the surface is separated into patches, PCA only needs to be conducted on each patch but not on the whole surface. The spatial relationships between the semantic parameter, the wireframe and the patches are learned by DNN and linear regression respectively. An application of semantic parametric design is used to demonstrate the capability of the method, where the semantic parameters are linked to the feature wireframe instead of the mesh directly. Under this hierarchy, the feature wireframe acts like an agent between semantic parameters and the mesh, and also contains semantic meaning by itself. The proposed method of learning human body statistically with the help of feature wireframe is scalable and has a better quality.","Feature,Wireframe,Human body,Deep learning,Parametric design","JidaHuanga,Tsz-HoKwokb,ChiZhoua","Computer-Aided Design","https://doi.org/10.1016/j.cad.2018.10.004","https://www.sciencedirect.com/science/article/pii/S0010448518302707"
"A384","A 3D spatial data model of the solar rights associated with individual residential properties","Increased residence in high-rise buildings has aroused demand for sunlight or sunlight duration because a lack of sunlight may lead to negative effects on the mental health of the residents of high-rise buildings. To address this issue, many countries have already enacted laws, regulations and standards that ensure solar rights for residents by guaranteeing a certain duration of sunlight. However, feasible methods that clearly describe the temporal-spatial properties of solar rights for residential buildings are presently lacking, especially for individual housing units distributed in high-rise buildings. Consequently, no relevant data model exists in any current cadastral database. This study presents a 3D data model that incorporates a range of data elements to represent the temporal-spatial extent of solar rights in the context of the current legal system of China. Using existing legal stipulations and spatial features, solar rights are classified into solar easements and neighbouring solar rights, which are separately described by geometric elements developed from the relevant legal stipulations. In addition, the geometric elements of the model are systematically integrated with existing property elements to enable the description of solar rights associated with individual residential properties. To enable the use of this model in a wide range of applications, the model is extended from the Land Administration Domain Model (LADM) and implemented using CityGML application domain extensions (ADEs). The experiments described in this study demonstrate the utility of the 3D data model for the spatial clarification of the solar rights associated with individual 3D properties.","Solar rights,Property,Cadastre,3D model,CityGML,LADM","LinLiabc,YuanLeid,LeiTanga,FenYana,FengLuoae,HaihongZhuac","Computers, Environment and Urban Systems","https://doi.org/10.1016/j.compenvurbsys.2018.12.003","https://www.sciencedirect.com/science/article/pii/S0198971517305185"
"A385","Multi-commodity demand fulfillment via simultaneous pickup and delivery for a fast fashion retailer","This study addresses a multi-commodity many-to-many vehicle routing problem with simultaneous pickup and delivery (M-M-VRPSPD) for a fast fashion retailer in Singapore. Different from other widely studied pickup and delivery problems, the unique characteristics are: (1) collected products from customers are encouraged to be reallocated to fulfill demands of other customers; (2) it is multi-commodity and the number of involved commodities can be over 10,000. To solve this problem, we provide a nonvehicle-index arc-flow formulation and some strengthening strategies. Moreover, for large-scale instances, an adaptive memory programming based algorithm combined with techniques such as the regret insertion method for initializing the solution pool, the segment-based evaluation scheme, and advanced pool management method, is proposed. We test our algorithm on 66 real-world and 96 newly generated instances, and provide the results for future-use comparisons. The experiments on small-scale instances show that the proposed algorithm can quickly reach the optimality obtained by solving the mathematical formulation. In addition, the proposed algorithm is shown to perform well and stably on medium and large scale instances. Finally, we analyze some features of this problem, and find that relocation of commodities increases their utilization.","Vehicle routing problem,Simultaneous pickup and delivery,Multi-commodities,Fast fashion,Adaptive memory programming","ZhenzhenZhangac,BrendaCheangb,ChongshouLia,AndrewLima","Computers & Operations Research","https://doi.org/10.1016/j.cor.2018.10.020","https://www.sciencedirect.com/science/article/pii/S0305054818302843"
"A386","An efficient linear second order unconditionally stable direct discretization method for the phase-field crystal equation on surfaces","We develop an unconditionally stable direct discretization scheme for solving the phase-field crystal equation on surfaces. The surface is discretized by using an unstructured triangular mesh. Gradient, divergence, and Laplacian operators are defined on triangular meshes. The proposed numerical method is second-order accurate in space and time. At each time step, the proposed computational scheme results in linear elliptic equations to be solved, thus it is easy to implement the algorithm. It is proved that the proposed scheme satisfies a discrete energy-dissipation law. Therefore, it is unconditionally stable. A fast and efficient biconjugate gradients stabilized solver is used to solve the resulting discrete system. Numerical experiments are conducted to demonstrate the performance of the proposed algorithm.","Unconditionally stable,Phase-field crystal equation,Triangular surface mesh,Laplace–Beltrami operator","YibaoLia,ChaojunLuoa,BinhuXiaa,JunseokKimb","Applied Mathematical Modelling","https://doi.org/10.1016/j.apm.2018.11.012","https://www.sciencedirect.com/science/article/pii/S0307904X18305419"
"A387","Hypersomnia and Bipolar Disorder: A systematic review and meta-analysis of proportion","BackgroundHypersomnia is a common problem amongst individuals with Bipolar Disorder (BD). The objective of this meta-analysis is to estimate the frequency of hypersomnia in individuals with BD, and identify associated factors,MethodsOur search focused on articles documenting the frequency of hypersomnia among individuals with BD indexed in PubMed database and in the Cochrane Library, following the recommendations from the Meta-Analysis Of Observational Studies in Epidemiology (MOOSE) Group. A meta-analysis of proportion was conducted; funnel plot and Egger's test were used for the assessment of publication bias. Subgroups analyses were performed in order to evaluate possible confounders and associated factors.,ResultsWe identified 10 studies, which included 1824 patients with BD. The overall estimate of the proportion of BD cases that reported hypersomnia was 29.9% [95% confidence interval (CI): 25.8 - 34.1%, I2<U+202F>=<U+202F>59.2%; p<U+202F><<U+202F>.05]. The funnel plot and the Egger's test suggest a low risk of publication bias (p<U+202F>=<U+202F>.527). The polarity of mood state, Bipolar Disorder type, use of medication, age, diagnostic criteria and hypersomnia criteria were not significantly related to hypersomnia.,LimitationsThere is a possibility that smaller cross-sectional studies were not included. The high heterogeneity between studies is frequent in meta-analysis of both interventional and observational studies. Hypersomnia was not the primary outcome in some of the included studies.,ConclusionsTo our knowledge, this is the first systematic review and meta-analysis of hypersomnia prevalence in patients with BD. Further studies focused on clinical correlates and implications for health outcomes in BD are warranted.","Bipolar Disorder,Depression,Chronobiology,Circadian rhythm,Hypersomnia","Ruth B.Grigolona,Alisson P.Trevizolbc,Raphael O.Cerqueiraa,YenaLeee,Rodrigo B.Mansure,Roger S.McIntyrede,ElisaBrietzkeae","Journal of Affective Disorders","https://doi.org/10.1016/j.jad.2018.12.030","https://www.sciencedirect.com/science/article/pii/S0165032718301745"
"A388","Modeling anisotropic shape evolution during Czochralski growth of oxide single crystals","We present a technique for modeling three-dimensional (3D) anisotropic crystal shape evolution in meniscus defined growth systems. In particular we apply this model to a simplified low gradient Czochralski growth process used to grow bismuth–germanium–oxide–like crystals. Our Lattice Boltzmann Model (LBM) based approach involves a two-dimensional unstructured mesh (embedded within the 3D LBM grid) which accurately tracks the crystal/melt and melt/gas interfaces while accounting for anisotropic interface attachment kinetics as well as capillarity, involving the enforcement of either isotropic or anisotropic growth angles (GA) at the crystal/melt/gas triple phase line (GA-TPL). The robustness of the algorithm is demonstrated by a series of tests involving mesh refinement, comparisons with results from an older study and an evaluation of the impact on accuracy of a time-saving artificial pull-rate speedup scheme described within the manuscript. Physically significant results (which do not involve diameter control) include a demonstration of the impact of changes in kinetic parameters on resultant ingot shapes, calculations showing how (for conditions considered here) the diameter of the growing crystal decreases with increasing isotropic growth angle values, and growth simulations demonstrating how anisotropic growth angles can impact the shape of the evolving ingot. The dependence of crystal diameter on isotropic growth angle values is reproduced in a local sense in the case of anisotropic growth angles. A specific point on the GA-TPL will tend to extend inwards or outwards (respectively exhibiting a decreased or increased local radial position value) when the growth angle value is locally (and respectively) increased or decreased. As a result, considering crystals whose non-circular cross-sectional shapes are due to kinetic anisotropy as a baseline, growth angle anisotropy acts to either decrease or increase shape anisotropy when the extended (rough) parts of the GA-TPL respectively support large or small local growth angle values as compared to reduced-radius (faceted) parts of the GA-TPL. It should finally be mentioned that our results, concerning the sensitivity of the (local or average) radial position value of the GA-TPL to the growth angle, are consistent with other computational results exhibited in the literature (concerning solidifying semiconductor drops and floating zone growth of oxides).","A1. Modeling,A1. Facets,A1. Anisotropy,A2. Czochralski method,A2. Growth from melt,B1. Oxides","OlegWeinsteina,AlexanderVirozuba,WolframMillerb,SimonBrandona","Journal of Crystal Growth","https://doi.org/10.1016/j.jcrysgro.2018.12.019","https://www.sciencedirect.com/science/article/pii/S0022024818306316"
"A389","Parallel score fusion of ECG and fingerprint for human authentication based on convolution neural network","Biometrics have been extensively used in the past decades in various security systems and have been deployed around the world. However, all unimodal biometrics have their own limitations and disadvantages (e.g., fingerprint suffers from spoof attacks). Most of these limitations can be addressed by designing a multimodal biometric system, which deploys over one biometric modality to improve the performance and make the system robust to spoof attacks. In this paper, we proposed a secure multimodal biometric system by fusing electrocardiogram (ECG) and fingerprint based on convolution neural network (CNN). To the best of our knowledge, this is the first study to fuse ECG and fingerprint using CNN for human authentication. The feature extraction for individual modalities are performed using CNN and then biometric templates are generated from these features. After that, we have applied one of the cancelable biometric techniques to protect these templates. In the authentication stage, we proposed a Q-Gaussian multi support vector machine (QG-MSVM) as a classifier to improve the authentication performance. Dataset augmentation is successfully used to increase the authentication performance of the proposed system. Our system is tested on two databases, the PTB database from PhysioNet bank for ECG and LivDet2015 database for the fingerprint. Experimental results show that the proposed multimodal system is efficient, robust and reliable than existing multimodal authentication algorithms. According to the advantages of the proposed system, it can be deployed in real applications.","Authentication,CNN,ECG,Fingerprint,Multimodal biometrics,MSVM","MohamedHammadab,WangKuanquana","Computers & Security","https://doi.org/10.1016/j.cose.2018.11.003","https://www.sciencedirect.com/science/article/pii/S0167404818308411"
"A390","Investigating the combined effect of square microgrooves and CNT coating on condensation heat transfer","The combined effect of square grooves fabricated using picosecond laser treatment and CNT coating deposited using dip coating technique on the condensation surface was studied. Apart from being a highly time efficient process, the utilisation of laser texturing technique allows for precise control of the groove dimensions. The fabricated surface was characterized for its surface morphologies and wettability characteristics and the results are placed appropriately. A condensation experimental setup was designed and fabricated, in which the experiments were carried out to analyse the performance of modified copper surfaces. The values obtained from the plain copper surface served as a reference to compare the performance of various modified surfaces. The combined effect of square grooves and the CNT coating were evaluated and compared with its counterparts. Wettability of the modified surfaces was measured using contact angle meter which is very crucial for condensation heat transfer. Results corresponding to the modified surfaces were found to have improved performance as compared to the plain copper surface. In case of modified surfaces, the sample with the combination of square grooves and CNT coating was found to excel in heat transfer performance when compared to its counterparts. An enhancement of approximately 63%, 29% and 96% were obtained for grooved, CNT coated surface and grooved CNT coated surface respectively in the heat flux values, when compared against bare copper surface. Similarly, heat transfer coefficient values registered an improvement of 29%, 31% and 58% respectively for grooved, CNT coated surface and grooved CNT coated surface. The CNT coated surface was hydrophobic in nature, while the micron scale grooves reduced the departure diameter and increased the sweeping cycle rate, which has a positive effect on the heat transfer rate. Droplet departure diameter reduced by nearly half and departure frequency increased by nearly 3 times for grooved CNT coated surface, against the bare copper surface.","Condensation heat transfer,Copper nanotube,Square grooves,Heat transfer coefficient,Droplet departure diameter,Droplet departure,Frequency","G.Udaya Kumara1,D.Venkata Krishnana1,S.Suresha,M.R.Thansekharb2,R.Varun Prasannaa1,M.Jubala1","Applied Surface Science","https://doi.org/10.1016/j.apsusc.2018.10.245","https://www.sciencedirect.com/science/article/pii/S0169433218330289"
"A391","A novel lipid droplets-targeting ratiometric fluorescence probe for hypochlorous acid in living cells","Lipid droplets were found to be involved in many organism activities. Here, a lipid droplets-targeted near-infrared fluorescence probe (named XHZ) for ratiometric detection of endogenous hypochlorous acid/hypochlorite (HClO/ClO-) in living cells was developed, which was constructed by a coumarin moiety and a malononitrile derivative. XHZ could detect HClO/ClO- with high selectivity and sensitivity in a ratiometric manner based on FRET (Förster Resonance Energy Transfer) mechanism. The two well-resolved emission (470/672<U+202F>nm) bands could ensure accurate detection of HClO/ClO- in vitro as well as in vivo. XHZ was successfully used for ratiometric fluorescence imaging of exogenous and endogenous HClO/ClO- in RAW264.7 cells. A good linear relationship between the fluorescence intensity ratios of the two emissions and HClO/ClO- concentrations from 0 to 40<U+202F>µM was obtained. Importantly, XHZ could localize mainly in lipid droplets of RAW264.7 cells. To the best of our knowledge, XHZ is the first lipid droplets-targeted ratiometric fluorescence probe for HClO/ClO-.","Ratiometric fluorescence,Lipid droplets-targeting,Endogenous hypochlorous acid,Cell image","Wen-LiWua,Han-LinMab,Long-LongXia,Miao-FeiHuanga,Kai-MingWangc,Jun-YingMiaob,Bao-XiangZhaoa","Talanta","https://doi.org/10.1016/j.talanta.2018.10.006","https://www.sciencedirect.com/science/article/pii/S003991401831052X"
"A392","Stability analysis of a non-conventional breakwater for wave energy conversion","This paper presents the stability analysis of a non-conventional breakwater cross-section integrating an overtopping wave energy converter, named OBREC. The device consists of a traditional rubble-mound breakwater in which the upper part of the armour layer is replaced by a smooth ramp and a reservoir.The analysis of the structure is carried out by combining model scale experiments and numerical simulations based on the Volume-Averaged Reynolds Averaged Navier-Stokes (VARANS) equations.The numerical analysis is used to complete and extend the results of the physical model test campaign, providing a deeper understanding of the pressure distribution and resultant force behaviour in locations where laboratory measurements were difficult to obtain or not available. Results show that the maximum vertical and horizontal total forces on the device are not simultaneous. At the time instant of the maximum total horizontal force, the vertical force is zero or directed downward, due to the significant positive contribution of the force acting on the sloping ramp. Additional numerical simulations show the influence of the submerged ramp length on the forces acting on the structure using the global and local stability analysis. The presence of the shaft contributes positively to the global stability against the sliding failure mode by reducing the uplift force exerted on the horizontal base. Moreover, the stability analysis shows that the critical conditions for the global failure modes occur at different time instants.","Non-conventional breakwater,Wave energy converter,Wave loadings,Numerical model,Structure stability","EnricoDi Lauroa,Javier L.Larab,MariaMazab,Inigo J.Losadab,PasqualeContestabilea,DiegoVicinanzaa","Coastal Engineering","https://doi.org/10.1016/j.coastaleng.2018.12.008","https://www.sciencedirect.com/science/article/pii/S0378383918303430"
"A393","Impact of random weights on nonlinear system identification using convolutional neural networks","Randomized algorithms have been successfully applied in modeling dynamic system. How do random weights affect system identification and why do they sometimes work well? In this paper, we use the convolutional neural network (CNN) as an identification model to answer these questions.Since the convolution operation is an important property of the dynamic system and in the frequency domain it becomes the product, the CNN model is analyzed in the frequency domain. We first modify the CNN model, so that it can model both the input and the output series. Then we analyze the impact of the random weights of CNN in the frequency domain. We prove the existence of optimal weights and analyze the modeling accuracy under optimal weights and random weights. Through theoretical analysis, we propose a two-step training method and compare it with the random weight algorithm. The proposed CNN model with random weights is validated with three benchmark problems.","Convolutional neural network,Random algorithms,Frequency domain,Deep learning","WenYu,MarioPacheco","Information Sciences","https://doi.org/10.1016/j.ins.2018.10.019","https://www.sciencedirect.com/science/article/pii/S0020025518308168"
"A394","NTP-ERSN: A new package for solving the multigroup neutron transport equation in a slab geometry","The package, called NTP-ERSN (N eutron T ransport P ackage from the R adiations and N uclear S ystems G roup), is an open-source code written in FORTRAN90 for a pedagogical purpose to solve the steady-state multigroup neutron transport equation. This package is based on three classical methods, namely the collision probability (CP) method, the discrete ordinates (SN) method and the method of characteristics (MOC). These methods are employed to obtain scalar and angular flux distributions in homogeneous and heterogeneous slab geometry with isotropic and anisotropic scattering. The source code algorithms are very simple to be comprehensive by engineering students. In addition, NTP-ERSN is a simple framework to add and test new algorithms. On the other hand, a graphical user interface written in Python programing language has been developed to simplify the use of NTP-ERSN. Numerical results are given to illustrate the NTP-ERSN code's accuracy. Finally, the present software can be useful as an academic tool for teaching reactor physics. It is freely available for download on GitHub (https://github.com/mohamedlahdour/NTP-ERSN).","Package,NTP-ERSN,Neutron transport equation,FORTRAN90,GUI,Python,CP,SN,MOC,Eigenvalue calculation","M.Lahdoura,T.El Bardounia,E.Chakirb,K.Benaaliloua,M.Mohammeda,H.Bougueniza,H.El Yaakoubia","Applied Radiation and Isotopes","https://doi.org/10.1016/j.apradiso.2018.12.004","https://www.sciencedirect.com/science/article/pii/S0969804318306687"
"A395","miR675 Accelerates Malignant Transformation of Mesenchymal Stem Cells by Blocking DNA Mismatch Repair","","miR675,human mesenchymal stem cell,malignant transformation,P62","YananLu1,ShutingSong1,XiaoxueJiang1,QiuyuMeng1,ChenWang1,XiaonanLi1,YuxinYang1,XiaoruXin1,QidiZheng1,LiyanWang1,HuPu1,XinGui1,TianmingLi1,DongdongLu1","Molecular Therapy - Nucleic Acids","https://doi.org/10.1016/j.omtn.2018.11.010","https://www.sciencedirect.com/science/article/pii/S2162253118303044"
"A396","Numerical simulations of the microvascular fluid balance with a non-linear model of the lymphatic system","Fluid homeostasis is required for life. Processes involved in fluid balance are strongly related to exchanges at the microvascular level. Computational models have been presented in the literature to analyze the microvascular-interstitial interactions. As far as we know, none of those models consider a physiological description for the lymphatic drainage-interstitial pressure relation. We develop a computational model that consists of a network of straight cylindrical vessels and an isotropic porous media with a uniformly distributed sink term acting as the lymphatic system. In order to describe the lymphatic flow rate, a non-linear function of the interstitial pressure is defined, based on literature data on the lymphatic system. The proposed model of lymphatic drainage is compared to a linear one, as is typically used in computational models. To evaluate the response of the model, the two are compared with reference to both physiological and pathological conditions. Differences in the local fluid dynamic description have been observed using the non-linear model. In particular, the distribution of interstitial pressure is heterogeneous in all the cases analyzed. The resulting averaged values of the interstitial pressure are also different, and they agree with literature data when using the non-linear model. This work highlights the key role of lymphatic drainage and its modeling when studying the fluid balance in microcirculation for both to physiological and pathological conditions, e.g. uremia.","00-01,99-00,Keywords,Microvascular environment,Lymphatic system,Fluid homeostasis,Uremia,Interstitial pressure,Finite element model","LucaPossentia,GiustinaCasagrandea,SimoneDi Gregorioab,PaoloZuninob,Maria LauraCostantinoa","Microvascular Research","https://doi.org/10.1016/j.mvr.2018.11.003","https://www.sciencedirect.com/science/article/pii/S0026286218300384"
"A397","Upregulated levels and pathological aggregation of abnormally phosphorylated Tau-protein in children with neurodevelopmental disorders","The tubulin-associated unit (Tau) protein is an intrinsically disordered protein that plays a well-established role in promoting microtubule assembly and regulation of microtubule dynamics in neuronal axons at all stages of development. Identification of new interacting partners and different sub-cellular localizations of Tau in recent years led to the discovery of novel physiological functions in regulation of neuronal activity, neurogenesis, long-term depression, iron export and genomic integrity. In addition, Tau gene mutations, aberrant mRNA splicing and abnormal post-translational modifications, such as hyperphosphorylation, lead to formation of pathological, insoluble Tau aggregates that are a hallmark of neurodegenerative diseases, collectively known as tauopathies. Characterized by synaptic dysfunction, neuroinflammation/neuronal cell death and dementia, tauopathies are designated as a group of adult-onset neurodegenerative diseases. Recent studies summarized in this review document several neurological conditions and diseases in an early life stage with upregulated levels or even pathological aggregation of abnormally phosphorylated Tau protein. These findings suggest that Tau might play a previously underestimated role in neurodevelopmental disorders and regression in children.","","MarijaRankovica,MarkusZweckstetterab","Neuroscience & Biobehavioral Reviews","https://doi.org/10.1016/j.neubiorev.2018.12.014","https://www.sciencedirect.com/science/article/pii/S0149763418307309"
"A398","Co-expression profiling of plasma miRNAs and long noncoding RNAs in gastric cancer patients","PurposeThe recent researches indicate that differential non-coding RNAs expression signatures could be associated with the pathogenesis of gastric cancer (GC). However, there are few studies focused on lncRNA-miRNAs co-expression profiling in GC patients. Therefore, in the present study the expression of H19 and MEG3 and their related miRNAs including miR-148a-3p, miR-181a-5p, miR-675-5p and miR-141-3p were determined in the plasma samples of GC patients and controls.,Materials and methodsThis case-control study included 62 GC patients and 40 age- sex matched controls. The non-coding RNA levels were assessed by real-time PCR. Further, using in silico analysis, we identified shared targets of studied miRNAs and performed GC-associated pathway enrichment analysis.,ResultsOur results showed that the H19 level was significantly (P<U+202F>=<U+202F>0.008) elevated and MEG3 expression was significantly (P<U+202F>=<U+202F>0.002) down-regulated in GC patients compared to healthy participants. Furthermore, it was revealed that the miR-675-5p level was increased, while miR-141-3p plasma levels were significantly reduced in GC patients (P<U+202F><<U+202F>0.05). We did not observe a significant difference for miR-148a-3p (P<U+202F>=<U+202F>0.682) and miR-181a-5p (P<U+202F>=<U+202F>0.098) expression between groups. In addition, the expression levels of H19, MEG3 and miR-148a-3p were associated with some clinicopathological features of patients (P<U+202F><<U+202F>0.05). ROC analysis revealed that a combination of H19, MEG3 and miR-675-5p levels able to discriminate controls and GC subjects with 88.87% sensitivity and 85% specificity (AUC, 0.927; 0.85–0.96 CI, P<U+202F><<U+202F>0.0001).,ConclusionThe results of current study demonstrated that combination of H19, MEG3 and miR-675-5p expression levels could provide a potential diagnostic panel for GC.","GCGastric Cancer,ncRNAsNon-coding RNAs,lncRNAsLong-noncoding RNAs,miRNAmicroRNA,MEG3maternally expressed 3,ROCReceiver Operating Characteristic,AUCArea Under the ROC curve,Keywords,Gastric cancer,H19,MEG3,miR-148a-3p,miR-181a-5p,miR-675-5p,miR-141-3p","HamidGhaedia,Mohammad Amin NazerMozaffarib,ZakerSalehic,HassanGhasemid,Seyed SajjadZadiane,SadeghAlipoorf,ShivaHadianpourg,BehnamAlipoorg","Gene","https://doi.org/10.1016/j.gene.2018.11.034","https://www.sciencedirect.com/science/article/pii/S0378111918311788"
"A399","The impact of wind turbines on local recreation: Evidence from two travel cost method – contingent behavior studies","This paper analyzes recreation demand on the fringe of an urban center in Norway. Specifically, it investigates the potential impact of wind energy projects on local recreation values. Recreation areas near cities are often scarce and under increasing pressures from growing populations with associated real-estate development and expanding or emerging industries. Hence, public planners and policy makers who seek to make optimal resource management decisions need information on all opportunity costs, including those associated with diminished recreational access or quality. Two separate case studies utilize the travel cost method (TCM) to derive baseline recreation demands. Supplementary information from contingent behavior (CB) scenarios provides identification of the impact of wind turbines on recreation benefits. For a unique comparison, one case examines a possible inland wind farm near a popular local mountain area, whereas the other case examines an offshore wind farm near local beaches. Econometric estimations are performed in a joint revealed preference (RP) – stated preference (SP) pseudo-panel count-data framework. The analysis generates baseline consumer surplus estimates in the range of NOK 70–155 per trip and indicates that the wind turbines would have negative impacts that are both statistically and economically significant.","Recreation demand,Travel cost method,Contingent behavior,Renewable energy,Wind energy externalities,Consumer surplus","GormKipperberg,YukoOnozaka,Linh ThiBui,MartheLohaugen,GretaRefsdal,SandraSæland","Journal of Outdoor Recreation and Tourism","https://doi.org/10.1016/j.jort.2018.11.004","https://www.sciencedirect.com/science/article/pii/S2213078018300616"
"A400","Adsorption and Desorption of Pb(II) on l-Lysine Modified Montmorillonite and the simulation of Interlayer Structure","Herein, we reported the adsorption and desorption of Pb(II) on l-lysine modified montmorillonite (L-Mt) with molecular dynamics simulation. l-lysine (Lys) modified montmorillonite (L-Mt) was prepared, characterized by various analytical techniques, and the simulation studies were performed to evaluate the interlayer structure and interaction properties of l-lysine and L-Mt. The results of X-ray powder diffraction (XRD) and Fourier transform infrared (FTIR) spectrum suggested that Lys+ was intercalated into the interlayer of Na-montmorillonite (NaMt) successfully. The batch adsorption experiments were implemented to study the adsorption capacity of Pb(II) on L-Mt in water. The maximum adsorption capacity of Pb(II) on the L-Mt (up to 43.3<U+202F>mmol/100<U+202F>g) were considerably higher than that on NaMt (up to 15.3<U+202F>mmol/100<U+202F>g), at room temperature. The adsorption isotherms of both, L-Mt and NaMt can fit the Langmuir isotherm. The adsorption experiments showed that Pb(II) removal efficiency of L-Mt is better than NaMt in acidic solution. The simulation results revealed the micro-mechanism of Lys+ inserted into the interlayer gallery of NaMt. It can be deduced that lysine interacted with montmorillonite surface mainly through the protonated side-chain amino group rather than through the protonated main-chain amino group or deprotonated carboxyl group. These consequences are expected to elucidate the adsorption mechanisms occurring at the water/clay minerals interface at atom level, providing significant insight into the adsorption and retention of Pb(II) on L-Mt composite, and lead to relevant engineering applications while treating heavy metals of wastewater.","Montmorillonite,l-lysine,Adsorption,Molecular dynamics simulation,Desorption","SidiZhu,MingzhuXia,YutingChu,Muhammad AsimKhan,WuLei,FengyunWang,TahirMuhmood,AlongWang","Applied Clay Science","https://doi.org/10.1016/j.clay.2018.12.017","https://www.sciencedirect.com/science/article/pii/S0169131718305192"
"A401","Stability analysis of a non-conventional breakwater for wave energy conversion","This paper presents the stability analysis of a non-conventional breakwater cross-section integrating an overtopping wave energy converter, named OBREC. The device consists of a traditional rubble-mound breakwater in which the upper part of the armour layer is replaced by a smooth ramp and a reservoir.The analysis of the structure is carried out by combining model scale experiments and numerical simulations based on the Volume-Averaged Reynolds Averaged Navier-Stokes (VARANS) equations.The numerical analysis is used to complete and extend the results of the physical model test campaign, providing a deeper understanding of the pressure distribution and resultant force behaviour in locations where laboratory measurements were difficult to obtain or not available. Results show that the maximum vertical and horizontal total forces on the device are not simultaneous. At the time instant of the maximum total horizontal force, the vertical force is zero or directed downward, due to the significant positive contribution of the force acting on the sloping ramp. Additional numerical simulations show the influence of the submerged ramp length on the forces acting on the structure using the global and local stability analysis. The presence of the shaft contributes positively to the global stability against the sliding failure mode by reducing the uplift force exerted on the horizontal base. Moreover, the stability analysis shows that the critical conditions for the global failure modes occur at different time instants.","Non-conventional breakwater,Wave energy converter,Wave loadings,Numerical model,Structure stability","EnricoDi Lauroa,Javier L.Larab,MariaMazab,Inigo J.Losadab,PasqualeContestabilea,DiegoVicinanzaa","Coastal Engineering","https://doi.org/10.1016/j.coastaleng.2018.12.008","https://www.sciencedirect.com/science/article/pii/S0378383918303430"
"A402","Co-expression profiling of plasma miRNAs and long noncoding RNAs in gastric cancer patients","PurposeThe recent researches indicate that differential non-coding RNAs expression signatures could be associated with the pathogenesis of gastric cancer (GC). However, there are few studies focused on lncRNA-miRNAs co-expression profiling in GC patients. Therefore, in the present study the expression of H19 and MEG3 and their related miRNAs including miR-148a-3p, miR-181a-5p, miR-675-5p and miR-141-3p were determined in the plasma samples of GC patients and controls.,Materials and methodsThis case-control study included 62 GC patients and 40 age- sex matched controls. The non-coding RNA levels were assessed by real-time PCR. Further, using in silico analysis, we identified shared targets of studied miRNAs and performed GC-associated pathway enrichment analysis.,ResultsOur results showed that the H19 level was significantly (P<U+202F>=<U+202F>0.008) elevated and MEG3 expression was significantly (P<U+202F>=<U+202F>0.002) down-regulated in GC patients compared to healthy participants. Furthermore, it was revealed that the miR-675-5p level was increased, while miR-141-3p plasma levels were significantly reduced in GC patients (P<U+202F><<U+202F>0.05). We did not observe a significant difference for miR-148a-3p (P<U+202F>=<U+202F>0.682) and miR-181a-5p (P<U+202F>=<U+202F>0.098) expression between groups. In addition, the expression levels of H19, MEG3 and miR-148a-3p were associated with some clinicopathological features of patients (P<U+202F><<U+202F>0.05). ROC analysis revealed that a combination of H19, MEG3 and miR-675-5p levels able to discriminate controls and GC subjects with 88.87% sensitivity and 85% specificity (AUC, 0.927; 0.85–0.96 CI, P<U+202F><<U+202F>0.0001).,ConclusionThe results of current study demonstrated that combination of H19, MEG3 and miR-675-5p expression levels could provide a potential diagnostic panel for GC.","GCGastric Cancer,ncRNAsNon-coding RNAs,lncRNAsLong-noncoding RNAs,miRNAmicroRNA,MEG3maternally expressed 3,ROCReceiver Operating Characteristic,AUCArea Under the ROC curve,Keywords,Gastric cancer,H19,MEG3,miR-148a-3p,miR-181a-5p,miR-675-5p,miR-141-3p","HamidGhaedia,Mohammad Amin NazerMozaffarib,ZakerSalehic,HassanGhasemid,Seyed SajjadZadiane,SadeghAlipoorf,ShivaHadianpourg,BehnamAlipoorg","Gene","https://doi.org/10.1016/j.gene.2018.11.034","https://www.sciencedirect.com/science/article/pii/S0378111918311788"
"A403","PM2.5 exposure impairs sperm quality through testicular damage dependent on NALP3 inflammasome and miR-183/96/182 cluster targeting FOXO1 in mouse","Exposure to ambient fine particular matter (PM2.5) has been clearly associated with male reproductive disorders. However, very limited toxicological studies were carried out to investigate the potential mechanisms underlying the PM2.5-induced sperm quality decline. In the present study, we established a real time whole-body PM2.5 exposure mouse model to investigate the effects of PM2.5 on sperm quality and its potential mechanisms. Sixty male C57BL/6 mice were randomly subjected to three groups: filtered air group, unfiltered air group and concentrated air group. Half of the mice from each group were sacrificed for study when the exposure duration accumulated to 8 weeks and the rest of the mice were sacrificed when exposed for 16 weeks. Our results suggested that PM2.5 exposure could induce significant increases in circulating white blood cells and inflammation in lungs. PM2.5 exposure induced apparently DNA damages and histopathologic changes in testes. There were significantly decreased sperm densities of mice, which were paralleled with the down-regulated testosterone levels in testes tissue of mice after exposure to PM2.5 for 16 weeks. The numbers of motile sperms were decreased and sperms with abnormal morphology were increased after PM2.5 exposure in a time-depended and dose-depended manner. PM2.5 exposure significantly increased the expression of the major components of the NACHT, LRR and PYD domains-containing protein3 (NALP3) inflammasome, accompanied by the increased expression of miR-183/96/182 targeting FOXO1 in testes. The present data demonstrated that sperm quality decline induced by PM2.5 could be partly explained by the inflammatory reaction in testes which might be a consequence of systemic inflammation. The molecular mechanism was depended on the activation of NALP3 inflammasome accompanied by miR-183/96/182 targeting FOXO1 in testes.","Ambient fine particular matter (PM2.5),Sperm quality,NALP3 inflammasome,FOXO1,Male reproductive system","LixiaoZhoua,XuanSua,BinghuaLib,ChenChua,HongyueSuna,NingZhanga,BinHana,ChenLia,BingjieZoua,YujieNiuac,RongZhangac","Ecotoxicology and Environmental Safety","https://doi.org/10.1016/j.ecoenv.2018.10.108","https://www.sciencedirect.com/science/article/pii/S0147651318311278"
"A404","Modeling anisotropic shape evolution during Czochralski growth of oxide single crystals","We present a technique for modeling three-dimensional (3D) anisotropic crystal shape evolution in meniscus defined growth systems. In particular we apply this model to a simplified low gradient Czochralski growth process used to grow bismuth–germanium–oxide–like crystals. Our Lattice Boltzmann Model (LBM) based approach involves a two-dimensional unstructured mesh (embedded within the 3D LBM grid) which accurately tracks the crystal/melt and melt/gas interfaces while accounting for anisotropic interface attachment kinetics as well as capillarity, involving the enforcement of either isotropic or anisotropic growth angles (GA) at the crystal/melt/gas triple phase line (GA-TPL). The robustness of the algorithm is demonstrated by a series of tests involving mesh refinement, comparisons with results from an older study and an evaluation of the impact on accuracy of a time-saving artificial pull-rate speedup scheme described within the manuscript. Physically significant results (which do not involve diameter control) include a demonstration of the impact of changes in kinetic parameters on resultant ingot shapes, calculations showing how (for conditions considered here) the diameter of the growing crystal decreases with increasing isotropic growth angle values, and growth simulations demonstrating how anisotropic growth angles can impact the shape of the evolving ingot. The dependence of crystal diameter on isotropic growth angle values is reproduced in a local sense in the case of anisotropic growth angles. A specific point on the GA-TPL will tend to extend inwards or outwards (respectively exhibiting a decreased or increased local radial position value) when the growth angle value is locally (and respectively) increased or decreased. As a result, considering crystals whose non-circular cross-sectional shapes are due to kinetic anisotropy as a baseline, growth angle anisotropy acts to either decrease or increase shape anisotropy when the extended (rough) parts of the GA-TPL respectively support large or small local growth angle values as compared to reduced-radius (faceted) parts of the GA-TPL. It should finally be mentioned that our results, concerning the sensitivity of the (local or average) radial position value of the GA-TPL to the growth angle, are consistent with other computational results exhibited in the literature (concerning solidifying semiconductor drops and floating zone growth of oxides).","A1. Modeling,A1. Facets,A1. Anisotropy,A2. Czochralski method,A2. Growth from melt,B1. Oxides","OlegWeinsteina,AlexanderVirozuba,WolframMillerb,SimonBrandona","Journal of Crystal Growth","https://doi.org/10.1016/j.jcrysgro.2018.12.019","https://www.sciencedirect.com/science/article/pii/S0022024818306316"
"A405","A latent profile analysis of the Five Factor Model of personality: A constructive replication and extension","Recent research into the underlying structure of personality has created considerable debate among academics. Further, a new, person-centered approach to studying personality has recently gathered support, but results have been underwhelming and inconsistent. The present study steps into the debate from a new angle with a constructive replication and derives a model of latent personality profiles in an archival sample of over three million respondents from almost every country in the world who completed a Five-Factor Model of personality questionnaire and other work and life outcomes measures. Three latent profiles emerged from this analysis, which were characterized by the degree to which respondents endorsed the traits of Conscientiousness, Extraversion, Agreeableness, and Emotional Stability. The trait of Openness to Experience did not appear to discriminate between the three latent profiles. Consistent with socioanalytic theory, evolutionary psychology, and more nascent theory on the general factor of personality, personality profiles were labelled as maladaptive, adaptive, and highly adaptive. More adaptive personality profiles were associated with higher life satisfaction, job self-efficacy, and passion towards work, as well as favorable value systems. Theoretical implications are subsequently discussed.","Latent profile analysis,General factor of personality,Socioanalytic theory,Evolutionary psychology","Peter A.Fisher,ChetRobie","Personality and Individual Differences","https://doi.org/10.1016/j.paid.2018.12.002","https://www.sciencedirect.com/science/article/pii/S0191886918306366"
"A406","Characterization of OCT3/4, Nestin, NANOG, CD44 and CD24 as stem cell markers in canine prostate cancer","The cancer cell population is heterogeneous, and cancer stem cells (CSCs) are important for tumor growth and maintenance. The CSC population is associated with different neoplastic characteristics, such as cell migration, resistance to apoptosis, radiation therapy and chemotherapy. To increase the knowledge of CSCs in canine prostate cancer (PC), we characterized CSC markers in canine PC tissues and tumorspheres. We performed immunohistochemistry of OCT3/4, Nestin, NANOG, CD44 and CD24 in 10 normal canine prostatic tissue samples, 10 prostatic hyperplastic (PH) tissue samples and 28 PC tissue samples. Then, we established two canine prostate cancer cell cultures and characterized the CSC profile of tumorspheres grown from these cultures. Normal and PH tissues were positive for Nestin, NANOG, CD44 and CD24 only in the basal cell layer. OCT3/4 was expressed in the luminal cells of normal and PH tissues. There was no significant difference in Nestin expression among the prostatic tissues. However, we found higher expression of NANOG and CD44 in canine PC tissues than that in normal and PH tissues. Tumorspheres from canine prostate cancer cells express OCT3/4, Nestin, NANOG and CD44, indicating that these markers may be potential cancer stem cell markers in canine PC. The results obtained can be useful to better characterize the stem cell population in canine prostatic cancer and to guide future studies in comparative oncology.","CSCcancer stem cells,PCprostate cancer,OCT3/4octamer-binding protein 3/4,CD44cluster of differentiation 44,CD24cluster of differentiation 24,PHprostatic hyperplastic,MELKmaternal embryonic leucine zipper kinase,WHOWorld Health Organization,DAB3,3´-diaminobenzidine,DPBSDulbecco's Phosphate Buffered Saline Modified,FBSfetal bovine serum,EDTA2,2',2”,2”'-(ethane-1,2-diyldinitrilo) tetraacetic acid,PBSphosphate buffered saline,DAPI4'6-diamidine-2'-phenylindole dihydrochloride,DMEMDulbecco's Modified Eagle's Medium,EGFepidermal growth factor,RNAribonucleic acid,Keywords,Dog,OCT3/4,Prostate cancer,NANOG,CD44","Camila DoroteaCostaa1,Andre AugustoJustob1,Priscila EmikoKobayashib,Michelle M.Storyc,ChiaraPalmieric,RenéeLaufer Amorimb2,Carlos EduardoFonseca-Alvesa2","The International Journal of Biochemistry & Cell Biology","https://doi.org/10.1016/j.biocel.2019.01.002","https://www.sciencedirect.com/science/article/pii/S1357272519300020"
"A407","Do a few tools necessarily mean a few people? A techno-morphological approach to the question of group size at Gesher Benot Ya'aqov, Israel","The question of Paleolithic group size has been addressed by scholars in many disciplines applying different methods. In our study we apply a novel analytical approach in an attempt to assess the group size of hominins that occupied the Acheulian site of Gesher Benot Ya'aqov, Israel (GBY). Within this framework, we subjected the handaxe assemblages from several archaeological horizons at the site to a morpho-technological analysis. The analysis combined high-resolution three-dimensional geometric morphometric analysis with typo-technological attribute analysis to assess the inter- and intra-assemblage morpho-technological variability. The analysis was also applied to an experimental handaxe assemblage produced by an expert knapper. The results of the analysis show high morphological homogeneity coupled with high technological variability in each of the archaeological assemblages. This pattern is highly indicative of the work of expert knappers, as is also suggested by the comparison between the archaeological and experimental assemblages. The high density of archaeological remains in some of the GBY occupations and their pristine taphonomic condition provide additional support for the involvement of large groups of hominins, although some horizons are far poorer in archaeological remains and hence do not allow such an interpretation. Nevertheless, the fact that in all assemblages the handaxes show the same techno-morphological pattern indicates that they were all produced by expert knappers. As shown by numerous models and ethnographic data, the presence of experts can be viewed as an indication of large and socially complex societies. Thus, although some of the GBY occupations were not formed by large groups, the smaller groups whose activities are recorded were very likely to be part of larger, socially complex cultural groups. This variability in occupational intensity is interpreted as representing an aggregation-dispersal mechanism, similar to those documented in many hunter-gatherer societies.","Handaxe,Acheulian,Geometric morphometric analyses,Technology,Expertise,Social complexity","GadiHerzlingerab,NaamaGoren-Inbara","Journal of Human Evolution","https://doi.org/10.1016/j.jhevol.2018.11.008","https://www.sciencedirect.com/science/article/pii/S0047248418301507"
"A408","GaitGANv2: Invariant gait feature extraction using generative adversarial networks","The performance of gait recognition can be adversely affected by many sources of variation such as view angle, clothing, presence of and type of bag, posture, and occlusion, among others. To extract invariant gait features, we proposed a method called GaitGANv2 which is based on generative adversarial networks (GAN). In the proposed method, a GAN model is taken as a regressor to generate a canonical side view of a walking gait in normal clothing without carrying any bag. A unique advantage of this approach is that, unlike other methods, GaitGANv2 does not need to determine the view angle before generating invariant gait images. Indeed, only one model is needed to account for all possible sources of variation such as with or without carrying accessories and varying degrees of view angle. The most important computational challenge, however, is to address how to retain useful identity information when generating the invariant gait images. To this end, our approach differs from the traditional GAN in that GaitGANv2 contains two discriminators instead of one. They are respectively called fake/real discriminator and identification discriminator. While the first discriminator ensures that the generated gait images are realistic, the second one maintains the human identity information. The proposed GaitGANv2 represents an improvement over GaitGANv1 in that the former adopts a multi-loss strategy to optimize the network to increase the inter-class distance and to reduce the intra-class distance, at the same time. Experimental results show that GaitGANv2 can achieve state-of-the-art performance.","Gait recognition,Generative adversarial networks,Invariant feature","ShiqiYua,RijunLiaoa,WeizhiAna,HaifengChena,Edel B.Garcíab,YongzhenHuangcd,NormanPohe","Pattern Recognition","https://doi.org/10.1016/j.patcog.2018.10.019","https://www.sciencedirect.com/science/article/pii/S0031320318303649"
"A409","Anisotropy of volume change and permeability evolution of hard sandstones under triaxial stress conditions","Volumetric strain and permeability are strictly interconnected properties and important controlling parameters for deformation patterns in rock masses. Under reservoir conditions, stresses may be highly inhomogeneous and anisotropic, leading to porosity changes and consequently affecting fluid flow. Therefore, it turns out be a challenging issue in rock mechanics to evaluate volume change based on traditional soil mechanics background, originally intended for soft materials under low and mostly isotropic pressures. In this respect, triaxial compression tests were carried out to describe the interplay between physical properties, volume change and permeability of two hard sandstones by quantifying porefluid volume change with fully water saturated rock specimens (14<U+202F>cm length and 7<U+202F>cm radius). The investigated sedimentary rocks are (1) the greyish Trendelburg beds, a silica cemented subarkose Bunter Sandstone of Triassic age (porosity of ca. 12%), and (2) the red-brownish Rotliegend Sandstone (Bebertal), a carbonate and silica cemented sandstone of Permian age, clearly less porous (ca. 6% of effective porosity) and less permeable (3.5<U+202F>×<U+202F>10-10<U+202F>m/s) than the Bunter Sandstone. Both materials present a pronounced brittle behaviour influenced by coring direction: permeability, volumetric strain and fracture pattern are direction-dependent. Effective porosity and pore pressure level affect the fracturing development, which therefore influences the permeability after stress fall. For the Bunter Sandstone, increasing porefluid pressure leads to an earlier microcraking stage, which shortens the forestage of compaction and induces a more pronounced dilatant behaviour with decreased compressive strength. For the Rotliegend, the increase of pore fluid pressure enhances compaction. Altogether, this examination is valuable to understand the combined effects of pore pressure change and pore space quality on the mechanical behaviour of rock masses.","Triaxial testing,Volume change,Fracture pattern,Permeability,Bunter Sandstone,Rotliegend","FloraFeitosa Menezes","Journal of Petroleum Science and Engineering","https://doi.org/10.1016/j.petrol.2018.11.079","https://www.sciencedirect.com/science/article/pii/S0920410518310751"
"A410","A 3D spatial data model of the solar rights associated with individual residential properties","Increased residence in high-rise buildings has aroused demand for sunlight or sunlight duration because a lack of sunlight may lead to negative effects on the mental health of the residents of high-rise buildings. To address this issue, many countries have already enacted laws, regulations and standards that ensure solar rights for residents by guaranteeing a certain duration of sunlight. However, feasible methods that clearly describe the temporal-spatial properties of solar rights for residential buildings are presently lacking, especially for individual housing units distributed in high-rise buildings. Consequently, no relevant data model exists in any current cadastral database. This study presents a 3D data model that incorporates a range of data elements to represent the temporal-spatial extent of solar rights in the context of the current legal system of China. Using existing legal stipulations and spatial features, solar rights are classified into solar easements and neighbouring solar rights, which are separately described by geometric elements developed from the relevant legal stipulations. In addition, the geometric elements of the model are systematically integrated with existing property elements to enable the description of solar rights associated with individual residential properties. To enable the use of this model in a wide range of applications, the model is extended from the Land Administration Domain Model (LADM) and implemented using CityGML application domain extensions (ADEs). The experiments described in this study demonstrate the utility of the 3D data model for the spatial clarification of the solar rights associated with individual 3D properties.","Solar rights,Property,Cadastre,3D model,CityGML,LADM","LinLiabc,YuanLeid,LeiTanga,FenYana,FengLuoae,HaihongZhuac","Computers, Environment and Urban Systems","https://doi.org/10.1016/j.compenvurbsys.2018.12.003","https://www.sciencedirect.com/science/article/pii/S0198971517305185"
"A411","Parametric design for human body modeling by wireframe-assisted deep learning","Statistical learning of human body shape can be used for reconstructing or estimating body shapes from incomplete data, semantic parametric design, modifying images and videos, or simulation. A digital human body is normally represented in a high-dimensional space, and the number of vertices in a mesh is far larger than the number of human bodies in public available databases, which results in a model learned by Principle Component Analysis (PCA) can hardly reflect the true variety in human body shapes. While deep learning has been most successful on data with an underlying Euclidean or grid-like structure, the geometric nature of human body is non-Euclidean, it will be very challenging to perform deep learning techniques directly on such non-Euclidean domain. This paper presents a deep neural network (DNN) based hierarchical method for statistical learning of human body by using feature wireframe as one of the layers to separate the whole problem into smaller and more solvable sub-problems. The feature wireframe is a collection of feature curves which are semantically defined on the mesh of human body, and it is consistent to all human bodies. A set of patches can then be generated by clustering the whole mesh surface to separated ones that interpolate the feature wireframe. Since the surface is separated into patches, PCA only needs to be conducted on each patch but not on the whole surface. The spatial relationships between the semantic parameter, the wireframe and the patches are learned by DNN and linear regression respectively. An application of semantic parametric design is used to demonstrate the capability of the method, where the semantic parameters are linked to the feature wireframe instead of the mesh directly. Under this hierarchy, the feature wireframe acts like an agent between semantic parameters and the mesh, and also contains semantic meaning by itself. The proposed method of learning human body statistically with the help of feature wireframe is scalable and has a better quality.","Feature,Wireframe,Human body,Deep learning,Parametric design","JidaHuanga,Tsz-HoKwokb,ChiZhoua","Computer-Aided Design","https://doi.org/10.1016/j.cad.2018.10.004","https://www.sciencedirect.com/science/article/pii/S0010448518302707"
"A412","Modeling head-related transfer functions with spherical wavelets","The head-related transfer function (HRTF) describes the sound transmission characteristics from a sound source to a listener’s ears. Recently, spherical harmonic decomposition has been extensively used for modeling the HRTF spatial patterns. Despite its advantage of approximating the coarse structure of HRTF spatial variations with modeling up to a low order, there are still some limitations since spherical harmonics take significant values in all directions. First, rapidly changing HRTF spatial variations in some local regions may require modeling up to a rather high order; this is not wise in terms of the modeling efficiency. Second, the expansion coefficients of the spherical harmonics describe the spatial frequency of the target dataset in all directions, and thus have difficulties in revealing the direction dependent HRTF characteristics. In this study, a method for locally modeling HRTF spatial patterns is proposed based on spherical wavelets, which take significant values only over a local region on the sphere. Results of numerical experiments show that our proposed method yields smaller approximation errors than the conventional method when representing HRTFs inside the local regions under evaluation. Furthermore, the expansion coefficients in the proposed method could well correspond to the HRTF local features on the sphere, which makes it a useful tool for the analysis and visualization of HRTF spatial patterns.","Spherical acoustics,Head-related transfer function,Spherical wavelets,Spherical harmonics,Binaural audio,Auditory display","ShichaoHu,JorgeTrevino,CésarSalvador,ShuichiSakamoto,YôitiSuzuki","Applied Acoustics","https://doi.org/10.1016/j.apacoust.2018.10.026","https://www.sciencedirect.com/science/article/pii/S0003682X18301397"
"A413","Effect of material parameter variability on vibroacoustic response in wood floors","The use of wood as construction material in multi-story buildings increased in Europe during the last decades. Wood buildings are more sensitive to dynamic loading compared to conventional concrete buildings, especially in terms of vibroacoustic comfort. Furthermore, it is more difficult to predict the accurate response due to dynamic loading for wood buildings. This is due to factors such as a complex structure involving many connections which vary in their mechanical behavior and the variability in the material parameters of wood. In the study, a reduced-order finite element model correlated to measurement data is used to examine the effect of experimentally obtained variability in material parameters on the vibroacoustic response of a wooden floor. The floor is subjected to surface loading. Monte Carlo simulations are conducted and in order to execute the probabilistic analysis in an efficient manner, the use of various sampling techniques is investigated. It was concluded that the variability in material parameters of wood significantly affects the predicted low-frequency vibrations, and thereby also affects the transmission of structure-borne sound.","Floor vibrations,Structure-borne sound,Wood buildings,Monte Carlo simulations,Finite element method,Probabilistic analysis","PeterPerssona,OlaFlodénb","Applied Acoustics","https://doi.org/10.1016/j.apacoust.2018.10.034","https://www.sciencedirect.com/science/article/pii/S0003682X18306297"
"A414","An efficient linear second order unconditionally stable direct discretization method for the phase-field crystal equation on surfaces","We develop an unconditionally stable direct discretization scheme for solving the phase-field crystal equation on surfaces. The surface is discretized by using an unstructured triangular mesh. Gradient, divergence, and Laplacian operators are defined on triangular meshes. The proposed numerical method is second-order accurate in space and time. At each time step, the proposed computational scheme results in linear elliptic equations to be solved, thus it is easy to implement the algorithm. It is proved that the proposed scheme satisfies a discrete energy-dissipation law. Therefore, it is unconditionally stable. A fast and efficient biconjugate gradients stabilized solver is used to solve the resulting discrete system. Numerical experiments are conducted to demonstrate the performance of the proposed algorithm.","Unconditionally stable,Phase-field crystal equation,Triangular surface mesh,Laplace–Beltrami operator","YibaoLia,ChaojunLuoa,BinhuXiaa,JunseokKimb","Applied Mathematical Modelling","https://doi.org/10.1016/j.apm.2018.11.012","https://www.sciencedirect.com/science/article/pii/S0307904X18305419"
"A415","Comparative study of ß-thymosin in two scallop species Argopecten irradians and Chlamys farreri","The ß-thymosin (Tß) proteins participate in numerous biological processes, such as cell proliferation and differentiation, anti-inflammatory and antimicrobial mechanism. To date, Tß proteins have been well studied in vertebrates, especially mammals. While limited Tß or Tß-like proteins have been reported in invertebrates. Moreover, rare information of Tß or Tß-like proteins is available in scallop species yet. In the present study, two Tß homologues, AiTß and CfTß, were identified and characterized from two scallop species bay scallop Argopecten irradians and Zhikong scallop Chlamys farreri. They were both 41 amino acid peptide and contained one THY domain, a highly conserved actin-binding motif and two conserved helix forming regions. Tissue distribution and expression profiles of their mRNA transcripts were roughly similar yet different in detail, while their recombinant proteins exhibited different immunomodulation activity on the downstream immune parameters. These results collectively indicated that the function of Tß family in scallop were functionally differentiated.","ß-thymosin,Innate immunity,Immunomodulation","MengqiangWangac,BaojieWanga,MeiLiua,KeyongJianga,LeiWangabd","Fish & Shellfish Immunology","https://doi.org/10.1016/j.fsi.2018.11.050","https://www.sciencedirect.com/science/article/pii/S1050464818307691"
"A416","NTP-ERSN: A new package for solving the multigroup neutron transport equation in a slab geometry","The package, called NTP-ERSN (N eutron T ransport P ackage from the R adiations and N uclear S ystems G roup), is an open-source code written in FORTRAN90 for a pedagogical purpose to solve the steady-state multigroup neutron transport equation. This package is based on three classical methods, namely the collision probability (CP) method, the discrete ordinates (SN) method and the method of characteristics (MOC). These methods are employed to obtain scalar and angular flux distributions in homogeneous and heterogeneous slab geometry with isotropic and anisotropic scattering. The source code algorithms are very simple to be comprehensive by engineering students. In addition, NTP-ERSN is a simple framework to add and test new algorithms. On the other hand, a graphical user interface written in Python programing language has been developed to simplify the use of NTP-ERSN. Numerical results are given to illustrate the NTP-ERSN code's accuracy. Finally, the present software can be useful as an academic tool for teaching reactor physics. It is freely available for download on GitHub (https://github.com/mohamedlahdour/NTP-ERSN).","Package,NTP-ERSN,Neutron transport equation,FORTRAN90,GUI,Python,CP,SN,MOC,Eigenvalue calculation","M.Lahdoura,T.El Bardounia,E.Chakirb,K.Benaaliloua,M.Mohammeda,H.Bougueniza,H.El Yaakoubia","Applied Radiation and Isotopes","https://doi.org/10.1016/j.apradiso.2018.12.004","https://www.sciencedirect.com/science/article/pii/S0969804318306687"
"A417","Impact of random weights on nonlinear system identification using convolutional neural networks","Randomized algorithms have been successfully applied in modeling dynamic system. How do random weights affect system identification and why do they sometimes work well? In this paper, we use the convolutional neural network (CNN) as an identification model to answer these questions.Since the convolution operation is an important property of the dynamic system and in the frequency domain it becomes the product, the CNN model is analyzed in the frequency domain. We first modify the CNN model, so that it can model both the input and the output series. Then we analyze the impact of the random weights of CNN in the frequency domain. We prove the existence of optimal weights and analyze the modeling accuracy under optimal weights and random weights. Through theoretical analysis, we propose a two-step training method and compare it with the random weight algorithm. The proposed CNN model with random weights is validated with three benchmark problems.","Convolutional neural network,Random algorithms,Frequency domain,Deep learning","WenYu,MarioPacheco","Information Sciences","https://doi.org/10.1016/j.ins.2018.10.019","https://www.sciencedirect.com/science/article/pii/S0020025518308168"
"A418","State of the art of cyber-physical systems security: An automatic control perspective","Cyber-physical systems are integrations of computation, networking, and physical processes. Due to the tight cyber-physical coupling and to the potentially disrupting consequences of failures, security here is one of the primary concerns. Our systematic mapping study sheds light on how security is actually addressed when dealing with cyber-physical systems from an automatic control perspective. The provided map of 138 selected studies is defined empirically and is based on, for instance, application fields, various system components, related algorithms and models, attacks characteristics and defense strategies. It presents a powerful comparison framework for existing and future research on this hot topic, important for both industry and academia.","Cyber-physical systems,Security,Systematic mapping study","YuriyZacchia Luna,AlessandroD’Innocenzob,FrancescoSmarrab,IvanoMalavoltac,Maria DomenicaDi Benedettob","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2018.12.006","https://www.sciencedirect.com/science/article/pii/S0164121218302681"
"A419","Adsorption and Desorption of Pb(II) on l-Lysine Modified Montmorillonite and the simulation of Interlayer Structure","Herein, we reported the adsorption and desorption of Pb(II) on l-lysine modified montmorillonite (L-Mt) with molecular dynamics simulation. l-lysine (Lys) modified montmorillonite (L-Mt) was prepared, characterized by various analytical techniques, and the simulation studies were performed to evaluate the interlayer structure and interaction properties of l-lysine and L-Mt. The results of X-ray powder diffraction (XRD) and Fourier transform infrared (FTIR) spectrum suggested that Lys+ was intercalated into the interlayer of Na-montmorillonite (NaMt) successfully. The batch adsorption experiments were implemented to study the adsorption capacity of Pb(II) on L-Mt in water. The maximum adsorption capacity of Pb(II) on the L-Mt (up to 43.3<U+202F>mmol/100<U+202F>g) were considerably higher than that on NaMt (up to 15.3<U+202F>mmol/100<U+202F>g), at room temperature. The adsorption isotherms of both, L-Mt and NaMt can fit the Langmuir isotherm. The adsorption experiments showed that Pb(II) removal efficiency of L-Mt is better than NaMt in acidic solution. The simulation results revealed the micro-mechanism of Lys+ inserted into the interlayer gallery of NaMt. It can be deduced that lysine interacted with montmorillonite surface mainly through the protonated side-chain amino group rather than through the protonated main-chain amino group or deprotonated carboxyl group. These consequences are expected to elucidate the adsorption mechanisms occurring at the water/clay minerals interface at atom level, providing significant insight into the adsorption and retention of Pb(II) on L-Mt composite, and lead to relevant engineering applications while treating heavy metals of wastewater.","Montmorillonite,l-lysine,Adsorption,Molecular dynamics simulation,Desorption","SidiZhu,MingzhuXia,YutingChu,Muhammad AsimKhan,WuLei,FengyunWang,TahirMuhmood,AlongWang","Applied Clay Science","https://doi.org/10.1016/j.clay.2018.12.017","https://www.sciencedirect.com/science/article/pii/S0169131718305192"
"A420","Evaluating the extension mechanisms of the knowledge discovery metamodel for aspect-oriented modernizations","Crosscutting concerns are an intrinsic problem of legacy systems, hindering their maintenance and evolution. A possible solution is to modernize these systems employing aspect-orientation, which provides suitable abstractions for modularizing these kind of concerns. Architecture-Driven Modernization is a more specific kind of software reengineering focused on employing standard metamodels along the whole process, promoting interoperability and reusability across different tools/vendors. Its main metamodel is the Knowledge Discovery Metamodel (KDM), which is able to represent a significant amount of system details. However, up to this moment, there is no extension of this metamodel for aspect-orientation, preventing software engineers from conducting Aspect-Oriented Modernizations. Therefore, in this paper we present our experience on creating a heavyweight and a lightweight extension of KDM for aspect-orientation. We conducted two evaluations. The first one showed all aspect-oriented concepts were represented in both extensions. The second one was a experiment, in which we have analyzed the productivity of software engineers using both extensions. The results showed that the heavyweight extension propitiate a more productive environment in terms of time and number of errors when compared to the lightweight one.","Aspect-oriented modernization,Knowledge discovery metamodel,Legacy systems,Heavyweight extension,Lightweight extension,OMG","Bruno M.Santosa,André de S.Landib,Daniel S.Santibáñeza,Rafael S.Durellic,Valter V.de Camargoa","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2018.12.011","https://www.sciencedirect.com/science/article/pii/S0164121218302711"
"A421","Evaluation of the molecular variability and characteristics of Paramecium polycaryum and Paramecium nephridiatum, within subgenus Cypriostomum (Ciliophora, Protista)","Although some Paramecium species are suitable research objects in many areas of life sciences, the biodiversity structure of other species is almost unknown. In the current survey, we present a molecular analysis of 60 Cypriostomum strains, which for the first time allows for the study of intra- and interspecific relationships within that subgenus, as well as the assessment of the biogeography patterns of its morphospecies. Analysis of COI mtDNA variation revealed three main clades (separated from each other by approximately 130 nucleotide substitutions), each one with internal sub-clusters (differing by 30 to 70 substitutions – a similar range found between P. aurelia cryptic species and P. bursaria syngens). The first clade is represented exclusively by P. polycaryum; the second one includes only four strains identified as P. calkinsi. The third cluster seems to be paraphyletic, as it includes P. nephridiatum, P. woodruffi, and Eucandidatus P. hungarianum. Some strains, previously identified as P. calkinsi, had COI sequences identical or very similar to P. nephridiatum ones. Morphological reinvestigation of several such strains revealed common morphological features with P. nephridiatum. The paper contains new information concerning speciation within particular species, i.e. existence of cryptic species within P. polycaryum (three) and in P. nephridiatum (six).","Microbial eukaryotes,Paramecium,Morpho-molecular analysis,Cryptic species,COI haplotypes,Biogeography","EwaPrzybosa,MariaRautianb,AlexandraBeliavskaiabc,SebastianTarcza","Molecular Phylogenetics and Evolution","https://doi.org/10.1016/j.ympev.2018.12.003","https://www.sciencedirect.com/science/article/pii/S1055790318300988"
"A422","Overhead reduction scheme for SDN-based Data Center Networks","This paper proposes a framework on controller and switches to reduce overhead of controller-switch communication for SDN-based Data Center Networks (DCN). The proposal focuses on OpenFlow (OF), a well-known, sophisticated protocol for SDN, to reduce the number of control messages, consisting of both PACKET_IN and PACKET_OUT messages handled by the OF controller during rule installation on OF switches’ flow tables. The controller receives the first packet of a flow for forwarding path determination and selectively chooses switches for rule installation. Moreover, to ensure lower loads for the controller to handle, the proposed framework adds an out-of-band controller and avoids a hybrid architecture. Extensive simulation shows significant results on reduced controller workload. The performance provides a mutual trade-off by considerably improving rule matching rate in the presence of slightly enhanced number of flow entries, conserving resources on both OF controller and OF switches for SDN-based DCN operation. As a consequence, network latency is reduced while throughput is enhanced, which offers a great promise in the future deployment of DCN.","OpenFlow,Controller,Switch,Overhead reduction,Data Center Networks","Alif AkbarPranataa,Tae SooJunb,Dong SeongKima","Computer Standards & Interfaces","https://doi.org/10.1016/j.csi.2018.11.001","https://www.sciencedirect.com/science/article/pii/S0920548917304427"
"A423","Distribution of niche spaces over different homogeneous river sections at seasonal resolution","Planktic algae have an essential role in the food web as primary producers; the determination of the ecological niche space occupied by them is thus essential in strategies aimed at sustaining the biodiversity of surface waters. In the present study, principal component analysis combined with the outlying mean index was applied to 14 water quality time series (1993–2005) derived from three previously determined homogeneous sections of the Hungarian part of the River Tisza. As a result, the seasonal distribution of the ecological n-dimensional hypervolumes was determined for the different river sections. In the first upper section, the seasonal niches overlay each other, and no clear separation could be detected. In the middle- and lower reaches, however, a clear separation between the seasons was observed. The identification of these separate niches of the various seasons as the main indicators/drivers of certain ecological communities (e.g. phytoplankton) proved possible.","Combined cluster and discriminant analysis,Homogeneous groups,Hydrochemical seasons,Niche space,Principal component analysis","István GáborHatvania,PéterTanosb,GáborVárbírócd,MiklósAratóef,SándorMolnárb,TamásGaramhegyig,JózsefKovácsg","Ecological Indicators","https://doi.org/10.1016/j.ecolind.2018.11.059","https://www.sciencedirect.com/science/article/pii/S1470160X18309221"
"A424","Storytelling in the digital era: A meta-analysis of relevant moderators of the narrative transportation effect","In the digital era, marketers increasingly use storytelling techniques to narratively transport and persuade their customers. This paper pursues three primary objectives: (1) to integrate three digitally relevant moderators of the narrative transportation effect into the marketing literature, (2) to empirically assess the integrated model with a quantitative meta-analysis of extant research, and (3) to provide directions for marketing managers to enhance the narrative transportation effect in an evolving technological environment. The paper contributes to the field by means of a meta-analysis of 64 articles featuring 138 narrative transportation effect sizes. The research shows that the narrative transportation effect is stronger when the story falls in a commercial (vs. non-commercial) domain, is user (vs. professional) generated, and is received by one story-receiver at a time. The study concludes with implications for research and practice and directions for future research.","Digital marketing,Meta-analysis,Narrative transportation,Story domain,Story-receiver,User-generated content","Tomvan Laera,StephanieFeiereisenb,Luca M.Visconticd","Journal of Business Research","https://doi.org/10.1016/j.jbusres.2018.10.053","https://www.sciencedirect.com/science/article/pii/S0148296318305356"
"A425","Disaster recovery solutions for IT systems: A Systematic mapping study","Context: Organizations are spending an unprecedented amount of money towards the cost of keeping Information Technology (IT) systems operational. Hence, these systems need to be designed using effective fault-tolerant techniques like Disaster Recovery (DR) solutions. Even though research has been done in the DR field, it is necessary to assess the current state of research and practice, to provide practitioners with evidence that enables foster its further development. Objective: This paper has the following goals: to investigate state-of-the-art solutions for DR, as well as to systematically analyze the current published research and identify different strategies available in the literature. Method: A systematic mapping study was conducted, in which 49 studies, dated from 2007 to 2017, were evaluated. Results: Various DR practices are being investigated. The results identified a number of relevant issues, including reasons to adopt DR solutions, strategies used to implement DR solutions, approaches employed to analyze DR solutions, and metrics considered during the analyses of DR solutions. Conclusion: The number of strategies and reasons for adopting DR solutions is overwhelming. Hence, there was a need to provide a consolidated view of the field. Also, the results can help to direct future research efforts in this critical area.","Disaster recovery,Information technology,Systematic mapping","JúlioMendonçaa,ErmesonAndradeb,Patricia TakakoEndoc,RicardoLimaa","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2018.12.023","https://www.sciencedirect.com/science/article/pii/S0164121218302814"
"A426","Software product lines and variability modeling: A tertiary study","Context: A software product line is a means to develop a set of products in which variability is a central phenomenon captured in variability models. The field of SPLs and variability have been topics of extensive research over the few past decades. Objective: This research characterizes systematic reviews (SRs) in the field, studies how SRs analyze and use evidence-based results, and identifies how variability is modeled. Method: We conducted a tertiary study as a form of systematic review. Results: 86 SRs were included. SRs have become a widely adopted methodology covering the field broadly otherwise except for variability realization. Numerous variability models exist that cover different development artifacts, but the evidence is insufficient in quantity and immature, and we argue for better evidence. SRs perform well in searching and selecting studies and presenting data. However, their analysis and use of the quality of and evidence in the primary studies often remains shallow, merely presenting of what kinds of evidence exist. Conclusions: There is a need for actionable, context-sensitive, and evaluated solutions rather than novel ones. Different kinds of SRs (SLRs and Maps) need to be better distinguished, and evidence and quality need to be better used in the resulting syntheses.","Software product line,Variability,Variability modeling,Systematic literature review,Mapping study,Tertiary study","MikkoRaatikainenab,JuhaTiihonenb,TomiMännistöb","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2018.12.027","https://www.sciencedirect.com/science/article/pii/S016412121830284X"
"A427","The role of evidence-based information in regional operational water management in the Netherlands","The integration of evidence-based information in operational water management is essential for robust decision-making. We investigated the current use of experiential and evidence-based information in Dutch regional operational water management. Interviews with operational water managers at regional water authorities in the Netherlands reveal that they use both evidence-based and experiential information for decision-making. While operational water management is shifting towards an evidence-based approach, experiential information is still important for decision-making. To fulfil the current information need, the operational water managers indicate they would like to have access to high-resolution spatial data, value-added products and tools for communication to stakeholders. We argue that hydrological models are suitable tools to support these needs. However, while several evidence-based information types are used by operational water managers, hydrological models are limitedly applied. Hydrological models are regarded as inaccurate for operational water management at desired spatial scales. Also, operational water managers often struggle to correctly interpret hydrological model output. We propose several means to overcome these problems, including educating operational water managers to interpret hydrological model output and selecting suitable indicators for evidence-based decision-making.","Evidence-based information,Decision-making,Operational water management,Hydrological modelling","MichielPezijab,Denie C.M.Augustijna,Dimmie M.D.Hendriksb,Suzanne J.M.H.Hulschera","Environmental Science & Policy","https://doi.org/10.1016/j.envsci.2018.12.025","https://www.sciencedirect.com/science/article/pii/S1462901118305653"
"A428","The midbrain periaqueductal gray as an integrative and interoceptive neural structure for breathing","The periaqueductal gray (PAG) plays a critical role in autonomic function and behavioural responses to threatening stimuli. Recent evidence has revealed the PAG’s potential involvement in the perception of breathlessness, a highly threatening respiratory symptom. In this review, we outline the current evidence in animals and humans on the role of the PAG in respiratory control and in the perception of breathlessness. While recent work has unveiled dissociable brain activity within the lateral PAG during perception of breathlessness and ventrolateral PAG during conditioned anticipation in healthy humans, this is yet to be translated into diseases dominated by breathlessness symptomology, such as chronic obstructive pulmonary disease. Understanding how the sub-structures of the PAG differentially interact with interoceptive brain networks involved in the perception of breathlessness will help towards understanding discordant symptomology, and may reveal treatment targets for those debilitated by chronic and pervasive breathlessness.","Periaqueductal gray,Respiration,Breathlessness,Interoception","Olivia K.Faullab,Hari H.Subramanianc,MartynEzrab,Kyle T.S.Pattinsonb","Neuroscience & Biobehavioral Reviews","https://doi.org/10.1016/j.neubiorev.2018.12.020","https://www.sciencedirect.com/science/article/pii/S0149763418306067"
"A429","Combined interventions for physical activity, sleep, and diet using smartphone apps: A scoping literature review","BackgroundThe use of smartphone apps to track and manage physical activity (PA), diet, and sleep is growing rapidly. Many apps aim to change individual behavior on these three key health dimensions (PA, sleep, diet) by using various interventions. Earlier reviews have examined interventions using smartphone apps for one or two of these dimensions. However, there is lack of reviews focusing on interventions for all three of these dimensions in combination with each other. This is important since the dimensions are often inter-related, and all are required for a healthy lifestyle.,ObjectiveThe objective of this study is to conduct a review to: (1) map out the research done using smartphone app interventions targeting all three or any two of the three dimensions (PA, sleep, and diet), (2) examine if the studies consider the inter-relationships among the dimensions, and (3) identify the personalization methods implemented by the studies.,MethodsA literature search was conducted in electronic databases and libraries related to medical and informatics literature – PubMed, ScienceDirect, PsycINFO (ProQuest, Ovid) – using relevant selected keywords. Article selection and inclusion were done by removing duplicates, analyzing titles and abstracts, and then reviewing the full text of the articles.,ResultsIn the final analysis, 14 articles were selected – 2 articles focusing on PA and sleep, 8 on PA and diet, and 4 that examine or (at least) collect data of all three dimensions (PA, sleep, and diet). No research was found that focused on sleep and diet together. Of the 14 articles, only 4 build user profiles. Further, 3 of these 4 studies deliver personalized feedback based on the user’s profile, with only 1 study providing automated, personalized recommendations for behavior change. Additionally, 6 of the included studies report all positive outcomes, while for 3 studies the primary outcomes are awaited. The remaining 5 studies do not report significant changes in all outcomes. In all, only 1 study examines the relationship between two (PA and diet) dimensions. No study was found to assess the relationships among the 3 dimensions.","BCTbehavior change technique,BMIbody mass index (kg/m2),CGcontrol group,CVHcardiovascular health,DPPdiabetes prevention program,EMAecological momentary assessment,FACT-Gfunctional assessment of cancer therapy – general,IGintervention group,mDPPmobile phone-based Diabetes Prevention Program,MVPAmoderate to vigorous physical activity,NRnot reported,PAphysical activity,PRISMApreferred reporting of systematic reviews and meta-analyses,RCTrandomized control trial,SCTsocial cognitive theory,WELweight efficacy lifestyle questionnaire,Keywords,Scoping review,Smartphone intervention,Physical activity,Sleep,Diet,Personalization","AtreyiKankanhallia,MeghnaSaxenaa,BimleshWadhwab","International Journal of Medical Informatics","https://doi.org/10.1016/j.ijmedinf.2018.12.005","https://www.sciencedirect.com/science/article/pii/S1386505618307238"
"A430","Introducing environmental auditing as a tool of environmental governance in Ukraine","This paper intends to describe and analyse the introduction, development and practice of environmental auditing in Ukraine and how it is affected by the EU-Ukraine integration process. Environmental auditing in Ukraine has combined features of both command-and-control and marked-based policy tools, which reflects a complex combination of influences from its Soviet past and international practices adopted as part of its transition to a market economy. Consequently, there are two types of environmental auditing: mandatory and voluntary, which, although based on different normative documents and having different objectives, largely rely on the same practitioners - environmental auditors. Environmental auditing in countries undergoing political and economic transition, like Ukraine, has not been studied before. A theoretical framework was developed for this purpose, consisting of 1) 'shift of policy paradigms' theory, 2) 'collective action' theory and 3) 'community of practice' theory. Several qualitative methods were used for data collection: literature review, semi-structure open-ended interviews, and participant/non-participant observations. The gathered data are summarised in a three-stage development of environmental auditing in Ukraine as preliminary (1991–2004), foundation (2004–2010) and stagnation (2010–2015) stages. Future EU-Ukraine integration will affect environmental auditing in Ukraine as the supremacy of European Law is accepted, mandatory and voluntary environmental auditing practices will follow different paths.","Environmental auditing,Environmental governance,Ukraine,EU-Ukraine integration process,Transition economy,Abbreviations,IEMAAuditors Institute of Environmental Management & Assessment,TÜV(Technischer Überwachungsverein),IRCAThe International Register of Certificated Auditors","AnnaRubana,LarsRydénb","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.11.059","https://www.sciencedirect.com/science/article/pii/S0959652618334607"
"A431","Acoustic analysis on the dynamic motion of vapor-liquid interface for the identification of boiling regime and critical heat flux","In this study, the feasibility of identifying boiling regimes through acoustic emission (AE) measurement is tested, and the relationship between AE features and boiling dynamics is investigated. Conventional pool quenching experiments are performed using a spherical test section to investigate the entire boiling regime from film boiling to nucleate boiling. The AE measurements and accompanying optical visualization enable analyses of the AE features of each boiling regime, which are characterized by statistical and spectral parameters. The recorded boiling dynamics provide the history of vapor–liquid interface motion to verify the characteristics of AE features. The present work analyzes different acoustic features generated from different boiling regimes including nucleate boiling, transition boiling, boiling crisis, and film boiling. Each boiling regime is characterized by its measured AE signal with respect to various parameters. At the same time, optical visualization of the boiling process accompanies the AE measurements. A comparison of the wave information in vapor–liquid interface motion with AE features proves the feasibility of AE measurement for clear identification of boiling regimes and offers an insight into understanding boiling dynamics with respect to vapor behaviors.","Acoustic emission,Identification system,Boiling dynamics,Vapor-liquid interface motion","Seok BinSeo,In CheolBang","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.11.136","https://www.sciencedirect.com/science/article/pii/S0017931018346994"
"A432","Multi-aspect local inference for functional data: Analysis of ultrasound tongue profiles","Motivated by the analysis of a dataset of ultrasound tongue profiles, we present multi-aspect interval-wise testing (IWT), i.e., a local nonparametric inferential technique for functional data embedded in Sobolev spaces. Multi-aspect IWT is a nonparametric procedure that tests differences between groups of functional data, jointly taking into account the curves and their derivatives. Multi-aspect IWT provides adjusted multi-aspect p-value functions that can be used to select intervals of the domain that are imputable for the rejection of a null hypothesis. As a result, it can impute the rejection of a functional null hypothesis to specific intervals of the domain and to specific orders of differentiation. We show that the multi-aspect p-value functions are provided with a control of the family-wise error rate and that they are consistent. We apply multi-aspect IWT to the analysis of a dataset of tongue profiles recorded for a study on Tyrolean, a German dialect spoken in South Tyrol. We test differences between five different ways of articulating the uvular /r/: vocalized /r/, approximant, fricative, tap, and trill. Multi-aspect IWT-based comparisons result in an informative and detailed representation of the regions of the tongue where a significant difference occurs.","62G09,62G10,62H15,62H99,62P10,Keywords,Articulatory phonetics,Derivatives,Functional data analysis,Inference,Interval-wise error rate","AlessiaPiniab,LorenzoSpreaficoc,SimoneVantinid,AlessandroViettie","Journal of Multivariate Analysis","https://doi.org/10.1016/j.jmva.2018.11.006","https://www.sciencedirect.com/science/article/pii/S0047259X1730711X"
"A433","Overexpression of both full-length and truncated isoforms of bovine PGC-1alpha enhances myoblasts differentiation","The transcriptional co-activator PGC-1a has been reported to play a key role in adaptive thermogenesis and to influence muscle homeostasis and growth in mouse and human. PGC-1a has a complex structure with multiple protein domains whose gene is controlled by two promoters and is subject to alternative splicing events. In cattle, very little is currently known about PGC-1a, the only available data are putative transcripts. So, the aim of our study was to investigate the presence and the structure of bovine PGC-1a alternative transcripts. We found different transcripts, two full-length isoforms named PGC-1a-a and PGC-1a-b, and two truncated forms, NT-PGC-1a and PGC-1a4. In basal conditions, our results showed that the truncated forms are the most expressed in bovine muscle. In addition, the transcripts derived from the proximal promoter are predominant, suggesting that NT-PGC-1a would be the main form. Finally, we showed that the overexpression of either full-length or truncated isoforms of bovine PGC-1a enhances myoblasts differentiation. The multiplicity of isoforms resulting from PGC-1a as well as their implication in myogenesis makes PGC-1a as a gene of interest for the study of the muscular phenotypic variability found in different cattle breeds.","PGC-1aperoxisome proliferator-activated receptor-gamma coactivator 1-alpha,NTN-truncated,Keywords,PPARGC1A,PGC-1a,Bovine,Skeletal muscle","JessicaBamba,AlexisParenté,NathalieDuprat,LionelForestier,VéroniqueBlanquet","Gene Reports","https://doi.org/10.1016/j.genrep.2018.10.012","https://www.sciencedirect.com/science/article/pii/S245201441830133X"
"A434","Comparison of various uncertainty modelling approaches based on geostatistics and machine learning algorithms","We compared the suitability of several commonly applied digital soil mapping (DSM) techniques to quantify uncertainty with regards to a survey of soil organic carbon stock (SOCS) in Hungary. To represent the wide range of DSM techniques fairly, the followings were selected: universal kriging (UK), sequential Gaussian simulation (SGS), random forest combined with kriging (RFK) and quantile regression forest (QRF). For RFK two different uncertainty quantification approaches were adopted based on kriging variance (RFK-1) and bootstrapping (RFK-2). The selection of the potential environmental covariates was based on Jenny's factorial model of soil formation. The spatial predictions of SOCS and their uncertainty models were evaluated and compared using a control dataset. For this purpose, we applied the most common measures (i.e. mean error and root mean square error), furthermore, accuracy plot and G statistic. According to our results, QRF and SGS produced the best uncertainty models. UK and RFK-2 overestimated the uncertainty whereas RFK-1 produced the worst uncertainty quantification according to the accuracy plots and G statistics. We could draw the general conclusion that there is a need to validate the uncertainty models. Furthermore, great attention should be paid to the assumptions made in uncertainty modelling.","Digital soil mapping,Uncertainty,Kriging variance,Geostatistical simulation,Machine learning,Bootstrapping","GáborSzatmári,LászlóPásztor","Geoderma","https://doi.org/10.1016/j.geoderma.2018.09.008","https://www.sciencedirect.com/science/article/pii/S0016706117318499"
"A435","Investigation of KCNQ1 polymorphisms as biomarkers for cardiovascular diseases in the Turkish Cypriots for establishing preventative medical measures","Potassium channels are important in transmitting electrical signals through potassium ions transport. These potassium channels are made from signals encoded by KCNQ1 gene. KCNQ1 polymorphisms were associated with many diseases, including many metabolic and cardiovascular diseases and therefore they can be employed as biomarkers. In this study we aimed to investigate KCNQ1 polymorphisms in the Turkish Cypriot population to reveal the allele frequencies specific for this population and use these polymorphisms as biomarkers to develop preventative medical measures.The genotypes of KCNQ1 polymorphisms (rs231361, rs231359, rs151290, rs2283228, rs2237895, rs2237896) were investigated for the first time in Turkish Cypriot population. The correlation between genotypes of these polymorphisms and plasma lipid levels in this population was also explored.The results of this study showed that there was significant differences of the allele frequencies of between rs2283228 allele of C and rs2237896 (P<U+202F>><U+202F>0.05) in Turkish Cypriot population. There was no association between the genotypes of the six polymorphisms and the lipid metabolism.This study is the first genetic epidemiology study that investigated the allelic frequencies of KCNQ1 polymorphisms associated with metabolic syndromes as well as cardiovascular diseases. This study proves to be crucial since the etiologic determinants and molecular pathology of cardiovascular diseases have not yet clearly understood. This study showed that genome wide association studies should be designed for preventative medicine in the Turkish Cypriot population.","KCNQ1,Biomarker,Cardiovascular diseases,Turkish Cypriot","P.Tulaya,S.G.Temelbc,M.C.Ergorend","International Journal of Biological Macromolecules","https://doi.org/10.1016/j.ijbiomac.2018.11.227","https://www.sciencedirect.com/science/article/pii/S0141813018348505"
"A436","A carefully designed nanoplatform based on multi walled carbon nanotube wrapped with aptamers","The interaction between carbon nanotubes (CNTs) and biological molecules of diagnostic and therapeutic interest, as well as the internalization of the CNTs-biomolecules complexes in different types of cell, has been extensively studied due to the potential use of these nanocomplexes as multifunctional nanoplatforms in a great variety of biomedical applications. The effective use of these nanobiotechnologies requires broad multidisciplinary studies of biocompatibility, regarding, for example, the in vitro and in vivo nanotoxicological assays, the capacity to target specific cells and the evaluation of their biomedical potential. However, the first step to be reached is the careful obtainment of the nanoplatform and the understanding of the actual surface composition and structural integrity of the complex system. In this work, we show the detailed construction of a nanoplatform created by the noncovalent interaction between oxidized multi walled carbon nanotubes (MWCNTs) and a DNA aptamer targeting tumor cells. The excess free aptamer was removed by successive washes, revealing the actual surface of the nanocomplex. The MWCNT-aptamer interaction by p-stacking was evidenced and shown to contribute in obtaining a stable nanocomplex compatible with aqueous media having good cell viability. The nucleotide sequence of the aptamer remained intact after the functionalization, allowing its use in further studies of specificity and binding affinity and for the construction of functional nanoplatforms.","Carbon nanotube,Aptamer,Noncovalent functionalization,Nanoplatform","Mariana BotelhoBarbosaa,Estefânia Mara do NascimentoMartinsa,Thayana FurtadoTeixeiraa,Regina Duque EstradaCarvalhoa,João PauloCoelhoa,Rodrigo RibeiroResendeb,Ester FigueiredoOliveiraa,Adelina PinheiroSantosa,Antero Silva Ribeiro deAndradea,Clascídia AparecidaFurtadoa","Colloids and Surfaces B: Biointerfaces","https://doi.org/10.1016/j.colsurfb.2018.11.064","https://www.sciencedirect.com/science/article/pii/S0927776518308464"
"A437","Surgeon and Caregiver Agreement on the Goals and Indications for Scoliosis Surgery in Children With Cerebral Palsy","Study DesignProspective multicenter comparative study.,ObjectivesWe aimed 1) to survey surgeons and caregivers to rank the surgical indications for spinal fusion of pediatric patients with neuromuscular scoliosis secondary to cerebral palsy in order of importance and 2) to characterize the agreement of surgeons and caregivers on major (top three) indications.,Summary of Background DataSurgery for spinal deformity in children with cerebral palsy is a multifaceted and individualized decision that may lead to miscommunication during informed consent. Little data exist on communication effectiveness between surgeon and caregiver during preoperative discussion.,MethodsThis is a multicenter, prospective survey of Harms Study Group patient caregivers and their surgeons. Participants ranked their most important of 15 indications in descending level of importance, where the top 3 selections were considered major indications for surgery for the particular patient in question. Demographic and other perioperative factors were recorded. Surgeon-caregiver agreement on major indications was determined, taking into account preoperative factors and intersurgeon differences.,Results126 surgeon-caregiver pairs responded. The greatest percentage agreement that an indication was major was “to improve sitting” (69.0% major, 0.8% nonmajor), followed by “to prevent pulmonary compromise” (33.3% major, 24.6% nonmajor), “to improve pain” (31.7% major, 20.6% nonmajor), and “to improve head control/position” (20.7% major, 69.0% nonmajor). Preoperative pain showed an association with surgeon-caregiver agreement on pain as a major indication (p=.004), and intersurgeon differences in agreement on gastrointestinal and pain considerations existed (p=.002, p=.007, respectively).,ConclusionsSurgeon-caregiver agreement is greater where literature support for a particular surgical indication is strong (ie, spinal fusion’s known improvement of sitting posture in children with neuromuscular scoliosis). Stronger literature support may bolster surgeons’ confidence in recommending a particular procedure, fostering greater communication, understanding, and agreement on surgical necessity between caregivers and surgeons.,Level of EvidenceLevel II, prospective comparative study.","Cerebral palsy,Scoliosis surgery,Surgeon caregiver agreement,Surgical goals and indications,Preoperative discussion","Alexander J.AdamsBSa,Christian A.RefakisMDb,John M.FlynnMDa,Joshua M.PahysMDc,Randal R.BetzMDd,Tracey P.BastromMAe,Amer F.SamdaniMDc,Christopher M.BrusalisMDf,Paul D.SponsellerMDg,Patrick J.CahillMDa","Spine Deformity","https://doi.org/10.1016/j.jspd.2018.07.004","https://www.sciencedirect.com/science/article/pii/S2212134X18301400"
"A438","Toward high-accuracy and high-applicability of a practical model to predict effective thermal conductivity of particle-reinforced composites","A particle-reinforced composite material is a matrix with thermally conductive particles that has a diverse range of applications from electronics to energy harvesting/storage systems. In the engineering design of a particle-reinforced composite material for application, it is crucial to accurately and practically predict its effective thermal conductivity. Here, we report the development of a simple analytical model for predictions with improved accuracy and applicability. Comprehensive evaluation of existing models was first conducted to clarify their limitations in prediction accuracy and applicability to various experimental conditions. To overcome the challenges of the existing models, our new model was derived to consider the effect of shape, particle aggregation, and mutual interaction of particles on effective thermal conductivity. Lattice Boltzmann simulations were conducted to obtain a quasi-universal coefficient representing interactions of particles, whereas a shape coefficient characterizing microstructures of aggregated particles was obtained from experimental data available from literature. As a result, our model prediction outperformed the existing models in its prediction accuracy, and it could be applicable to any experimental circumstances where previous model predictions are inappropriate to use.","Particle-reinforced composites,Effective thermal conductivity,Practical model prediction,Lattice Boltzmann simulations","JeonggeonKima,Yong-RackGooa,IndaeChoiab,SongkilKima,DonggeunLeea","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.11.107","https://www.sciencedirect.com/science/article/pii/S0017931018342182"
"A439","Large-eddy simulation of turbulent flow over the DrivAer fastback vehicle model","Turbulent flow over the DrivAer fastback vehicle model is investigated using large-eddy simulation with particular emphasis on flow separation, vortical structures and unsteady quantities. A systematic and detailed analysis of the flow field is made considering rotating wheels and moving ground floor. Overall features of vortical structures at the cowl top, behind side mirrors, near front and back wheels, at A-, B- and C-pillars and behind the rear end of the vehicle are revealed by investigating velocity and vorticity fields. The rear end is identified to be the main contributor to the pressure force acting on the vehicle, followed by back and front wheels and side mirrors. The resulting pressure force on the upper part of the vehicle, including A-, B-, and C-pillars but excluding the cowl top and side mirrors, is found to be only slightly higher than the contribution of the gap in the cowl top. Flow separation and resulting vortices do not only have an impact on automotive drag, it is also pointed out how unsteadiness in the flow field affects pressure fluctuations. High levels of surface pressure fluctuations are found near side mirrors and front wheels. Similarities in distributions of pressure fluctuations and turbulent kinetic energy are found.","Large-eddy simulation,DrivAer model,Separated flow,Turbulent flow,Vortical structures,Pressure fluctuations","MarioRüttgers1,JunshinPark1,DonghyunYou","Journal of Wind Engineering and Industrial Aerodynamics","https://doi.org/10.1016/j.jweia.2019.01.003","https://www.sciencedirect.com/science/article/pii/S0167610518307682"
"A440","Optimizing the master surgery schedule in a private hospital","This paper proposes a new mixed-integer linear programming model to build cyclic master surgery schedules (MSSs) for a case study of a medium-sized Portuguese private hospital. The problem integrates tactical and strategical decisions of operating room (OR) planning and scheduling. OR time blocks are assigned to surgical services and to individual surgeons. A target OR time per surgical specialty is not given as it is often the case of other studies in the literature. The model aims to: level the workload at downstream departments (hospitalization units); avoid sharing OR time among different surgical specialties; allocate OR time blocks to the surgical specialty with the highest number of surgeons available; renew the MSS based on recent demand for surgeries. This approach allows the surgical suite to be more efficiently managed, while increasing the sense of fairness among surgeons and facilitating the negotiation for OR time. Moreover, this automated system releases the surgical suite manager to more added value tasks.","OR in health services,Operating room planning,Master surgery schedule,Mixed-integer linear programming","InêsMarquesa,M. EugéniaCaptivobc,NaraBarrosc","Operations Research for Health Care","https://doi.org/10.1016/j.orhc.2018.11.002","https://www.sciencedirect.com/science/article/pii/S2211692318300225"
"A441","Anthocyanins from colored maize ameliorated the inflammatory paracrine interplay between macrophages and adipocytes through regulation of NF-<U+03BA>B and JNK-dependent MAPK pathways","This study aimed to investigate the anti-inflammatory effect of two anthocyanin-rich extracts from purple (PMW) and red maize (RMW), in comparison to three pure anthocyanins [cyanidin-3-O-glucoside (C3G); peonidin-3-O-glucoside (P3G); pelargonidin-3-O-glucoside (Pr3G)] on the inflammatory states that occurred during the macrophage-adipocyte interaction, using both mono- and co-culture in vitro models. PMW and RMW reduced production of pro-inflammatory cytokines (TNF-a: -8.8% to -44.2%; MCP-1: -18.4% to -56.9%) in both macrophages and adipocytes mono-cultures. PMW and RMW, as well as C3G and Pr3G inhibited activation of NF-<U+03BA>B and JNK pathways, via regulation of phosphorylation of I<U+03BA>Ba and JNK, respectively. Both extracts and pure anthocyanins restored inflammation-mediated oxidative stress and insulin resistance in macrophage-conditioned media-treated adipocytes. PMW and RMW decreased pro-inflammatory cytokine production and lipolysis, while enhanced the glucose transporter 4 membrane translocation in the adipocyte-macrophage co-cultures. These results suggested that colored maize anthocyanins could potentially ameliorate the paracrine interplay between adipocytes and macrophages.","Anthocyanins,Colored maize,Inflammation,Obesity,Macrophage-adipocyte interaction","QiaozhiZhangab,DiegoLuna-Vitala,ElviraGonzalez de Mejiaa","Journal of Functional Foods","https://doi.org/10.1016/j.jff.2019.01.016","https://www.sciencedirect.com/science/article/pii/S1756464619300167"
"A442","Fiber motion in highly confined flows of carbon fiber and non-Newtonian polymer","Inks compounded of short carbon fibers suspended in polymer resin can be extruded to produce composite materials during additive manufacturing or 3D printing processes. The flow process induces anisotropic orientation of the fibers which is set into the matrix and significantly affects the mechanical and physical properties of the final product. Therefore, the flow of fiber suspensions needs to be understood in order to predict the orientation distribution of the fibers during such manufacturing processes. There is still a lack of knowledge for extrusion of the complex mixture of a non-Newtonian polymer containing a high-volume fraction of fibers with high fiber aspect ratio, where both inter-particle, fluid-particle and fiber-wall interactions are computationally evaluated. This paper presents predictive numerical simulations and experimental results of such confined flow in a concentrated regime. The code is based on Lagrange multiplier technique and resolves each particle and interaction between the fibers and surrounding fluid and nozzle walls. We investigate numerically how the fiber length impacts the fiber alignment during extrusion. We found that a fiber length above 67% of the nozzle's diameter induces dramatic change in the fiber flow, causing fibers to concentrate at the nozzle boundaries with very low concentration of fibers in the center of the nozzle. It was found that the best fiber alignment is reached for fiber lengths equal to 40–50% of the nozzle diameters. Numerical findings are supported by experimental results. This work improves understanding of fiber orientation during 3D printing and is an important milestone for the prediction of the complex mechanical properties of additively manufactured fiber composites.","Carbon fiber,Non-Newtonian fluid,Additive manufacturing,Lagrange multipliers,Numerical modeling,Direct ink writing","Y.Kanarska,E.B.Duoss,J.P.Lewicki,J.N.Rodriguez,A.Wu","Journal of Non-Newtonian Fluid Mechanics","https://doi.org/10.1016/j.jnnfm.2019.01.003","https://www.sciencedirect.com/science/article/pii/S0377025717304494"
"A443","Assessing fungal contributions to cellulose degradation in soil by using high-throughput stable isotope probing","Soils represent one of the largest and most active pools of C in the biosphere, and soil respiration represents a major component of global C flux. Fungi are essential to soil carbon cycling due to their propensity for decomposing organic polymers such as cellulose. We performed high throughput sequencing enabled stable isotope probing (HTS-SIP) with 13C-cellulose to characterize the dynamics of fungi and bacteria during cellulose degradation in an agricultural soil. A total of 1900 fungal taxa were observed and 190 of these assimilated 13C-cellulose during a 30-day incubation. A majority of 13C-labeled fungi belonged to Ascomycota, Basidiomycota, and Mucoromycota. However, most 13C-labeled fungi could not be annotated at the species (71%, n<U+202F>=<U+202F>134), or genus (49%, n<U+202F>=<U+202F>93) level. Mucoromycota were 13C-labeled early, and by day 3 the most abundant 13C-labeled organism belonged to Mortierella. In contrast, 13C-labeled Ascomycota increased in diversity through day 14 and their relative abundance comprised more than 40% of fungal ITS sequences by day 30. These results show that: i) the majority of fungal taxa that assimilated 13C from 13C-cellulose are uncultivated and poorly characterized, ii) the beta-diversity of 13C-labeled fungi changed significantly over time during cellulose degradation, iii) a relatively small number of the 13C-labeled taxa dominated the community response to cellulose, and iv) fungi incorporated cellulose into DNA more rapidly and in greater numbers than did bacteria. These results show that fungi in a tilled agricultural field respond rapidly to new cellulose inputs, exhibiting complex temporal dynamics that likely drive carbon flow into diverse taxa within the soil community.","Carbon cycling,Stable isotope probing,Fungi,Cellulose,Decomposition","ChantalKoechli,Ashley N.Campbell,CharlesPepe-Ranney,Daniel H.Buckley","Soil Biology and Biochemistry","https://doi.org/10.1016/j.soilbio.2018.12.013","https://www.sciencedirect.com/science/article/pii/S0038071718304231"
"A444","Harnessing the power of big data analytics in the cloud to support learning analytics in mobile learning environment","Technology enhanced learning (TEL) such as online learning environment with adaptive technologies has gained growing interest in recent past in the field of teaching and learning. In this context, mobile learning has got much momentum and is exemplified by diverse characteristics associated with the technologies and devices used, the enormous size of data generated throughout a learning session, and the interactions among the learners that occur outside the classroom. Consequently, sophisticated data analysis techniques are required to handle the intricacy of mobile learning and analyze the vast amount of datasets to enhance the learning experiences of mobile learners. This has led to the adoption of big data analytics for efficient processing of big learning data to add value to the mobile learning environments. Yet limited processing capability of the mobile devices is another key challenge faced by such big data analytics in mobile learning environments. To overcome this limitation, certain heavy computational parts could be offloaded to the cloud which can provide enough computation and storage resources. To this end, this paper presents a cloud based mobile learning framework that utilizes big data analytics technique to extract values from huge volume of mobile learners' data. Finally, we investigate learners' readiness and driving factors of mobile learning adoption in higher education institutions. In particular, we propose a hypothesized model for mobile learning adoption built on a locally extended technology acceptance model (TAM).","Mobile learning (m-learning),Learning analytics,Big data analytics,Cloud computing,Map-reduce technique,Technology acceptance model (TAM)","MohammadShorfuzzamana,M. ShamimHossainbc,AmrilNazira,GhulamMuhammadd,AtifAlamribc","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2018.07.002","https://www.sciencedirect.com/science/article/pii/S0747563218303248"
"A445","Sympathetic arousal commonalities and arousal contagion during collaborative learning: How attuned are triad members?","This article explores the dynamics of collaborative learning in the classroom from the perspective of the commonalities and interdependence in the degree of physiological activation from the sympathetic nervous system (i.e., sympathetic arousal) of group members. Using Empatica E4 wristbands, electrodermal activity—to derive arousal—was measured in 24 high school students working in groups of three (i.e., triads) during two runs of an advanced physics course. The participants met three times a week over six weeks for lessons of 75<U+202F>min each. Most of the time (˜60–95% of the lesson) the triad members were at different arousal levels, and, when they were on the same level, it was mainly the low arousal (or deactivated) level. Less than 4% of the time were the triad members simultaneously in high arousal. Possible within-triad arousal contagion cases (71.3%) occurred mostly on a one-to-one basis and with a latency from within a few seconds up to 10<U+202F>min, but usually within 1<U+202F>min. This study supports the view that only small parts of group work are collaborative, as far as the synchronicity and coordination which collaboration presupposes. Although exploratory, results also illustrate the affordances of physiological measures to characterize collaborative processes.","Collaborative learning,Interpersonal physiology,Sympathetic arousal,Arousal contagion,Biosensors,Electrodermal activity","Héctor J.Pijeira-Díaza,HendrikDrachslerbcd,SannaJärveläa,Paul A.Kirschnerad","Computers in Human Behavior","https://doi.org/10.1016/j.chb.2018.11.008","https://www.sciencedirect.com/science/article/pii/S0747563218305442"
"A446","Numerical and experimental assessment of random matrix theory to quantify uncertainty in aerospace structures","The increased complexities of modernized structures have catalyzed additional research over the past few decades to accurately quantify the variabilities within static designs, which can be categorized into parametric, non-parametric and experimental uncertainties. The majority of works have dealt with parametric uncertainty alone and utilize algorithms that require priori knowledge of the input uncertainty. This is problematic since there is a large number of uncertain variables that typically percolate physical engineering problems which are difficult to characterize using precise probability distributions. A unified method to encompass these stochastic properties in a computationally efficient manner is needed and one such approach is using random matrix theory (RMT), which has integrated and validated its importance through various fields, however largely excluding the aerospace sector. This study utilizes RMT and the Wishart distribution to characterize modal uncertainties that arise due to parametric, non-parametric and experimental variabilities. Numerical studies are undertaken with finite element models of a rectangular wing and an aircraft wing box to validate RMT and the Marchenko-Pastur (MP) density function. An experimental study is also conducted on six nominally designed aircraft T-tails, where RMT is used to provide a quantitative bound on the unknown uncertainties that exist within the physical system.","Uncertainty quantification,Random matrix theory,Aerospace structures,Modal response,Wishart distribution,Marchenko-Pastur density","AdityaVishwanathan,Gareth A.Vio","Mechanical Systems and Signal Processing","https://doi.org/10.1016/j.ymssp.2018.09.006","https://www.sciencedirect.com/science/article/pii/S0888327018306162"
"A447","Comparative proteomics of goat milk during heated processing","Milk proteins have shown to be very sensitive to heated processing. This study investigated the heat-dependent changes of goat milk proteins using label-free quantification (LFQ). A total of 843 proteins were identified in all the samples, of which 625 proteins were quantified. There were 527, 543, 537, 533 and 539 proteins quantified in the control group (CG) and heated groups (HGs: HG1, HG2, HG3 and HG4), respectively, and 438 proteins were common to all groups. The effects of high temperature/short time (HTST) treatment on proteins were similar to ultra-pasteurization (UP) and ultra-high temperature (UHT), but the low temperature/long time (LTLT) was different. Proteomics analysis demonstrated that heated processing increases the digestibility of proteins and is beneficial for anti-atherosclerosis therapy. These results expand the knowledge of the protein compositions from different heated processing. And it can further the utilization of the protein component of goat milk for human nutrition and health.","Goat milk,Pasteurization,UHT,LFQ,Proteomics","DiChena,XiangyingLia,XuanZhaoa,YusiQina,JianminWangb,CunfangWanga","Food Chemistry","https://doi.org/10.1016/j.foodchem.2018.09.129","https://www.sciencedirect.com/science/article/pii/S030881461831700X"
"A448","Fusing pattern discovery and visual analytics approaches in tweet propagation","Over the past several years, social networks have become a major channel for information delivery. At present, social networks are being used to obtain more followers and exert influence over people during political campaigns. However, the propagation of a social network post is dependent on numerous factors. Some of these are known; for example, the post contents, the time when it was posted, and the person or entity by whom it was posted. However, other factors remain unknown, such as what makes a post more successful than others, and how posts from similar profiles evolve and propagate differently over time. The main subject of this work is addressing these types of questions. Our approach relies on a three-fold methodology for studying the influence and propagation of posts: graph-based, semantic, and contrast pattern recognition analysis. The results obtained are complemented by a dynamic visualization that encompasses all of the variables involved. In order to corroborate our results, we collected all posts from the Twitter accounts of the most prominent Mexican political figures and analyzed the influence and propagation of each post issued.","Social networks,Twitter,Pattern recognition,Influence modeling,Visual analytics","OctavioLoyola-Gonzáleza,ArmandoLópez-Cuevasb,Miguel AngelMedina-Péreza,BenitoCamiñaa,José EmmanuelRamírez-Márquezc,RaúlMonroya","Information Fusion","https://doi.org/10.1016/j.inffus.2018.05.004","https://www.sciencedirect.com/science/article/pii/S1566253517307716"
"A449","Computing melodic templates in oral music traditions","The term melodic template or skeleton refers to a basic melody which is subject to variation during a music performance. In many oral music traditions, these templates are implicitly passed throughout generations without ever being formalized in a score. In this work, we introduce a new geometric optimization problem, the spanning tube problem, to approximate a melodic template for a set of labeled performance transcriptions corresponding to a specific style in oral music traditions. Given a set of n piecewise linear functions, we solve the problem of finding a continuous function, f*, and a minimum value, e*, such that, the vertical segment of length 2e* centered at (x, f*(x)) intersects at least p functions (p<U+202F>=<U+202F>n). The method explored here also provide a novel tool for quantitatively assess the amount of melodic variation which occurs across performances.","Melodic skeleton,Geometric algorithm,Oral music tradition","SergeyBerega,José-MiguelDíaz-Báñezb,NadineKroherb,InmaculadaVenturab","Applied Mathematics and Computation","https://doi.org/10.1016/j.amc.2018.09.071","https://www.sciencedirect.com/science/article/pii/S0096300318308580"
"A450","Artificial intelligence-based fast and efficient hybrid approach for spatial modelling of soil electrical conductivity","Expert systems adopted to support modern and rapidly advancing proximal soil sensing technologies can help generate accurately modelled electrical conductivity, as a decision-support parameter defining soil health in terms of the salinity, clay and bulk density compositions, among the other primal soil properties. Electrical conductivity (EC) is expected to correlate with the pertinent factors that regulate the crop yield (i.e., soil texture, cation exchange, drainage conditions, organic matter level, salinity, and the subsoil characteristics), which in turn, can also acts to control the overall health of the crop. Utilizing a fast and efficient artificial intelligence approach, this study designs a hybrid predictive model integrating multilayer perceptron with the Firefly Algorithm (MLP-FFA), and then evaluates its performance in respect to the standalone MLP and the ordinary kriging (OK) model applied in agricultural locality of the Soofiyan, plains in Tabriz, northwest of Iran. To develop a spatial modelling framework, 126 distinct measurements of EC were obtained through a grid sampled at 1000<U+2009>m<U+2009>×<U+2009>1000<U+2009>m spacing, partitioned in training (88) and testing (38) sets. Applying a ratio of nugget to sill to determine the spatial dependence, a spatial modelling strategy was utilized where the spherical, exponential, Gaussian and linear semi-variograms depicting the autocorrelation of the sampled points (latitude<U+2009>×<U+2009>longitude) over the study area were analyzed in ArcGIS to deduce the optimal data characteristics and the respective statistical model. Spherical semi-variogram was the optimal representor for EC, relative to its latitude and longitude, in agreement with the lowest Residual Sums of Squares (RSS) and the highest coefficient of determination (R2). Hybrid MLP-FFA and standalone MLP models were thus developed with latitude, longitude and measured electrical conductivity in the training set and evaluated in respect to the OK method by means of statistical scores: root mean square error (RMSE), mean absolute error (MAE) including the normalized metrics represented by Willmott’s Index (WI), Nash Sutcliffe’s coefficient (ENS) and Legates & McCabe’s Index (ELM). Verified by diagnostic plots and grid-averaged metrics, the results revealed that the hybrid MLP-FFA model performed significantly better than both comparative models, with WI<U+2009>=<U+2009>0.780 relative to 0.637 (MLP) and 0.714 (OK) models and ENS<U+2009>=<U+2009>0.725 (vs. 0.511 & 0.589) and ELM = 0.552 (vs. 0.402 & 0.413), respectively. Expanded uncertainty, t-statistic and global performance indicators combining the R2, RMSE and mean bias error and a Taylor plot also confirmed the efficacy of the hybrid MLP-FFA over the standalone MLP and OK model. There was no significant difference between the results of standalone MLP and OK when evaluated through spatial trend maps, while the hybrid MLP-FFA model exhibited a better ability to establishing nonlinear relationships with electrical conductivity data, resulting in a better representation of the spatially modelled EC. Our results ascertain the prodigious performance of a hybrid MLP-FFA over a standalone MLP and ordinary kriging approaches, attributable to a better utility of the Firefly algorithm in improved spatial estimation of electrical conductivity. This study concludes that the hybrid MLP-FFA model should be explored to solve practical problems in soil physics, particularly in designing decision-support systems to attain agricultural precision.","Electrical conductivity,Firefly algorithm,Spatial estimation","Mohammad AliGhorbaniab,Ravinesh CDeoc,Mahsa H.Kashanid,MahmoudShahabie,ShahryarGhorbanif","Soil and Tillage Research","https://doi.org/10.1016/j.still.2018.09.012","https://www.sciencedirect.com/science/article/pii/S0167198718310973"
"A451","A mixed-method empirical study of Function-as-a-Service software development in industrial practice","Function-as-a-Service (FaaS) describes cloud computing services that make infrastructure components transparent to application developers, thus falling in the larger group of “serverless” computing models. When using FaaS offerings, such as AWS Lambda, developers provide atomic and short-running code for their functions, and FaaS providers execute and horizontally scale them on-demand. Currently, there is no systematic research on how developers use serverless, what types of applications lend themselves to this model, or what architectural styles and practices FaaS-based applications are based on. We present results from a mixed-method study, combining interviews with practitioners who develop applications and systems that use FaaS, a systematic analysis of grey literature, and a Web-based survey. We find that successfully adopting FaaS requires a different mental model, where systems are primarily constructed by composing pre-existing services, with FaaS often acting as the “glue” that brings these services together. Tooling availability and maturity, especially related to testing and deployment, remains a major difficulty. Further, we find that current FaaS systems lack systematic support for function reuse, and abstractions and programming models for building non-trivial FaaS applications are limited. We conclude with a discussion of implications for FaaS providers, software developers, and researchers.","Cloud computing,Serverless,Function-as-a-Service,Empirical research","PhilippLeitnera,ErikWitternb,JosefSpillnerc,WaldemarHummerb","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2018.12.013","https://www.sciencedirect.com/science/article/pii/S0164121218302735"
"A452","Literature review on modeling and simulation of energy infrastructures from a resilience perspective","Recent years have witnessed an increasing frequency of disasters, both natural and human-induced. This applies pressure to critical infrastructures (CIs). Among all the CI sectors, the energy infrastructure plays a critical role, as almost all other CIs depend on it. In this paper, 30 energy infrastructure models dedicated for the modeling and simulation of power or natural gas networks are collected and reviewed using the emerging concept of resilience. Based on the review, typical modeling approaches for energy infrastructure resilience problems are summarized and compared. The authors, then, propose five indicators for evaluating a resilience model; namely, catering to different stakeholders, intervening in development phases, dedicating to certain stressor and failure, taking into account different interdependencies, and involving socio-economic characteristics. As a supplement, other modeling features such as data needs and time scale are further discussed. Finally, the paper offers observations of existing energy infrastructure models as well as future trends for energy infrastructure modeling.","Energy infrastructure,Resilience,Power grid,Modeling and simulation,Model evaluation,Natural gas network","JingWanga,WangdaZuoa,LandolfRhode-Barbarigosb,XingLua,JianhuiWangc,YanlingLind","Reliability Engineering & System Safety","https://doi.org/10.1016/j.ress.2018.11.029","https://www.sciencedirect.com/science/article/pii/S0951832017313972"
"A453","Molecular characterization, expression analysis, and ontogeny of complement component C9 in southern catfish (Silurus meridionalis)","The complement system plays an important role in host defense against invading microorganisms. Complement component C9 is the last component that is involved in the formation of the membrane attack complex (MAC) on the surface of target cells. In the present study, the full length C9 cDNA sequence of 1984 bp with an open reading frame (ORF) of 1809 bp was cloned from southern catfish (Silurus meridionalis). The deduced amino acid sequence showed similarity with other teleost fish. The mRNA expression of C9 was detected in the liver, spleen, stomach, intestine, and head kidney, with highest levels detected in the liver. The mRNA of C9 was first detected in the yolk syncytial layer at 34<U+202F>h post fertilization (hpf) with whole mount in situ hybridization, followed by the liver at 36<U+202F>h post hatching (hph). The mRNA expression of C9 was upregulated significantly in the liver, spleen, and intestine following the injection with Aeromonas hydrophila, suggesting that C9 played an important role in defense against invading pathogens in southern catfish. Therefore, these results provide important information to understand the functions of C9 during fish early development in fish.","Silurus meridionalis,Complement component C9,Expression analysis,Whole mount in situ hybridization,Ontogeny,Aeromonas hydrophila","Yao-WuFua1,Cheng-KeZhub1,Qi-ZhongZhanga,Ting-LongHoua","Fish & Shellfish Immunology","https://doi.org/10.1016/j.fsi.2018.11.069","https://www.sciencedirect.com/science/article/pii/S1050464818307897"
"A454","A physics-based model explains the prion-like features of neurodegeneration in Alzheimer’s disease, Parkinson’s disease, and amyotrophic lateral sclerosis","Prion disease is characterized by a chain reaction in which infectious misfolded proteins force native proteins into a similar pathogenic structure. Recent studies have reinforced the hypothesis that the prion paradigm–the templated growth and spreading of misfolded proteins–could help explain the progression of a variety of neurodegenerative disorders. However, our current understanding of prion-like growth and spreading is rather empirical. Here we show that a physics-based reaction-diffusion model can explain the growth and spreading of misfolded protein in Alzheimer’s disease, Parkinson’s disease, and amyotrophic lateral sclerosis. To characterize the progression of misfolded proteins across the brain, we combine the classical Fisher–Kolmogorov equation for population dynamics with an anisotropic diffusion model and simulate misfolding across a sagittal section and across the entire brain. In a systematic sensitivity analysis, we probe the role of the individual model parameters and show that the misfolded protein concentration is sensitive to the coefficients of growth, extracellular diffusion, and axonal transport, to the axonal fiber orientation, and to the initial seeding region. Our model correctly predicts amyloid-ß deposits and tau inclusions in Alzheimer’s disease, a-synuclein inclusions in Parkinson’s disease, and TDP-43 inclusions in amyotrophic lateral sclerosis and displays excellent agreement with the histological patterns in diseased human brains. When integrated across the brain, our concentration profiles result in biomarker curves that display a striking similarity with the sigmoid shape and qualitative timeline of clinical biomarker models. Our results suggest that misfolded proteins in various neurodegenerative disorders grow and spread according to a universal law that follows the basic physical principles of nonlinear reaction and anisotropic diffusion. Our findings substantiate the notion of a common underlying principle for the pathogenesis of a wide variety of neurodegenerative disorders, the prion paradigm. A more quantitative understanding of the growth and spreading of misfolded amyloid-ß, tau, a-synuclein, and TDP-43 would allow us to establish a prognostic timeframe of disease progression. This could have important clinical implications, ranging from more accurate estimates of the socioeconomic burden of neurodegeneration to a more informed design of clinical trials and pharmacological intervention.","Continuum modeling,Reaction diffusion,Neurodegeneration,Prion,Biomarker","JohannesWeickenmeiera,MathiasJuckerb,AlainGorielyc,EllenKuhld","Journal of the Mechanics and Physics of Solids","https://doi.org/10.1016/j.jmps.2018.10.013","https://www.sciencedirect.com/science/article/pii/S0022509618307063"
"A455","Clinical and histopathologic prognostic implications of the expression of cytokeratins 8, 10, 13, 14, 16, 18 and 19 in oral and oropharyngeal squamous cell carcinoma","ObjectivesTo identify cytokeratins (CK) of significant correlations with clinical and histopathologic prognostic parameters in oral and oropharyngeal squamous cell carcinoma (SCC).,DesignThe sample consisted of 100 cases retrieved from the archives of the Pathology Department/ King Hussein Cancer Center/Amman/ Jordan. Recorded data included: age, gender, location, grade, depth of invasion, the presence of epithelial dysplasia, tumor size, lymph node metastasis, number of positive lymph nodes, distant metastases, clinical stage, local recurrence, treatment modalities and 5-year survival rate. Immunohistochemical staining of 7 cytokeratins: 8, 10, 13, 14, 16, 18, and 19 was performed using standard protocols. Stained sections were digitized and analyzed using ImageJ-color deconvolution to identify the percentage of cytokeratin-positive area (score). Statistical tests used were: student t-test, analysis of variance, bivariate analysis and logistic regression.,ResultsLower CK8,18, 19 scores correlated with lower 5-year survival rate. Higher CK19 and lower CK 10, 14, 16 scores were associated with distant metastasis. Increased CK8, 18, 19 scores correlated with higher stage and with higher depth of invasion. Increased CK18 scores correlated with increased local recurrence. Higher CK10, 13, 16 scores correlated with well-differentiated grade. Higher CK19 and lower CK16 scores were associated with adjacent epithelial dysplasia. Regression analysis showed that better 5-year survival rate was significantly correlated with increased CK16, decreased CK18 and 19 scores.,ConclusionExpression scores of a panel of cytokeratin are potential prognostic indicators for 5-year survival and correlates with other prognostic parameters.","Cytokeratin,Immunohistochemistry,Oral,Prognosis,SCC,Survival","Rima A.Safadiab1,Niveen I.Abdullahc,Rolla F.Alaarajc,Dima H.Baderd,Darshan D.Divakare,Abed A.Hamashaab1,Maher A.Sughayerc","Archives of Oral Biology","https://doi.org/10.1016/j.archoralbio.2018.12.007","https://www.sciencedirect.com/science/article/pii/S0003996918306575"
"A456","Transition to chaos in the flow-induced vibration of a pitching–plunging airfoil at low Reynolds numbers : Ruelle–Takens–Newhouse scenario","This study focuses on numerically analyzing the transition from periodic to chaotic dynamics in the fluid-elastic response of a 2-dof flexibly-mounted airfoil with chord-wise rigidity. The computational framework is composed of a high fidelity Navier–Stokes solver, weakly coupled with a structural model having geometric nonlinearity represented by cubic order stiffness terms. A low Reynolds number flow regime and a very low structure-to-fluid added mass ratio have been considered to simulate the flying conditions of very light-weight unmanned devices. A bifurcation analysis of the system, in the absence of actuation or control forces, is undertaken with the wind velocity as the control parameter. The route to chaos – identified to be the Ruelle–Takens–Newhouse quasi-periodic route – is established for the first time for a flexible pitch–plunge flapping system. Robust nonlinear time series analysis techniques have been implemented to characterize different complex dynamical states present in the system.","Flexible flapping,Fluid–structure interaction,Quasi-periodicity,Frequency locking,Route to chaos","ChandanBosea,SayanGuptaa,SunetraSarkarb","International Journal of Non-Linear Mechanics","https://doi.org/10.1016/j.ijnonlinmec.2018.11.012","https://www.sciencedirect.com/science/article/pii/S0020746218305201"
"A457","Ferroelastic twin reorientation mechanisms in shape memory alloys elucidated with 3D X-ray microscopy","Three-dimensional (3D) X-ray diffraction methods were used to analyze the evolution of the load-induced rearrangements of monoclinic twin microstructures within bulk nickel–titanium specimens in 3D and across six orders of magnitude in length scales: changes in lattice plane spacings and orientations at the nanoscale, growth and nucleation of martensite twin variants at the microscale, and localization of plastic strain into deformation bands at the macroscale. Portions of the localized deformation bands were reconstructed in situ and in 3D. Analyses of the data elucidate the sequence of twin rearrangement mechanisms that occur within the propagating localized deformation bands, connect these mechanisms to the texture evolution, and reveal the effects of geometrically necessary lattice curvature across the band interfaces. The similarities between shear bands and localized deformation bands in twin reorientation are also discussed. These findings will guide future researchers in employing twin rearrangement in novel multiferroic technologies, and they demonstrate the strength of 3D, multiscale, in situ experiments to improve our understanding of complicated material behaviors and to provide opportunities to advance our abilities to model them.","Shape-memory materials,Ferroics,Stimuli-responsive materials,Structure-property relationships,Characterization tools","A.N.Bucseka1,D.C.Paganb,L.Casalenac2,Y.Chumlyakovd,M.J.Millsc,A.P.Stebnera","Journal of the Mechanics and Physics of Solids","https://doi.org/10.1016/j.jmps.2018.12.003","https://www.sciencedirect.com/science/article/pii/S0022509618304137"
"A458","Mapping of the lubrication regimes in rough surface EHL contacts","Understanding film formation in rough surface elastohydrodynamically lubricated (EHL) contacts have been an ongoing pursuit in lubrication science for more than half a century. This study furthers that quest by establishing a single combined friction and electrical contact resistance map that forms a clear and comprehensive overview of the lubrication performance. A ball-on-disc machine was operated under a wide variety of heavily loaded rolling/sliding contact conditions. Results show that while sweeping the contact over the SRR- and entrainment speed-domain, the primary sweep direction significantly affects running-in and consequently the transition from EHL to the mixed lubrication regime. Such knowledge sheds new light into the mechanisms that governs EHL film formation and the concurrent interplay with the mixed lubricated friction coefficient.","Rough surface EHL,Friction,Stribeck curve,Running-in","JonnyHansenab,MarcusBjörlinga,RolandLarssona","Tribology International","https://doi.org/10.1016/j.triboint.2018.11.015","https://www.sciencedirect.com/science/article/pii/S0301679X18305553"
"A459","Simulation of fatigue failure on tooth flanks in consideration of pitting initiation and growth","Gears are used under demanding conditions which lead to a continuous change of the tooth surface. With an increasing operation time, appearances of fatigue, like micropitting, can be noticed. Micropitting is characterized by micro-cracks in the surface. In some cases, these cracks grow or join to networks and in combination with subsurface caused stress intensities, e.g. at microstructural defects in the material, this leads to macroscopic pittings, which end the serviceability of a transmission.This contribution defines micropitting and pitting and analyses their interaction and interdependency. A fatigue simulation for these mechanisms is introduced. Results of test rig trials and material analyses are presented and have been used to research these mechanisms, their interaction and also to validate the simulation.","Wear,Fatigue,Pitting,Spur gears","MaxWeibring,LeonardGondecki,PeterTenberge","Tribology International","https://doi.org/10.1016/j.triboint.2018.10.029","https://www.sciencedirect.com/science/article/pii/S0301679X18305103"
"A460","Creative design of emergency management scenarios driven by semantics: An application to smart cities","We present a framework to support creative design of emergency management scenarios. By creative design of scenarios we mean the process of imagining situations and describing them through models and stories. The framework supports the tasks of gathering and organizing knowledge about emergency management situations by automatically generating conceptual models, related to fragments of emergency scenarios. It leverages semantics-based techniques to enable a computational creativity approach. A software application was defined to support the activities of modeling scenarios by permitting to generate, organize, and query sets of these conceptual models, which we name mini-stories, and that can be adopted to inspire the activity of creative design. Selected mini-stories are blueprints for more detailed user scenario descriptions and models that can be used, for instance, for analysis or simulation. As a case study, we consider emergency management in smart cities. This is a challenging domain because smart cities are characterized by interconnected physical and virtual services forming complex ecosystems, which provide sophisticated services to the population and to institutions, manage public resources in a optimal way, and involve citizens in decisional processes. As a consequence, smart city ecosystems can be threatened by several hazards spanning from natural disasters, as tsunami and earthquakes, to anthropic events, as terrorist attacks. Ability of service providers and institutional operators to face and manage emergency situations is therefore a relevant issue. Simulation and analysis of both crisis events and executions of management plans are a promising approach to deal with these articulated problems. However, manual definition of models to base the analysis is a demanding activity due to the huge number of different situations to consider. It requires knowledge related to the crisis and emergency domains, to the context (e.g., a specific city and its current regulations) and ability in modeling tasks. All these aspects demand for tools to support modeling activities, and our proposal aims at fulfilling this need. In particular, the discussed framework uses in a integrated way three types of knowledge: structural knowledge, to support the construction of models based on design patterns; domain knowledge, here related to smart cities and emergency management and represented by means of ontologies; and contextual knowledge, related to specific aspects (e.g., localization) of the considered scenario and represented as rules. We validated the presented approach by means of experiments performed by real city planners.","Computational creativity,Conceptual modeling,Design pattern,Emergency management,Ontology,Smart city","AntonioDe Nicolaa,MicheleMelchiorib,Maria LuisaVillania","Information Systems","https://doi.org/10.1016/j.is.2018.10.005","https://www.sciencedirect.com/science/article/pii/S0306437918304277"
"A461","Analyzing airport security checkpoint performance using cognitive agent models","Modern airports operate under high demands and pressures, and strive to satisfy many diverse, interrelated, sometimes conflicting performance goals. Airport performance areas, such as security, safety, and efficiency are usually studied separately from each other. However, operational decisions made by airport managers often impact several areas simultaneously. Current knowledge on how different performance areas are related to each other is limited. This paper contributes to filling this gap by identifying and quantifying relations and trade-offs between the detection performance of illegal items and the average queuing time at airport security checkpoints. These relations and trade-offs were analyzed by simulations with a cognitive agent model of airport security checkpoint operations. By simulation analysis a security checkpoint performance curve with three different regions was identified. Furthermore, the importance of focus on accuracy for a security operator is shown. The results of the simulation studies were related to empirical research at an existing regional airport.","Agent-based modelling and simulation,Airport security operations,Trade-off relations,Sociotechnical system modelling,Airport performance metrics","ArthurKnol,AlexeiSharpanskykh,StefJanssen","Journal of Air Transport Management","https://doi.org/10.1016/j.jairtraman.2018.11.003","https://www.sciencedirect.com/science/article/pii/S096969971830190X"
"A462","Increased tolerance to organic xenobiotics following recent allopolyploidy in Spartina (Poaceae)","Genome doubling or polyploidy is a widespread phenomenon in plants where it has important evolutionary consequences affecting the species distribution and ecology. PAHs are ubiquitous organic pollutants, which represent a major environmental concern. Recent data showed that tolerance to organic xenobiotics involve specific signaling pathways, and detoxifying gene sets referred as ‘the xenome’. However, no data are available about how polyploidy impacts tolerance to organic xenobiotics. In the present paper, we investigated PAH tolerance following allopolyploidization in Spartina alterniflora, S. maritima and their derived allopolyploid species S. anglica. We performed comparative analyses of cellular compartmentalization, photosynthetic indices, and oxidative stress markers under phenanthrene-induced stress, and found that S. anglica exhibit increased tolerance compared to its parents. Based on 52 genes potentially involved in phenanthrene detoxification previously identified in A. thaliana, we investigated the Spartina xenome using genomic and transcriptomic available resources. Subsequently, we focused on GSTs, a ubiquitous enzymes class involved in organic xenobiotic detoxification. We examined expression profiles of selected genes by RT-qPCR, and revealed various patterns of parental expression alteration in the allopolyploid. The impacts of allopolyploidization on phenanthrene-induced stress and their potential ecological implications are discussed. The neo-allopolyploid S. anglica appears as a potential candidate for phytoremediation in PAH-polluted marshes.","Genome doubling,PAHs,Abiotic stress,GSTs,Spartina","ArmandCavé-Radet,ArmelSalmon,OscarLima,Malika L.Ainouche,AbdelhakEl Amrani","Plant Science","https://doi.org/10.1016/j.plantsci.2018.11.005","https://www.sciencedirect.com/science/article/pii/S0168945217311433"
"A463","Efficient RNA interference-based knockdown of mutant torsinA reveals reversibility of PERK-eIF2a pathway dysregulation in DYT1 transgenic rats in vivo","DYT1 dystonia is a neurological disease caused by a dominant mutation that results in the loss of a glutamic acid in the endoplasmic reticulum-resident protein torsinA. Currently, treatments are symptomatic and only provide partial relief. Multiple reports support the hypothesis that selectively reducing expression of mutant torsinA without affecting levels of the wild type protein should be beneficial. Published cell-based studies support this hypothesis. It is unclear, however, if phenotypes are reversible by targeting the molecular defect once established in vivo. Here, we generated adeno-associated virus encoding artificial microRNA targeting human mutant torsinA and delivered them to the striatum of symptomatic transgenic rats that express the full human TOR1A mutant gene. We achieved efficient suppression of human mutant torsinA expression in DYT1 transgenic rats, partly reversing its accumulation in the nuclear envelope. This intervention rescued PERK-eIF2a pathway dysregulation in striatal projection neurons but not behavioral abnormalities. Moreover, we found abnormal expression of components of dopaminergic neurotransmission in DYT1 rat striatum, which were not normalized by suppressing mutant torsinA expression. Our findings demonstrate the reversibility of translational dysregulation in DYT1 neurons and confirm the presence of abnormal dopaminergic neurotransmission in DYT1 dystonia.","Dystonia,torsinA,RNA interference,AAV,DYT1","GenevieveBeauvaisa,Jaime L.Watsona,Jose A.Aguirreb1,LuisTecedora,Michelle E.Ehrlichc,PedroGonzalez-Alegread","Brain Research","https://doi.org/10.1016/j.brainres.2018.10.025","https://www.sciencedirect.com/science/article/pii/S0006899318305377"
"A464","Identification of complex glass transition phenomena by DSC in expanded cereal-based food extrudates: Impact of plasticization by water and sucrose","The physical state and mechanical properties of extruded cereal based products were studied as a function of sucrose content and relative humidity (RH) to evaluate how the presence of sucrose affects glass transition temperature (Tg), sorption isotherm, and texture parameters. Extrudates were prepared with different sucrose content (0–20 %wt). Sorption isotherm showed the water content of extrudates decreased when product contains high sucrose at low aw range and the inverse effect was observed at high aw. Tg s were determined using differential scanning calorimetry (DSC) and two transitions were detected on the heat flow first derivative curve. Addition of sucrose or water decreased both Tg s in extrudates. Young's modulus showed water acts as anti-plasticizer at low aw, while shows plasticizing effect at high aw. A stability map can explain the brittle-ductile transition occurred while it was below Tg.","Extrudate cereal based-products,Sugars,Texture,Thermal properties,Heterogeneity,Stability map","SupuksornMasavang,GaëlleRoudaut,DominiqueChampion","Journal of Food Engineering","https://doi.org/10.1016/j.jfoodeng.2018.10.008","https://www.sciencedirect.com/science/article/pii/S0260877418304357"
"A465","Numerical investigation of laminar compressible natural convection flow in asymmetrically and isothermally heated open-ended inclined channel","This study presents a numerical investigation of laminar compressible natural convection flow induced under high-temperature difference in an open-ended inclined parallel-walled channel heated isothermally and asymmetrically at the top wall (hot plate facing downwards) while the lower plate is considered adiabatic. The investigation is carried out with air (Pr=0.72) as the working fluid for a temperature difference of 110<U+202F>°C from the ambient, over of range of modified Rayleigh number 6.2×101 to 1.6×104 and inclination of channel varying between 10 and 90° with respect to horizontal position. For the simulation, compressible governing equations without Boussinesq approximation is solved by employing new modified all-speed Roe scheme with matching preconditioning method, dual time-stepping technique and utilizing the modified Local One-dimensional Inviscid (LODI) relations suitable for compressible natural convection flow as non-reflecting boundary conditions at the inlet and outlet of the channel. Average Nusselt number based on inter-plate spacing increases with the increase of modified Rayleigh number and also with the increase of inclination from the horizontal position. This increase in average Nusselt number can be described by the variation of the level of thermal saturation inside the channel. Significant reduction in average Nusselt number is observed in the combined zone of lower angle of inclination and lower modified Rayleigh number. Visualization of fluid flow (temperature contour and velocity magnitude contour) indicates the existence of both fully developed flow and developing flow regime within the span of investigated modified Rayleigh number. Based on the investigation, a composite correlation between average Nusselt number and product of modified Rayleigh number and the sine of the angle of inclination considering as a single parameter is presented which can be conveniently used for designing of engineering application dealing with natural convection heat transfer under high-temperature difference.","Numerical simulation,Laminar natural convection,Compressible flow,Inclined channel,Asymmetrical and isothermal heating,Composite correlation","DeboprasadTalukdara,Chung-GangLib,MakotoTsubokurab","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.10.076","https://www.sciencedirect.com/science/article/pii/S001793101832862X"
"A466","Heat transfer by natural convection of Fe3O4-water nanofluid in an annulus between a wavy circular cylinder and a rhombus","Researchers in modern science always attempt to find new techniques to optimize the performance of energy devices through heat transfer enhancement. It comes to the knowledge that such enhancement can be done with the help of nanofluids. Therefore, the present study is aimed to investigate the role of natural convection and thermal radiation on thermo-hydrodynamics of nanofluid heat transfer in an annulus between a wavy circular cylinder and a rhombus enclosure subject to a uniform magnetic field. A new model for viscosity called magnetic field dependent (MFD) viscosity is used. Mathematical formulation of the current physical model is based on the continuity, momentum and energy equations. Numerical simulation of the reduced problem is done with the help of Control Volume based Finite Element Method (CVFEM). The impacts of controlling physical parameters, for instance, Rayleigh number, radiation parameter, Hartmann number, aspect ratio, shape factor of nanoparticles and solid volume fraction of nanoparticles on thermo-hydrodynamics of flow are studied. The quantities of physical interest are graphically presented and discussed in detail. From the present study it becomes apparent that the local heat transfer rate decreases with an increase in aspect ratio in the absence of Hartmann number. In addition, for decreasing values of aspect ratio, the space for fluid flow inside enclosure becomes wider.","Natural convection,Nanoparticles,Heat transfer,Thermal radiation,Wavy circular cylinder,Rhombus","A.S.Dogonchia,Hashimb","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.10.086","https://www.sciencedirect.com/science/article/pii/S0017931018348440"
"A467","An empirical study on decision making for quality requirements","ContextQuality requirements are important for product success yet often handled poorly. The problems with scope decision lead to delayed handling and an unbalanced scope.,ObjectiveThis study characterizes the scope decision process to understand influencing factors and properties affecting the scope decision of quality requirements.,MethodWe studied one company's scope decision process over a period of five years. We analyzed the decisions artifacts and interviewed experienced engineers involved in the scope decision process.,ResultsFeatures addressing quality aspects explicitly are a minor part (4.41%) of all features handled. The phase of the product line seems to influence the prevalence and acceptance rate of quality features. Lastly, relying on external stakeholders and upfront analysis seems to lead to long lead-times and an insufficient quality requirements scope.,ConclusionsThere is a need to make quality mode explicit in the scope decision process. We propose a scope decision process at a strategic level and a tactical level. The former to address long-term planning and the latter to cater for a speedy process. Furthermore, we believe it is key to balance the stakeholder input with feedback from usage and market in a more direct way than through a long plan-driven process.","Quality requirements,Non-functional requirements,Requirements scope decision,Product management,Requirements engineering","ThomasOlssona,KrzysztofWnukb,TonyGorschekb","Journal of Systems and Software","https://doi.org/10.1016/j.jss.2018.12.002","https://www.sciencedirect.com/science/article/pii/S0164121218302668"
"A468","Fast synthesis of ZnO nanoflowers using a conductively heated sealed-vessel reactor without additives","Even though the hydrothermal synthesis of ZnO nanoflowers has been previously reported by numerous authors, the developed routes present improvement opportunities. Herein we report the hydrothermal synthesis of ZnO nanoflowers using a conductively heated sealed-vessel reactor without additives. Although the use of this novel reactor allowed to obtain well-defined flower-like morphologies within 5<U+202F>min, we studied the influence of the reaction time on the morphology at 10, 15 and 30<U+202F>min. The structural characterization demonstrated high crystallinity of hexagonal ZnO (wurtzite) without impurities in all the samples and the optical characterization showed a band gap energy values in the range of 3.10–3.28<U+202F>eV. To investigate if the reaction time had an impact in the electric resistance of the material, the sheet resistance of electrodes composed by each sample was measured, the results proved that the sheet resistance decreases significatively along the reaction time.","ZnO nanoflowers,Heated sealed-vessel reactor,Solvothermal synthesis","SusanaBorbónab,ShadaiLugocd,IsraelLópezab","Materials Science in Semiconductor Processing","https://doi.org/10.1016/j.mssp.2018.12.001","https://www.sciencedirect.com/science/article/pii/S1369800118317633"
"A469","Increased sesqui- and triterpene production by co-expression of HMG-CoA reductase and biotin carboxyl carrier protein in tobacco (Nicotiana benthamiana)","Terpenoids are the most diverse natural products with many industrial applications and are all synthesized from simple precursors, isopentenyl diphosphate (IPP) and its isomer dimethylallyl diphosphate (DMAPP). In plants, IPP is synthesized by two distinct metabolic pathways – cytosolic mevalonate (MVA) pathway for C15 sesquiterpene and C30 triterpene, and plastidic methylerythritol phosphate (MEP) pathway for C10 monoterpene and C20 diterpene. A number of studies have altered the metabolic gene expressions in either the MVA or MEP pathway to increase terpene production; however, it remains unknown if the alteration of the acetyl-CoA pool in plastid fatty acid biosynthesis can influence terpenoid flux. Here, we focused on the fact that acetyl-CoA is the precursor for both fatty acid biosynthesis in plastid and terpene biosynthesis in cytosol, and the metabolic impact of increased plastidic acetyl-CoA level on the cytosolic terpene biosynthesis was investigated. In tobacco leaf infiltration studies, the acetyl-CoA carboxylase complex (the enzyme supplying malonyl-CoA in plastid) was partially inhibited by overexpressing the inactive form of biotin carboxyl carrier protein (BCCP) by a negative dominant effect. Overexpression of BCCP showed 1.4–2.4-fold increase of sesquiterpenes in cytosol; however, surprisingly overexpression of BCCP linked to truncated HMG-CoA reductase (tHMGR) by a cleavable peptide 2A showed 20–40-fold increases of C15 sesquiterpenes (a-bisabolol, amorphadiene, and valerenadiene) and a 6-fold increase of C30 ß-amyrin. a-Bisabolol and ß-amyrin production reached 28.8<U+202F>mg<U+202F>g-1 and 9.8<U+202F>mg<U+202F>g-1 dry weight, respectively. Detailed analyses showed that a large increase in flux was achieved by the additive effect of BCCP- and tHMGR-overexpression, and an enhanced tHMGR activity by 2A peptide tag. Kinetic analyses showed that tHMGR-2A has a three-fold higher kcat value than tHMGR. The tHMGR-2A-BCCP1 co-expression strategy in this work provides a new insight into metabolic cross-talks and can be a generally applicable approach to over-produce sesqui- and tri-terpene in plants.","Acetyl-CoA carboxylase,Biotin carboxyl carrier protein,a -bisabolol,Mevalonate pathway,Terpene","Ah-ReumLeea,MoonhyukKwonbc,Min-KyoungKanga,JeonghanKima,Soo-UnKimad,Dae-KyunRoc","Metabolic Engineering","https://doi.org/10.1016/j.ymben.2018.10.008","https://www.sciencedirect.com/science/article/pii/S1096717618301708"
"A470","On the solution of the neutron diffusion kinetic equation in planar geometry free of stiffness with convergence analysis","In this work we solve the space kinetic diffusion equation in a one-dimensional geometry considering a homogeneous domain, for two energy groups and six groups of delayed neutron precursors. The proposed methodology makes use of a Taylor expansion in the space variable of the scalar neutron flux (fast and thermal) and the concentration of delayed neutron precursors, allocating the time dependence to the coefficients. Upon truncating the Taylor series at quadratic order, one obtains a set of recursive systems of ordinary differential equations, where a modified decomposition method is applied. The coefficient matrix is split into two, one constant diagonal matrix and the second one with the remaining time dependent and off-diagonal terms. Moreover, the equation system is reorganized such that the terms containing the latter matrix are treated as source terms. Note, that the homogeneous equation system has a well known solution, since the matrix is diagonal and constant. This solution plays the role of the recursion initialization of the decomposition method. The recursion scheme is set up in a fashion where the solutions of the previous recursion steps determine the source terms of the subsequent steps. A second feature of the method is the choice of the initial and boundary conditions, which are satisfied by the recursion initialization, while from the first recursion step onward the initial and boundary conditions are homogeneous. The recursion depth is then governed by a prescribed accuracy for the solution. To this end we present error estimates and a convergence and stability analysis.","Spatial kinetics,Neutron diffusion equation,Taylor series,Modified decomposition method,Analytical representation","FernandaTumeleroa,BardoBodmanna,Marco TúllioVilhenaa,Celso M.F.Lapab","Annals of Nuclear Energy","https://doi.org/10.1016/j.anucene.2018.11.024","https://www.sciencedirect.com/science/article/pii/S0306454918306212"
"A471","Reviewing the DATAS of aviation research data: Diversity, availability, tractability, applicability, and sources","The field of aviation research is entering the era of big data. While data-driven advancements in aviation have clearly brought about applicable models and results with immediate implications, we argue that the influx of aviation data should be better characterized and documented to enable more efficient and standardized usage. To this end, we examine 200 well-cited research articles from sub-disciplines ranging from revenue management to air traffic control published on or after 2010 in order to analyze the diversity, availability, tractability, applicability, and sources (DATAS) of data utilized in aviation research. We find high levels of data diversity within aviation research, with 16 data categories ranging from air traffic flow management-type data to data from distributed sensors in line with the Internet-of-Things (IoT) paradigm. We identified a dominance of proprietary, non-public data in aviation research, with 68% of the 200 research articles utilizing solely proprietary data in deriving their results, and a further 8% utilizing a mixture of proprietary and publicly available data. The pervasiveness of proprietary data has implications on reproducibility and extending research results. We also highlight the increasing tractability of the data by surveying the computational power required to process the data sets, and present vignettes of applications and results that stem from these data-driven studies. Finally, we propose several recommendations regarding standardizing data source nomenclature as well as increasing the availability of and usage of publicly available data.","Aviation data,Data availability,Publicly available data,Aviation data sources","Max Z.Lia,Megan S.Ryersonb","Journal of Air Transport Management","https://doi.org/10.1016/j.jairtraman.2018.12.004","https://www.sciencedirect.com/science/article/pii/S096969971830379X"
"A472","A unified method for super-resolution recovery and real exponential-sum separation","In this paper, motivated by diffraction of traveling light waves, a simple mathematical model is proposed, both for the multivariate super-resolution problem and the problem of blind-source separation of real-valued exponential sums. This model facilitates the development of a unified theory and a unified solution of both problems in this paper. Our consideration of the super-resolution problem is aimed at applications to fluorescence microscopy and observational astronomy, and the motivation for our consideration of the second problem is the current need of extracting multivariate exponential features in magnetic resonance spectroscopy (MRS) for the neurologist and radiologist as well as for providing a mathematical tool for isotope separation in Nuclear Chemistry. The unified method introduced in this paper can be easily realized by processing only finitely many data, sampled at locations that are not necessarily prescribed in advance, with computational scheme consisting only of matrix-vector multiplication, peak finding, and clustering.","Multivariate super-resolution,Separation of exponential sums,Backward solution of heat equation,Gaussian kernels","Charles K.Chuia1,H.N.Mhaskarb2","Applied and Computational Harmonic Analysis","https://doi.org/10.1016/j.acha.2017.12.007","https://www.sciencedirect.com/science/article/pii/S1063520318300290"
"A473","Image super-resolution via feature-augmented random forest","Recent random-forest (RF)-based image super-resolution approaches inherit some properties from dictionary-learning-based algorithms, but the effectiveness of the features working in RF is overlooked in the literature. In this paper, we present a novel feature-augmented random forest (FARF) method for image super-resolution, where the conventional gradient-based features are proposed to augment the features used in RF, and different feature recipes are formulated on different processing stages in an RF. The advantages of our method are that, firstly, the dictionary-learning-based features are enhanced by adding gradient magnitudes, based on the observation that the non-linear gradient magnitudes are highly discriminative. Secondly, generalized locality-sensitive hashing (LSH) is used to replace principal component analysis (PCA) for feature dimensionality reduction in constructing the trees, but the original high-dimensional features are employed, instead of the compressed LSH features, for the leaf-nodes’ regressors. With the use of the original higher dimensional features, the regressors can achieve better learning performances. Finally, we present a generalized weighted ridge regression (GWRR) model for the leaf-nodes’ regressors. Experiment results on several public benchmark datasets show that our FARF method can achieve an average gain of about 0.3 dB, compared to traditional RF-based methods. Furthermore, a fine-tuned FARF model can compare to, or (in many cases) outperform, some recent state-of-the-art deep-learning-based algorithms.","Random forest,Gradient magnitude filter,Clustering and regression,Image super-resolution,Weighted ridge regression","HailiangLia,Kin-ManLama,MiaohuiWangb","Signal Processing: Image Communication","https://doi.org/10.1016/j.image.2018.12.001","https://www.sciencedirect.com/science/article/pii/S0923596518301632"
"A474","Prediction of HIV integrase resistance mutation using in silico approaches","The Antiretroviral Therapy (ART) has been providing better treatment for the Human Immunodeficiency Virus 1 (HIV) infection, by reducing its viral load to undetectable levels and recovering the immune system. However, new HIV mutations could induce drug resistance to ART, increasing the viral load and disruption of immune system. One of these drugs is Dolutegravir (DTG), which inhibits HIV integrase (INT) activity.Our objective was to predict novel HIV mutations related to DTG resistance using in silico approaches in order to stablish a framework of searching for new HIV drug-resistant mutations. To this end, we modelled the INT structure and produced a mutational profile to investigate hotspots that may affect INT. Being the Y226K mutation the most frequent (0.3) and with a higher <U+0394><U+0394>G (+2.07), we selected to test the framework. To ratify the impact of Y226K, we docked the mutant INT with the DTG and compared the results with the Wild Type (WT) with known drug-resistant mutations. Moreover, we performed molecular dynamics simulations and calculated the binding energy along the time-course. When we compared the energies of the systems, the Y226K complex showed less binding affinity (<U+0394><U+0394>G<U+202F>=<U+202F>104.88) than the other mutated complexes compared with the WT, the Y226K complex showed even less binding affinity (<U+0394><U+0394>G<U+202F>=<U+202F>104.88). This variant somehow impedes the attachment of DTG to INT, indicating this mutant as possible resistance mutation.","Molecular modeling,Molecular docking,Drug resistance,MM-PBSA,SNP,Abbreviations,HAARTHighly Active Anti-Retroviral Therapy,HIVHuman Immunodeficiency Virus,DTGDolutegravir,INIntegrase Inhibitors,INTIntegrase Enzyme,RMSDRoot-mean-square deviation,MM/PBSAMolecular Mechanics Poisson Boltzmann Surface Area,TM-scoreTemplate-Modeling Score","Heitor Horlando Sampaio Araujoda Silvabcd,NataliaPereirabcd,LucasBrandãobd,SergioCrovellaad,RonaldMourabd","Infection, Genetics and Evolution","https://doi.org/10.1016/j.meegid.2018.11.014","https://www.sciencedirect.com/science/article/pii/S1567134818306361"
"A475","Plasma proteome profiling of high-altitude polycythemia using TMT-based quantitative proteomics approach","High-altitude polycythemia (HAPC) is one of the classic chronic mountain sicknesses and has been a serious public health problem in high-altitude regions. Despite numerous studies on HAPC via genomics or transcriptomics approaches, the pathogenesis of HAPC is still unclear. Here, we performed a TMT- based comparative quantitative proteomics analysis to reveal the changes of plasma proteomics profiles between HAPC subjects and healthy controls. Of identified 818 proteins, 7 and 12 proteins were up-regulated and down-accumulated, respectively, compared HAPC patients with healthy controls. GO and KEGG pathway analyses revealed the dysregulated proteins were primarily involved in complement and coagulation cascades, inflammation and immune response. ELISA validation demonstrated that C4A, C6 and CALR were down-regulated, and MASP1 and CNDP1 were up-regulated in HAPC patients. By ROC analysis, combinations of these five proteins (i.e., C4A, C6, CALR, MASP1 and CNDP1) resulted in a high AUC value (0.919; 95% CI, 0.817–961; p<U+202F><<U+202F>.0001) to diagnose HAPC patients. Moreover, CNDP1 seems to be a robust biomarker for HAPC. This study not only provided a comprehensive dataset on overall proteomics changes in HAPC patients compared with healthy controls, but also indicated that CNDP1 can serve as a strong plasma biomarker of HAPC for the diagnostic and therapeutic potential.,SignificanceHAPC, one of the classic chronic mountain sicknesses, has been a serious public health problem in high-altitude regions. Despite numerous studies on HAPC via genomics or transcriptomics approaches, the pathogenesis of HAPC is still largely unknown to date. In this study, we addressed this issue by performing TMT-based quantitative analyses of the plasma proteome profiles of HAPC patients and healthy controls. We identified 818 proteins, of which 19 were differentially expressed. Bioinformatics analysis revealed the differentially expressed proteins were mainly involved in complement and coagulation cascades, inflammation and immune response. By ROC analysis, combinations of C4A, C6, CALR, MASP1 and CNDP1 resulted in a high AUC value (0.919, p<U+202F><<U+202F>.0001) to distinguish HAPC patients from healthy controls. Collectively, the current study provided a comprehensive dataset on overall proteomic changes in HAPC patients for the first time, and it also revealed C4A, C6, CALR, MASP1 and CNDP1 can be served as candidate plasma biomarkers of HAPC for their diagnostic and therapeutic potential.","TMT,High-altitude polycythemia,Proteomics,Complement and coagulation cascades,Abbreviations,Hbhemoglobin,HAPChigh-altitude polycythemia,MSmass spectrometry,TMTtandem mass tag,iTRAQisobaric tag for relative and absolute quantification,2D-DIGEtwo-dimensional difference gel electrophoresis,DEPdifferentially expressed protein,RBCred blood cell count,HCThematocrit,PLTplatelet count,PTprothrombin time,aPTTactivated partial thromboplastin time,TTthrombin time,Fbgfibrinogen,FDRfalse discovery rate,GOGene Ontology,ELISAEnzyme-linked immunosorbent assay,KEGGKyoto Encyclopedia of Genes and Genomes,MACPFmembrane attack complex component/perforin,Igimmunoglobulin,CNDP1Beta-Ala-His dipeptidase,MASP1mannan-binding lectin serine protease 1,AGEsadvanced glycation end-products,PROCvitamin K-dependent protein C,CALRcalreticulin,MASP1mannan-binding lectin serine protease 1,Igimmunoglobulin","ZongkuiWanga1,FengjuanLiua1,ShengliangYea,PengJianga,XiaochuanYub,JinXuc,XiDua,LiMaa,HaijunCaoa,ChuangYuand,YuanzhenShenb,FangzhaoLina,RongZhanga,ChangqingLia","Journal of Proteomics","https://doi.org/10.1016/j.jprot.2018.12.031","https://www.sciencedirect.com/science/article/pii/S1874391918304603"
"A476","Technology, application and potential of dynamic breast thermography for the detection of breast cancer","Early breast cancer detection improves the chances of survival, increases the options for curative treatment and helps reduce costs. There are a variety of screening techniques available to detect breast cancer such as mammography, magnetic resonance imaging and ultrasound. However, their sensitivities and specificities are suboptimal, especially in breasts with dense tissue. Infrared breast thermography is an adjunct screening technique that has been associated with the detection of early signs of breast cancer. However, its success has been limited. Dynamic infrared thermography was introduced to improve the detection of breast cancer and reduce the false positive and false negative rates. This works reviews the different modalities of dynamic infrared thermography, their advantages, shortcomings and opportunities for future development. This paper also covers recent advances, suggestions and possible directions for future work in the fields of numerical simulations, automatic feature identification and artificial intelligence for improving the detection of breast cancer using dynamic infrared thermography.","Breast cancer detection,Dynamic thermography,Cold challenge","Jose-LuisGonzalez-Hernandeza,Alyssa N.Recinellaa,Satish G.Kandlikara,DonnetteDabydeenb,LoriMedeirosc,PradyumnaPhatakd","International Journal of Heat and Mass Transfer","https://doi.org/10.1016/j.ijheatmasstransfer.2018.11.089","https://www.sciencedirect.com/science/article/pii/S001793101834033X"
"A477","Biosynthesis of methyleugenol and methylisoeugenol in Daucus carota leaves: Characterization of eugenol/isoeugenol synthase and O-Methyltransferase","Carrot (Daucus carota subsp. sativus) is a widely cultivated root vegetable of high economic importance. The aroma of carrot roots and aboveground organs is mainly defined by terpenes. We found that leaves of orange carrot cultivar also produce considerable amounts of the phenylpropenes methyleugenol and methylisoeugenol. Notably, methyleugenol is most abundant in young leaves, while methylisoeugenol is the dominant phenylpropene in mature leaf tissue. The goal of the present study was to shed light on the biochemistry and molecular biology of these compounds' biosynthesis and accumulation. Using the available genomic and transcriptomic data, we isolated a cDNA encoding eugenol/isoeugenol synthase (DcE(I)GS1), an NADPH-dependent enzyme that converts coniferyl acetate to eugenol. This enzyme exhibits dual product specificity and yields propenylphenol isoeugenol alongside allylphenol eugenol. Furthermore, we identified a cDNA encoding S-adenosyl-L-methionine:eugenol/isoeugenol O-methyltransferase 1 (DcE(I)OMT1) that produces methyleugenol and methylisoeugenol via methylation of the para-OH-group of their respective precursors. Both DcE(I)GS1 and DcE(I)OMT1 were expressed in seeds, roots, young and mature leaves, and the DcE(I)OMT1 transcript levels were the highest in leaves. The DcE(I)GS1 protein is 67% identical to anise t-anol/isoeugenol synthase and displays an apparent Km of 247<U+202F>µM for coniferyl acetate. The catalytic efficiency of DcEOMT1 with eugenol is more than five-fold higher than that with isoeugenol, with Km values of 40<U+202F>µM for eugenol, and of 115<U+202F>µM for isoeugenol. This work expands the current knowledge of the enzymes involved in phenylpropene biosynthesis and would enable studies into structural elements defining the regioselectivity of phenylpropene synthases.","Daucus carota subsp. sativus,Apiaceae,Eugenol synthase,Methyleugenol,Methylisoeugenol,O-Methyltransferase","MosaabYahyaaa,AnnaBerimb,BhagwatNawadea,MuhammadIbdahc,NataliaDudarevad,MwafaqIbdaha","Phytochemistry","https://doi.org/10.1016/j.phytochem.2018.12.020","https://www.sciencedirect.com/science/article/pii/S0031942218302498"
"A478","iTRAQ-based quantitative proteomics reveals insights into metabolic and molecular responses of glucose-grown cells of Rubrivivax benzoatilyticus JA2","Anoxygenic photosynthetic bacteria thrive under diverse habitats utilising an extended range of inorganic/organic compounds under different growth modes. Although they display incredible metabolic flexibility, their responses and adaptations to changing carbon regimes is largely unexplored. In the present study, we employed iTRAQ-based global proteomic profiling and physiological studies to uncover the adaptive strategies of a phototrophic bacterium, Rubrivivax benzoatilyticus JA2 to glucose. Strain JA2 displayed altered growth rates, reduced cell size and progressive loss of pigmentation when grown on glucose compared to malate under photoheterotrophic condition. A ten-fold increase in the saturated to unsaturated fatty acid ratio of glucose-grown cells indicates a possible membrane adaptation. Proteomic profiling revealed extensive metabolic remodelling in the glucose-grown cells wherein signal-transduction, selective-transcription, DNA-repair, transport and protein quality control processes were up-regulated to cope with the changing milieu. Proteins involved in DNA replication, translation, electron-transport, photosynthetic machinery were down-regulated possibly to conserve the energy. Glycolysis/gluconeogenesis, TCA cycle and pigment biosynthesis were also down-regulated. The cell has activated alternative energy metabolic pathways viz., fatty acid ß-oxidation, glyoxylate, acetate-switch and Entner-Doudoroff pathways. Overall, the present study deciphered the molecular/metabolic events associated with glucose-grown cells of strain JA2 and also unraveled how a carbon source modulates the metabolic phenotypes.,SignificanceAnoxygenic photosynthetic bacteria (APB) exhibit incredible metabolic flexibility leading to diverse phenotypes. They thrive under diverse habitat using an array of inorganic/organic compounds as carbon sources, yet their metabolic adaptation to varying carbon regime is mostly unexplored. Present study uncovered the proteomic insights of the cellular responses of strain JA2 to changing carbon sources viz. malate and glucose under photoheterotrophic conditions. Our study suggests that carbon source can also determine the metabolic fate of the cells and reshape the energy dynamics of APB. Here, for the first time study highlighted the plausible carbon source (glucose) mediated regulation of photosynthesis in APB. The study sheds light on the plausible cellular events and adaptive metabolic strategies employed by strain JA2 in presence of non-preferred carbon source. It also revealed new insights into the metabolic plasticity of APB to the changing milieu.","ACNAcetonitrile,AldhAldehyde dehydrogenase,APBAnoxygenic photosynthetic bacteria,DEPDifferentially expressed proteins,DICDifferential interference contrast,EDEntner Doudoroff pathway,EMPEmbden-Meyerhof-Parnas pathway,ETCElectron transport chain,FAMEFatty acid methyl esters,FCFold change,GOGene ontology,GRAVYGrand average hydropathy index,HPLCHigh performance liquid chromatography,iTRAQIsobaric tag for relative and absolute quantitation,KEGGKyoto encyclopedia of genes and genomes,LHCLight harvesting complex,MK-8Menaquinone-8,ODOptical density,PBSPhosphate buffered saline,PMFProton motive force,PPPPentose phosphate pathway,Q8Ubiquinone-8,RCReaction center,TCA cycleTricarboxylic acid cycle,Keywords,Rubrivivax benzoatilyticus JA2,Anoxygenic photosynthetic bacteria (APB),Glucose,Metabolic remodelling,Loss of pigmentation,Membrane adaptation,iTRAQ,Fatty acid","DeepshikhaGuptaa,MujahidMohammeda,Lakshmi PrasunaMekalaa,SasikalaChintalapatib,Venkata RamanaChintalapatia","Journal of Proteomics","https://doi.org/10.1016/j.jprot.2018.12.027","https://www.sciencedirect.com/science/article/pii/S1874391918304561"
"A479","Characterization of a Knudsen force based vacuum sensor for N2H2O gas mixtures","Radiometric phenomena can arise in gas flows in which the local molecular mean free path is in the same order as the temperature gradient length scale. The forces exerted on immersed bodies by such rarefied flows are known as Knudsen (or thermophoretic) forces and can play a major role in nonisothermal microflows. In this work, the direct simulation Monte Carlo (DSMC) method is used to numerically characterize the force and thermal mechanisms on a second generation Microscale In-Plane Knudsen Radiometric Actuator (MIKRA) designed for gas pressure and composition sensing. First, a brief verification analysis of the present DSMC solver in reproducing the thermal conductivity for the gas species of interest – nitrogen and water vapor – is carried out. The geometric impact of the gap between MIKRA beams is then investigated for pure N2 environments. In addition, the beam heat transfer coefficients for N2H2O binary mixtures are extracted from the DSMC data and a dimensionless correlation is proposed for predicting the corresponding Knudsen forces. These results are intended to assist in the operation and design of the MIKRA device.","Knudsen thermal force,Direct simulation Monte Carlo,MEMS,Pressure sensor","A.Pikus,I. BorgesSebastião,A.Strongrich,A.Alexeenko","Vacuum","https://doi.org/10.1016/j.vacuum.2018.12.003","https://www.sciencedirect.com/science/article/pii/S0042207X18304317"
"A480","Changes in milk fat globules and membrane lipids under the shear fields of microfiltration and centrifugation","This study compared the efficiency of centrifugal and microfiltration separation of milk fat globules (MFG) from bovine cream and the changes that take place in the corresponding lipid membranes (MFGM). Creams were washed with water (1:10) and subjected to either centrifugation or microfiltration to fractionate proteins and other non-fat milk components. Protein analyses of the obtained fractions were carried out by gel electrophoresis. Lipid extraction and thin layer chromatography were also employed to separate lipid types and the amount of polar lipids were determined by gas chromatography. The effect of flow conditions on MFG's colloidal properties and MFGM components was evaluated based on estimates of the average rate of energy dissipation in microfiltration and centrifugation processes. Both were equally effective in removing the protein fraction (93% yield) as well as non-fat dry matter (~100% removal). Microfiltration reduced the mean particle size by 0.3<U+202F>µm, whereas the opposite was observed for centrifugal separation (average size increase by 0.8<U+202F>µm). The latter process also induced a more significant reduction in the electrostatic charges (zeta potential) of the colloids in the cream, which relates to the changes in the milk fat globule surface composition and the release of MFGM components. The dissociated polar lipids amounted to 24% and 20% upon centrifugation and microfiltration, respectively. Overall, the results suggest that MFG and MFGM are partially damaged under the shear forces typical of centrifugal and microfiltration separation. A high separation efficiency, with minimal fat globule damage and high MFGM yield is possible by adopting microfiltration under carefully optimized conditions.","Milk fat globules,Microfiltration,Centrifugation,Milk fat globule membrane (MFGM),Shear","AnnamariJukkolaa,SannaHokkanena,TeroKämäräinena,RiittaPartanenb,AnttiHeinob,Orlando J.Rojasa","Journal of Membrane Science","https://doi.org/10.1016/j.memsci.2018.12.007","https://www.sciencedirect.com/science/article/pii/S0376738818326528"
"A481","Internet of things forensics: Recent advances, taxonomy, requirements, and open challenges","The explosive growth of smart objects and their dependency on wireless technologies for communication increases the vulnerability of Internet of Things (IoT) to cyberattacks. Cyberattacks faced by IoT present daunting challenges to digital forensic experts. Researchers adopt various forensic techniques to investigate such attacks. These techniques aim to track internal and external attacks by emphasizing on communication mechanisms and IoT’s architectural vulnerabilities. In this study, we explore IoT’s novel factors affecting traditional computer forensics. We investigate recent studies on IoT forensics by analyzing their strengths and weaknesses. We categorize and classify the literature by devising a taxonomy based on forensics phases, enablers, networks, sources of evidence, investigation modes, forensics models, forensics layers, forensics tools, and forensics data processing. We also enumerate a few prominent use cases of IoT forensics and present the key requirements for enabling IoT forensics. Finally, we identify and discuss several indispensable open research challenges as future research directions.","Internet of Things,Cybersecurity,Internet of Things forensics,Security,Cybercrime,Smart city","IbrarYaqooba,Ibrahim Abaker TargioHashemb,ArifAhmedac,S.M. AhsanKazmia,Choong SeonHonga","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.09.058","https://www.sciencedirect.com/science/article/pii/S0167739X18315644"
"A482","Modeling affective character network for story analytics","Consideration of the stories included in the narrative works is important for analyzing and providing narrative works (e.g., movies, novels, and comics) to users. In this study, we analyzed the stories in a narrative work with three goals: (i) eliciting, (ii) modeling, and (iii) utilizing the stories. Based upon our previous studies regarding ‘character networks’ (i.e., social networks among characters in the stories), we elicited the stories with three methods: (i) composing affective character networks with affective relationships among the characters, (ii) measuring temporal changes in tension according to the flows of the stories, and (iii) detecting affective events which refer to dramatic changes in the tension. The affective relationships contain emotional changes of the characters on each segment of the stories. By aggregating the characters’ emotional changes, we measured the tension of each segment. We called it ‘Affective Fluctuation’ and represented it as a discrete function (Affective Fluctuation Function, AFF). The AFFs enable us to detect affective events by using gradients of them and measure similarities among the stories by comparing their shapes. Also, we proposed a computational model of the stories by annotating the affective events and characters involved in those events. Finally, we demonstrated a practical application with a recommendation method which exploited the similarities between stories. Additionally, we verified the reliabilities and efficiencies of the proposed method for narrative works in the real world.","Story analytics,Affective relationship,Affective fluctuation,Affective event detection,Story-based recommender system","O-JounLee,Jason J.Jung","Future Generation Computer Systems","https://doi.org/10.1016/j.future.2018.01.030","https://www.sciencedirect.com/science/article/pii/S0167739X17310221"
"A483","The multi-scale challenges of biomass fast pyrolysis and bio-oil upgrading: Review of the state of art and future research directions","Biomass fast pyrolysis is potentially one of the cheapest routes toward renewable liquid fuels. Its commercialization, however, poses a multi-scale challenge, which starts with the characterization of feedstock, products and reaction intermediates at molecular scales, and continues with understanding the complex reaction network taking place in different reactor configurations, and in the case of catalytic pyrolysis and upgrading on different catalysts. In addition, crude pyrolysis oil is not immediately usable in the current energy infrastructure, due to undesirable properties such as low energy content and corrosiveness as a result of its high oxygenate content. It, therefore, needs to be upgraded and fractionated to desired specifications. While various types of pyrolysis reactors and upgrading technologies are under development, knowledge transfer and closing the gap between theory and application requires model development. In-depth understanding of the reaction mechanisms and kinetics should be combined with the knowledge of multi-scale transport phenomena to enable design, optimization, and control of complex pyrolysis reactors. Finally, underpinning economic and environmental impacts of biofuel production requires expanding the system boundaries to include the overall process and supply chain. The present contribution aims at providing a comprehensive multi-scale review that discusses the state of the art of each of these aspects, as well as their multi-scale interactions. The study is mainly focused on fast pyrolysis, although reference to other types of pyrolysis technologies is made for the sake of comparison and knowledge transfer.","Biomass fast pyrolysis,Characterization,Catalysis,Reaction mechanism and kinetics,Modeling,Economy,Life cycle assessment","MahdiSharifzadehaf,MajidSadeqzadeha,MiaoGuoa,Tohid N.Borhania,N.V.S.N.Murthy Kondab,Marti CortadaGarciac,LeiWangd,JasonHallette,NilayShaha","Progress in Energy and Combustion Science","https://doi.org/10.1016/j.pecs.2018.10.006","https://www.sciencedirect.com/science/article/pii/S036012851830025X"
"A484","Supporting end-user debugging of trigger-action rules for IoT applications","End users need tools to enable them to control and personalise Internet of Things (IoT) applications, which may involve hundreds of interconnected objects. Trigger-action programming has shown to be a useful support for this purpose because it allows users to easily associate dynamic events with the activation of desired effects. End User Development (EUD) tools aim to allow even users without programming experience to define the behaviour of IoT applications. However, users may define rules triggering various actions that may be in conflict, or may specify rules that do not result in the intended behaviour. Although such situations can often occur, there seems to be a lack of tools able to help users understand whether the specified rules actually bring about the desired behaviour and, if not, the reasons why they fail. We present an original solution for filling this gap, which takes into account the specific aspects of trigger-action rules. We describe the design and implementation of this debugging support, and then discuss the results of a first user test.","End user development,Internet of things,Trigger-Action Rules,Debugging","MarcoManca,Fabio,Paternò,CarmenSantoro,LucaCorcella","International Journal of Human-Computer Studies","https://doi.org/10.1016/j.ijhcs.2018.11.005","https://www.sciencedirect.com/science/article/pii/S1071581918306529"
"A485","LYN, a key mediator in estrogen-dependent suppression of osteoclast differentiation, survival, and function","Estrogen insufficiency at menopause cause accelerated bone loss due to unwarranted differentiation and function of osteoclasts. Unraveling the underlying mechanism/s may identify mediators of estrogen action which can be targeted for improved management of osteoporosis. Towards this, we analyzed the effect of 17ß-estradiol on the proteomes of differentiating human osteoclasts. The major proteomic changes observed included upregulation of LYN by estrogen. We, therefore, investigated the effect of estrogen on osteoclast differentiation, survival, and function in control and LYN knockdown conditions. In control condition, estrogen treatment increased the apoptosis rate and suppressed the calcium signaling by reducing the intracellular Ca2+ levels as well as expression and activation of NFATc1 and c-Src during differentiation, resulting in reduced osteoclastogenesis. These osteoclasts were smaller in size with reduced extent of multinuclearity and produced significantly low levels of bone resorbing enzymes. They also exhibited disrupted sealing zone formation with low podosome density, impaired cell polarization and reduced resorption of dentine slices. Interestingly, in LYN knockdown condition, estrogen failed to induce apoptosis and inhibit activation of NFATc1 and c-Src. Compared to effect of estrogen on osteoclast in control condition, LYN knockdown osteoclasts did not show reduction in production of bone resorbing enzymes and had defined sealing zone formation with high podosome density with no impairment in cell polarization. They resorbed significant area on dentine slices. Thus, the inhibitory action of estrogen on osteoclast was severely restrained in LYN knockdown condition, demonstrating the importance of LYN as a key mediator of the effect of estrogen on osteoclastogenesis.","Estrogen,Osteoclast,Osteoporosis,LYN","ShubhangiGavalia,Manoj KumarGuptabc,BhavnaDaswania,Mohan R.Wanid,RaviSirdeshmukhbe,M. IkramKhatkhataya","Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease","https://doi.org/10.1016/j.bbadis.2018.12.016","https://www.sciencedirect.com/science/article/pii/S0925443918305027"
"A486","A real-time data-based scan conversion method for single element ultrasound transducers","The current work investigates the performance of a real-time scan conversion algorithm for generating a 2-D ultrasound image from a laterally scanned single-element ultrasound transducer, which has applications in point-of-care devices such as for skin imaging. The algorithm employs a fixed calibration curve to update a predefined image grid in real time. Simulations showed that the calibration curve (with a maximum of 1) is robust to changes in scatterer concentration (8.3×10-3 mean absolute error), signal to noise ratio (1.0×10-3 mean absolute error for -5<U+202F>dB SNR), and can be accurately predicted from a small number (31) of point scatterers (6.9×10-3 mean absolute error). Good agreement was also found between the calibration curves obtained from simulated and experimental data (1.19×10-2 mean absolute error). The scan conversion algorithm was validated by evaluation of the position estimation errors on both simulations and experiments. Clinical images of skin lesions (N<U+202F>=<U+202F>20) demonstrate the feasibility of the algorithm for real, non-homogeneous tissue. Use of a fixed calibration curve compared to an adaptive calibration curve gave similar accuracies in the scanning step size range of 150–350 µm (with an average overlap of the accuracy ranges of 92.94% for simulations and 42.83% for experiments), and a 350-fold improvement in computation time.","Single-element transducer,Image formation,Freehand scanning,Scan conversion,Correlation","GergelyCsánya,KláraSzalaib,MiklósGyöngya","Ultrasonics","https://doi.org/10.1016/j.ultras.2018.10.006","https://www.sciencedirect.com/science/article/pii/S0041624X18303512"
"A487","Uncertainty-aware asynchronous scattered motion interpolation using Gaussian process regression","We address the problem of interpolating randomly non-uniformly spatiotemporally scattered uncertain motion measurements, which arises in the context of soft tissue motion estimation. Soft tissue motion estimation is of great interest in the field of image-guided soft-tissue intervention and surgery navigation, because it enables the registration of pre-interventional/pre-operative navigation information on deformable soft-tissue organs. To formally define the measurements as spatiotemporally scattered motion signal samples, we propose a novel motion field representation. To perform the interpolation of the motion measurements in an uncertainty-aware optimal unbiased fashion, we devise a novel Gaussian process (GP) regression model with a non-constant-mean prior and an anisotropic covariance function and show through an extensive evaluation that it outperforms the state-of-the-art GP models that have been deployed previously for similar tasks. The employment of GP regression enables the quantification of uncertainty in the interpolation result, which would allow the amount of uncertainty present in the registered navigation information governing the decisions of the surgeon or intervention specialist to be conveyed.","Gaussian processes,Interpolation,Motion estimation,Uncertainty","BojanKocevabc,Horst KarlHahnbc,LarsLinsend,William M.Wellse,RonKikinisabe","Computerized Medical Imaging and Graphics","https://doi.org/10.1016/j.compmedimag.2018.12.001","https://www.sciencedirect.com/science/article/pii/S0895611118300909"
"A488","Meningeal inflammatory response and fibrous tissue remodeling around intracortical implants: An in vivo two-photon imaging study","Meningeal inflammation and encapsulation of neural electrode arrays is a leading cause of device failure, yet little is known about how it develops over time or what triggers it. This work characterizes the dynamic changes of meningeal inflammatory cells and collagen-I in order to understand the meningeal tissue response to neural electrode implantation. We use in vivo two-photon microscopy of CX3CR1-GFP mice over the first month after electrode implantation to quantify changes in inflammatory cell behavior as well as meningeal collagen-I remodeling. We define a migratory window during the first day after electrode implantation hallmarked by robust inflammatory cell migration along electrodes in the meninges as well as cell trafficking through meningeal venules. This migratory window attenuates by 2 days post-implant, but over the next month, the meningeal collagen-I remodels to conform to the surface of the electrode and thickens. This work shows that there are distinct time courses for initial meningeal inflammatory cell infiltration and meningeal collagen-I remodeling. This may indicate a therapeutic window early after implantation for modulation and mitigation of meningeal inflammation.","Intravital imaging,Neural interface,Foreign body response,Hydrogel,Meninges,Brain-computer interface","J.R.Elesab,A.L.Vazquezabc,T.D.Y.Kozaiabdef,X.T.Cuiabd","Biomaterials","https://doi.org/10.1016/j.biomaterials.2018.12.031","https://www.sciencedirect.com/science/article/pii/S0142961218308664"
"A489","Solar plant with short diffuser concept: Further improvement of numerical model by included influence of guide vane topology on shape and stability of gravitational vortex","An alternative renewable energy concept, i.e. the concept of a solar power plant with short diffuser (SPD), was numerically investigated by more advanced computational fluid dynamics (CFD) model. Developed model is characterized by a more sophisticated and streamlined guide vane topology. The main novelty of this work is conducted optimization of the guide vane topology, for a specific novel application related to the alternative renewable energy concept (SPD). Optimization involved determining the required guide vane topology using minimal number of geometry influencing parameters. The objective was to result in vortex genesis and stabilization with respect to the desired circumferential velocity and to minimize the required pressure potential that is necessary for stable operation of the SDP plant. Provided numerical investigation was necessary, and for sure a step forward towards consideration of the experimental plant (which will assume introduction of the turbines). It needs to be taken into account that we deal with complex flow structure that requires gradual numerical investigation, in order to be able to get detail insight in the various influences and processes that can strongly affect SPD operating parameters. The guide vane topology was altered to develop an SPD capable of establishing and maintaining a stable gravitational vortex in pressure ranges which resemble atmospheric vortex phenomena (feasible for development of a compact system, and with maximal velocities in chimney throat regions ranging below 20<U+202F>m<U+202F>s-1). The study outlines nine cases, each representing the altered guide vane design, where the best case is determined and compared with the available experimental data from other research groups. The comparison indicates that the numerical model, although quite simple, is accurate and robust in predicting the distribution of local velocity and pressure profiles and fit for implementation on wind turbines in order to determine the influence of the installed turbines on the vortex shape and stability in a future study. An important finding is that the swirl ratio can be manipulated by altering the guide vane shape, and it is independent of the Reynolds number (which will be important during the design phase since it can be used as a control strategy for vortex genesis and as a prevention of unintentional genesis regarding additional multiple vortices). The gained numerical results revealed specific operating conditions that will ensure a safer environment around the SPD and that will enable a carbon free electricity production.","Solar power plant,Numerical modelling,Solar energy,Thermodynamics,Vortices,Carbon-free electricity production","ŽeljkoPengaa,SandroNižetica,MüslümAricib","Journal of Cleaner Production","https://doi.org/10.1016/j.jclepro.2018.12.021","https://www.sciencedirect.com/science/article/pii/S0959652618337235"
"A490","Neuroimaging of individual differences: A latent variable modeling perspective","Neuroimaging data is being increasingly utilized to address questions of individual difference. When examined with task-related fMRI (t-fMRI), individual differences are typically investigated via correlations between the BOLD activation signal at every voxel and a particular behavioral measure. This can be problematic because: 1) correlational designs require evaluation of t-fMRI psychometric properties, yet these are not well understood; and 2) bivariate correlations are severely limited in modeling the complexities of brain-behavior relationships. Analytic tools from psychometric theory such as latent variable modeling (e.g., structural equation modeling) can help simultaneously address both concerns. This review explores the advantages gained from integrating psychometric theory and methods with cognitive neuroscience for the assessment and interpretation of individual differences. The first section provides background on classic and modern psychometric theories and analytics. The second section details current approaches to t-fMRI individual difference analyses and their psychometric limitations. The last section uses data from the Human Connectome Project to provide illustrative examples of how t-fMRI individual differences research can benefit by utilizing latent variable models.","Latent variable,Structural equation modeling,Psychometrics,Human connectome project","Shelly R.Cooper,Joshua J.Jackson,Deanna M.Barch,Todd S.Braver","Neuroscience & Biobehavioral Reviews","https://doi.org/10.1016/j.neubiorev.2018.12.022","https://www.sciencedirect.com/science/article/pii/S0149763418305165"
"A491","Charging infrastructure for electric vehicles in Multi-Unit Residential Buildings: Mapping feedbacks and policy recommendations","Achieving meaningful reductions in greenhouse gas emissions from the global transportation sector will rely on a large-scale transition to electric vehicles (EVs). Many governments aim to encourage the uptake of EVs in cities, because urban areas are well suited to EV driving ranges and stand to benefit hugely from reduced local emissions. In the Canadian province of British Columbia (BC), where clean renewable electricity sourcing makes EV deployment an attractive proposition, over a quarter of residents live in Multi-Unit Residential Buildings (MURBs), most of which are not equipped with EV charging infrastructure. In a related study, Lopez-Behar et al. (accepted) explored the challenges and decision-making processes involved in the installation of EV charging infrastructure in MURBs in BC, from the perspective of different stakeholders. Here, we build on those findings to map out and analyze feedback loops within this system using a Causal Loop Diagram (CLD). We then present potential demand-focused policy interventions to address the issues raised by our modelling results, grouped into three categories: financial/fiscal, regulatory and information/awareness measures. Financial/fiscal policy measures include creating incentives for EV owners and extending them to the building owners, and programs to incentivize and provide financial aid for building owners to develop building retrofit plans. Regulatory policy measures include addressing the rights and obligations of the stakeholders and making mandatory the installation of charging stations in new MURBs. Information/awareness policy measures include expanding the existing guidelines and informing the development of a long-term EV charging infrastructure plan. Our policy recommendations are designed to inform the interventions of municipal and provincial governments in BC, but could also be relevant to many urban EV markets worldwide.","Causal Loop Diagrams,EV policy,Alternative fuel vehicles,Stakeholder analysis","DianaLopez-Behara,MartinoTranb,ThomasFroesea,Jerome R.Mayaudb,Omar E.Herrerac,WalterMeridac","Energy Policy","https://doi.org/10.1016/j.enpol.2018.10.030","https://www.sciencedirect.com/science/article/pii/S0301421518306840"
"A492","Subjective and physiological responses to façade and sunlight pattern geometry in virtual reality","This study investigates the joint impact of façade geometry and associated sunlight patterns on occupant subjective perception and physiological responses through a novel experimental method coupling physically-based simulations shown in virtual reality with a wearable biometric device. A total of 72 subjects participated in a study combining three façade configurations of an equal aperture ratio with different scenarios of space use (a social or working context). The façade variations –a non-uniform distribution of openings (“Irregular”), a uniform distribution of openings (“Regular”) and venetian blinds (“Blinds”)– were applied to an interior scene with clear sky and direct sun penetration. Subjective evaluations (how pleasant, interesting, and exciting the space was perceived) and physiological responses (heart rate and skin conductance) were collected during exposure to façade variations, while a neutral scene was used to record baseline physiological responses. Results revealed that façade and sunlight pattern geometry significantly influenced subjective responses for both context scenarios, while subsequent analyses showed differences mostly between the Irregular and Regular conditions, with the former being evaluated more positively. Façade and sunlight pattern geometry affected heart rate responses, but not skin conductance responses. In particular, participants showed a larger decrease in heart rate while exposed to the Irregular condition compared to the Blinds. Context scenarios influenced evaluations of interest and excitement. Findings are particularly relevant for applications in architecture and lighting, demonstrating that façade elements and their interaction with light can influence occupant subjective and physiological responses, and showcasing the potential of the presented method for investigating human perception.","Façade,Sunlight,Pattern,Perception,Physiological response,Virtual reality","K.Chamilothoria,G.Chinazzoa,J.Rodriguesb,E.S.Dan-Glauserc,J.Wienolda,M.Andersena","Building and Environment","https://doi.org/10.1016/j.buildenv.2019.01.009","https://www.sciencedirect.com/science/article/pii/S0360132319300095"
"A493","Integrating green infrastructure and ecosystem services in land use planning. Results from two Finnish case studies","Scientific advancements on Green Infrastructure (GI) and Ecosystem Services (ES) have been conducted by experts from several disciplines such as landscape ecology, landscape architecture and, more recently, regional and urban planning. However, there are still difficulties in defining and operationalizing GI and ES within planning. This paper explores the possibilities and obstacles in incorporating the GI and ES concepts into policy frameworks, planning strategies and planning practices by taking as case studies the Helsinki-Uusimaa Region and the City of Järvenpää in Finland. In both cases, several studies on GI and ES have been developed with the collaboration of academics, research institutes and planners. The literature review focuses on the understanding and integration of GI and ES within land use planning. A qualitative content analysis was conducted of policy and planning documents and interviews with regional and city planners. The results show that while the national policy has already embraced the two concepts, the planning strategies of the Helsinki-Uusimaa Region and the City of Järvenpää need to fully integrate GI and ES. A wider and more concrete picture about the difficulties in operationalising GI and ES is provided by the planning practitioners. Rigid regulatory framework and current planning tools still represent obstacles to the effective integration of GI and ES. More science-practice collaborations between experts, practitioners and policymakers should support the development of our cities and urban regions having GI and ES in mind.","Green infrastructure,Ecosystem services,Urban densification,Integration,Understanding,Planning practitioners","MinaDi Marinoa,MaijaTiitub,KimmoLapintiec,ArtoViinikkab,LeenaKopperoinend","Land Use Policy","https://doi.org/10.1016/j.landusepol.2019.01.007","https://www.sciencedirect.com/science/article/pii/S0264837718309773"
"A494","A deep learning and gamification approach to improving human-building interaction and energy efficiency in smart infrastructure","In this paper, we propose a gamification approach as a novel framework for smart building infrastructure with the goal of motivating human occupants to consider personal energy usage and to have positive effects on their environment. Human interaction in the context of cyber-physical systems is a core component and consideration in the implementation of any smart building technology. Research has shown that the adoption of human-centric building services and amenities leads to improvements in the operational efficiency of these cyber-physical systems directed toward controlling building energy usage. We introduce a strategy that incorporates humans-in-the-loop modeling by creating an interface to allow building managers to interact with occupants and potentially incentivize energy efficient behavior. Game theoretic analysis typically relies on the assumption that the utility function of each individual agent is known a priori. Instead, we propose a novel benchmark utility learning framework that employs robust estimations of occupant actions toward energy efficiency. To improve forecasting performance, we extend the benchmark utility learning scheme by leveraging Deep Learning end-to-end training with deep bi-directional Recurrent Neural Networks. We apply the proposed methods to high-dimensional data from a social game experiment designed to encourage energy efficient behavior among smart building occupants. Using data gathered from occupant actions for resources such as room lighting, we forecast patterns of resource usage to demonstrate the performance of the proposed methods on ground truth data. The results of our study show that we can achieve a highly accurate representation of the ground truth for occupant resource usage. For demonstrations of our infrastructure and for downloading de-identified, high-dimensional data sets, please visit our website (smartNTU demo web portal: https://smartntu.eecs.berkeley.edu)","Artificial intelligence for humans-in-the-loop cyber-physical systems,Human-building interaction,Deep learning,Discrete choice models,Game theory","Ioannis C.Konstantakopoulos,Andrew R.Barkan,ShiyingHe,TanyaVeeravalli,HuihanLiu,CostasSpanos","Applied Energy","https://doi.org/10.1016/j.apenergy.2018.12.065","https://www.sciencedirect.com/science/article/pii/S0306261918318841"
"A495","Zinc(II) and cadmium(II) halide complexes with caffeine: Synthesis, X-ray crystal structure, cytotoxicity and genotoxicity studies","Molecular complexes [Zn(caf)(H2O)I2] (I), [Zn(caf)(H2O)Cl2] (IV), and the polymeric ones {[Cd(H2O)2I2](caf).2H2O}n (II) and {[Cd(H2O)2Br2](caf).2H2O}n (III) consisting of infinite Cd-containing chains with bridging halide ions and water molecules in trans-position and connected with each other due to hydrogen bonding with participation of caffeine (caf) and water molecules, were prepared and characterized by the powder and single crystal X-ray diffraction, IR vibrational spectroscopy, 1H NMR, ESI-MS spectroscopy, thermal analysis and DFT calculations. It was found that the complexes (I) and (IV) are characterized by tetrahedral geometry, the caffeine molecule being coordinated by the central atom via its N9 atom. The preferability of complex formation was evaluated by quantum-chemical calculations. Cyto- and genotoxicity of the compounds have been investigated and discussed in comparison with that of [Zn(AP)2I2] (1) and [Cd(AP)6][Cd(AP)I3]2 (2). It was demonstrated that the prepared complexes, primarily that of cadmium iodide with caffeine (II), are the promising ones for further studies both in vitro and in vivo.","Zinc and cadmium complexes,Caffeine,Crystal structure,DFT calculations,Cyto- and genotoxicity","Nataliya S.Rukka,Lyudmila G.Kuzminab,Ravshan S.Shamsieva,Galina A.Davydovac,Elena A.Mironovac,Artem M.Ermakovc,Grigory A.Buzanovb,Alena Yu.Skryabinaa,Andrej N.Streletskiid,Galina A.Vorob'evad,Vasilii M.Retivove,Pavel A.Volkove,Svetlana K.Beluse,Evgeniya I.Kozhukhovae,Valeriya N.Krasnoperovaa","Inorganica Chimica Acta","https://doi.org/10.1016/j.ica.2018.11.036","https://www.sciencedirect.com/science/article/pii/S0020169318306674"
"A496","Improving the reliability of soil EC-mapping: Robust apparent electrical conductivity (rECa) estimation in ground-based frequency domain electromagnetics","The use of frequency domain electromagnetic (FDEM) instrumentation in ground-based near-surface applications is continually expanding. In soil studies, FDEM is mainly deployed to inform on soil properties such as salinity, texture, moisture or compaction by evaluating the low induction number (LIN) apparent electrical conductivity (ECa). However, advanced FDEM applications face terrains and conditions in which these LIN approximations are no longer valid. Under such conditions, the aforementioned instrumentation output systematically underestimates ECa values; making semi-qualitative data analysis, representation and practical interpretation impossible. For this reason, methods have to be developed to relate the complex FDEM responses to a reliable ECa, beyond the limitations of the LIN approximation. In this work, we present a quadrature-phase algorithm (i.e. excluding the in-phase signal from the estimation) to obtain a robust apparent electrical conductivity at both low and high induction numbers. In addition, the algorithm classifies the ECa estimations as either robust or non-robust based on instrument noise, desired precision of the ECa estimation and the effect of subsurface magnetic variations. The algorithm accounts for electrical conductivity, instrument elevation, coil geometry, operating frequency, subsurface magnetic variation and random errors. The presented procedure, which was tested on synthetic and experimental data, consists a robust and straightforward approach to increase reliability of ECa derived soil mapping.","Ground conductivity meter (GCM),Electromagnetic induction (EMI),Soil salinity,ECa,Precision agriculture","DaanHanssensa,SamuëlDelefortriea,ChristinBobea,ThomasHermansb,PhilippeDe Smedta","Geoderma","https://doi.org/10.1016/j.geoderma.2018.11.030","https://www.sciencedirect.com/science/article/pii/S001670611831721X"
"A497","Characterization of the coherent dynamics of bacteriochlorophyll a in solution","Disclosing the physical origin of quantum beatings in the early dynamics of biological light-harvesting pigment-protein complexes is one of the major challenges in the ultrafast spectroscopy community. 2D electronic spectroscopy (2DES) is a powerful tool for this purpose, but the complexity of the beating behavior in multichromophoric systems complicates the interpretation. For this reason, the availability of control datasets providing a full characterization of the response of isolated chromophores is highly desirable to untangle the features of intermolecular interactions from the properties of individual pigments. Here, a thorough 2DES characterization of the frequencies and dephasing times of intramolecular vibrational coherences of bacteriochlorophyll a in solution is provided. Several beating modes in the ground and excited state have been found and their dephasing times have been determined. The obtained results represent an essential interpretation key of the beating dynamics of pigment-protein complexes binding bacteriochlorophyll a.","Coherent dynamics,Bacteriochlorophyll a,2D electronic spectroscopy,Vibrational coherence,Raman spectroscopy","ElenaMeneghin,DaniloPedron,ElisabettaCollini","Chemical Physics","https://doi.org/10.1016/j.chemphys.2018.12.008","https://www.sciencedirect.com/science/article/pii/S0301010418311005"
"A498","Numerical investigation into the underlying mechanism connecting the vortex breakdown to the flow unsteadiness in a transonic compressor rotor","This paper presents a series of systematic multi-passage unsteady RANS simulations on a transonic axial flow compressor rotor (Rotor 35). The objective is to have a better understanding of the underlying flow mechanism which connects the phenomena of the tip leakage vortex (TLV)'s breakdown to the appearance of flow unsteadiness. It has been revealed that both bubble-type and spiral-type breakdown of the TLV can result in a self-sustained flow unsteadiness at high-loading flow conditions. The origin of such unsteadiness lies in that the vorticity region redistributed by the vortex breakdown is capable of affecting the pressure distribution on the pressure side of a passage. Once this threshold event is met, the swirl intensity of the TLV and the strength of shock wave, which are key factors controlling the vortex breakdown, varies accordingly, thus leading to an instantaneous rather than a stationary vortex breakdown occurring in the confined rotor–passage system. As compared to the bubble-type breakdown of TLV, the spiral-type breakdown of TLV exerts more severe impact on the pressure distribution on the PS of the passage. As a result, a significant change in the scale of the breakdown region occurs. This gives rise to not only an appearance of a new vortex structure but also a blockage transfer across the passage against the rotor turning direction. The new vortex structure, termed as tip secondary vortex (TSV), is essentially a vortex segment arising from the spiral-type breakdown of TLV. The necessary condition for the inception of the rotating wave like RI is the blockage transfer induced by the spiral-type breakdown of TLV and its resultant interaction with the tip leakage in the adjacent passage.","Vortex breakdown,Flow unsteadiness,Tip secondary vortex,Rotating disturbance,Rotating instability,Transonic compressor rotor","YanhuiWuab,GuangyaoAnab,BoWangab","Aerospace Science and Technology","https://doi.org/10.1016/j.ast.2018.12.040","https://www.sciencedirect.com/science/article/pii/S1270963818314202"
"A499","Regulatory interventions and industrial accidents: A case from India for ‘Vision Zero’ goals","Despite best efforts to minimize risk in organizations, accidents appear almost unavoidable due to various reasons. In India and other parts of the world industrial accidents are investigated to know the causes so that recurrence can be minimized by designing adequate preventive measures. However, findings of investigation are seldom used appropriately to strengthen Occupational Safety and Health (OSH). The mineral rich state of Odisha (India), known as a hub for Iron & Steel industries, witnessed frequent accidents during 2005–2009. This article based on study of 982 fatal ‘factory-accidents’ occurred during 2001–2016, discusses the ‘turnaround-story’ resulting in reduction of fatal accident from 122 in 2009 to 45 in 2016. The paper examines the type of accidents, industries and distribution of the year; role of climate and harsh weather conditions on accident causation; impact of regulatory interventions in reducing accidents. Software such as R, SQL, MS-Excel and Tableau were used for analysis of data. It is found that maximum fatality is caused due to ‘fall from height’ (24%) and the harsh weather conditions of summer increase chances of accidents. Further, the study suggests that enforcement of partial work-restriction around lunch time during peak summer and screening and training of employees tend to reduce accidents due to fall from height. The study indicates that preventive enforcement based on learning from experience can be considered as an effective method to improve occupational safety and minimize employment injury in the journey towards ‘Vision Zero’ goal.","Occupational accidents in India,Accident investigation,Vision zero goals,Regulatory intervention,Weather and accident,Odisha","Ramesh KumarBeheraa,Md. IzharHassanb","Safety Science","https://doi.org/10.1016/j.ssci.2018.12.013","https://www.sciencedirect.com/science/article/pii/S0925753518307902"
"A500","The effects of electrical and thermal boundary condition on the simulation of radiofrequency ablation of liver cancer for tumours located near to the liver boundary","Effects of different boundary conditions prescribed across the boundaries of radiofrequency ablation (RFA) models of liver cancer are investigated for the case where the tumour is at the liver boundary. Ground and Robin-type conditions (electrical field) and body temperature and thermal insulation (thermal field) conditions are examined. 3D models of the human liver based on publicly-available CT images of the liver are developed. An artificial tumour is placed inside the liver at the boundary. Simulations are carried out using the finite element method. The numerical results indicated that different electrical and thermal boundary conditions led to different predictions of the electrical potential, temperature and thermal coagulation distributions. Ground and body temperature conditions presented an unnatural physical conditions around the ablation site, which results in more intense Joule heating and excessive heat loss from the tissue. This led to thermal damage volumes that are smaller than the cases when the Robin type or the thermal insulation conditions are prescribed. The present study suggests that RFA simulations in the future must take into consideration the choice of the type of electrical and thermal boundary conditions to be prescribed in the case where the tumour is located near to the liver boundary.","RFA simulation,Patient-specific model,Liver cancer,Hyperthermia,Thermal therapy","Ean H.Ooiab,Khiy W.Leea,ShelleyYapa,Mahmoud A.Khattabc,Iman Y.Liaoc,Ean T.Ooid,Ji J.Fooa,Shalini R.Naire,Ahmad F.Mohd Alif","Computers in Biology and Medicine","https://doi.org/10.1016/j.compbiomed.2019.01.003","https://www.sciencedirect.com/science/article/pii/S0010482519300034"
